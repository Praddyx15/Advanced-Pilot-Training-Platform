#include <drogon/drogon.h>
#include <json/json.h>
#include <string>
#include <vector>
#include <map>
#include <memory>
#include <mutex>
#include "admin_repository.h"
#include "analytics_aggregator.h"
#include "resource_optimizer.h"

namespace atp {
namespace admin {

class AdminDashboardService : public drogon::HttpController<AdminDashboardService> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(AdminDashboardService::getTrainingStatus, "/api/admin/training-status", drogon::Get);
    ADD_METHOD_TO(AdminDashboardService::getComplianceStatus, "/api/admin/compliance-status", drogon::Get);
    ADD_METHOD_TO(AdminDashboardService::getResourceUtilization, "/api/admin/resource-utilization", drogon::Get);
    ADD_METHOD_TO(AdminDashboardService::getInstructorPerformance, "/api/admin/instructor-performance", drogon::Get);
    ADD_METHOD_TO(AdminDashboardService::getTraineeProgress, "/api/admin/trainee-progress/{id}", drogon::Get);
    ADD_METHOD_TO(AdminDashboardService::getSystemStats, "/api/admin/system-stats", drogon::Get);
    ADD_METHOD_TO(AdminDashboardService::getKeyPerformanceIndicators, "/api/admin/kpis", drogon::Get);
    ADD_METHOD_TO(AdminDashboardService::optimizeResources, "/api/admin/optimize-resources", drogon::Post);
    ADD_METHOD_TO(AdminDashboardService::forecastResourceNeeds, "/api/admin/forecast-resources", drogon::Post);
    ADD_METHOD_TO(AdminDashboardService::generateExecutiveSummary, "/api/admin/executive-summary", drogon::Get);
    ADD_METHOD_TO(AdminDashboardService::getTrainingEffectiveness, "/api/admin/training-effectiveness", drogon::Get);
    ADD_METHOD_TO(AdminDashboardService::identifyBottlenecks, "/api/admin/bottlenecks", drogon::Get);
    METHOD_LIST_END

    AdminDashboardService();

    void getTrainingStatus(const drogon::HttpRequestPtr& req, 
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getComplianceStatus(const drogon::HttpRequestPtr& req,
                            std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getResourceUtilization(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getInstructorPerformance(const drogon::HttpRequestPtr& req,
                                 std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getTraineeProgress(const drogon::HttpRequestPtr& req,
                           std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                           const std::string& id);
    
    void getSystemStats(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getKeyPerformanceIndicators(const drogon::HttpRequestPtr& req,
                                    std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void optimizeResources(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void forecastResourceNeeds(const drogon::HttpRequestPtr& req,
                              std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void generateExecutiveSummary(const drogon::HttpRequestPtr& req,
                                 std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getTrainingEffectiveness(const drogon::HttpRequestPtr& req,
                                 std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void identifyBottlenecks(const drogon::HttpRequestPtr& req,
                            std::function<void(const drogon::HttpResponsePtr&)>&& callback);

private:
    std::shared_ptr<AdminRepository> adminRepo_;
    std::shared_ptr<AnalyticsAggregator> analyticsAggregator_;
    std::shared_ptr<ResourceOptimizer> resourceOptimizer_;
    
    // Helper methods
    Json::Value calculateTrainingCompletionRates();
    Json::Value aggregateComplianceMetrics();
    Json::Value calculateResourceUtilization();
    Json::Value identifyTrainingBottlenecks();
    Json::Value generateKPIDashboard();
    Json::Value calculateInstructorEffectiveness(const std::string& instructorId = "");
    Json::Value aggregateTraineePerformance(const std::string& traineeId = "");
    Json::Value getSystemHealthMetrics();
    Json::Value highlightCriticalAlerts();
};

AdminDashboardService::AdminDashboardService() {
    // Initialize components
    adminRepo_ = std::make_shared<AdminRepository>();
    analyticsAggregator_ = std::make_shared<AnalyticsAggregator>();
    resourceOptimizer_ = std::make_shared<ResourceOptimizer>();
}

void AdminDashboardService::getTrainingStatus(const drogon::HttpRequestPtr& req, 
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string period = params.find("period") != params.end() ? params["period"] : "month";
        std::string trainingType = params.find("type") != params.end() ? params["type"] : "";
        bool includeDetails = params.find("details") != params.end() && params["details"] == "true";
        
        // Get training status data
        Json::Value trainingStatus = adminRepo_->getTrainingStatus(period, trainingType);
        
        // Calculate completion rates
        Json::Value completionRates = calculateTrainingCompletionRates();
        
        // Prepare response
        Json::Value result;
        result["period"] = period;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["training_status"] = trainingStatus;
        result["completion_rates"] = completionRates;
        
        // Include detailed data if requested
        if (includeDetails) {
            result["details"] = adminRepo_->getTrainingStatusDetails(period, trainingType);
        }
        
        // Add training effectiveness data
        result["training_effectiveness"] = analyticsAggregator_->getTrainingEffectivenessMetrics(period);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::getComplianceStatus(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string regulationType = params.find("regulation_type") != params.end() ? params["regulation_type"] : "all";
        std::string period = params.find("period") != params.end() ? params["period"] : "current";
        
        // Get compliance status data
        Json::Value complianceStatus = adminRepo_->getComplianceStatus(regulationType, period);
        
        // Aggregate compliance metrics
        Json::Value aggregatedMetrics = aggregateComplianceMetrics();
        
        // Prepare response
        Json::Value result;
        result["regulation_type"] = regulationType;
        result["period"] = period;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["compliance_status"] = complianceStatus;
        result["aggregated_metrics"] = aggregatedMetrics;
        
        // Add compliance trend data
        result["compliance_trends"] = adminRepo_->getComplianceTrends(regulationType);
        
        // Add compliance alerts
        result["compliance_alerts"] = adminRepo_->getComplianceAlerts(regulationType);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::getResourceUtilization(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string resourceType = params.find("type") != params.end() ? params["type"] : "all";
        std::string period = params.find("period") != params.end() ? params["period"] : "month";
        std::string location = params.find("location") != params.end() ? params["location"] : "";
        
        // Get resource utilization data
        Json::Value utilizationData = adminRepo_->getResourceUtilization(resourceType, period, location);
        
        // Calculate utilization metrics
        Json::Value utilizationMetrics = calculateResourceUtilization();
        
        // Get optimization opportunities
        Json::Value optimizationOpportunities = resourceOptimizer_->identifyOptimizationOpportunities(utilizationData);
        
        // Prepare response
        Json::Value result;
        result["resource_type"] = resourceType;
        result["period"] = period;
        result["location"] = location.empty() ? "all" : location;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["utilization_data"] = utilizationData;
        result["utilization_metrics"] = utilizationMetrics;
        result["optimization_opportunities"] = optimizationOpportunities;
        
        // Add utilization trends
        result["utilization_trends"] = adminRepo_->getUtilizationTrends(resourceType, period);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::getInstructorPerformance(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string instructorId = params.find("instructor_id") != params.end() ? params["instructor_id"] : "";
        std::string period = params.find("period") != params.end() ? params["period"] : "month";
        std::string metric = params.find("metric") != params.end() ? params["metric"] : "all";
        
        // Get instructor performance data
        Json::Value performanceData;
        
        if (instructorId.empty()) {
            // Get all instructors
            performanceData = adminRepo_->getAllInstructorsPerformance(period, metric);
        } else {
            // Get specific instructor
            performanceData = adminRepo_->getInstructorPerformance(instructorId, period, metric);
        }
        
        // Calculate instructor effectiveness
        Json::Value effectiveness = calculateInstructorEffectiveness(instructorId);
        
        // Prepare response
        Json::Value result;
        result["period"] = period;
        result["metric"] = metric;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["performance_data"] = performanceData;
        result["effectiveness"] = effectiveness;
        
        // Add standardization metrics
        result["standardization"] = analyticsAggregator_->getInstructorStandardizationMetrics(instructorId);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::getTraineeProgress(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                         const std::string& id) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string period = params.find("period") != params.end() ? params["period"] : "all";
        bool includeDetails = params.find("details") != params.end() && params["details"] == "true";
        
        // Get trainee progress data
        Json::Value progressData = adminRepo_->getTraineeProgress(id, period);
        
        if (progressData.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Trainee not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Aggregate trainee performance
        Json::Value performanceData = aggregateTraineePerformance(id);
        
        // Prepare response
        Json::Value result;
        result["trainee_id"] = id;
        result["period"] = period;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["progress_data"] = progressData;
        result["performance_data"] = performanceData;
        
        // Include detailed data if requested
        if (includeDetails) {
            result["details"] = adminRepo_->getTraineeProgressDetails(id, period);
        }
        
        // Add skill progression data
        result["skill_progression"] = analyticsAggregator_->getTraineeSkillProgression(id);
        
        // Add competency metrics
        result["competency_metrics"] = analyticsAggregator_->getTraineeCompetencyMetrics(id);
        
        // Add training recommendations
        result["recommendations"] = analyticsAggregator_->generateTraineeRecommendations(id);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::getSystemStats(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string period = params.find("period") != params.end() ? params["period"] : "day";
        std::string category = params.find("category") != params.end() ? params["category"] : "all";
        
        // Get system stats data
        Json::Value statsData = adminRepo_->getSystemStats(period, category);
        
        // Get system health metrics
        Json::Value healthMetrics = getSystemHealthMetrics();
        
        // Prepare response
        Json::Value result;
        result["period"] = period;
        result["category"] = category;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["stats_data"] = statsData;
        result["health_metrics"] = healthMetrics;
        
        // Add usage trends
        result["usage_trends"] = adminRepo_->getSystemUsageTrends(period);
        
        // Add alert count
        result["alert_count"] = adminRepo_->getSystemAlertCount(period);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::getKeyPerformanceIndicators(const drogon::HttpRequestPtr& req,
                                  std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string period = params.find("period") != params.end() ? params["period"] : "month";
        std::string category = params.find("category") != params.end() ? params["category"] : "all";
        
        // Generate KPI dashboard
        Json::Value kpiDashboard = generateKPIDashboard();
        
        // Get KPI trend data
        Json::Value kpiTrends = adminRepo_->getKPITrends(period, category);
        
        // Get critical alerts
        Json::Value criticalAlerts = highlightCriticalAlerts();
        
        // Prepare response
        Json::Value result;
        result["period"] = period;
        result["category"] = category;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["kpi_dashboard"] = kpiDashboard;
        result["kpi_trends"] = kpiTrends;
        result["critical_alerts"] = criticalAlerts;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::optimizeResources(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract optimization parameters
        std::string resourceType = (*json)["resource_type"].asString();
        std::string optimizationGoal = (*json)["optimization_goal"].asString();
        Json::Value constraints = (*json)["constraints"];
        
        // Run resource optimization
        Json::Value optimizationResult = resourceOptimizer_->optimizeResources(resourceType, optimizationGoal, constraints);
        
        // Calculate cost savings
        Json::Value costSavings = resourceOptimizer_->calculateCostSavings(optimizationResult);
        
        // Generate implementation plan
        Json::Value implementationPlan = resourceOptimizer_->generateImplementationPlan(optimizationResult);
        
        // Prepare response
        Json::Value result;
        result["resource_type"] = resourceType;
        result["optimization_goal"] = optimizationGoal;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["optimization_result"] = optimizationResult;
        result["cost_savings"] = costSavings;
        result["implementation_plan"] = implementationPlan;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::forecastResourceNeeds(const drogon::HttpRequestPtr& req,
                            std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract forecast parameters
        std::string resourceType = (*json)["resource_type"].asString();
        std::string forecastPeriod = (*json)["forecast_period"].asString();
        Json::Value trainingDemand = (*json)["training_demand"];
        
        // Generate resource forecast
        Json::Value forecastResult = resourceOptimizer_->forecastResourceNeeds(resourceType, forecastPeriod, trainingDemand);
        
        // Generate capacity plan
        Json::Value capacityPlan = resourceOptimizer_->generateCapacityPlan(forecastResult);
        
        // Generate budget forecast
        Json::Value budgetForecast = resourceOptimizer_->generateBudgetForecast(forecastResult);
        
        // Prepare response
        Json::Value result;
        result["resource_type"] = resourceType;
        result["forecast_period"] = forecastPeriod;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["forecast_result"] = forecastResult;
        result["capacity_plan"] = capacityPlan;
        result["budget_forecast"] = budgetForecast;
        
        // Add confidence intervals
        result["confidence_intervals"] = resourceOptimizer_->calculateForecastConfidenceIntervals(forecastResult);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::generateExecutiveSummary(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string period = params.find("period") != params.end() ? params["period"] : "month";
        std::string format = params.find("format") != params.end() ? params["format"] : "json";
        
        // Generate key metrics
        Json::Value keyMetrics = analyticsAggregator_->getKeyMetrics(period);
        
        // Generate financial metrics
        Json::Value financialMetrics = analyticsAggregator_->getFinancialMetrics(period);
        
        // Generate performance metrics
        Json::Value performanceMetrics = analyticsAggregator_->getPerformanceMetrics(period);
        
        // Generate compliance metrics
        Json::Value complianceMetrics = analyticsAggregator_->getComplianceMetrics(period);
        
        // Generate resource utilization metrics
        Json::Value utilizationMetrics = analyticsAggregator_->getUtilizationMetrics(period);
        
        // Prepare executive summary
        Json::Value executiveSummary;
        executiveSummary["period"] = period;
        executiveSummary["generated_at"] = drogon::utils::getFormattedDate();
        executiveSummary["key_metrics"] = keyMetrics;
        executiveSummary["financial_metrics"] = financialMetrics;
        executiveSummary["performance_metrics"] = performanceMetrics;
        executiveSummary["compliance_metrics"] = complianceMetrics;
        executiveSummary["utilization_metrics"] = utilizationMetrics;
        
        // Add executive highlights
        executiveSummary["highlights"] = analyticsAggregator_->generateExecutiveHighlights(period);
        
        // Add strategic recommendations
        executiveSummary["recommendations"] = analyticsAggregator_->generateStrategicRecommendations(period);
        
        // Return in requested format
        if (format == "pdf") {
            // In a real implementation, this would generate a PDF
            // For this example, we'll return a JSON with a notice
            executiveSummary["format"] = "pdf";
            executiveSummary["notice"] = "PDF generation would be implemented in production version";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(executiveSummary);
            callback(resp);
        }
        else {
            // Return as JSON
            auto resp = drogon::HttpResponse::newHttpJsonResponse(executiveSummary);
            callback(resp);
        }
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::getTrainingEffectiveness(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string trainingType = params.find("type") != params.end() ? params["type"] : "all";
        std::string period = params.find("period") != params.end() ? params["period"] : "month";
        
        // Get training effectiveness data
        Json::Value effectivenessData = analyticsAggregator_->getTrainingEffectivenessData(trainingType, period);
        
        // Generate A/B test comparison
        Json::Value abTestResults = analyticsAggregator_->getABTestResults(trainingType, period);
        
        // Generate training ROI analysis
        Json::Value roiAnalysis = analyticsAggregator_->calculateTrainingROI(trainingType, period);
        
        // Prepare response
        Json::Value result;
        result["training_type"] = trainingType;
        result["period"] = period;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["effectiveness_data"] = effectivenessData;
        result["ab_test_results"] = abTestResults;
        result["roi_analysis"] = roiAnalysis;
        
        // Add competency growth metrics
        result["competency_growth"] = analyticsAggregator_->getCompetencyGrowthMetrics(trainingType, period);
        
        // Add training intervention effectiveness
        result["intervention_effectiveness"] = analyticsAggregator_->getInterventionEffectiveness(trainingType, period);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AdminDashboardService::identifyBottlenecks(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string trainingType = params.find("type") != params.end() ? params["type"] : "all";
        std::string period = params.find("period") != params.end() ? params["period"] : "month";
        
        // Identify training bottlenecks
        Json::Value bottlenecks = identifyTrainingBottlenecks();
        
        // Identify critical path elements
        Json::Value criticalPath = analyticsAggregator_->identifyCriticalPath(trainingType);
        
        // Generate bottleneck mitigation strategies
        Json::Value mitigationStrategies = analyticsAggregator_->generateBottleneckMitigationStrategies(bottlenecks);
        
        // Prepare response
        Json::Value result;
        result["training_type"] = trainingType;
        result["period"] = period;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["bottlenecks"] = bottlenecks;
        result["critical_path"] = criticalPath;
        result["mitigation_strategies"] = mitigationStrategies;
        
        // Add performance impact analysis
        result["performance_impact"] = analyticsAggregator_->analyzeBottleneckPerformanceImpact(bottlenecks);
        
        // Add resource reallocation suggestions
        result["resource_reallocation"] = resourceOptimizer_->suggestResourceReallocation(bottlenecks);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

// Helper methods
Json::Value AdminDashboardService::calculateTrainingCompletionRates() {
    // In a real implementation, this would calculate actual completion rates
    // For this example, we'll return mock data
    
    Json::Value completionRates;
    
    // Overall completion rate
    completionRates["overall"] = 85.7;
    
    // Completion rates by training type
    Json::Value byType;
    byType["initial_type_rating"] = 92.3;
    byType["recurrent"] = 98.1;
    byType["instructor"] = 89.5;
    byType["conversion"] = 78.6;
    
    completionRates["by_type"] = byType;
    
    // Completion rates by month
    Json::Value byMonth;
    byMonth["Jan"] = 81.2;
    byMonth["Feb"] = 83.7;
    byMonth["Mar"] = 85.9;
    byMonth["Apr"] = 87.2;
    byMonth["May"] = 88.5;
    byMonth["Jun"] = 85.7;
    
    completionRates["by_month"] = byMonth;
    
    return completionRates;
}

Json::Value AdminDashboardService::aggregateComplianceMetrics() {
    // In a real implementation, this would aggregate actual compliance metrics
    // For this example, we'll return mock data
    
    Json::Value aggregatedMetrics;
    
    // Overall compliance percentage
    aggregatedMetrics["overall_compliance"] = 94.3;
    
    // Compliance by regulation type
    Json::Value byRegulation;
    byRegulation["FAA"] = 96.8;
    byRegulation["EASA"] = 95.2;
    byRegulation["ICAO"] = 93.7;
    byRegulation["Internal"] = 91.4;
    
    aggregatedMetrics["by_regulation"] = byRegulation;
    
    // Compliance by category
    Json::Value byCategory;
    byCategory["Documentation"] = 98.2;
    byCategory["Training_Records"] = 95.7;
    byCategory["Instructor_Qualifications"] = 97.3;
    byCategory["Syllabus_Adherence"] = 92.8;
    byCategory["Equipment_Certification"] = 93.5;
    
    aggregatedMetrics["by_category"] = byCategory;
    
    // Non-compliance count
    aggregatedMetrics["non_compliance_count"] = 12;
    
    // Critical non-compliance count
    aggregatedMetrics["critical_non_compliance_count"] = 2;
    
    return aggregatedMetrics;
}

Json::Value AdminDashboardService::calculateResourceUtilization() {
    // In a real implementation, this would calculate actual resource utilization
    // For this example, we'll return mock data
    
    Json::Value utilizationMetrics;
    
    // Overall utilization percentage
    utilizationMetrics["overall_utilization"] = 78.3;
    
    // Utilization by resource type
    Json::Value byType;
    byType["Simulator"] = 87.5;
    byType["Instructor"] = 82.1;
    byType["Classroom"] = 65.8;
    byType["VR_Equipment"] = 72.4;
    byType["Computer_Based_Training"] = 63.9;
    
    utilizationMetrics["by_type"] = byType;
    
    // Utilization by time of day
    Json::Value byTime;
    byTime["Morning"] = 92.3;
    byTime["Afternoon"] = 85.7;
    byTime["Evening"] = 68.4;
    byTime["Night"] = 42.1;
    
    utilizationMetrics["by_time"] = byTime;
    
    // Utilization by day of week
    Json::Value byDay;
    byDay["Monday"] = 82.5;
    byDay["Tuesday"] = 85.2;
    byDay["Wednesday"] = 86.1;
    byDay["Thursday"] = 84.7;
    byDay["Friday"] = 80.3;
    byDay["Saturday"] = 62.8;
    byDay["Sunday"] = 45.6;
    
    utilizationMetrics["by_day"] = byDay;
    
    // Idle time (hours per month)
    utilizationMetrics["idle_time_hours"] = 128;
    
    // Potential capacity increase
    utilizationMetrics["potential_capacity_increase"] = 18.5;
    
    return utilizationMetrics;
}

Json::Value AdminDashboardService::identifyTrainingBottlenecks() {
    // In a real implementation, this would analyze actual training flow data
    // For this example, we'll return mock data
    
    Json::Value bottlenecks(Json::arrayValue);
    
    // Bottleneck 1: Simulator availability
    Json::Value bottleneck1;
    bottleneck1["id"] = "BN001";
    bottleneck1["resource_type"] = "Simulator";
    bottleneck1["bottleneck_type"] = "Capacity";
    bottleneck1["severity"] = "High";
    bottleneck1["description"] = "Insufficient simulator slots during peak hours (8AM-2PM)";
    bottleneck1["impact"] = "Training delays averaging 3.2 days per trainee";
    bottleneck1["affected_trainees"] = 37;
    
    Json::Value mitigation1(Json::arrayValue);
    mitigation1.append("Extended simulator hours to 18 hours/day");
    mitigation1.append("Prioritization of time-sensitive training needs");
    mitigation1.append("Exploration of external simulator options for overflow");
    
    bottleneck1["mitigation_options"] = mitigation1;
    
    bottlenecks.append(bottleneck1);
    
    // Bottleneck 2: Instructor qualification
    Json::Value bottleneck2;
    bottleneck2["id"] = "BN002";
    bottleneck2["resource_type"] = "Instructor";
    bottleneck2["bottleneck_type"] = "Qualification";
    bottleneck2["severity"] = "Medium";
    bottleneck2["description"] = "Limited instructors qualified for A350 type rating";
    bottleneck2["impact"] = "Scheduling conflicts and occasional training delays";
    bottleneck2["affected_trainees"] = 18;
    
    Json::Value mitigation2(Json::arrayValue);
    mitigation2.append("Accelerated instructor qualification program");
    mitigation2.append("Cross-training existing instructors from similar aircraft types");
    mitigation2.append("Temporary instructor sharing agreement with partner organization");
    
    bottleneck2["mitigation_options"] = mitigation2;
    
    bottlenecks.append(bottleneck2);
    
    // Bottleneck 3: Assessment processing
    Json::Value bottleneck3;
    bottleneck3["id"] = "BN003";
    bottleneck3["resource_type"] = "Administrative";
    bottleneck3["bottleneck_type"] = "Process";
    bottleneck3["severity"] = "Low";
    bottleneck3["description"] = "Delays in assessment processing and feedback delivery";
    bottleneck3["impact"] = "1.5 day average delay in trainee progression to next module";
    bottleneck3["affected_trainees"] = 52;
    
    Json::Value mitigation3(Json::arrayValue);
    mitigation3.append("Implementation of real-time assessment tools");
    mitigation3.append("Streamlined workflow for assessment review and approval");
    mitigation3.append("Automated notification system for completed assessments");
    
    bottleneck3["mitigation_options"] = mitigation3;
    
    bottlenecks.append(bottleneck3);
    
    return bottlenecks;
}

Json::Value AdminDashboardService::generateKPIDashboard() {
    // In a real implementation, this would use actual performance data
    // For this example, we'll return mock data
    
    Json::Value kpiDashboard;
    
    // Overall training performance
    kpiDashboard["training_success_rate"] = 92.7;
    kpiDashboard["average_completion_time"] = 87.5;  // % of planned time
    kpiDashboard["first_time_pass_rate"] = 84.3;
    
    // Resource efficiency
    kpiDashboard["resource_utilization"] = 78.3;
    kpiDashboard["cost_per_training_hour"] = 387.50;
    kpiDashboard["instructor_productivity"] = 89.2;
    
    // Quality metrics
    kpiDashboard["trainee_satisfaction"] = 4.6;  // out of 5
    kpiDashboard["training_effectiveness"] = 91.4;
    kpiDashboard["defect_rate"] = 2.3;  // % of training sessions with issues
    
    // Compliance metrics
    kpiDashboard["regulatory_compliance"] = 98.7;
    kpiDashboard["documentation_accuracy"] = 99.2;
    kpiDashboard["audit_success_rate"] = 97.5;
    
    // Safety metrics
    kpiDashboard["safety_event_rate"] = 0.5;  // per 1000 training hours
    kpiDashboard["near_miss_reporting"] = 8.7;  // per 1000 training hours
    kpiDashboard["safety_culture_index"] = 93.2;
    
    return kpiDashboard;
}

Json::Value AdminDashboardService::calculateInstructorEffectiveness(const std::string& instructorId) {
    // In a real implementation, this would calculate from actual instructor data
    // For this example, we'll return mock data
    
    Json::Value effectiveness;
    
    if (instructorId.empty()) {
        // Effectiveness metrics across all instructors
        effectiveness["average_effectiveness_score"] = 87.6;
        effectiveness["top_performer_score"] = 96.8;
        effectiveness["lowest_performer_score"] = 72.4;
        effectiveness["standard_deviation"] = 6.3;
        
        // Effectiveness distribution
        Json::Value distribution;
        distribution["excellent"] = 12;  // % of instructors
        distribution["good"] = 67;
        distribution["average"] = 18;
        distribution["below_average"] = 3;
        
        effectiveness["distribution"] = distribution;
    }
    else {
        // Individual instructor effectiveness
        effectiveness["instructor_id"] = instructorId;
        effectiveness["effectiveness_score"] = 89.4;
        effectiveness["percentile_rank"] = 72;  // percentile among all instructors
        
        // Score breakdown
        Json::Value breakdown;
        breakdown["technical_knowledge"] = 92.7;
        breakdown["teaching_skills"] = 88.3;
        breakdown["feedback_quality"] = 90.5;
        breakdown["trainee_outcomes"] = 85.6;
        breakdown["adaptability"] = 87.9;
        
        effectiveness["score_breakdown"] = breakdown;
        
        // Trend over time
        Json::Value trend;
        trend["current_quarter"] = 89.4;
        trend["previous_quarter"] = 87.2;
        trend["year_ago"] = 83.6;
        
        effectiveness["trend"] = trend;
    }
    
    return effectiveness;
}

Json::Value AdminDashboardService::aggregateTraineePerformance(const std::string& traineeId) {
    // In a real implementation, this would aggregate from actual trainee data
    // For this example, we'll return mock data
    
    Json::Value performance;
    
    if (traineeId.empty()) {
        // Performance metrics across all trainees
        performance["average_score"] = 85.3;
        performance["pass_rate"] = 92.7;
        performance["average_completion_time"] = 103.5;  // % of planned time
        
        // Performance distribution
        Json::Value distribution;
        distribution["excellent"] = 15;  // % of trainees
        distribution["good"] = 58;
        distribution["satisfactory"] = 22;
        distribution["needs_improvement"] = 5;
        
        performance["distribution"] = distribution;
    }
    else {
        // Individual trainee performance
        performance["trainee_id"] = traineeId;
        performance["overall_score"] = 88.2;
        performance["percentile_rank"] = 68;  // percentile among all trainees
        
        // Score breakdown
        Json::Value breakdown;
        breakdown["technical_knowledge"] = 86.5;
        breakdown["practical_skills"] = 90.3;
        breakdown["decision_making"] = 85.8;
        breakdown["communication"] = 91.2;
        breakdown["crew_coordination"] = 87.4;
        
        performance["score_breakdown"] = breakdown;
        
        // Improvement over time
        Json::Value improvement;
        improvement["initial_assessment"] = 78.6;
        improvement["midpoint_assessment"] = 83.5;
        improvement["final_assessment"] = 88.2;
        
        performance["improvement"] = improvement;
        
        // Strengths and areas for improvement
        Json::Value strengths(Json::arrayValue);
        strengths.append("Exceptional situational awareness");
        strengths.append("Strong technical knowledge of aircraft systems");
        strengths.append("Effective communication in normal operations");
        
        performance["strengths"] = strengths;
        
        Json::Value improvement_areas(Json::arrayValue);
        improvement_areas.append("Decision making under high workload");
        improvement_areas.append("Cross-checking during abnormal procedures");
        improvement_areas.append("Assertiveness in challenging situations");
        
        performance["improvement_areas"] = improvement_areas;
    }
    
    return performance;
}

Json::Value AdminDashboardService::getSystemHealthMetrics() {
    // In a real implementation, this would retrieve actual system health data
    // For this example, we'll return mock data
    
    Json::Value healthMetrics;
    
    // System availability
    healthMetrics["availability_percentage"] = 99.87;
    healthMetrics["uptime_hours_last_30_days"] = 719.1;
    healthMetrics["unplanned_outages"] = 1;
    
    // Performance metrics
    healthMetrics["average_response_time_ms"] = 147;
    healthMetrics["99th_percentile_response_time_ms"] = 326;
    healthMetrics["requests_per_second_peak"] = 438;
    
    // Resource usage
    healthMetrics["cpu_utilization_percent"] = 42.5;
    healthMetrics["memory_utilization_percent"] = 61.8;
    healthMetrics["storage_utilization_percent"] = 68.3;
    healthMetrics["network_bandwidth_utilization_percent"] = 35.6;
    
    // Database metrics
    healthMetrics["database_query_avg_time_ms"] = 28.5;
    healthMetrics["database_connections_peak"] = 256;
    healthMetrics["database_storage_growth_gb_per_month"] = 15.7;
    
    // User metrics
    healthMetrics["active_users_daily"] = 287;
    healthMetrics["active_users_monthly"] = 682;
    healthMetrics["concurrent_users_peak"] = 139;
    
    // Error rates
    healthMetrics["error_rate_percent"] = 0.08;
    healthMetrics["authentication_failures_per_day"] = 3.2;
    healthMetrics["api_error_rate_percent"] = 0.12;
    
    return healthMetrics;
}

Json::Value AdminDashboardService::highlightCriticalAlerts() {
    // In a real implementation, this would query actual alert data
    // For this example, we'll return mock data
    
    Json::Value alerts(Json::arrayValue);
    
    // Alert 1: Resource shortage
    Json::Value alert1;
    alert1["id"] = "ALT001";
    alert1["type"] = "Resource";
    alert1["severity"] = "Critical";
    alert1["title"] = "Simulator shortage for B737 MAX training";
    alert1["description"] = "Projected simulator availability insufficient for scheduled training volume (next 30 days)";
    alert1["impact"] = "Potential delay for 27 trainees";
    alert1["triggered_at"] = "2023-06-15T09:32:17Z";
    
    Json::Value actions1(Json::arrayValue);
    actions1.append("Allocate additional simulator sessions from partner facility");
    actions1.append("Temporarily reduce session duration by 10% to increase capacity");
    actions1.append("Prioritize trainees with approaching deadlines");
    
    alert1["recommended_actions"] = actions1;
    
    alerts.append(alert1);
    
    // Alert 2: Compliance risk
    Json::Value alert2;
    alert2["id"] = "ALT002";
    alert2["type"] = "Compliance";
    alert2["severity"] = "High";
    alert2["title"] = "Instructor currency requirements at risk";
    alert2["description"] = "7 instructors approaching currency requirement deadlines within 15 days";
    alert2["impact"] = "Potential reduction in instructor availability by 12%";
    alert2["triggered_at"] = "2023-06-14T16:45:33Z";
    
    Json::Value actions2(Json::arrayValue);
    actions2.append("Schedule priority recurrent training for affected instructors");
    actions2.append("Implement temporary instructor reallocation plan");
    actions2.append("Prepare waiver request documentation (contingency only)");
    
    alert2["recommended_actions"] = actions2;
    
    alerts.append(alert2);
    
    // Alert 3: Quality issue
    Json::Value alert3;
    alert3["id"] = "ALT003";
    alert3["type"] = "Quality";
    alert3["severity"] = "Medium";
    alert3["title"] = "Increased failure rate in emergency procedures training";
    alert3["description"] = "First-time pass rate for emergency procedures module decreased from 92% to 78% in past 30 days";
    alert3["impact"] = "Increased training time and resource utilization";
    alert3["triggered_at"] = "2023-06-13T11:18:05Z";
    
    Json::Value actions3(Json::arrayValue);
    actions3.append("Conduct root cause analysis of failure patterns");
    actions3.append("Review instructor standardization for emergency procedures training");
    actions3.append("Evaluate pre-training preparation materials for effectiveness");
    
    alert3["recommended_actions"] = actions3;
    
    alerts.append(alert3);
    
    return alerts;
}

} // namespace admin
} // namespace atp

// Main application setup
int main() {
    // Configure Drogon app
    drogon::app().setLogPath("./")
                 .setLogLevel(trantor::Logger::kInfo)
                 .addListener("0.0.0.0", 8085)
                 .setThreadNum(16)
                 .run();
    
    return 0;
}

#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <chrono>
#include <Eigen/Dense>
#include <nlohmann/json.hpp>

namespace ai_analytics {
namespace cognitive {

/**
 * @brief Cognitive state types
 */
enum class CognitiveState {
    FOCUSED,
    DISTRACTED,
    OVERLOADED,
    FATIGUED,
    STRESSED,
    CONFUSED,
    COMFORTABLE,
    VIGILANT
};

/**
 * @brief Convert CognitiveState to string
 */
std::string cognitiveStateToString(CognitiveState state);

/**
 * @brief Convert string to CognitiveState
 */
CognitiveState cognitiveStateFromString(const std::string& state_str);

/**
 * @brief Mental workload level
 */
enum class WorkloadLevel {
    LOW,
    MEDIUM,
    HIGH,
    OVERLOAD
};

/**
 * @brief Convert WorkloadLevel to string
 */
std::string workloadLevelToString(WorkloadLevel level);

/**
 * @brief Convert string to WorkloadLevel
 */
WorkloadLevel workloadLevelFromString(const std::string& level_str);

/**
 * @brief Eye tracking data
 */
struct EyeTrackingData {
    std::vector<std::pair<double, double>> gaze_positions;  // (x,y) normalized 0-1
    std::vector<double> pupil_diameters;
    std::vector<int> fixation_durations;
    std::vector<double> saccade_velocities;
    std::vector<std::chrono::microseconds> timestamps;
    
    /**
     * @brief Convert to JSON
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     */
    static std::optional<EyeTrackingData> fromJson(const nlohmann::json& json);
};

/**
 * @brief Physiological data
 */
struct PhysiologicalData {
    std::vector<double> heart_rate;
    std::vector<double> heart_rate_variability;
    std::vector<double> galvanic_skin_response;
    std::vector<double> respiration_rate;
    std::vector<std::chrono::microseconds> timestamps;
    
    /**
     * @brief Convert to JSON
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     */
    static std::optional<PhysiologicalData> fromJson(const nlohmann::json& json);
};

/**
 * @brief Performance data
 */
struct PerformanceData {
    std::vector<double> reaction_times;
    std::vector<int> error_counts;
    std::vector<double> task_completion_times;
    std::vector<double> accuracy_scores;
    std::vector<std::chrono::microseconds> timestamps;
    
    /**
     * @brief Convert to JSON
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     */
    static std::optional<PerformanceData> fromJson(const nlohmann::json& json);
};

/**
 * @brief Cognitive state assessment input data
 */
struct CognitiveAssessmentInput {
    std::string session_id;
    std::string trainee_id;
    std::string exercise_id;
    std::optional<EyeTrackingData> eye_tracking;
    std::optional<PhysiologicalData> physiological;
    std::optional<PerformanceData> performance;
    std::chrono::system_clock::time_point timestamp;
    
    /**
     * @brief Convert to JSON
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     */
    static std::optional<CognitiveAssessmentInput> fromJson(const nlohmann::json& json);
};

/**
 * @brief Cognitive state assessment result
 */
struct CognitiveAssessmentResult {
    std::string session_id;
    std::string trainee_id;
    std::string exercise_id;
    CognitiveState primary_state;
    std::map<CognitiveState, double> state_probabilities;
    WorkloadLevel workload_level;
    double workload_score;  // 0-100
    double attention_score;  // 0-100
    double stress_level;  // 0-100
    double fatigue_level;  // 0-100
    std::chrono::system_clock::time_point timestamp;
    std::vector<std::string> observations;
    std::vector<std::string> recommendations;
    
    /**
     * @brief Convert to JSON
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     */
    static std::optional<CognitiveAssessmentResult> fromJson(const nlohmann::json& json);
};

/**
 * @brief Cognitive state assessment model interface
 */
class ICognitiveModel {
public:
    virtual ~ICognitiveModel() = default;
    
    /**
     * @brief Initialize the model
     * @param config Configuration parameters
     * @return True if initialized successfully
     */
    virtual bool initialize(const nlohmann::json& config) = 0;
    
    /**
     * @brief Assess cognitive state
     * @param input Assessment input data
     * @return Assessment result
     */
    virtual CognitiveAssessmentResult assessCognitiveState(const CognitiveAssessmentInput& input) = 0;
    
    /**
     * @brief Train the model
     * @param training_data Training data
     * @return True if trained successfully
     */
    virtual bool train(const std::vector<std::pair<CognitiveAssessmentInput, CognitiveAssessmentResult>>& training_data) = 0;
    
    /**
     * @brief Save model to file
     * @param file_path File path
     * @return True if saved successfully
     */
    virtual bool saveModel(const std::string& file_path) = 0;
    
    /**
     * @brief Load model from file
     * @param file_path File path
     * @return True if loaded successfully
     */
    virtual bool loadModel(const std::string& file_path) = 0;
    
    /**
     * @brief Get model metrics
     * @return Model metrics as JSON
     */
    virtual nlohmann::json getModelMetrics() const = 0;
};

/**
 * @brief Feature-based cognitive model implementation
 */
class FeatureBasedCognitiveModel : public ICognitiveModel {
public:
    /**
     * @brief Constructor
     */
    FeatureBasedCognitiveModel();
    
    /**
     * @brief Destructor
     */
    ~FeatureBasedCognitiveModel() override;
    
    bool initialize(const nlohmann::json& config) override;
    CognitiveAssessmentResult assessCognitiveState(const CognitiveAssessmentInput& input) override;
    bool train(const std::vector<std::pair<CognitiveAssessmentInput, CognitiveAssessmentResult>>& training_data) override;
    bool saveModel(const std::string& file_path) override;
    bool loadModel(const std::string& file_path) override;
    nlohmann::json getModelMetrics() const override;
    
private:
    /**
     * @brief Extract eye tracking features
     * @param eye_data Eye tracking data
     * @return Extracted features
     */
    std::vector<double> extractEyeFeatures(const EyeTrackingData& eye_data) const;
    
    /**
     * @brief Extract physiological features
     * @param phys_data Physiological data
     * @return Extracted features
     */
    std::vector<double> extractPhysiologicalFeatures(const PhysiologicalData& phys_data) const;
    
    /**
     * @brief Extract performance features
     * @param perf_data Performance data
     * @return Extracted features
     */
    std::vector<double> extractPerformanceFeatures(const PerformanceData& perf_data) const;
    
    /**
     * @brief Generate recommendations based on cognitive state
     * @param state Cognitive state
     * @param workload Workload level
     * @return List of recommendations
     */
    std::vector<std::string> generateRecommendations(CognitiveState state, WorkloadLevel workload) const;
    
    /**
     * @brief Calculate workload level
     * @param features Feature vector
     * @return Workload level and score
     */
    std::pair<WorkloadLevel, double> calculateWorkload(const Eigen::VectorXd& features) const;
    
    /**
     * @brief Map features to cognitive state
     * @param features Feature vector
     * @return Cognitive state probabilities
     */
    std::map<CognitiveState, double> mapFeaturesToStates(const Eigen::VectorXd& features) const;
    
    std::vector<std::string> feature_names_;
    Eigen::MatrixXd model_weights_;
    Eigen::VectorXd model_bias_;
    bool initialized_;
    nlohmann::json model_metrics_;
    double attention_threshold_;
    double stress_threshold_;
    double fatigue_threshold_;
};

/**
 * @brief Deep learning based cognitive model
 */
class DeepLearningCognitiveModel : public ICognitiveModel {
public:
    DeepLearningCognitiveModel();
    ~DeepLearningCognitiveModel() override;
    
    bool initialize(const nlohmann::json& config) override;
    CognitiveAssessmentResult assessCognitiveState(const CognitiveAssessmentInput& input) override;
    bool train(const std::vector<std::pair<CognitiveAssessmentInput, CognitiveAssessmentResult>>& training_data) override;
    bool saveModel(const std::string& file_path) override;
    bool loadModel(const std::string& file_path) override;
    nlohmann::json getModelMetrics() const override;
    
private:
    // Deep learning model implementation details
    // In a real implementation, this would use a deep learning framework
    bool initialized_;
    nlohmann::json model_metrics_;
};

/**
 * @brief Cognitive model factory
 */
class CognitiveModelFactory {
public:
    /**
     * @brief Get singleton instance
     * @return Factory instance
     */
    static CognitiveModelFactory& getInstance();
    
    /**
     * @brief Create a cognitive model
     * @param model_type Model type name
     * @return Model instance
     */
    std::unique_ptr<ICognitiveModel> createModel(const std::string& model_type);
    
    /**
     * @brief Register a model type
     * @tparam T Model class type
     * @param model_type Model type name
     */
    template<typename T>
    void registerModel(const std::string& model_type) {
        creators_[model_type] = []() { return std::make_unique<T>(); };
    }
    
private:
    CognitiveModelFactory();
    ~CognitiveModelFactory() = default;
    
    CognitiveModelFactory(const CognitiveModelFactory&) = delete;
    CognitiveModelFactory& operator=(const CognitiveModelFactory&) = delete;
    
    std::map<std::string, std::function<std::unique_ptr<ICognitiveModel>()>> creators_;
};

} // namespace cognitive
} // namespace ai_analytics
#pragma once

#include "models/model_interface.h"
#include <string>
#include <memory>
#include <unordered_map>
#include <mutex>
#include <thread>
#include <queue>
#include <future>
#include <functional>
#include <condition_variable>

namespace ai_analytics {
namespace inference {

/**
 * @brief Inference request
 */
struct InferenceRequest {
    std::string request_id;
    std::string model_id;
    nlohmann::json input_data;
    std::chrono::system_clock::time_point timestamp;
    std::promise<nlohmann::json> result_promise;
};

/**
 * @brief Inference engine interface
 */
class IInferenceEngine {
public:
    virtual ~IInferenceEngine() = default;
    
    /**
     * @brief Initialize the inference engine
     * @param model_repository Model repository
     * @return True if initialized successfully
     */
    virtual bool initialize(std::shared_ptr<models::IModelRepository> model_repository) = 0;
    
    /**
     * @brief Shutdown the inference engine
     */
    virtual void shutdown() = 0;
    
    /**
     * @brief Run inference
     * @param model_id Model ID
     * @param input_data Input data
     * @return Inference result or nullopt if inference failed
     */
    virtual std::optional<nlohmann::json> runInference(
        const std::string& model_id,
        const nlohmann::json& input_data
    ) = 0;
    
    /**
     * @brief Submit inference request
     * @param model_id Model ID
     * @param input_data Input data
     * @return Future with inference result
     */
    virtual std::future<nlohmann::json> submitInferenceRequest(
        const std::string& model_id,
        const nlohmann::json& input_data
    ) = 0;
    
    /**
     * @brief Get model by ID
     * @param model_id Model ID
     * @return Model instance or nullptr if not found
     */
    virtual std::shared_ptr<models::IModel> getModel(const std::string& model_id) = 0;
    
    /**
     * @brief Load model
     * @param model_id Model ID
     * @return True if loaded successfully
     */
    virtual bool loadModel(const std::string& model_id) = 0;
    
    /**
     * @brief Unload model
     * @param model_id Model ID
     * @return True if unloaded successfully
     */
    virtual bool unloadModel(const std::string& model_id) = 0;
    
    /**
     * @brief Get loaded models
     * @return List of loaded model IDs
     */
    virtual std::vector<std::string> getLoadedModels() const = 0;
    
    /**
     * @brief Get engine statistics
     * @return Statistics as JSON
     */
    virtual nlohmann::json getStatistics() const = 0;
};

/**
 * @brief Inference engine implementation
 */
class InferenceEngine : public IInferenceEngine {
public:
    /**
     * @brief Constructor
     * @param num_threads Number of worker threads (default: number of CPU cores)
     */
    explicit InferenceEngine(
        int num_threads = std::thread::hardware_concurrency()
    );
    
    /**
     * @brief Destructor
     */
    ~InferenceEngine() override;
    
    // IInferenceEngine implementation
    bool initialize(std::shared_ptr<models::IModelRepository> model_repository) override;
    void shutdown() override;
    std::optional<nlohmann::json> runInference(
        const std::string& model_id,
        const nlohmann::json& input_data
    ) override;
    std::future<nlohmann::json> submitInferenceRequest(
        const std::string& model_id,
        const nlohmann::json& input_data
    ) override;
    std::shared_ptr<models::IModel> getModel(const std::string& model_id) override;
    bool loadModel(const std::string& model_id) override;
    bool unloadModel(const std::string& model_id) override;
    std::vector<std::string> getLoadedModels() const override;
    nlohmann::json getStatistics() const override;

private:
    /**
     * @brief Worker thread function
     */
    void workerFunction();
    
    /**
     * @brief Generate unique request ID
     * @return Unique request ID
     */
    std::string generateRequestId();
    
    std::shared_ptr<models::IModelRepository> model_repository_;
    std::unordered_map<std::string, std::shared_ptr<models::IModel>> loaded_models_;
    mutable std::mutex models_mutex_;
    
    std::queue<InferenceRequest> request_queue_;
    std::mutex queue_mutex_;
    std::condition_variable queue_condition_;
    std::atomic<bool> running_;
    
    std::vector<std::thread> worker_threads_;
    int num_threads_;
    
    // Statistics
    std::atomic<uint64_t> total_requests_;
    std::atomic<uint64_t> successful_requests_;
    std::atomic<uint64_t> failed_requests_;
    std::unordered_map<std::string, uint64_t> model_usage_;
    mutable std::mutex stats_mutex_;
    
    std::chrono::system_clock::time_point start_time_;
};

/**
 * @brief Cognitive state assessment model interface
 */
class ICognitiveStateModel : public models::IModel {
public:
    /**
     * @brief Cognitive state type
     */
    enum class StateType {
        WORKLOAD,
        FATIGUE,
        ATTENTION,
        STRESS,
        EXPERTISE_LEVEL
    };
    
    /**
     * @brief Cognitive state result
     */
    struct StateResult {
        StateType type;
        double value;
        double confidence;
        std::string interpretation;
        std::unordered_map<std::string, double> contributing_factors;
    };
    
    /**
     * @brief Predict cognitive state
     * @param input_data Input data
     * @return Cognitive state result or nullopt if prediction failed
     */
    virtual std::optional<StateResult> predictState(
        const nlohmann::json& input_data
    ) = 0;
};

/**
 * @brief Performance prediction model interface
 */
class IPerformanceModel : public models::IModel {
public:
    /**
     * @brief Performance prediction result
     */
    struct PredictionResult {
        double score;
        double confidence;
        std::unordered_map<std::string, double> factor_contributions;
        std::vector<std::string> areas_for_improvement;
        std::vector<std::string> strengths;
    };
    
    /**
     * @brief Predict performance
     * @param input_data Input data
     * @return Performance prediction result or nullopt if prediction failed
     */
    virtual std::optional<PredictionResult> predictPerformance(
        const nlohmann::json& input_data
    ) = 0;
};

/**
 * @brief Anomaly detection model interface
 */
class IAnomalyDetectionModel : public models::IModel {
public:
    /**
     * @brief Anomaly detection result
     */
    struct AnomalyResult {
        bool is_anomaly;
        double anomaly_score;
        double confidence;
        std::string anomaly_type;
        std::unordered_map<std::string, double> contributing_factors;
        std::vector<std::string> recommendations;
    };
    
    /**
     * @brief Detect anomalies
     * @param input_data Input data
     * @return Anomaly detection result or nullopt if detection failed
     */
    virtual std::optional<AnomalyResult> detectAnomalies(
        const nlohmann::json& input_data
    ) = 0;
};

} // namespace inference
} // namespace ai_analytics
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <functional>
#include <nlohmann/json.hpp>

namespace ai_analytics {
namespace inference {

/**
 * @brief Model input data
 */
struct ModelInput {
    std::string model_id;
    std::string input_type;
    nlohmann::json parameters;
    std::vector<uint8_t> binary_data;
};

/**
 * @brief Model output data
 */
struct ModelOutput {
    std::string model_id;
    std::string output_type;
    nlohmann::json results;
    std::vector<uint8_t> binary_data;
    double confidence;
    double latency_ms;
    bool success;
    std::string error_message;
};

/**
 * @brief Model metadata
 */
struct ModelMetadata {
    std::string model_id;
    std::string name;
    std::string version;
    std::string description;
    std::vector<std::string> input_types;
    std::vector<std::string> output_types;
    std::map<std::string, std::string> capabilities;
    bool is_loaded;
    double average_inference_time_ms;
    std::string creation_date;
    std::string last_updated;
};

/**
 * @brief Inference callback type
 */
using InferenceCallback = std::function<void(const ModelOutput&)>;

/**
 * @brief Model interface for inference engines
 */
class IModel {
public:
    virtual ~IModel() = default;
    
    /**
     * @brief Get model metadata
     * @return Model metadata
     */
    virtual ModelMetadata getMetadata() const = 0;
    
    /**
     * @brief Load the model
     * @return True if loaded successfully
     */
    virtual bool load() = 0;
    
    /**
     * @brief Unload the model
     */
    virtual void unload() = 0;
    
    /**
     * @brief Run inference
     * @param input Model input
     * @return Model output
     */
    virtual ModelOutput runInference(const ModelInput& input) = 0;
    
    /**
     * @brief Run inference asynchronously
     * @param input Model input
     * @param callback Callback to receive results
     * @return Request ID for tracking
     */
    virtual std::string runInferenceAsync(const ModelInput& input, InferenceCallback callback) = 0;
    
    /**
     * @brief Check if model supports input type
     * @param input_type Input type
     * @return True if supported
     */
    virtual bool supportsInputType(const std::string& input_type) const = 0;
    
    /**
     * @brief Check if model supports output type
     * @param output_type Output type
     * @return True if supported
     */
    virtual bool supportsOutputType(const std::string& output_type) const = 0;
};

/**
 * @brief Inference engine interface
 */
class IInferenceEngine {
public:
    virtual ~IInferenceEngine() = default;
    
    /**
     * @brief Initialize the engine
     * @param config Engine configuration
     * @return True if initialized successfully
     */
    virtual bool initialize(const nlohmann::json& config) = 0;
    
    /**
     * @brief Shutdown the engine
     */
    virtual void shutdown() = 0;
    
    /**
     * @brief Load model
     * @param model_path Path to model
     * @param model_id Model ID (empty for auto-generation)
     * @return Model ID if loaded successfully, empty string otherwise
     */
    virtual std::string loadModel(const std::string& model_path, const std::string& model_id = "") = 0;
    
    /**
     * @brief Unload model
     * @param model_id Model ID
     * @return True if unloaded successfully
     */
    virtual bool unloadModel(const std::string& model_id) = 0;
    
    /**
     * @brief Get model
     * @param model_id Model ID
     * @return Model instance or nullptr if not found
     */
    virtual std::shared_ptr<IModel> getModel(const std::string& model_id) = 0;
    
    /**
     * @brief List available models
     * @return List of model metadata
     */
    virtual std::vector<ModelMetadata> listModels() = 0;
    
    /**
     * @brief Run inference
     * @param input Model input
     * @return Model output
     */
    virtual ModelOutput runInference(const ModelInput& input) = 0;
    
    /**
     * @brief Run inference asynchronously
     * @param input Model input
     * @param callback Callback to receive results
     * @return Request ID for tracking
     */
    virtual std::string runInferenceAsync(const ModelInput& input, InferenceCallback callback) = 0;
    
    /**
     * @brief Cancel asynchronous inference request
     * @param request_id Request ID
     * @return True if cancelled successfully
     */
    virtual bool cancelAsyncRequest(const std::string& request_id) = 0;
    
    /**
     * @brief Get engine capabilities
     * @return Engine capabilities as JSON
     */
    virtual nlohmann::json getCapabilities() const = 0;
    
    /**
     * @brief Get engine statistics
     * @return Engine statistics as JSON
     */
    virtual nlohmann::json getStatistics() const = 0;
};

/**
 * @brief Tensor data type
 */
enum class TensorDataType {
    FLOAT32,
    INT32,
    INT64,
    UINT8,
    STRING
};

/**
 * @brief Convert tensor data type to string
 * @param type Tensor data type
 * @return String representation
 */
std::string tensorDataTypeToString(TensorDataType type);

/**
 * @brief Convert string to tensor data type
 * @param str String representation
 * @return Tensor data type
 */
TensorDataType tensorDataTypeFromString(const std::string& str);

/**
 * @brief Tensor shape
 */
using TensorShape = std::vector<int64_t>;

/**
 * @brief Tensor definition
 */
struct TensorDef {
    std::string name;
    TensorDataType data_type;
    TensorShape shape;
};

/**
 * @brief Tensor data
 */
class Tensor {
public:
    /**
     * @brief Constructor
     * @param name Tensor name
     * @param data_type Tensor data type
     * @param shape Tensor shape
     */
    Tensor(const std::string& name, TensorDataType data_type, const TensorShape& shape);
    
    /**
     * @brief Constructor with data
     * @param name Tensor name
     * @param data_type Tensor data type
     * @param shape Tensor shape
     * @param data Tensor data
     * @param data_size Data size in bytes
     */
    Tensor(const std::string& name, TensorDataType data_type, const TensorShape& shape, 
           const void* data, size_t data_size);
    
    /**
     * @brief Get tensor definition
     * @return Tensor definition
     */
    TensorDef getDefinition() const;
    
    /**
     * @brief Get tensor name
     * @return Tensor name
     */
    const std::string& getName() const;
    
    /**
     * @brief Get tensor data type
     * @return Tensor data type
     */
    TensorDataType getDataType() const;
    
    /**
     * @brief Get tensor shape
     * @return Tensor shape
     */
    const TensorShape& getShape() const;
    
    /**
     * @brief Get tensor data
     * @return Tensor data
     */
    const void* getData() const;
    
    /**
     * @brief Get tensor data size
     * @return Tensor data size in bytes
     */
    size_t getDataSize() const;
    
    /**
     * @brief Set tensor data
     * @param data Tensor data
     * @param data_size Data size in bytes
     * @return True if data set successfully
     */
    bool setData(const void* data, size_t data_size);
    
    /**
     * @brief Resize tensor
     * @param shape New tensor shape
     * @return True if resized successfully
     */
    bool resize(const TensorShape& shape);
    
    /**
     * @brief Get number of elements
     * @return Number of elements
     */
    int64_t getNumElements() const;
    
    /**
     * @brief Get element size
     * @return Element size in bytes
     */
    size_t getElementSize() const;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Tensor or nullopt if invalid
     */
    static std::optional<Tensor> fromJson(const nlohmann::json& json);
    
private:
    std::string name_;
    TensorDataType data_type_;
    TensorShape shape_;
    std::vector<uint8_t> data_;
    
    /**
     * @brief Calculate buffer size
     * @return Buffer size in bytes
     */
    size_t calculateBufferSize() const;
};

/**
 * @brief Factory for creating inference engines
 */
class InferenceEngineFactory {
public:
    /**
     * @brief Get the singleton instance
     * @return Factory instance
     */
    static InferenceEngineFactory& getInstance();
    
    /**
     * @brief Register an inference engine type
     * @tparam T Engine type
     * @param name Engine name
     */
    template<typename T>
    void registerEngine(const std::string& name) {
        creators_[name] = []() { return std::make_unique<T>(); };
    }
    
    /**
     * @brief Create an inference engine
     * @param name Engine name
     * @return Engine instance or nullptr if not found
     */
    std::unique_ptr<IInferenceEngine> createEngine(const std::string& name);
    
    /**
     * @brief Get all registered engine names
     * @return List of engine names
     */
    std::vector<std::string> getRegisteredEngines() const;
    
private:
    InferenceEngineFactory() = default;
    ~InferenceEngineFactory() = default;
    
    InferenceEngineFactory(const InferenceEngineFactory&) = delete;
    InferenceEngineFactory& operator=(const InferenceEngineFactory&) = delete;
    
    using CreatorFunc = std::function<std::unique_ptr<IInferenceEngine>()>;
    std::map<std::string, CreatorFunc> creators_;
};

} // namespace inference
} // namespace ai_analytics
#include "inference/inference_engine.h"
#include "logging/logger.h"
#include <fstream>
#include <algorithm>
#include <numeric>
#include <random>
#include <cmath>

namespace ai_analytics {
namespace inference {

InferenceEngine::InferenceEngine()
    : initialized_(false),
      model_path_(""),
      batch_size_(1),
      use_gpu_(false),
      verbose_(false) {
    
    // Initialize random generator for fallback predictions
    std::random_device rd;
    random_generator_ = std::mt19937(rd());
}

InferenceEngine::~InferenceEngine() {
    if (initialized_) {
        unloadModel();
    }
}

bool InferenceEngine::initialize(const InferenceConfig& config) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    try {
        model_path_ = config.model_path;
        batch_size_ = config.batch_size;
        use_gpu_ = config.use_gpu;
        verbose_ = config.verbose;
        
        // Load model
        if (!loadModel()) {
            logging::Logger::getInstance().error("Failed to load model from {}", model_path_);
            return false;
        }
        
        initialized_ = true;
        logging::Logger::getInstance().info("Inference engine initialized with model {}", model_path_);
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error initializing inference engine: {}", e.what());
        return false;
    }
}

bool InferenceEngine::loadModel() {
    try {
        // Check if model file exists
        std::ifstream model_file(model_path_);
        if (!model_file.good()) {
            logging::Logger::getInstance().error("Model file not found: {}", model_path_);
            return false;
        }
        
        // In a real implementation, this would load the model using TensorFlow C++ API
        // For this example, we'll simulate model loading
        
        // Parse model configuration
        std::string model_content((std::istreambuf_iterator<char>(model_file)),
                                 std::istreambuf_iterator<char>());
        
        // Extract input and output shapes from model
        input_shape_ = {batch_size_, 128}; // Example input shape: [batch_size, feature_dim]
        output_shape_ = {batch_size_, 10}; // Example output shape: [batch_size, num_classes]
        
        // Set up TensorFlow session
        if (use_gpu_) {
            logging::Logger::getInstance().info("Using GPU for inference");
            // In a real implementation, configure TensorFlow to use GPU
        } else {
            logging::Logger::getInstance().info("Using CPU for inference");
            // In a real implementation, configure TensorFlow to use CPU
        }
        
        logging::Logger::getInstance().info("Model loaded successfully from {}", model_path_);
        logging::Logger::getInstance().debug("Input shape: {}x{}", input_shape_[0], input_shape_[1]);
        logging::Logger::getInstance().debug("Output shape: {}x{}", output_shape_[0], output_shape_[1]);
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error loading model: {}", e.what());
        return false;
    }
}

void InferenceEngine::unloadModel() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (initialized_) {
        // In a real implementation, this would clean up TensorFlow resources
        
        initialized_ = false;
        logging::Logger::getInstance().info("Model unloaded");
    }
}

InferenceResult InferenceEngine::infer(const std::vector<float>& features) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    InferenceResult result;
    result.success = false;
    
    if (!initialized_) {
        result.error_message = "Inference engine not initialized";
        logging::Logger::getInstance().error(result.error_message);
        return result;
    }
    
    try {
        // Check input shape
        if (features.size() != static_cast<size_t>(input_shape_[1])) {
            std::ostringstream oss;
            oss << "Input feature size mismatch: expected " << input_shape_[1]
                << ", got " << features.size();
            result.error_message = oss.str();
            logging::Logger::getInstance().error(result.error_message);
            return result;
        }
        
        // In a real implementation, this would run inference using TensorFlow C++ API
        // For this example, we'll simulate inference with some calculations
        
        // Normalize features
        std::vector<float> normalized_features = features;
        float feature_mean = std::accumulate(features.begin(), features.end(), 0.0f) / features.size();
        float feature_stddev = std::sqrt(std::inner_product(
            features.begin(), features.end(), features.begin(), 0.0f,
            std::plus<>(), [feature_mean](float x, float y) {
                return (x - feature_mean) * (y - feature_mean);
            }) / features.size());
        
        if (feature_stddev > 0) {
            for (size_t i = 0; i < normalized_features.size(); ++i) {
                normalized_features[i] = (normalized_features[i] - feature_mean) / feature_stddev;
            }
        }
        
        // Create input tensor
        // In a real implementation: TF_Tensor* input_tensor = ...
        
        // Run inference
        // In a real implementation: TF_SessionRun(session, ...)
        
        // Generate simulated output
        std::vector<float> logits(output_shape_[1]);
        
        // Simulate a simple linear transformation
        for (size_t i = 0; i < logits.size(); ++i) {
            float sum = 0.0f;
            for (size_t j = 0; j < normalized_features.size(); ++j) {
                // Simulate weights with a simple pattern
                float weight = std::sin(static_cast<float>(i * j) / normalized_features.size());
                sum += normalized_features[j] * weight;
            }
            logits[i] = sum;
        }
        
        // Apply softmax to get probabilities
        float max_logit = *std::max_element(logits.begin(), logits.end());
        std::vector<float> probs(logits.size());
        float sum_exp = 0.0f;
        
        for (size_t i = 0; i < logits.size(); ++i) {
            probs[i] = std::exp(logits[i] - max_logit);
            sum_exp += probs[i];
        }
        
        for (size_t i = 0; i < probs.size(); ++i) {
            probs[i] /= sum_exp;
        }
        
        // Get top prediction
        auto max_it = std::max_element(probs.begin(), probs.end());
        int predicted_class = std::distance(probs.begin(), max_it);
        float confidence = *max_it;
        
        // Set result
        result.success = true;
        result.predictions = probs;
        result.predicted_class = predicted_class;
        result.confidence = confidence;
        
        if (verbose_) {
            logging::Logger::getInstance().debug("Inference result: class={}, confidence={:.4f}",
                                              predicted_class, confidence);
        }
        
        return result;
    }
    catch (const std::exception& e) {
        result.error_message = std::string("Error during inference: ") + e.what();
        logging::Logger::getInstance().error(result.error_message);
        return result;
    }
}

InferenceResult InferenceEngine::inferBatch(const std::vector<std::vector<float>>& batch_features) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    InferenceResult result;
    result.success = false;
    
    if (!initialized_) {
        result.error_message = "Inference engine not initialized";
        logging::Logger::getInstance().error(result.error_message);
        return result;
    }
    
    try {
        // Check batch size
        if (batch_features.empty()) {
            result.error_message = "Empty batch";
            logging::Logger::getInstance().error(result.error_message);
            return result;
        }
        
        if (batch_features.size() > static_cast<size_t>(batch_size_)) {
            std::ostringstream oss;
            oss << "Batch size too large: max=" << batch_size_ << ", got=" << batch_features.size();
            result.error_message = oss.str();
            logging::Logger::getInstance().error(result.error_message);
            return result;
        }
        
        // Check feature dimensions
        for (size_t i = 0; i < batch_features.size(); ++i) {
            if (batch_features[i].size() != static_cast<size_t>(input_shape_[1])) {
                std::ostringstream oss;
                oss << "Input feature size mismatch at index " << i
                    << ": expected " << input_shape_[1]
                    << ", got " << batch_features[i].size();
                result.error_message = oss.str();
                logging::Logger::getInstance().error(result.error_message);
                return result;
            }
        }
        
        // In a real implementation, this would run batch inference using TensorFlow C++ API
        // For this example, we'll process each sample individually
        
        std::vector<std::vector<float>> batch_predictions;
        std::vector<int> batch_predicted_classes;
        std::vector<float> batch_confidences;
        
        for (const auto& features : batch_features) {
            InferenceResult single_result = infer(features);
            
            if (!single_result.success) {
                result.error_message = single_result.error_message;
                return result;
            }
            
            batch_predictions.push_back(single_result.predictions);
            batch_predicted_classes.push_back(single_result.predicted_class);
            batch_confidences.push_back(single_result.confidence);
        }
        
        // Set batch result
        result.success = true;
        result.batch_predictions = batch_predictions;
        result.batch_predicted_classes = batch_predicted_classes;
        result.batch_confidences = batch_confidences;
        
        if (verbose_) {
            logging::Logger::getInstance().debug("Batch inference completed for {} samples",
                                              batch_features.size());
        }
        
        return result;
    }
    catch (const std::exception& e) {
        result.error_message = std::string("Error during batch inference: ") + e.what();
        logging::Logger::getInstance().error(result.error_message);
        return result;
    }
}

std::vector<float> InferenceEngine::preprocessFeatures(const DataPoint& data_point) {
    try {
        // Extract features from data point based on its type
        std::vector<float> features;
        
        switch (data_point.data_type) {
            case DataType::GAZE: {
                // Extract gaze features
                const GazeData& gaze = data_point.gaze_data;
                features = {
                    gaze.x, gaze.y, gaze.z,
                    gaze.confidence,
                    // Add derived features
                    static_cast<float>(std::sin(gaze.x * M_PI)),
                    static_cast<float>(std::cos(gaze.y * M_PI))
                };
                break;
            }
            
            case DataType::PHYSIOLOGICAL: {
                // Extract physiological features
                const PhysiologicalData& physio = data_point.physiological_data;
                features = {
                    physio.heart_rate,
                    physio.respiration_rate,
                    physio.skin_conductance,
                    physio.temperature,
                    // Add normalized features
                    physio.heart_rate / 100.0f,
                    physio.respiration_rate / 20.0f,
                    physio.skin_conductance / 10.0f,
                    (physio.temperature - 36.0f) / 2.0f
                };
                break;
            }
            
            case DataType::SIMULATOR: {
                // Extract simulator features
                const SimulatorData& sim = data_point.simulator_data;
                features = {
                    sim.altitude,
                    sim.airspeed,
                    sim.heading,
                    sim.pitch,
                    sim.roll,
                    sim.vertical_speed,
                    // Add control inputs
                    sim.control_pitch,
                    sim.control_roll,
                    sim.control_yaw,
                    sim.control_throttle
                };
                break;
            }
            
            case DataType::PERFORMANCE: {
                // Extract performance features
                const PerformanceData& perf = data_point.performance_data;
                features = {
                    perf.score,
                    perf.completion_time,
                    perf.error_count,
                    perf.accuracy,
                    // Add normalized features
                    perf.score / 100.0f,
                    perf.completion_time / 300.0f,
                    perf.error_count / 10.0f,
                    perf.accuracy
                };
                break;
            }
            
            default: {
                logging::Logger::getInstance().error("Unsupported data type for preprocessing");
                return {};
            }
        }
        
        // Pad or truncate features to match expected input size
        if (features.size() < static_cast<size_t>(input_shape_[1])) {
            features.resize(input_shape_[1], 0.0f);
        } else if (features.size() > static_cast<size_t>(input_shape_[1])) {
            features.resize(input_shape_[1]);
        }
        
        return features;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error preprocessing features: {}", e.what());
        return {};
    }
}

InferenceResult InferenceEngine::inferCognitiveState(const std::vector<DataPoint>& data_points) {
    try {
        // Check if we have enough data points
        if (data_points.empty()) {
            InferenceResult result;
            result.success = false;
            result.error_message = "No data points provided";
            return result;
        }
        
        // Preprocess each data point and create a batch
        std::vector<std::vector<float>> batch_features;
        
        for (const auto& data_point : data_points) {
            std::vector<float> features = preprocessFeatures(data_point);
            
            if (features.empty()) {
                InferenceResult result;
                result.success = false;
                result.error_message = "Failed to preprocess features";
                return result;
            }
            
            batch_features.push_back(features);
        }
        
        // Run batch inference
        InferenceResult result = inferBatch(batch_features);
        
        // Map class indices to cognitive states
        if (result.success) {
            for (size_t i = 0; i < result.batch_predicted_classes.size(); ++i) {
                int class_index = result.batch_predicted_classes[i];
                std::string state;
                
                switch (class_index) {
                    case 0: state = "FOCUSED"; break;
                    case 1: state = "DISTRACTED"; break;
                    case 2: state = "COGNITIVE_OVERLOAD"; break;
                    case 3: state = "FATIGUED"; break;
                    case 4: state = "STRESSED"; break;
                    case 5: state = "RELAXED"; break;
                    case 6: state = "CONFUSED"; break;
                    case 7: state = "ENGAGED"; break;
                    case 8: state = "BORED"; break;
                    case 9: state = "NORMAL"; break;
                    default: state = "UNKNOWN";
                }
                
                result.state_labels.push_back(state);
            }
        }
        
        return result;
    }
    catch (const std::exception& e) {
        InferenceResult result;
        result.success = false;
        result.error_message = std::string("Error inferring cognitive state: ") + e.what();
        logging::Logger::getInstance().error(result.error_message);
        return result;
    }
}

InferenceResult InferenceEngine::inferPerformancePrediction(
    const std::vector<DataPoint>& historical_data,
    const std::vector<DataPoint>& current_data
) {
    try {
        // Combine historical and current data
        std::vector<DataPoint> combined_data = historical_data;
        combined_data.insert(combined_data.end(), current_data.begin(), current_data.end());
        
        // Check if we have enough data points
        if (combined_data.empty()) {
            InferenceResult result;
            result.success = false;
            result.error_message = "No data points provided";
            return result;
        }
        
        // Preprocess data and create features
        std::vector<float> features;
        
        // Extract statistical features from combined data
        features = extractStatisticalFeatures(combined_data);
        
        if (features.empty()) {
            InferenceResult result;
            result.success = false;
            result.error_message = "Failed to extract statistical features";
            return result;
        }
        
        // Run inference
        InferenceResult result = infer(features);
        
        // Map output to performance metrics
        if (result.success) {
            // For performance prediction, we interpret the output as regression values
            // Each output value corresponds to a different performance metric
            
            std::unordered_map<std::string, float> performance_metrics;
            
            if (result.predictions.size() >= 10) {
                performance_metrics["overall_score"] = result.predictions[0] * 100.0f;
                performance_metrics["accuracy"] = result.predictions[1];
                performance_metrics["completion_time"] = result.predictions[2] * 300.0f; // Scale to seconds
                performance_metrics["error_rate"] = result.predictions[3];
                performance_metrics["learning_progress"] = result.predictions[4];
                performance_metrics["proficiency"] = result.predictions[5];
                performance_metrics["training_effectiveness"] = result.predictions[6];
                performance_metrics["recommendation_confidence"] = result.predictions[7];
                performance_metrics["cognitive_load"] = result.predictions[8];
                performance_metrics["engagement"] = result.predictions[9];
            }
            
            result.performance_metrics = performance_metrics;
        }
        
        return result;
    }
    catch (const std::exception& e) {
        InferenceResult result;
        result.success = false;
        result.error_message = std::string("Error inferring performance prediction: ") + e.what();
        logging::Logger::getInstance().error(result.error_message);
        return result;
    }
}

InferenceResult InferenceEngine::generateRecommendations(
    const std::vector<DataPoint>& performance_data,
    const std::vector<DataPoint>& cognitive_data
) {
    try {
        // Combine performance and cognitive data
        std::vector<DataPoint> combined_data = performance_data;
        combined_data.insert(combined_data.end(), cognitive_data.begin(), cognitive_data.end());
        
        // Check if we have enough data points
        if (combined_data.empty()) {
            InferenceResult result;
            result.success = false;
            result.error_message = "No data points provided";
            return result;
        }
        
        // Extract features for recommendation generation
        std::vector<float> features = extractRecommendationFeatures(combined_data);
        
        if (features.empty()) {
            InferenceResult result;
            result.success = false;
            result.error_message = "Failed to extract recommendation features";
            return result;
        }
        
        // Run inference
        InferenceResult result = infer(features);
        
        // Generate recommendations based on model output
        if (result.success) {
            std::vector<std::string> recommendations;
            
            // Determine which recommendation templates to use based on prediction probabilities
            if (result.predictions.size() >= 10) {
                std::vector<std::pair<float, int>> sorted_probs;
                for (size_t i = 0; i < result.predictions.size(); ++i) {
                    sorted_probs.push_back({result.predictions[i], static_cast<int>(i)});
                }
                
                // Sort in descending order of probability
                std::sort(sorted_probs.begin(), sorted_probs.end(),
                          [](const auto& a, const auto& b) { return a.first > b.first; });
                
                // Use top 3 recommendations
                for (size_t i = 0; i < std::min(size_t(3), sorted_probs.size()); ++i) {
                    int rec_index = sorted_probs[i].second;
                    float confidence = sorted_probs[i].first;
                    
                    // Only include recommendations with sufficient confidence
                    if (confidence < 0.1f) {
                        continue;
                    }
                    
                    // Generate recommendation based on index
                    std::string recommendation;
                    switch (rec_index) {
                        case 0:
                            recommendation = "Focus on improving procedural knowledge through additional ground training.";
                            break;
                        case 1:
                            recommendation = "Practice emergency scenarios to improve response time and accuracy.";
                            break;
                        case 2:
                            recommendation = "Review communication protocols and practice radio communication.";
                            break;
                        case 3:
                            recommendation = "Work on maintaining situational awareness during high-workload phases.";
                            break;
                        case 4:
                            recommendation = "Practice flight planning and decision-making exercises.";
                            break;
                        case 5:
                            recommendation = "Focus on precise aircraft control during approach and landing.";
                            break;
                        case 6:
                            recommendation = "Review and practice instrument scan techniques.";
                            break;
                        case 7:
                            recommendation = "Work on task prioritization during complex scenarios.";
                            break;
                        case 8:
                            recommendation = "Practice checklist discipline and procedural compliance.";
                            break;
                        case 9:
                            recommendation = "Focus on developing a consistent and methodical approach to troubleshooting.";
                            break;
                        default:
                            break;
                    }
                    
                    if (!recommendation.empty()) {
                        recommendations.push_back(recommendation);
                    }
                }
            }
            
            result.recommendations = recommendations;
        }
        
        return result;
    }
    catch (const std::exception& e) {
        InferenceResult result;
        result.success = false;
        result.error_message = std::string("Error generating recommendations: ") + e.what();
        logging::Logger::getInstance().error(result.error_message);
        return result;
    }
}

std::vector<float> InferenceEngine::extractStatisticalFeatures(const std::vector<DataPoint>& data_points) {
    try {
        if (data_points.empty()) {
            return {};
        }
        
        // Initialize feature vector
        std::vector<float> features;
        
        // Count data points by type
        int gaze_count = 0;
        int physio_count = 0;
        int simulator_count = 0;
        int performance_count = 0;
        
        // Collect values by type for statistical analysis
        std::vector<float> gaze_x_values;
        std::vector<float> gaze_y_values;
        std::vector<float> heart_rate_values;
        std::vector<float> altitude_values;
        std::vector<float> airspeed_values;
        std::vector<float> pitch_values;
        std::vector<float> roll_values;
        std::vector<float> score_values;
        std::vector<float> error_values;
        
        for (const auto& data_point : data_points) {
            switch (data_point.data_type) {
                case DataType::GAZE:
                    gaze_count++;
                    gaze_x_values.push_back(data_point.gaze_data.x);
                    gaze_y_values.push_back(data_point.gaze_data.y);
                    break;
                
                case DataType::PHYSIOLOGICAL:
                    physio_count++;
                    heart_rate_values.push_back(data_point.physiological_data.heart_rate);
                    break;
                
                case DataType::SIMULATOR:
                    simulator_count++;
                    altitude_values.push_back(data_point.simulator_data.altitude);
                    airspeed_values.push_back(data_point.simulator_data.airspeed);
                    pitch_values.push_back(data_point.simulator_data.pitch);
                    roll_values.push_back(data_point.simulator_data.roll);
                    break;
                
                case DataType::PERFORMANCE:
                    performance_count++;
                    score_values.push_back(data_point.performance_data.score);
                    error_values.push_back(data_point.performance_data.error_count);
                    break;
                
                default:
                    break;
            }
        }
        
        // Add counts as features
        features.push_back(static_cast<float>(data_points.size()));
        features.push_back(static_cast<float>(gaze_count));
        features.push_back(static_cast<float>(physio_count));
        features.push_back(static_cast<float>(simulator_count));
        features.push_back(static_cast<float>(performance_count));
        
        // Add statistical features for each data type
        auto add_stats = [&features](const std::vector<float>& values) {
            if (values.empty()) {
                features.push_back(0.0f);  // Mean
                features.push_back(0.0f);  // Std
                features.push_back(0.0f);  // Min
                features.push_back(0.0f);  // Max
                features.push_back(0.0f);  // Range
                return;
            }
            
            float sum = std::accumulate(values.begin(), values.end(), 0.0f);
            float mean = sum / values.size();
            
            float sq_sum = std::inner_product(
                values.begin(), values.end(), values.begin(), 0.0f,
                std::plus<>(), [mean](float x, float y) {
                    return (x - mean) * (y - mean);
                });
            float stddev = std::sqrt(sq_sum / values.size());
            
            float min_val = *std::min_element(values.begin(), values.end());
            float max_val = *std::max_element(values.begin(), values.end());
            float range = max_val - min_val;
            
            features.push_back(mean);
            features.push_back(stddev);
            features.push_back(min_val);
            features.push_back(max_val);
            features.push_back(range);
        };
        
        // Add stats for each collected value type
        add_stats(gaze_x_values);
        add_stats(gaze_y_values);
        add_stats(heart_rate_values);
        add_stats(altitude_values);
        add_stats(airspeed_values);
        add_stats(pitch_values);
        add_stats(roll_values);
        add_stats(score_values);
        add_stats(error_values);
        
        // Add derived features
        
        // Gaze dispersion
        if (!gaze_x_values.empty() && !gaze_y_values.empty()) {
            float gaze_dispersion = 0.0f;
            for (size_t i = 0; i < gaze_x_values.size(); ++i) {
                float x_diff = gaze_x_values[i] - 0.5f;  // Assuming center is at (0.5, 0.5)
                float y_diff = gaze_y_values[i] - 0.5f;
                gaze_dispersion += std::sqrt(x_diff * x_diff + y_diff * y_diff);
            }
            gaze_dispersion /= gaze_x_values.size();
            features.push_back(gaze_dispersion);
        } else {
            features.push_back(0.0f);
        }
        
        // Heart rate variability
        if (heart_rate_values.size() > 1) {
            std::vector<float> hr_diffs;
            for (size_t i = 1; i < heart_rate_values.size(); ++i) {
                hr_diffs.push_back(std::abs(heart_rate_values[i] - heart_rate_values[i-1]));
            }
            float hr_variability = std::accumulate(hr_diffs.begin(), hr_diffs.end(), 0.0f) / hr_diffs.size();
            features.push_back(hr_variability);
        } else {
            features.push_back(0.0f);
        }
        
        // Control stability
        if (!pitch_values.empty() && !roll_values.empty()) {
            float pitch_stability = 0.0f;
            float roll_stability = 0.0f;
            
            for (size_t i = 1; i < pitch_values.size(); ++i) {
                pitch_stability += std::abs(pitch_values[i] - pitch_values[i-1]);
            }
            
            for (size_t i = 1; i < roll_values.size(); ++i) {
                roll_stability += std::abs(roll_values[i] - roll_values[i-1]);
            }
            
            if (pitch_values.size() > 1) {
                pitch_stability /= (pitch_values.size() - 1);
            }
            
            if (roll_values.size() > 1) {
                roll_stability /= (roll_values.size() - 1);
            }
            
            features.push_back(pitch_stability);
            features.push_back(roll_stability);
        } else {
            features.push_back(0.0f);
            features.push_back(0.0f);
        }
        
        // Performance trends
        if (score_values.size() > 1) {
            float score_trend = score_values.back() - score_values.front();
            features.push_back(score_trend);
        } else {
            features.push_back(0.0f);
        }
        
        // Ensure we have the expected number of features
        if (features.size() < static_cast<size_t>(input_shape_[1])) {
            features.resize(input_shape_[1], 0.0f);
        } else if (features.size() > static_cast<size_t>(input_shape_[1])) {
            features.resize(input_shape_[1]);
        }
        
        return features;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error extracting statistical features: {}", e.what());
        return {};
    }
}

std::vector<float> InferenceEngine::extractRecommendationFeatures(const std::vector<DataPoint>& data_points) {
    try {
        // Start with statistical features
        std::vector<float> features = extractStatisticalFeatures(data_points);
        
        if (features.empty()) {
            return {};
        }
        
        // Extract additional features specific to recommendations
        
        // Count data types
        int gaze_count = 0;
        int physio_count = 0;
        int simulator_count = 0;
        int performance_count = 0;
        
        // Recent performance metrics
        std::vector<float> recent_scores;
        std::vector<float> recent_errors;
        std::vector<float> recent_completion_times;
        
        // Cognitive state indicators
        float focus_indicator = 0.0f;
        float stress_indicator = 0.0f;
        float fatigue_indicator = 0.0f;
        
        // Extract recent data (last 10 points or all if fewer)
        size_t recent_count = std::min(size_t(10), data_points.size());
        auto recent_start = data_points.end() - recent_count;
        
        for (auto it = recent_start; it != data_points.end(); ++it) {
            const auto& data_point = *it;
            
            switch (data_point.data_type) {
                case DataType::GAZE:
                    gaze_count++;
                    // Calculate focus indicator from gaze stability
                    focus_indicator += data_point.gaze_data.confidence;
                    break;
                
                case DataType::PHYSIOLOGICAL:
                    physio_count++;
                    // Calculate stress from heart rate
                    if (data_point.physiological_data.heart_rate > 90.0f) {
                        stress_indicator += (data_point.physiological_data.heart_rate - 90.0f) / 30.0f;
                    }
                    break;
                
                case DataType::SIMULATOR:
                    simulator_count++;
                    // Control smoothness could indicate fatigue
                    fatigue_indicator += std::abs(data_point.simulator_data.control_pitch) +
                                       std::abs(data_point.simulator_data.control_roll);
                    break;
                
                case DataType::PERFORMANCE:
                    performance_count++;
                    recent_scores.push_back(data_point.performance_data.score);
                    recent_errors.push_back(data_point.performance_data.error_count);
                    recent_completion_times.push_back(data_point.performance_data.completion_time);
                    break;
                
                default:
                    break;
            }
        }
        
        // Normalize indicators
        if (gaze_count > 0) {
            focus_indicator /= gaze_count;
        }
        
        if (physio_count > 0) {
            stress_indicator /= physio_count;
        }
        
        if (simulator_count > 0) {
            fatigue_indicator /= simulator_count;
        }
        
        // Add cognitive indicators to features
        features.push_back(focus_indicator);
        features.push_back(stress_indicator);
        features.push_back(fatigue_indicator);
        
        // Add recent performance metrics
        if (!recent_scores.empty()) {
            float avg_score = std::accumulate(recent_scores.begin(), recent_scores.end(), 0.0f) / recent_scores.size();
            features.push_back(avg_score);
        } else {
            features.push_back(0.0f);
        }
        
        if (!recent_errors.empty()) {
            float avg_errors = std::accumulate(recent_errors.begin(), recent_errors.end(), 0.0f) / recent_errors.size();
            features.push_back(avg_errors);
        } else {
            features.push_back(0.0f);
        }
        
        if (!recent_completion_times.empty()) {
            float avg_time = std::accumulate(recent_completion_times.begin(), recent_completion_times.end(), 0.0f) / 
                           recent_completion_times.size();
            features.push_back(avg_time);
        } else {
            features.push_back(0.0f);
        }
        
        // Trend indicators (improvement or deterioration)
        if (recent_scores.size() > 1) {
            float first_half_avg = 0.0f;
            float second_half_avg = 0.0f;
            size_t half_size = recent_scores.size() / 2;
            
            for (size_t i = 0; i < half_size; ++i) {
                first_half_avg += recent_scores[i];
            }
            
            for (size_t i = half_size; i < recent_scores.size(); ++i) {
                second_half_avg += recent_scores[i];
            }
            
            first_half_avg /= half_size;
            second_half_avg /= (recent_scores.size() - half_size);
            
            float trend = second_half_avg - first_half_avg;
            features.push_back(trend);
        } else {
            features.push_back(0.0f);
        }
        
        // Ensure we have the expected number of features
        if (features.size() < static_cast<size_t>(input_shape_[1])) {
            features.resize(input_shape_[1], 0.0f);
        } else if (features.size() > static_cast<size_t>(input_shape_[1])) {
            features.resize(input_shape_[1]);
        }
        
        return features;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error extracting recommendation features: {}", e.what());
        return {};
    }
}

// InferenceResult methods

nlohmann::json InferenceResult::toJson() const {
    nlohmann::json json;
    json["success"] = success;
    
    if (!success) {
        json["error_message"] = error_message;
        return json;
    }
    
    // Add single prediction results if available
    if (!predictions.empty()) {
        json["predictions"] = predictions;
        json["predicted_class"] = predicted_class;
        json["confidence"] = confidence;
    }
    
    // Add batch prediction results if available
    if (!batch_predictions.empty()) {
        json["batch_predictions"] = batch_predictions;
        json["batch_predicted_classes"] = batch_predicted_classes;
        json["batch_confidences"] = batch_confidences;
    }
    
    // Add cognitive state labels if available
    if (!state_labels.empty()) {
        json["state_labels"] = state_labels;
    }
    
    // Add performance metrics if available
    if (!performance_metrics.empty()) {
        json["performance_metrics"] = performance_metrics;
    }
    
    // Add recommendations if available
    if (!recommendations.empty()) {
        json["recommendations"] = recommendations;
    }
    
    return json;
}

std::optional<InferenceResult> InferenceResult::fromJson(const nlohmann::json& json) {
    try {
        InferenceResult result;
        result.success = json["success"];
        
        if (!result.success) {
            result.error_message = json["error_message"];
            return result;
        }
        
        // Get single prediction results if available
        if (json.contains("predictions") && json["predictions"].is_array()) {
            result.predictions = json["predictions"].get<std::vector<float>>();
            result.predicted_class = json["predicted_class"];
            result.confidence = json["confidence"];
        }
        
        // Get batch prediction results if available
        if (json.contains("batch_predictions") && json["batch_predictions"].is_array()) {
            result.batch_predictions = json["batch_predictions"].get<std::vector<std::vector<float>>>();
            result.batch_predicted_classes = json["batch_predicted_classes"].get<std::vector<int>>();
            result.batch_confidences = json["batch_confidences"].get<std::vector<float>>();
        }
        
        // Get cognitive state labels if available
        if (json.contains("state_labels") && json["state_labels"].is_array()) {
            result.state_labels = json["state_labels"].get<std::vector<std::string>>();
        }
        
        // Get performance metrics if available
        if (json.contains("performance_metrics") && json["performance_metrics"].is_object()) {
            result.performance_metrics = json["performance_metrics"].get<std::unordered_map<std::string, float>>();
        }
        
        // Get recommendations if available
        if (json.contains("recommendations") && json["recommendations"].is_array()) {
            result.recommendations = json["recommendations"].get<std::vector<std::string>>();
        }
        
        return result;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing inference result from JSON: {}", e.what());
        return std::nullopt;
    }
}

} // namespace inference
} // namespace ai_analytics
#pragma once

#include <string>
#include <memory>
#include <map>
#include <vector>
#include <optional>
#include <mutex>
#include <filesystem>
#include <nlohmann/json.hpp>

namespace ai_analytics {
namespace models {

/**
 * @brief Model type enumeration
 */
enum class ModelType {
    COGNITIVE_STATE,
    PERFORMANCE_PREDICTION,
    ANOMALY_DETECTION,
    RECOMMENDATION,
    TEXT_ANALYSIS,
    CUSTOM
};

/**
 * @brief Convert ModelType to string
 * @param type Model type
 * @return String representation
 */
std::string modelTypeToString(ModelType type);

/**
 * @brief Convert string to ModelType
 * @param str String representation
 * @return Model type
 */
ModelType modelTypeFromString(const std::string& str);

/**
 * @brief Model framework enumeration
 */
enum class ModelFramework {
    TENSORFLOW,
    ONNX,
    PYTORCH,
    SCIKIT_LEARN,
    CUSTOM
};

/**
 * @brief Convert ModelFramework to string
 * @param framework Model framework
 * @return String representation
 */
std::string modelFrameworkToString(ModelFramework framework);

/**
 * @brief Convert string to ModelFramework
 * @param str String representation
 * @return Model framework
 */
ModelFramework modelFrameworkFromString(const std::string& str);

/**
 * @brief Model metadata
 */
struct ModelMetadata {
    std::string model_id;
    std::string name;
    std::string version;
    ModelType type;
    ModelFramework framework;
    std::string description;
    std::map<std::string, std::string> properties;
    std::vector<std::string> input_features;
    std::vector<std::string> output_features;
    std::chrono::system_clock::time_point created_at;
    std::chrono::system_clock::time_point updated_at;
    std::string author;
    double accuracy;
    std::string path;
    bool is_active;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Model metadata or nullopt if invalid
     */
    static std::optional<ModelMetadata> fromJson(const nlohmann::json& json);
};

/**
 * @brief Base model interface
 */
class IModel {
public:
    virtual ~IModel() = default;
    
    /**
     * @brief Get model metadata
     * @return Model metadata
     */
    virtual const ModelMetadata& getMetadata() const = 0;
    
    /**
     * @brief Load model from file
     * @param path Path to model file
     * @return True if loaded successfully
     */
    virtual bool load(const std::string& path) = 0;
    
    /**
     * @brief Unload model
     */
    virtual void unload() = 0;
    
    /**
     * @brief Check if model is loaded
     * @return True if loaded
     */
    virtual bool isLoaded() const = 0;
    
    /**
     * @brief Predict using model
     * @param inputs Input features
     * @return Output predictions
     */
    virtual nlohmann::json predict(const nlohmann::json& inputs) = 0;
    
    /**
     * @brief Get model accuracy
     * @return Accuracy value
     */
    virtual double getAccuracy() const = 0;
    
    /**
     * @brief Get model type
     * @return Model type
     */
    virtual ModelType getType() const = 0;
    
    /**
     * @brief Get model framework
     * @return Model framework
     */
    virtual ModelFramework getFramework() const = 0;
};

/**
 * @brief TensorFlow model implementation
 */
class TensorFlowModel : public IModel {
public:
    /**
     * @brief Constructor
     * @param metadata Model metadata
     */
    explicit TensorFlowModel(const ModelMetadata& metadata);
    
    /**
     * @brief Destructor
     */
    ~TensorFlowModel() override;
    
    const ModelMetadata& getMetadata() const override;
    bool load(const std::string& path) override;
    void unload() override;
    bool isLoaded() const override;
    nlohmann::json predict(const nlohmann::json& inputs) override;
    double getAccuracy() const override;
    ModelType getType() const override;
    ModelFramework getFramework() const override;
    
private:
    ModelMetadata metadata_;
    bool loaded_;
    void* model_ptr_; // TensorFlow C API model pointer
};

/**
 * @brief ONNX model implementation
 */
class ONNXModel : public IModel {
public:
    /**
     * @brief Constructor
     * @param metadata Model metadata
     */
    explicit ONNXModel(const ModelMetadata& metadata);
    
    /**
     * @brief Destructor
     */
    ~ONNXModel() override;
    
    const ModelMetadata& getMetadata() const override;
    bool load(const std::string& path) override;
    void unload() override;
    bool isLoaded() const override;
    nlohmann::json predict(const nlohmann::json& inputs) override;
    double getAccuracy() const override;
    ModelType getType() const override;
    ModelFramework getFramework() const override;
    
private:
    ModelMetadata metadata_;
    bool loaded_;
    void* model_ptr_; // ONNX Runtime model pointer
};

/**
 * @brief Model manager
 */
class ModelManager {
public:
    /**
     * @brief Constructor
     * @param models_path Path to models directory
     */
    explicit ModelManager(const std::string& models_path);
    
    /**
     * @brief Destructor
     */
    ~ModelManager();
    
    /**
     * @brief Initialize the model manager
     * @return True if initialized successfully
     */
    bool initialize();
    
    /**
     * @brief Shutdown the model manager
     */
    void shutdown();
    
    /**
     * @brief Get model by ID
     * @param model_id Model ID
     * @return Model pointer or nullptr if not found
     */
    std::shared_ptr<IModel> getModel(const std::string& model_id);
    
    /**
     * @brief Get models by type
     * @param type Model type
     * @return Vector of model pointers
     */
    std::vector<std::shared_ptr<IModel>> getModelsByType(ModelType type);
    
    /**
     * @brief Get all models
     * @return Map of model ID to model pointer
     */
    std::map<std::string, std::shared_ptr<IModel>> getAllModels();
    
    /**
     * @brief Add model
     * @param model Model pointer
     * @return True if added successfully
     */
    bool addModel(std::shared_ptr<IModel> model);
    
    /**
     * @brief Remove model
     * @param model_id Model ID
     * @return True if removed successfully
     */
    bool removeModel(const std::string& model_id);
    
    /**
     * @brief Load model from path
     * @param path Path to model file
     * @return Model pointer or nullptr if loading failed
     */
    std::shared_ptr<IModel> loadModelFromPath(const std::string& path);
    
    /**
     * @brief Create model from metadata
     * @param metadata Model metadata
     * @return Model pointer or nullptr if creation failed
     */
    std::shared_ptr<IModel> createModel(const ModelMetadata& metadata);
    
    /**
     * @brief Save model metadata
     * @param metadata Model metadata
     * @return True if saved successfully
     */
    bool saveModelMetadata(const ModelMetadata& metadata);
    
    /**
     * @brief Load model metadata
     * @param model_id Model ID
     * @return Model metadata or nullopt if not found
     */
    std::optional<ModelMetadata> loadModelMetadata(const std::string& model_id);
    
    /**
     * @brief Scan models directory for model files
     * @return Vector of discovered model metadata
     */
    std::vector<ModelMetadata> scanModelsDirectory();
    
private:
    std::string models_path_;
    std::map<std::string, std::shared_ptr<IModel>> models_;
    std::mutex models_mutex_;
    bool initialized_;
    
    /**
     * @brief Detect model framework from file
     * @param path Path to model file
     * @return Model framework or nullopt if detection failed
     */
    std::optional<ModelFramework> detectModelFramework(const std::string& path);
    
    /**
     * @brief Load metadata from JSON file
     * @param path Path to metadata JSON file
     * @return Model metadata or nullopt if loading failed
     */
    std::optional<ModelMetadata> loadMetadataFromFile(const std::string& path);
};

} // namespace models
} // namespace ai_analytics
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <Eigen/Dense>
#include <mlpack/core.hpp>
#include <mlpack/methods/random_forest/random_forest.hpp>

namespace ai_analytics {
namespace models {

/**
 * @brief Performance metric types
 */
enum class MetricType {
    ACCURACY,
    REACTION_TIME,
    DECISION_QUALITY,
    CONSISTENCY,
    WORKLOAD_MANAGEMENT,
    SITUATIONAL_AWARENESS,
    COMMUNICATION_QUALITY,
    PROCEDURAL_COMPLIANCE,
    RESOURCE_MANAGEMENT,
    TECHNICAL_PROFICIENCY
};

/**
 * @brief Performance rating scale (1-5)
 */
enum class PerformanceRating {
    UNSATISFACTORY = 1,
    NEEDS_IMPROVEMENT = 2,
    SATISFACTORY = 3,
    GOOD = 4,
    EXCELLENT = 5
};

/**
 * @brief Training session data
 */
struct SessionData {
    std::string session_id;
    std::string trainee_id;
    std::string exercise_id;
    std::vector<double> features;
    std::vector<double> labels;
    std::chrono::system_clock::time_point timestamp;
    
    /**
     * @brief Convert to vector for model input
     */
    Eigen::VectorXd toVector() const;
};

/**
 * @brief Performance prediction result
 */
struct PerformancePrediction {
    std::string trainee_id;
    std::string exercise_id;
    std::map<MetricType, double> metric_scores;
    std::map<std::string, double> skill_scores;
    double overall_score;
    PerformanceRating overall_rating;
    std::vector<std::string> strengths;
    std::vector<std::string> improvement_areas;
    std::map<std::string, std::vector<double>> trend_data;
    std::chrono::system_clock::time_point timestamp;
    
    /**
     * @brief Convert to JSON
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     */
    static std::optional<PerformancePrediction> fromJson(const nlohmann::json& json);
};

/**
 * @brief Feature extraction result
 */
struct FeatureExtractionResult {
    std::vector<double> features;
    std::vector<std::string> feature_names;
    std::map<std::string, double> feature_importances;
    
    /**
     * @brief Convert to JSON
     */
    nlohmann::json toJson() const;
};

/**
 * @brief Performance analysis model interface
 */
class IPerformanceModel {
public:
    virtual ~IPerformanceModel() = default;
    
    /**
     * @brief Initialize the model
     * @param config Configuration parameters
     * @return True if initialized successfully
     */
    virtual bool initialize(const nlohmann::json& config) = 0;
    
    /**
     * @brief Train the model
     * @param training_data Training data
     * @return True if trained successfully
     */
    virtual bool train(const std::vector<SessionData>& training_data) = 0;
    
    /**
     * @brief Predict performance
     * @param session_data Session data
     * @return Performance prediction
     */
    virtual PerformancePrediction predict(const SessionData& session_data) = 0;
    
    /**
     * @brief Extract features from raw data
     * @param raw_data Raw session data
     * @return Extracted features
     */
    virtual FeatureExtractionResult extractFeatures(const nlohmann::json& raw_data) = 0;
    
    /**
     * @brief Save model to file
     * @param file_path File path
     * @return True if saved successfully
     */
    virtual bool saveModel(const std::string& file_path) = 0;
    
    /**
     * @brief Load model from file
     * @param file_path File path
     * @return True if loaded successfully
     */
    virtual bool loadModel(const std::string& file_path) = 0;
    
    /**
     * @brief Get model metrics
     * @return Model metrics as JSON
     */
    virtual nlohmann::json getModelMetrics() const = 0;
};

/**
 * @brief Random forest based performance model
 */
class RandomForestPerformanceModel : public IPerformanceModel {
public:
    /**
     * @brief Constructor
     */
    RandomForestPerformanceModel();
    
    /**
     * @brief Destructor
     */
    ~RandomForestPerformanceModel() override;
    
    bool initialize(const nlohmann::json& config) override;
    bool train(const std::vector<SessionData>& training_data) override;
    PerformancePrediction predict(const SessionData& session_data) override;
    FeatureExtractionResult extractFeatures(const nlohmann::json& raw_data) override;
    bool saveModel(const std::string& file_path) override;
    bool loadModel(const std::string& file_path) override;
    nlohmann::json getModelMetrics() const override;
    
private:
    /**
     * @brief Preprocess training data
     * @param training_data Training data
     * @return Preprocessed data as arma::mat
     */
    std::pair<arma::mat, arma::Row<size_t>> preprocessTrainingData(
        const std::vector<SessionData>& training_data
    );
    
    /**
     * @brief Map raw features to prediction metrics
     * @param raw_prediction Raw model prediction
     * @return Mapped performance prediction
     */
    PerformancePrediction mapPredictionToMetrics(
        const SessionData& session_data,
        const arma::Row<size_t>& raw_prediction
    );
    
    /**
     * @brief Calculate feature importances
     * @return Feature importance map
     */
    std::map<std::string, double> calculateFeatureImportances() const;
    
    /**
     * @brief Generate improvement recommendations
     * @param metrics Performance metrics
     * @return Pair of strengths and improvement areas
     */
    std::pair<std::vector<std::string>, std::vector<std::string>> generateRecommendations(
        const std::map<MetricType, double>& metrics
    ) const;
    
    /**
     * @brief Extract time series features
     * @param time_series Time series data
     * @return Extracted features
     */
    std::vector<double> extractTimeSeriesFeatures(
        const std::vector<double>& time_series
    ) const;
    
    /**
     * @brief Extract spatial features
     * @param spatial_data Spatial data
     * @return Extracted features
     */
    std::vector<double> extractSpatialFeatures(
        const std::vector<std::vector<double>>& spatial_data
    ) const;
    
    std::unique_ptr<mlpack::RandomForest<>> model_;
    std::vector<std::string> feature_names_;
    std::vector<std::string> label_names_;
    std::map<std::string, double> feature_importances_;
    nlohmann::json model_metrics_;
    bool initialized_;
    unsigned int num_trees_;
    unsigned int min_leaf_size_;
    unsigned int max_depth_;
    double minimum_gain_split_;
    unsigned int num_samples_;
};

/**
 * @brief Neural network based performance model
 */
class NeuralNetworkPerformanceModel : public IPerformanceModel {
public:
    NeuralNetworkPerformanceModel();
    ~NeuralNetworkPerformanceModel() override;
    
    bool initialize(const nlohmann::json& config) override;
    bool train(const std::vector<SessionData>& training_data) override;
    PerformancePrediction predict(const SessionData& session_data) override;
    FeatureExtractionResult extractFeatures(const nlohmann::json& raw_data) override;
    bool saveModel(const std::string& file_path) override;
    bool loadModel(const std::string& file_path) override;
    nlohmann::json getModelMetrics() const override;
    
private:
    // Neural network implementation details
    // This would use a deep learning framework in a real implementation
    bool initialized_;
    nlohmann::json model_metrics_;
};

/**
 * @brief Performance model factory
 */
class PerformanceModelFactory {
public:
    /**
     * @brief Get singleton instance
     * @return Factory instance
     */
    static PerformanceModelFactory& getInstance();
    
    /**
     * @brief Create a performance model
     * @param model_type Model type name
     * @return Model instance
     */
    std::unique_ptr<IPerformanceModel> createModel(const std::string& model_type);
    
    /**
     * @brief Register a model type
     * @tparam T Model class type
     * @param model_type Model type name
     */
    template<typename T>
    void registerModel(const std::string& model_type) {
        creators_[model_type] = []() { return std::make_unique<T>(); };
    }
    
private:
    PerformanceModelFactory();
    ~PerformanceModelFactory() = default;
    
    PerformanceModelFactory(const PerformanceModelFactory&) = delete;
    PerformanceModelFactory& operator=(const PerformanceModelFactory&) = delete;
    
    std::map<std::string, std::function<std::unique_ptr<IPerformanceModel>()>> creators_;
};

} // namespace models
} // namespace ai_analytics
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <chrono>
#include <nlohmann/json.hpp>
#include <Eigen/Dense>

namespace ai_analytics {
namespace analytics {

/**
 * @brief Performance metric types
 */
enum class MetricType {
    ACCURACY,
    PRECISION,
    RECALL,
    F1_SCORE,
    ERROR_RATE,
    MEAN_ABSOLUTE_ERROR,
    MEAN_SQUARED_ERROR,
    ROOT_MEAN_SQUARED_ERROR,
    R_SQUARED,
    CONFUSION_MATRIX,
    ROC_CURVE,
    PR_CURVE,
    LEARNING_CURVE
};

/**
 * @brief Convert MetricType to string
 * @param type Metric type
 * @return String representation
 */
std::string metricTypeToString(MetricType type);

/**
 * @brief Convert string to MetricType
 * @param str String representation
 * @return Metric type
 */
MetricType metricTypeFromString(const std::string& str);

/**
 * @brief Prediction interval level
 */
enum class PredictionIntervalLevel {
    CONFIDENCE_50,
    CONFIDENCE_80,
    CONFIDENCE_90,
    CONFIDENCE_95,
    CONFIDENCE_99
};

/**
 * @brief Convert PredictionIntervalLevel to confidence value
 * @param level Prediction interval level
 * @return Confidence value (0-1)
 */
double predictionIntervalLevelToValue(PredictionIntervalLevel level);

/**
 * @brief Performance metric
 */
struct PerformanceMetric {
    MetricType type;
    double value;
    std::optional<double> lower_bound;
    std::optional<double> upper_bound;
    std::optional<std::vector<std::vector<double>>> matrix_value;
    std::optional<std::vector<std::pair<double, double>>> curve_points;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Performance metric or nullopt if invalid
     */
    static std::optional<PerformanceMetric> fromJson(const nlohmann::json& json);
};

/**
 * @brief Training history point
 */
struct TrainingHistoryPoint {
    int epoch;
    double training_loss;
    double validation_loss;
    std::map<std::string, double> metrics;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Training history point or nullopt if invalid
     */
    static std::optional<TrainingHistoryPoint> fromJson(const nlohmann::json& json);
};

/**
 * @brief Training history
 */
struct TrainingHistory {
    std::string model_id;
    std::vector<TrainingHistoryPoint> history;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Training history or nullopt if invalid
     */
    static std::optional<TrainingHistory> fromJson(const nlohmann::json& json);
};

/**
 * @brief Performance prediction
 */
struct PerformancePrediction {
    std::string trainee_id;
    std::string exercise_id;
    double predicted_score;
    std::optional<double> lower_bound;
    std::optional<double> upper_bound;
    std::map<std::string, double> criteria_predictions;
    std::chrono::system_clock::time_point prediction_time;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Performance prediction or nullopt if invalid
     */
    static std::optional<PerformancePrediction> fromJson(const nlohmann::json& json);
};

/**
 * @brief Performance trend
 */
struct PerformanceTrend {
    std::string trainee_id;
    std::string metric;
    std::vector<std::pair<std::chrono::system_clock::time_point, double>> data_points;
    std::optional<std::pair<double, double>> linear_trend; // (slope, intercept)
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Performance trend or nullopt if invalid
     */
    static std::optional<PerformanceTrend> fromJson(const nlohmann::json& json);
};

/**
 * @brief Performance benchmark
 */
struct PerformanceBenchmark {
    std::string benchmark_id;
    std::string name;
    std::string description;
    double threshold_value;
    double mean_value;
    double std_dev;
    std::vector<double> percentiles; // [p10, p25, p50, p75, p90]
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Performance benchmark or nullopt if invalid
     */
    static std::optional<PerformanceBenchmark> fromJson(const nlohmann::json& json);
};

/**
 * @brief Performance analytics service interface
 */
class IPerformanceAnalyticsService {
public:
    virtual ~IPerformanceAnalyticsService() = default;
    
    /**
     * @brief Calculate performance metrics
     * @param actual Actual values
     * @param predicted Predicted values
     * @param metric_types Metric types to calculate
     * @return Performance metrics
     */
    virtual std::vector<PerformanceMetric> calculateMetrics(
        const std::vector<double>& actual,
        const std::vector<double>& predicted,
        const std::vector<MetricType>& metric_types
    ) = 0;
    
    /**
     * @brief Calculate confusion matrix
     * @param actual Actual classes
     * @param predicted Predicted classes
     * @param class_labels Class labels
     * @return Confusion matrix
     */
    virtual PerformanceMetric calculateConfusionMatrix(
        const std::vector<int>& actual,
        const std::vector<int>& predicted,
        const std::vector<std::string>& class_labels
    ) = 0;
    
    /**
     * @brief Calculate ROC curve
     * @param actual Actual classes (0 or 1)
     * @param probabilities Predicted probabilities
     * @return ROC curve
     */
    virtual PerformanceMetric calculateROCCurve(
        const std::vector<int>& actual,
        const std::vector<double>& probabilities
    ) = 0;
    
    /**
     * @brief Calculate precision-recall curve
     * @param actual Actual classes (0 or 1)
     * @param probabilities Predicted probabilities
     * @return PR curve
     */
    virtual PerformanceMetric calculatePRCurve(
        const std::vector<int>& actual,
        const std::vector<double>& probabilities
    ) = 0;
    
    /**
     * @brief Predict trainee performance
     * @param trainee_id Trainee ID
     * @param exercise_id Exercise ID
     * @param features Input features
     * @param interval_level Prediction interval level
     * @return Performance prediction
     */
    virtual PerformancePrediction predictTraineePerformance(
        const std::string& trainee_id,
        const std::string& exercise_id,
        const std::map<std::string, double>& features,
        PredictionIntervalLevel interval_level = PredictionIntervalLevel::CONFIDENCE_95
    ) = 0;
    
    /**
     * @brief Calculate performance trend
     * @param trainee_id Trainee ID
     * @param metric Metric name
     * @param start_date Start date
     * @param end_date End date
     * @return Performance trend
     */
    virtual PerformanceTrend calculatePerformanceTrend(
        const std::string& trainee_id,
        const std::string& metric,
        const std::chrono::system_clock::time_point& start_date,
        const std::chrono::system_clock::time_point& end_date
    ) = 0;
    
    /**
     * @brief Get performance benchmarks
     * @param exercise_id Exercise ID
     * @return Performance benchmarks
     */
    virtual std::vector<PerformanceBenchmark> getPerformanceBenchmarks(
        const std::string& exercise_id
    ) = 0;
    
    /**
     * @brief Compare trainee performance to benchmarks
     * @param trainee_id Trainee ID
     * @param exercise_id Exercise ID
     * @return Comparison results as JSON
     */
    virtual nlohmann::json compareToPerformanceBenchmarks(
        const std::string& trainee_id,
        const std::string& exercise_id
    ) = 0;
    
    /**
     * @brief Get relative strengths and weaknesses
     * @param trainee_id Trainee ID
     * @return Strengths and weaknesses as JSON
     */
    virtual nlohmann::json getStrengthsAndWeaknesses(
        const std::string& trainee_id
    ) = 0;
    
    /**
     * @brief Generate training recommendations
     * @param trainee_id Trainee ID
     * @return Recommendations as JSON
     */
    virtual nlohmann::json generateTrainingRecommendations(
        const std::string& trainee_id
    ) = 0;
};

/**
 * @brief Performance analytics service implementation
 */
class PerformanceAnalyticsService : public IPerformanceAnalyticsService {
public:
    /**
     * @brief Constructor
     */
    PerformanceAnalyticsService();
    
    /**
     * @brief Destructor
     */
    ~PerformanceAnalyticsService() override;
    
    std::vector<PerformanceMetric> calculateMetrics(
        const std::vector<double>& actual,
        const std::vector<double>& predicted,
        const std::vector<MetricType>& metric_types
    ) override;
    
    PerformanceMetric calculateConfusionMatrix(
        const std::vector<int>& actual,
        const std::vector<int>& predicted,
        const std::vector<std::string>& class_labels
    ) override;
    
    PerformanceMetric calculateROCCurve(
        const std::vector<int>& actual,
        const std::vector<double>& probabilities
    ) override;
    
    PerformanceMetric calculatePRCurve(
        const std::vector<int>& actual,
        const std::vector<double>& probabilities
    ) override;
    
    PerformancePrediction predictTraineePerformance(
        const std::string& trainee_id,
        const std::string& exercise_id,
        const std::map<std::string, double>& features,
        PredictionIntervalLevel interval_level
    ) override;
    
    PerformanceTrend calculatePerformanceTrend(
        const std::string& trainee_id,
        const std::string& metric,
        const std::chrono::system_clock::time_point& start_date,
        const std::chrono::system_clock::time_point& end_date
    ) override;
    
    std::vector<PerformanceBenchmark> getPerformanceBenchmarks(
        const std::string& exercise_id
    ) override;
    
    nlohmann::json compareToPerformanceBenchmarks(
        const std::string& trainee_id,
        const std::string& exercise_id
    ) override;
    
    nlohmann::json getStrengthsAndWeaknesses(
        const std::string& trainee_id
    ) override;
    
    nlohmann::json generateTrainingRecommendations(
        const std::string& trainee_id
    ) override;
    
private:
    /**
     * @brief Calculate accuracy
     * @param actual Actual values
     * @param predicted Predicted values
     * @return Accuracy metric
     */
    PerformanceMetric calculateAccuracy(
        const std::vector<double>& actual,
        const std::vector<double>& predicted
    );
    
    /**
     * @brief Calculate precision
     * @param actual Actual values
     * @param predicted Predicted values
     * @return Precision metric
     */
    PerformanceMetric calculatePrecision(
        const std::vector<double>& actual,
        const std::vector<double>& predicted
    );
    
    /**
     * @brief Calculate recall
     * @param actual Actual values
     * @param predicted Predicted values
     * @return Recall metric
     */
    PerformanceMetric calculateRecall(
        const std::vector<double>& actual,
        const std::vector<double>& predicted
    );
    
    /**
     * @brief Calculate F1 score
     * @param actual Actual values
     * @param predicted Predicted values
     * @return F1 score metric
     */
    PerformanceMetric calculateF1Score(
        const std::vector<double>& actual,
        const std::vector<double>& predicted
    );
    
    /**
     * @brief Calculate error rate
     * @param actual Actual values
     * @param predicted Predicted values
     * @return Error rate metric
     */
    PerformanceMetric calculateErrorRate(
        const std::vector<double>& actual,
        const std::vector<double>& predicted
    );
    
    /**
     * @brief Calculate mean absolute error
     * @param actual Actual values
     * @param predicted Predicted values
     * @return MAE metric
     */
    PerformanceMetric calculateMAE(
        const std::vector<double>& actual,
        const std::vector<double>& predicted
    );
    
    /**
     * @brief Calculate mean squared error
     * @param actual Actual values
     * @param predicted Predicted values
     * @return MSE metric
     */
    PerformanceMetric calculateMSE(
        const std::vector<double>& actual,
        const std::vector<double>& predicted
    );
    
    /**
     * @brief Calculate root mean squared error
     * @param actual Actual values
     * @param predicted Predicted values
     * @return RMSE metric
     */
    PerformanceMetric calculateRMSE(
        const std::vector<double>& actual,
        const std::vector<double>& predicted
    );
    
    /**
     * @brief Calculate R-squared
     * @param actual Actual values
     * @param predicted Predicted values
     * @return R-squared metric
     */
    PerformanceMetric calculateRSquared(
        const std::vector<double>& actual,
        const std::vector<double>& predicted
    );
    
    /**
     * @brief Calculate linear regression parameters
     * @param x X values
     * @param y Y values
     * @return Pair of (slope, intercept)
     */
    std::pair<double, double> calculateLinearRegression(
        const std::vector<double>& x,
        const std::vector<double>& y
    );
};

} // namespace analytics
} // namespace ai_analytics
cmake_minimum_required(VERSION 3.20)
project(ai-analytics-service VERSION 1.0.0 LANGUAGES CXX)

# Set C++20 standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Set output directories
set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)

# Find required packages
find_package(gRPC REQUIRED)
find_package(Protobuf REQUIRED)
find_package(OpenSSL REQUIRED)
find_package(nlohmann_json 3.10.0 REQUIRED)
find_package(spdlog REQUIRED)
find_package(prometheus-cpp REQUIRED)
find_package(Boost REQUIRED COMPONENTS system filesystem)
find_package(TensorflowCC REQUIRED)
find_package(Eigen3 REQUIRED)

# Include directories
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_BINARY_DIR}/generated
    ${EIGEN3_INCLUDE_DIR}
)

# Generate protobuf and gRPC code
set(PROTO_FILES
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/ai_analytics_service.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/core_service.proto
)

protobuf_generate_cpp(PROTO_SRCS PROTO_HDRS ${PROTO_FILES})
grpc_generate_cpp(GRPC_SRCS GRPC_HDRS ${CMAKE_CURRENT_BINARY_DIR}/generated ${PROTO_FILES})

# Source files
file(GLOB_RECURSE SOURCES 
    ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp
)

# Add executable
add_executable(${PROJECT_NAME} ${SOURCES} ${PROTO_SRCS} ${PROTO_HDRS} ${GRPC_SRCS} ${GRPC_HDRS})

# Link libraries
target_link_libraries(${PROJECT_NAME}
    PRIVATE
    gRPC::grpc++
    gRPC::grpc++_reflection
    protobuf::libprotobuf
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
    spdlog::spdlog
    prometheus-cpp::core
    prometheus-cpp::push
    Boost::system
    Boost::filesystem
    TensorflowCC::TensorflowCC
    Eigen3::Eigen
    pthread
)

# Copy configuration files to build directory
configure_file(
    ${CMAKE_CURRENT_SOURCE_DIR}/config/config.json
    ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/config/config.json
    COPYONLY
)

# Add tests
enable_testing()
add_subdirectory(tests)

# Installation
install(TARGETS ${PROJECT_NAME}
    RUNTIME DESTINATION bin
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)

install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/config/
    DESTINATION etc/${PROJECT_NAME}
    FILES_MATCHING PATTERN "*.json"
)

# Copy model files to build directory
install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/models/
    DESTINATION ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/models
    FILES_MATCHING PATTERN "*"
)

# Documentation
find_package(Doxygen)
if(DOXYGEN_FOUND)
    set(DOXYGEN_IN ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in)
    set(DOXYGEN_OUT ${CMAKE_CURRENT_BINARY_DIR}/Doxyfile)
    
    configure_file(${DOXYGEN_IN} ${DOXYGEN_OUT} @ONLY)
    
    add_custom_target(docs
        COMMAND ${DOXYGEN_EXECUTABLE} ${DOXYGEN_OUT}
        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
        COMMENT "Generating API documentation with Doxygen"
        VERBATIM
    )
endif()
#include <iostream>
#include <memory>
#include <string>
#include <csignal>
#include <thread>
#include <chrono>
#include <fstream>
#include <sstream>
#include <grpcpp/grpcpp.h>
#include <grpcpp/health_check_service_interface.h>
#include <grpcpp/ext/proto_server_reflection_plugin.h>
#include <nlohmann/json.hpp>

#include "service/analytics_service_impl.h"
#include "models/model_manager.h"
#include "inference/inference_engine.h"
#include "analytics/analytics_processor.h"
#include "database/database_connection.h"
#include "logging/logger.h"
#include "metrics/metrics_service.h"
#include "visualization/visualization_service.h"

using namespace ai_analytics;

// Global flag for graceful shutdown
std::atomic<bool> running{true};

// Signal handler
void signalHandler(int signal) {
    logging::Logger::getInstance().info("Received signal {}, shutting down...", signal);
    running = false;
}

// Load configuration from file
nlohmann::json loadConfig(const std::string& config_path) {
    try {
        std::ifstream config_file(config_path);
        if (!config_file.is_open()) {
            throw std::runtime_error("Failed to open config file: " + config_path);
        }
        
        nlohmann::json config;
        config_file >> config;
        return config;
    } catch (const std::exception& e) {
        std::cerr << "Error loading configuration: " << e.what() << std::endl;
        return nlohmann::json::object();
    }
}

int main(int argc, char** argv) {
    try {
        // Register signal handlers
        std::signal(SIGINT, signalHandler);
        std::signal(SIGTERM, signalHandler);
        
        // Load configuration
        std::string config_path = "config/config.json";
        if (argc > 1) {
            config_path = argv[1];
        }
        
        auto config = loadConfig(config_path);
        
        // Initialize logger
        logging::Logger::getInstance().initialize(
            "ai-analytics-service",
            logging::LogLevel::INFO,
            config.value("logging", nlohmann::json::object()).value("file_path", "logs/ai-analytics-service.log")
        );
        
        logging::Logger::getInstance().info("AI Analytics Service starting up");
        
        // Initialize metrics
        std::string metrics_host = config.value("metrics", nlohmann::json::object()).value("host", "0.0.0.0");
        int metrics_port = config.value("metrics", nlohmann::json::object()).value("port", 9104);
        
        metrics::MetricsService::getInstance().initialize(
            "ai-analytics-service",
            true,
            metrics_host,
            metrics_port
        );
        
        // Initialize database connection
        std::string db_host = config.value("database", nlohmann::json::object()).value("host", "localhost");
        int db_port = config.value("database", nlohmann::json::object()).value("port", 5432);
        std::string db_name = config.value("database", nlohmann::json::object()).value("name", "analytics_db");
        std::string db_user = config.value("database", nlohmann::json::object()).value("user", "analytics_user");
        std::string db_password = config.value("database", nlohmann::json::object()).value("password", "analytics_password");
        
        auto db_connection = std::make_shared<database::DatabaseConnection>(
            db_host,
            db_port,
            db_name,
            db_user,
            db_password
        );
        
        if (!db_connection->connect()) {
            throw std::runtime_error("Failed to connect to database");
        }
        
        // Initialize model manager
        std::string model_path = config.value("models", nlohmann::json::object()).value("path", "models");
        auto model_manager = std::make_shared<models::ModelManager>(model_path);
        
        if (!model_manager->initialize()) {
            logging::Logger::getInstance().warn("Failed to initialize model manager, will run with limited functionality");
        }
        
        // Initialize inference engine
        auto inference_engine = std::make_shared<inference::InferenceEngine>(model_manager);
        
        if (!inference_engine->initialize()) {
            logging::Logger::getInstance().warn("Failed to initialize inference engine, will run with limited functionality");
        }
        
        // Initialize analytics processor
        auto analytics_processor = std::make_shared<analytics::AnalyticsProcessor>(db_connection);
        
        if (!analytics_processor->initialize()) {
            logging::Logger::getInstance().warn("Failed to initialize analytics processor, will run with limited functionality");
        }
        
        // Initialize visualization service
        auto visualization_service = std::make_shared<visualization::VisualizationService>(db_connection);
        
        if (!visualization_service->initialize()) {
            logging::Logger::getInstance().warn("Failed to initialize visualization service, will run with limited functionality");
        }
        
        // Initialize gRPC server
        std::string server_address = 
            config.value("server", nlohmann::json::object()).value("host", "0.0.0.0") + ":" + 
            std::to_string(config.value("server", nlohmann::json::object()).value("port", 50054));
        
        service::AnalyticsServiceImpl service(
            model_manager,
            inference_engine,
            analytics_processor,
            visualization_service,
            db_connection
        );
        
        grpc::EnableDefaultHealthCheckService(true);
        grpc::reflection::InitProtoReflectionServerBuilderPlugin();
        
        grpc::ServerBuilder builder;
        
        // Set authentication credentials if TLS is enabled
        if (config.value("security", nlohmann::json::object()).value("tls_enabled", false)) {
            std::string key_path = config.value("security", nlohmann::json::object()).value("key_path", "");
            std::string cert_path = config.value("security", nlohmann::json::object()).value("cert_path", "");
            
            std::ifstream key_file(key_path);
            std::ifstream cert_file(cert_path);
            
            if (!key_file.is_open() || !cert_file.is_open()) {
                throw std::runtime_error("Failed to open TLS key or certificate file");
            }
            
            std::stringstream key_buffer, cert_buffer;
            key_buffer << key_file.rdbuf();
            cert_buffer << cert_file.rdbuf();
            
            grpc::SslServerCredentialsOptions ssl_opts;
            ssl_opts.pem_key_cert_pairs.push_back({key_buffer.str(), cert_buffer.str()});
            
            builder.AddListeningPort(server_address, grpc::SslServerCredentials(ssl_opts));
        } else {
            builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());
        }
        
        builder.RegisterService(&service);
        
        // Set server options
        builder.SetMaxReceiveMessageSize(config.value("server", nlohmann::json::object()).value("max_message_size_mb", 100) * 1024 * 1024);
        builder.SetMaxSendMessageSize(config.value("server", nlohmann::json::object()).value("max_message_size_mb", 100) * 1024 * 1024);
        
        // Build and start server
        std::unique_ptr<grpc::Server> server(builder.BuildAndStart());
        logging::Logger::getInstance().info("Server listening on {}", server_address);
        
        // Create performance metrics
        auto& request_counter = metrics::MetricsService::getInstance().createCounter(
            "requests_total",
            "Total number of requests",
            {{"service", "ai-analytics-service"}}
        );
        
        auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
            "request_duration_seconds",
            "Request duration in seconds",
            {{"service", "ai-analytics-service"}}
        );
        
        auto& active_connections = metrics::MetricsService::getInstance().createGauge(
            "active_connections",
            "Number of active connections",
            {{"service", "ai-analytics-service"}}
        );
        
        // Main loop
        while (running) {
            // Update metrics
            active_connections.Set(server->GetNumActiveConnections());
            
            // Sleep to avoid busy waiting
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
        
        // Graceful shutdown
        logging::Logger::getInstance().info("Shutting down server...");
        server->Shutdown();
        logging::Logger::getInstance().info("Server shutting down");
        
        // Shutdown components
        visualization_service->shutdown();
        analytics_processor->shutdown();
        inference_engine->shutdown();
        model_manager->shutdown();
        
        // Shutdown metrics
        metrics::MetricsService::getInstance().shutdown();
        
        // Close database connection
        db_connection->disconnect();
        
        logging::Logger::getInstance().info("AI Analytics Service shut down successfully");
        return 0;
    } catch (const std::exception& e) {
        std::cerr << "Fatal error: " << e.what() << std::endl;
        
        try {
            logging::Logger::getInstance().critical("Fatal error: {}", e.what());
        } catch (...) {
            // Ignore if logging fails
        }
        
        return 1;
    }
}
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <optional>
#include <nlohmann/json.hpp>
#include <tensorflow/c/c_api.h>

namespace ai_analytics {
namespace models {

/**
 * @brief Model type enumeration
 */
enum class ModelType {
    COGNITIVE_STATE,
    PERFORMANCE_PREDICTION,
    ATTENTION_ASSESSMENT,
    ANOMALY_DETECTION,
    ERROR_PREDICTION,
    CUSTOM
};

/**
 * @brief Model metadata
 */
struct ModelMetadata {
    std::string model_id;
    std::string name;
    std::string version;
    std::string description;
    ModelType type;
    std::vector<std::string> input_features;
    std::vector<std::string> output_features;
    std::string framework;  // TensorFlow, PyTorch, etc.
    std::string creation_date;
    std::string author;
    double accuracy;
    std::unordered_map<std::string, std::string> additional_metadata;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Model metadata or nullopt if invalid
     */
    static std::optional<ModelMetadata> fromJson(const nlohmann::json& json);
};

/**
 * @brief Model inference interface
 */
class IModel {
public:
    virtual ~IModel() = default;
    
    /**
     * @brief Get model metadata
     * @return Model metadata
     */
    virtual ModelMetadata getMetadata() const = 0;
    
    /**
     * @brief Load model from file
     * @param model_path Path to model file
     * @return True if loaded successfully
     */
    virtual bool loadFromFile(const std::string& model_path) = 0;
    
    /**
     * @brief Predict using input data
     * @param input_data Input data as JSON
     * @return Prediction result as JSON or nullopt if prediction failed
     */
    virtual std::optional<nlohmann::json> predict(const nlohmann::json& input_data) = 0;
    
    /**
     * @brief Check if model is loaded
     * @return True if loaded
     */
    virtual bool isLoaded() const = 0;
    
    /**
     * @brief Get model version
     * @return Model version
     */
    virtual std::string getVersion() const = 0;
    
    /**
     * @brief Get model type
     * @return Model type
     */
    virtual ModelType getType() const = 0;
    
    /**
     * @brief Get model ID
     * @return Model ID
     */
    virtual std::string getId() const = 0;
};

/**
 * @brief TensorFlow model implementation
 */
class TensorFlowModel : public IModel {
public:
    /**
     * @brief Constructor
     * @param metadata Model metadata
     */
    explicit TensorFlowModel(const ModelMetadata& metadata);
    
    /**
     * @brief Destructor
     */
    ~TensorFlowModel() override;
    
    // IModel implementation
    ModelMetadata getMetadata() const override;
    bool loadFromFile(const std::string& model_path) override;
    std::optional<nlohmann::json> predict(const nlohmann::json& input_data) override;
    bool isLoaded() const override;
    std::string getVersion() const override;
    ModelType getType() const override;
    std::string getId() const override;

private:
    ModelMetadata metadata_;
    TF_Graph* graph_;
    TF_Session* session_;
    bool loaded_;
    
    /**
     * @brief Preprocess input data
     * @param input_data Input data as JSON
     * @return Preprocessed data as TF_Tensor* or nullptr if preprocessing failed
     */
    std::vector<TF_Tensor*> preprocessInput(const nlohmann::json& input_data);
    
    /**
     * @brief Postprocess output data
     * @param output_tensors Output tensors
     * @return Postprocessed data as JSON
     */
    nlohmann::json postprocessOutput(const std::vector<TF_Tensor*>& output_tensors);
    
    /**
     * @brief Free tensors
     * @param tensors Tensors to free
     */
    void freeTensors(const std::vector<TF_Tensor*>& tensors);
};

/**
 * @brief Model factory
 */
class ModelFactory {
public:
    /**
     * @brief Get singleton instance
     * @return Model factory instance
     */
    static ModelFactory& getInstance();
    
    /**
     * @brief Create model
     * @param metadata Model metadata
     * @return Model instance
     */
    std::shared_ptr<IModel> createModel(const ModelMetadata& metadata);
    
    /**
     * @brief Load model
     * @param model_path Path to model file
     * @return Model instance or nullptr if loading failed
     */
    std::shared_ptr<IModel> loadModel(const std::string& model_path);

private:
    ModelFactory() = default;
    ~ModelFactory() = default;
    
    ModelFactory(const ModelFactory&) = delete;
    ModelFactory& operator=(const ModelFactory&) = delete;
};

/**
 * @brief Model repository interface
 */
class IModelRepository {
public:
    virtual ~IModelRepository() = default;
    
    /**
     * @brief Save model
     * @param model Model to save
     * @param model_data Model data
     * @return True if saved successfully
     */
    virtual bool saveModel(
        const ModelMetadata& model,
        const std::vector<uint8_t>& model_data
    ) = 0;
    
    /**
     * @brief Load model
     * @param model_id Model ID
     * @return Model instance or nullptr if loading failed
     */
    virtual std::shared_ptr<IModel> loadModel(const std::string& model_id) = 0;
    
    /**
     * @brief Delete model
     * @param model_id Model ID
     * @return True if deleted successfully
     */
    virtual bool deleteModel(const std::string& model_id) = 0;
    
    /**
     * @brief List models
     * @param type Model type (optional)
     * @return List of model metadata
     */
    virtual std::vector<ModelMetadata> listModels(
        const std::optional<ModelType>& type = std::nullopt
    ) = 0;
    
    /**
     * @brief Get model metadata
     * @param model_id Model ID
     * @return Model metadata or nullopt if not found
     */
    virtual std::optional<ModelMetadata> getModelMetadata(
        const std::string& model_id
    ) = 0;
    
    /**
     * @brief Update model metadata
     * @param metadata Model metadata
     * @return True if updated successfully
     */
    virtual bool updateModelMetadata(
        const ModelMetadata& metadata
    ) = 0;
};

/**
 * @brief File-based model repository
 */
class FileModelRepository : public IModelRepository {
public:
    /**
     * @brief Constructor
     * @param base_path Base path for model storage
     */
    explicit FileModelRepository(const std::string& base_path);
    
    /**
     * @brief Destructor
     */
    ~FileModelRepository() override;
    
    // IModelRepository implementation
    bool saveModel(
        const ModelMetadata& model,
        const std::vector<uint8_t>& model_data
    ) override;
    
    std::shared_ptr<IModel> loadModel(const std::string& model_id) override;
    
    bool deleteModel(const std::string& model_id) override;
    
    std::vector<ModelMetadata> listModels(
        const std::optional<ModelType>& type = std::nullopt
    ) override;
    
    std::optional<ModelMetadata> getModelMetadata(
        const std::string& model_id
    ) override;
    
    bool updateModelMetadata(
        const ModelMetadata& metadata
    ) override;

private:
    std::string base_path_;
    
    /**
     * @brief Get model path
     * @param model_id Model ID
     * @return Model path
     */
    std::string getModelPath(const std::string& model_id) const;
    
    /**
     * @brief Get metadata path
     * @param model_id Model ID
     * @return Metadata path
     */
    std::string getMetadataPath(const std::string& model_id) const;
};

} // namespace models
} // namespace ai_analytics
syntax = "proto3";

package ai_analytics;

// AI & Analytics Service
service AIAnalyticsService {
  // Performance analytics
  rpc AnalyzePerformance (PerformanceRequest) returns (PerformanceAnalysis);
  rpc GetPerformanceTrends (TrendsRequest) returns (TrendsResponse);
  rpc ComparePerformance (ComparisonRequest) returns (ComparisonResponse);
  
  // Cognitive state assessment
  rpc AssessCognitiveState (CognitiveStateRequest) returns (CognitiveStateResponse);
  rpc GetCognitiveStateTimeline (CognitiveTimelineRequest) returns (CognitiveTimelineResponse);
  
  // Predictive analytics
  rpc PredictPerformance (PredictionRequest) returns (PredictionResponse);
  rpc GetRiskFactors (RiskFactorsRequest) returns (RiskFactorsResponse);
  
  // Visualization
  rpc GenerateVisualization (VisualizationRequest) returns (VisualizationResponse);
  
  // Model management
  rpc ListModels (ListModelsRequest) returns (ListModelsResponse);
  rpc GetModelInfo (ModelInfoRequest) returns (ModelInfoResponse);
  rpc TrainModel (TrainModelRequest) returns (TrainModelResponse);
  rpc EvaluateModel (EvaluateModelRequest) returns (EvaluateModelResponse);
}

// Performance request
message PerformanceRequest {
  string trainee_id = 1;
  string course_id = 2;
  string exercise_id = 3;  // Optional
  int64 start_date = 4;  // Milliseconds since epoch
  int64 end_date = 5;  // Milliseconds since epoch
  repeated string metrics = 6;  // Specific metrics to analyze
}

// Performance analysis
message PerformanceAnalysis {
  string trainee_id = 1;
  repeated PerformanceMetric metrics = 2;
  repeated PerformanceInsight insights = 3;
  string summary = 4;
  repeated Recommendation recommendations = 5;
}

// Performance metric
message PerformanceMetric {
  string name = 1;
  string category = 2;
  double value = 3;
  double percentile = 4;  // Percentile relative to peers
  double baseline = 5;  // Baseline or expected value
  double trend = 6;  // Rate of change over time
  repeated HistoricalDataPoint historical_data = 7;
}

// Historical data point
message HistoricalDataPoint {
  int64 timestamp = 1;  // Milliseconds since epoch
  double value = 2;
  string label = 3;  // Optional label for this point
}

// Performance insight
message PerformanceInsight {
  string description = 1;
  string category = 2;
  double confidence = 3;  // 0.0 to 1.0
  string supporting_evidence = 4;
}

// Recommendation
message Recommendation {
  string description = 1;
  string category = 2;
  double expected_impact = 3;  // Expected improvement if followed
  string rationale = 4;
  repeated string suggested_exercises = 5;
}

// Trends request
message TrendsRequest {
  string trainee_id = 1;
  string course_id = 2;
  string metric = 3;
  int64 start_date = 4;  // Milliseconds since epoch
  int64 end_date = 5;  // Milliseconds since epoch
  int32 resolution = 6;  // Data points requested (e.g., 30 for monthly)
  bool include_peer_comparison = 7;
}

// Trends response
message TrendsResponse {
  string metric = 1;
  repeated HistoricalDataPoint data_points = 2;
  repeated HistoricalDataPoint peer_average = 3;  // Only if requested
  string trend_direction = 4;  // IMPROVING, STABLE, DECLINING
  double trend_slope = 5;
  double statistical_significance = 6;  // p-value
}

// Comparison request
message ComparisonRequest {
  string trainee_id = 1;
  string comparison_group = 2;  // PEERS, PREVIOUS_COHORT, TOP_PERFORMERS
  string course_id = 3;
  repeated string metrics = 4;
  int64 start_date = 5;  // Milliseconds since epoch
  int64 end_date = 6;  // Milliseconds since epoch
}

// Comparison response
message ComparisonResponse {
  string trainee_id = 1;
  string comparison_group = 2;
  repeated ComparisonMetric metrics = 3;
  repeated string strengths = 4;
  repeated string improvement_areas = 5;
  string overall_standing = 6;  // e.g., "75th percentile"
}

// Comparison metric
message ComparisonMetric {
  string name = 1;
  double trainee_value = 2;
  double comparison_mean = 3;
  double comparison_median = 4;
  double comparison_stddev = 5;
  double percentile = 6;
  double z_score = 7;
}

// Cognitive state request
message CognitiveStateRequest {
  string trainee_id = 1;
  string session_id = 2;
  repeated SensorData sensor_data = 3;
  string context = 4;  // e.g., "landing_approach", "emergency_procedure"
}

// Sensor data
message SensorData {
  string sensor_type = 1;  // EYE_TRACKING, HEART_RATE, EEG, etc.
  int64 timestamp = 2;  // Milliseconds since epoch
  map<string, double> metrics = 3;  // Sensor-specific metrics
  bytes raw_data = 4;  // Optional raw sensor data
}

// Cognitive state response
message CognitiveStateResponse {
  double workload_level = 1;  // 0.0 to 1.0
  double attention_level = 2;  // 0.0 to 1.0
  double stress_level = 3;  // 0.0 to 1.0
  double fatigue_level = 4;  // 0.0 to 1.0
  repeated CognitiveEvent events = 5;
  map<string, double> additional_metrics = 6;
  double assessment_confidence = 7;  // 0.0 to 1.0
}

// Cognitive event
message CognitiveEvent {
  string event_type = 1;  // ATTENTION_LAPSE, COGNITIVE_OVERLOAD, etc.
  int64 timestamp = 2;  // Milliseconds since epoch
  int64 duration_ms = 3;  // Duration in milliseconds
  double severity = 4;  // 0.0 to 1.0
  string description = 5;
}

// Cognitive timeline request
message CognitiveTimelineRequest {
  string trainee_id = 1;
  string session_id = 2;
  int64 start_time = 3;  // Milliseconds since epoch
  int64 end_time = 4;  // Milliseconds since epoch
  repeated string metrics = 5;  // Specific metrics to include
  int32 resolution_ms = 6;  // Desired time resolution in milliseconds
}

// Cognitive timeline response
message CognitiveTimelineResponse {
  string session_id = 1;
  repeated CognitiveTimePoint time_points = 2;
  repeated CognitiveEvent events = 3;
  repeated CognitivePhase phases = 4;
}

// Cognitive time point
message CognitiveTimePoint {
  int64 timestamp = 1;  // Milliseconds since epoch
  map<string, double> metrics = 2;  // Metrics at this time point
}

// Cognitive phase
message CognitivePhase {
  string phase_name = 1;
  int64 start_time = 2;  // Milliseconds since epoch
  int64 end_time = 3;  // Milliseconds since epoch
  string description = 4;
  map<string, double> average_metrics = 5;
}

// Prediction request
message PredictionRequest {
  string trainee_id = 1;
  string course_id = 2;
  string exercise_id = 3;
  repeated string features = 4;  // Specific features to use for prediction
  string target_metric = 5;  // What to predict
  string model_id = 6;  // Optional specific model to use
}

// Prediction response
message PredictionResponse {
  double predicted_value = 1;
  double confidence = 2;  // 0.0 to 1.0
  double prediction_error = 3;  // Expected error margin
  repeated FeatureImportance feature_importances = 4;
  repeated string factors = 5;  // Factors influencing this prediction
  map<string, double> alternative_scenarios = 6;  // Predicted values under different scenarios
}

// Feature importance
message FeatureImportance {
  string feature_name = 1;
  double importance = 2;  // 0.0 to 1.0
  double feature_value = 3;
  string interpretation = 4;
}

// Risk factors request
message RiskFactorsRequest {
  string trainee_id = 1;
  string course_id = 2;
  int32 top_k = 3;  // Number of risk factors to return
  double threshold = 4;  // Minimum risk score to include
}

// Risk factors response
message RiskFactorsResponse {
  string trainee_id = 1;
  double overall_risk_score = 2;  // 0.0 to 1.0
  repeated RiskFactor risk_factors = 3;
  repeated Recommendation mitigations = 4;
}

// Risk factor
message RiskFactor {
  string name = 1;
  double risk_score = 2;  // 0.0 to 1.0
  string description = 3;
  string evidence = 4;
  string trend = 5;  // INCREASING, STABLE, DECREASING
}

// Visualization request
message VisualizationRequest {
  string visualization_type = 1;  // PERFORMANCE_RADAR, COGNITIVE_TIMELINE, etc.
  string trainee_id = 2;
  string context = 3;  // course_id, session_id, etc.
  map<string, string> parameters = 4;
  string format = 5;  // SVG, PNG, HTML, JSON
}

// Visualization response
message VisualizationResponse {
  string visualization_type = 1;
  string format = 2;
  bytes data = 3;  // Visualization data in the requested format
  string html_snippet = 4;  // Optional HTML for embedding
  map<string, string> metadata = 5;
}

// List models request
message ListModelsRequest {
  string model_type = 1;  // Optional filter by model type
  bool include_metadata = 2;
}

// List models response
message ListModelsResponse {
  repeated ModelInfo models = 1;
}

// Model info request
message ModelInfoRequest {
  string model_id = 1;
  bool include_performance_metrics = 2;
}

// Model info response
message ModelInfoResponse {
  ModelInfo model_info = 1;
}

// Model info
message ModelInfo {
  string model_id = 1;
  string model_type = 2;
  string description = 3;
  string version = 4;
  int64 created_at = 5;  // Milliseconds since epoch
  int64 updated_at = 6;  // Milliseconds since epoch
  repeated string input_features = 7;
  repeated string output_features = 8;
  ModelPerformance performance = 9;
  map<string, string> hyperparameters = 10;
  string training_dataset = 11;
}

// Model performance
message ModelPerformance {
  double accuracy = 1;
  double precision = 2;
  double recall = 3;
  double f1_score = 4;
  double mse = 5;  // Mean squared error
  double mae = 6;  // Mean absolute error
  double r_squared = 7;
  int32 training_samples = 8;
  int32 validation_samples = 9;
}

// Train model request
message TrainModelRequest {
  string model_type = 1;
  string description = 2;
  string dataset_id = 3;
  map<string, string> hyperparameters = 4;
  repeated string features = 5;
  string target = 6;
  double validation_split = 7;  // 0.0 to 1.0
  bool save_model = 8;
}

// Train model response
message TrainModelResponse {
  string model_id = 1;
  bool success = 2;
  string error_message = 3;
  ModelPerformance performance = 4;
  int64 training_time_ms = 5;
}

// Evaluate model request
message EvaluateModelRequest {
  string model_id = 1;
  string dataset_id = 2;  // Optional test dataset
}

// Evaluate model response
message EvaluateModelResponse {
  string model_id = 1;
  ModelPerformance performance = 2;
  repeated PredictionError errors = 3;  // Sample of prediction errors
  string error_analysis = 4;
}

// Prediction error
message PredictionError {
  map<string, double> inputs = 1;
  double predicted_value = 2;
  double actual_value = 3;
  double error = 4;
}
#pragma once

#include "inference/inference_engine.h"
#include <unordered_map>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <queue>
#include <atomic>
#include <chrono>
#include <tensorflow/c/c_api.h>

namespace ai_analytics {
namespace inference {

/**
 * @brief TensorFlow model implementation
 */
class TensorFlowModel : public IModel {
public:
    /**
     * @brief Constructor
     * @param model_path Path to model
     * @param model_id Model ID
     */
    TensorFlowModel(const std::string& model_path, const std::string& model_id);
    
    /**
     * @brief Destructor
     */
    ~TensorFlowModel() override;
    
    // IModel implementation
    ModelMetadata getMetadata() const override;
    bool load() override;
    void unload() override;
    ModelOutput runInference(const ModelInput& input) override;
    std::string runInferenceAsync(const ModelInput& input, InferenceCallback callback) override;
    bool supportsInputType(const std::string& input_type) const override;
    bool supportsOutputType(const std::string& output_type) const override;
    
private:
    /**
     * @brief Convert TensorFlow data type to tensor data type
     * @param tf_type TensorFlow data type
     * @return Tensor data type
     */
    static TensorDataType convertTfDataType(TF_DataType tf_type);
    
    /**
     * @brief Convert tensor data type to TensorFlow data type
     * @param type Tensor data type
     * @return TensorFlow data type
     */
    static TF_DataType convertToTfDataType(TensorDataType type);
    
    /**
     * @brief Convert TensorFlow tensor to internal tensor
     * @param tensor TensorFlow tensor
     * @param name Tensor name
     * @return Internal tensor
     */
    Tensor convertTfTensor(TF_Tensor* tensor, const std::string& name);
    
    /**
     * @brief Convert internal tensor to TensorFlow tensor
     * @param tensor Internal tensor
     * @return TensorFlow tensor
     */
    TF_Tensor* convertToTfTensor(const Tensor& tensor);
    
    /**
     * @brief Process JSON input
     * @param json_input JSON input
     * @return Map of input tensors
     */
    std::map<std::string, Tensor> processJsonInput(const nlohmann::json& json_input);
    
    /**
     * @brief Process binary input
     * @param binary_data Binary data
     * @param parameters Input parameters
     * @return Map of input tensors
     */
    std::map<std::string, Tensor> processBinaryInput(const std::vector<uint8_t>& binary_data, 
                                                   const nlohmann::json& parameters);
    
    /**
     * @brief Convert output tensors to JSON
     * @param output_tensors Output tensors
     * @return JSON output
     */
    nlohmann::json tensorsToJson(const std::map<std::string, Tensor>& output_tensors);
    
    /**
     * @brief Convert output tensors to binary
     * @param output_tensors Output tensors
     * @return Binary output
     */
    std::vector<uint8_t> tensorsToBinary(const std::map<std::string, Tensor>& output_tensors);
    
    std::string model_path_;
    std::string model_id_;
    std::atomic<bool> is_loaded_;
    
    TF_Graph* graph_;
    TF_Session* session_;
    
    std::vector<TensorDef> input_tensor_defs_;
    std::vector<TensorDef> output_tensor_defs_;
    
    ModelMetadata metadata_;
    mutable std::mutex mutex_;
    
    // Statistics
    std::atomic<uint64_t> inference_count_;
    std::atomic<double> total_inference_time_ms_;
    std::chrono::system_clock::time_point load_time_;
};

/**
 * @brief TensorFlow inference engine implementation
 */
class TensorFlowInferenceEngine : public IInferenceEngine {
public:
    /**
     * @brief Constructor
     */
    TensorFlowInferenceEngine();
    
    /**
     * @brief Destructor
     */
    ~TensorFlowInferenceEngine() override;
    
    // IInferenceEngine implementation
    bool initialize(const nlohmann::json& config) override;
    void shutdown() override;
    std::string loadModel(const std::string& model_path, const std::string& model_id = "") override;
    bool unloadModel(const std::string& model_id) override;
    std::shared_ptr<IModel> getModel(const std::string& model_id) override;
    std::vector<ModelMetadata> listModels() override;
    ModelOutput runInference(const ModelInput& input) override;
    std::string runInferenceAsync(const ModelInput& input, InferenceCallback callback) override;
    bool cancelAsyncRequest(const std::string& request_id) override;
    nlohmann::json getCapabilities() const override;
    nlohmann::json getStatistics() const override;
    
private:
    /**
     * @brief Async request
     */
    struct AsyncRequest {
        std::string request_id;
        ModelInput input;
        InferenceCallback callback;
        std::chrono::system_clock::time_point submit_time;
    };
    
    /**
     * @brief Worker thread function
     */
    void workerThread();
    
    /**
     * @brief Generate unique request ID
     * @return Unique request ID
     */
    std::string generateRequestId();
    
    nlohmann::json config_;
    std::unordered_map<std::string, std::shared_ptr<TensorFlowModel>> models_;
    mutable std::mutex models_mutex_;
    
    // Async processing
    std::queue<AsyncRequest> request_queue_;
    std::mutex queue_mutex_;
    std::condition_variable queue_condition_;
    std::vector<std::thread> worker_threads_;
    std::atomic<bool> running_;
    
    // Statistics
    std::atomic<uint64_t> total_inference_count_;
    std::atomic<double> total_inference_time_ms_;
    std::chrono::system_clock::time_point start_time_;
};

} // namespace inference
} // namespace ai_analytics
# backend/ai-modules/document-understanding/document_analyzer.py
import os
import sys
import logging
import json
import tempfile
from typing import List, Dict, Any, Optional, Tuple, Union
import numpy as np
import pandas as pd
from pathlib import Path
import torch
from transformers import (
    AutoTokenizer, 
    AutoModelForSequenceClassification,
    AutoModelForTokenClassification,
    AutoModelForQuestionAnswering,
    pipeline
)
from sklearn.metrics.pairwise import cosine_similarity
import pytesseract
from PIL import Image
import fitz  # PyMuPDF
import docx
import openpyxl
import re

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('document_analyzer.log')
    ]
)
logger = logging.getLogger(__name__)

class DocumentAnalyzer:
    """
    Main class for document understanding and analysis using transformer models.
    Handles document classification, entity extraction, summarization, and 
    relationship extraction.
    """
    
    def __init__(self, models_dir: str = 'models'):
        """
        Initialize the DocumentAnalyzer with models for various NLP tasks.
        
        Args:
            models_dir: Directory where models are stored or will be downloaded
        """
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True, parents=True)
        
        # Initialize model paths
        self.model_paths = {
            'classification': self.models_dir / 'classification',
            'ner': self.models_dir / 'ner',
            'qa': self.models_dir / 'qa',
            'summarization': self.models_dir / 'summarization',
            'embeddings': self.models_dir / 'embeddings'
        }
        
        # Create model directories
        for path in self.model_paths.values():
            path.mkdir(exist_ok=True, parents=True)
        
        # Initialize tokenizers and models
        self._initialize_models()
        
        # Define entity types
        self.entity_types = {
            'PER': 'Person',
            'ORG': 'Organization',
            'LOC': 'Location',
            'DATE': 'Date',
            'REGULATION': 'Regulation',
            'COMPETENCY': 'Competency',
            'LEARNING_OBJECTIVE': 'LearningObjective',
            'EQUIPMENT': 'Equipment',
            'PROCEDURE': 'Procedure',
            'SAFETY': 'Safety'
        }
        
        # Regulatory mapping patterns
        self.regulatory_patterns = {
            'FAA': r'(?:14\s*CFR\s*Part\s*\d+|FAR\s*\d+)(?:[.-]\d+)*',
            'EASA': r'(?:EASA\s*Part[-\s](?:[\w]+))(?:[.-]\d+)*',
            'ICAO': r'(?:ICAO\s*Annex\s*\d+)(?:[.-]\d+)*',
            'TCCA': r'(?:CAR\s*\d+)(?:[.-]\d+)*',
            'CASA': r'(?:CASR\s*Part\s*\d+)(?:[.-]\d+)*'
        }
        
    def _initialize_models(self):
        """Initialize all required NLP models"""
        logger.info("Initializing models...")
        
        try:
            # Document classification model
            self.classification_tokenizer = AutoTokenizer.from_pretrained(
                'distilbert-base-uncased', 
                cache_dir=self.model_paths['classification']
            )
            
            # For actual implementation, use a fine-tuned model
            # In this example, we're using a generic model
            self.classification_model = AutoModelForSequenceClassification.from_pretrained(
                'distilbert-base-uncased',
                cache_dir=self.model_paths['classification'],
                num_labels=10  # Number of document categories
            )
            
            # Named Entity Recognition model
            self.ner_tokenizer = AutoTokenizer.from_pretrained(
                'dbmdz/bert-large-cased-finetuned-conll03-english',
                cache_dir=self.model_paths['ner']
            )
            
            self.ner_model = AutoModelForTokenClassification.from_pretrained(
                'dbmdz/bert-large-cased-finetuned-conll03-english',
                cache_dir=self.model_paths['ner']
            )
            
            # Question Answering model for relationship extraction
            self.qa_tokenizer = AutoTokenizer.from_pretrained(
                'deepset/roberta-base-squad2',
                cache_dir=self.model_paths['qa']
            )
            
            self.qa_model = AutoModelForQuestionAnswering.from_pretrained(
                'deepset/roberta-base-squad2',
                cache_dir=self.model_paths['qa']
            )
            
            # Create pipelines
            self.ner_pipeline = pipeline(
                'ner',
                model=self.ner_model,
                tokenizer=self.ner_tokenizer,
                aggregation_strategy="simple"
            )
            
            self.qa_pipeline = pipeline(
                'question-answering',
                model=self.qa_model,
                tokenizer=self.qa_tokenizer
            )
            
            self.summarization_pipeline = pipeline(
                'summarization',
                model='facebook/bart-large-cnn',
                tokenizer='facebook/bart-large-cnn',
                device=0 if torch.cuda.is_available() else -1
            )
            
            logger.info("Models initialized successfully")
            
        except Exception as e:
            logger.error(f"Error initializing models: {str(e)}")
            raise
    
    def extract_text(self, file_path: Union[str, Path]) -> str:
        """
        Extract text content from various document formats
        
        Args:
            file_path: Path to the document file
            
        Returns:
            Extracted text content as a string
        """
        file_path = Path(file_path)
        file_extension = file_path.suffix.lower()
        
        try:
            # PDF extraction
            if file_extension == '.pdf':
                text = self._extract_from_pdf(file_path)
            
            # Word document extraction
            elif file_extension in ['.docx', '.doc']:
                text = self._extract_from_docx(file_path)
            
            # Excel spreadsheet extraction
            elif file_extension in ['.xlsx', '.xls']:
                text = self._extract_from_excel(file_path)
            
            # PowerPoint extraction
            elif file_extension in ['.pptx', '.ppt']:
                # For simplicity, we're not implementing PPT extraction in this example
                # In a real implementation, you would use a library like python-pptx
                text = "PowerPoint extraction not implemented in this example"
            
            # Plain text extraction
            elif file_extension in ['.txt', '.csv', '.json', '.md']:
                with open(file_path, 'r', encoding='utf-8', errors='replace') as file:
                    text = file.read()
            
            # Image extraction (using OCR)
            elif file_extension in ['.jpg', '.jpeg', '.png', '.tiff', '.bmp']:
                text = self._extract_from_image(file_path)
            
            else:
                logger.warning(f"Unsupported file format: {file_extension}")
                text = ""
                
            return text
            
        except Exception as e:
            logger.error(f"Error extracting text from {file_path}: {str(e)}")
            return ""
    
    def _extract_from_pdf(self, file_path: Path) -> str:
        """Extract text from PDF documents"""
        text_content = []
        
        try:
            # Open the PDF
            pdf_document = fitz.open(file_path)
            
            # Extract text from each page
            for page_num in range(pdf_document.page_count):
                page = pdf_document.load_page(page_num)
                text_content.append(page.get_text())
            
            return "\n\n".join(text_content)
            
        except Exception as e:
            logger.error(f"Error in PDF extraction: {str(e)}")
            return ""
    
    def _extract_from_docx(self, file_path: Path) -> str:
        """Extract text from Word documents"""
        try:
            doc = docx.Document(file_path)
            full_text = []
            
            # Extract text from paragraphs
            for para in doc.paragraphs:
                full_text.append(para.text)
            
            # Extract text from tables
            for table in doc.tables:
                for row in table.rows:
                    row_text = [cell.text for cell in row.cells]
                    full_text.append(" | ".join(row_text))
            
            return "\n".join(full_text)
            
        except Exception as e:
            logger.error(f"Error in DOCX extraction: {str(e)}")
            return ""
    
    def _extract_from_excel(self, file_path: Path) -> str:
        """Extract text from Excel spreadsheets"""
        try:
            workbook = openpyxl.load_workbook(file_path, data_only=True)
            texts = []
            
            # Process each worksheet
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                sheet_texts = []
                
                # Add sheet name as a header
                sheet_texts.append(f"Sheet: {sheet_name}")
                
                # Extract cell values
                for row in sheet.iter_rows():
                    row_values = [str(cell.value) if cell.value is not None else "" for cell in row]
                    if any(row_values):  # Skip empty rows
                        sheet_texts.append(" | ".join(row_values))
                
                texts.append("\n".join(sheet_texts))
            
            return "\n\n".join(texts)
            
        except Exception as e:
            logger.error(f"Error in Excel extraction: {str(e)}")
            return ""
    
    def _extract_from_image(self, file_path: Path) -> str:
        """Extract text from images using OCR"""
        try:
            image = Image.open(file_path)
            text = pytesseract.image_to_string(image)
            return text
            
        except Exception as e:
            logger.error(f"Error in image extraction: {str(e)}")
            return ""
    
    def classify_document(self, text: str) -> Dict[str, float]:
        """
        Classify the document into predefined categories
        
        Args:
            text: Document text content
            
        Returns:
            Dictionary of category labels and confidence scores
        """
        try:
            # Truncate text to fit model's maximum length
            max_length = self.classification_tokenizer.model_max_length
            tokens = self.classification_tokenizer(text, truncation=True, max_length=max_length, return_tensors="pt")
            
            # Get model predictions
            with torch.no_grad():
                outputs = self.classification_model(**tokens)
                predictions = outputs.logits.softmax(dim=1).squeeze().tolist()
            
            # Map to category labels (in real implementation, these would be your actual categories)
            categories = [
                "Regulations", "Training_Manual", "SOP", "Assessment_Form",
                "Syllabus", "Technical_Manual", "Research_Paper", "Checklist",
                "Flight_Manual", "Miscellaneous"
            ]
            
            # Create result dictionary
            results = {categories[i]: float(predictions[i]) for i in range(len(categories))}
            
            # Sort by confidence
            results = dict(sorted(results.items(), key=lambda x: x[1], reverse=True))
            
            return results
            
        except Exception as e:
            logger.error(f"Error in document classification: {str(e)}")
            return {"error": str(e)}
    
    def extract_entities(self, text: str, entity_types: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        Extract named entities from document text
        
        Args:
            text: Document text content
            entity_types: Optional list of entity types to extract
            
        Returns:
            List of extracted entities with type, text, and position
        """
        try:
            # Process text in chunks to handle long documents
            chunk_size = 512
            overlap = 50
            chunks = self._split_text_into_chunks(text, chunk_size, overlap)
            
            all_entities = []
            offset = 0
            
            for chunk in chunks:
                # Run NER pipeline on chunk
                chunk_entities = self.ner_pipeline(chunk)
                
                # Process entities
                for entity in chunk_entities:
                    # Adjust start and end positions based on offset
                    entity_adjusted = {
                        'entity_type': entity['entity_group'],
                        'text': entity['word'],
                        'start': entity['start'] + offset,
                        'end': entity['end'] + offset,
                        'score': float(entity['score'])
                    }
                    
                    all_entities.append(entity_adjusted)
                
                # Update offset for next chunk
                offset += len(chunk) - overlap
            
            # Filter by entity types if specified
            if entity_types:
                all_entities = [e for e in all_entities if e['entity_type'] in entity_types]
            
            # Extract aviation-specific entities using regex patterns
            aviation_entities = self._extract_aviation_entities(text)
            all_entities.extend(aviation_entities)
            
            # Handle overlapping entities (keep highest confidence)
            all_entities = self._resolve_entity_overlaps(all_entities)
            
            return all_entities
            
        except Exception as e:
            logger.error(f"Error in entity extraction: {str(e)}")
            return []
    
    def _extract_aviation_entities(self, text: str) -> List[Dict[str, Any]]:
        """Extract aviation-specific entities using regex patterns"""
        entities = []
        
        # Extract regulatory references
        for reg_body, pattern in self.regulatory_patterns.items():
            for match in re.finditer(pattern, text):
                entities.append({
                    'entity_type': 'REGULATION',
                    'text': match.group(0),
                    'start': match.start(),
                    'end': match.end(),
                    'score': 0.95,  # High confidence for regex matches
                    'regulatory_body': reg_body
                })
        
        # Learning objectives patterns (simplified example)
        lo_pattern = r'(?:Learning Objective|LO)[\s:]+([A-Z0-9]+(?:\.[A-Z0-9]+)*)\s*[-:]\s*(.*?)(?:\.|$)'
        for match in re.finditer(lo_pattern, text, re.DOTALL):
            entities.append({
                'entity_type': 'LEARNING_OBJECTIVE',
                'text': match.group(0),
                'id': match.group(1).strip(),
                'description': match.group(2).strip(),
                'start': match.start(),
                'end': match.end(),
                'score': 0.9
            })
        
        # Competency patterns (simplified example)
        comp_pattern = r'(?:Competency|Skill)[\s:]+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s*[-:]\s*(.*?)(?:\.|$)'
        for match in re.finditer(comp_pattern, text, re.DOTALL):
            entities.append({
                'entity_type': 'COMPETENCY',
                'text': match.group(0),
                'name': match.group(1).strip(),
                'description': match.group(2).strip(),
                'start': match.start(),
                'end': match.end(),
                'score': 0.9
            })
        
        return entities
    
    def _resolve_entity_overlaps(self, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Resolve overlapping entity spans by keeping highest confidence entity"""
        if not entities:
            return []
        
        # Sort entities by start position
        sorted_entities = sorted(entities, key=lambda e: (e['start'], -e['end']))
        
        resolved_entities = []
        current = sorted_entities[0]
        
        for next_entity in sorted_entities[1:]:
            # Check if entities overlap
            if next_entity['start'] < current['end']:
                # Keep entity with highest confidence score
                if next_entity['score'] > current['score']:
                    current = next_entity
            else:
                resolved_entities.append(current)
                current = next_entity
        
        resolved_entities.append(current)
        return resolved_entities
    
    def extract_relationships(self, text: str, entities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Extract relationships between entities
        
        Args:
            text: Document text content
            entities: List of extracted entities
            
        Returns:
            List of relationships between entities
        """
        try:
            relationships = []
            
            # Only process if we have multiple entities
            if len(entities) < 2:
                return relationships
            
            # Generate questions for entity pairs
            for i, entity1 in enumerate(entities):
                for entity2 in enumerate(entities[i+1:]):
                    # Skip if entities are of the same type
                    if entity1['entity_type'] == entity2['entity_type']:
                        continue
                    
                    # Extract context around the entities
                    context = self._extract_context(text, entity1, entity2)
                    
                    # Generate questions based on entity types
                    questions = self._generate_relationship_questions(entity1, entity2)
                    
                    for question in questions:
                        # Use QA model to extract relationship
                        qa_result = self.qa_pipeline(question=question, context=context)
                        
                        # If we have a good answer with reasonable confidence
                        if qa_result['score'] > 0.5:
                            relationships.append({
                                'source_entity': entity1['text'],
                                'source_type': entity1['entity_type'],
                                'target_entity': entity2['text'],
                                'target_type': entity2['entity_type'],
                                'relationship': qa_result['answer'],
                                'confidence': float(qa_result['score'])
                            })
            
            return relationships
            
        except Exception as e:
            logger.error(f"Error in relationship extraction: {str(e)}")
            return []
    
    def _extract_context(self, text: str, entity1: Dict[str, Any], entity2: Dict[str, Any]) -> str:
        """Extract text context surrounding two entities"""
        # Determine the span of text containing both entities
        start = min(entity1['start'], entity2['start'])
        end = max(entity1['end'], entity2['end'])
        
        # Add context window (200 characters before and after)
        context_start = max(0, start - 200)
        context_end = min(len(text), end + 200)
        
        return text[context_start:context_end]
    
    def _generate_relationship_questions(self, entity1: Dict[str, Any], entity2: Dict[str, Any]) -> List[str]:
        """Generate questions to discover relationships between entities"""
        questions = []
        
        # Base templates for different entity type combinations
        templates = {
            ('REGULATION', 'LEARNING_OBJECTIVE'): [
                f"What is the relationship between {entity1['text']} and {entity2['text']}?",
                f"How does {entity1['text']} regulate or apply to {entity2['text']}?"
            ],
            ('COMPETENCY', 'LEARNING_OBJECTIVE'): [
                f"How does {entity1['text']} relate to {entity2['text']}?",
                f"What skills from {entity1['text']} are needed for {entity2['text']}?"
            ],
            ('PERSON', 'ORGANIZATION'): [
                f"What is {entity1['text']}'s role in {entity2['text']}?",
                f"How is {entity1['text']} affiliated with {entity2['text']}?"
            ]
        }
        
        # Get questions based on entity type pair
        type_pair = (entity1['entity_type'], entity2['entity_type'])
        reverse_pair = (entity2['entity_type'], entity1['entity_type'])
        
        if type_pair in templates:
            questions.extend(templates[type_pair])
        elif reverse_pair in templates:
            # Reverse the questions if entity types are in opposite order
            for question in templates[reverse_pair]:
                # Swap entity mentions in the question
                modified = question.replace(entity2['text'], "ENTITY2_TMP")
                modified = modified.replace(entity1['text'], entity2['text'])
                modified = modified.replace("ENTITY2_TMP", entity1['text'])
                questions.append(modified)
        else:
            # Generic questions for other entity type combinations
            questions = [
                f"What is the relationship between {entity1['text']} and {entity2['text']}?",
                f"How do {entity1['text']} and {entity2['text']} relate to each other?"
            ]
        
        return questions
    
    def generate_summary(self, text: str, max_length: int = 150, min_length: int = 50) -> str:
        """
        Generate a concise summary of the document
        
        Args:
            text: Document text content
            max_length: Maximum length of summary in tokens
            min_length: Minimum length of summary in tokens
            
        Returns:
            Generated summary text
        """
        try:
            # Split long documents into chunks
            if len(text) > 10000:
                chunks = self._split_text_into_chunks(text, 4000, 200)
                summaries = []
                
                # Summarize each chunk
                for chunk in chunks:
                    chunk_summary = self.summarization_pipeline(
                        chunk,
                        max_length=max(30, max_length // len(chunks)),
                        min_length=min(20, min_length // len(chunks)),
                        do_sample=False
                    )[0]['summary_text']
                    
                    summaries.append(chunk_summary)
                
                # Combine chunk summaries and summarize again
                combined_summary = " ".join(summaries)
                final_summary = self.summarization_pipeline(
                    combined_summary,
                    max_length=max_length,
                    min_length=min_length,
                    do_sample=False
                )[0]['summary_text']
                
                return final_summary
            else:
                # For shorter documents, summarize directly
                summary = self.summarization_pipeline(
                    text,
                    max_length=max_length,
                    min_length=min_length,
                    do_sample=False
                )[0]['summary_text']
                
                return summary
                
        except Exception as e:
            logger.error(f"Error in document summarization: {str(e)}")
            return "Error generating summary."
    
    def map_to_regulations(self, text: str, regulatory_bodies: List[str] = None) -> List[Dict[str, Any]]:
        """
        Map document content to relevant regulatory standards
        
        Args:
            text: Document text content
            regulatory_bodies: Optional list of regulatory bodies to focus on
            
        Returns:
            List of regulatory mappings
        """
        try:
            # Default to all regulatory bodies if none specified
            if not regulatory_bodies:
                regulatory_bodies = list(self.regulatory_patterns.keys())
            
            mappings = []
            
            # Extract regulatory references using regex patterns
            for reg_body in regulatory_bodies:
                if reg_body in self.regulatory_patterns:
                    pattern = self.regulatory_patterns[reg_body]
                    
                    for match in re.finditer(pattern, text):
                        # Get context around the regulation reference
                        start_pos = max(0, match.start() - 200)
                        end_pos = min(len(text), match.end() + 200)
                        context = text[start_pos:end_pos]
                        
                        # Extract section and subsection information
                        full_reference = match.group(0)
                        
                        # Attempt to parse regulation ID and section
                        regulation_id = full_reference
                        section_id = ""
                        subsection_id = ""
                        
                        # Try to split into regulation and section parts
                        parts = re.split(r'[.-]', full_reference, 1)
                        if len(parts) > 1:
                            regulation_id = parts[0]
                            section_parts = parts[1].split('.', 1)
                            section_id = section_parts[0]
                            if len(section_parts) > 1:
                                subsection_id = section_parts[1]
                        
                        # Extract a brief description from the context
                        # In a real implementation, you would use NLP to get a better description
                        description = context.replace(full_reference, "").strip()
                        if len(description) > 150:
                            description = description[:150] + "..."
                        
                        mapping = {
                            'regulatory_body': reg_body,
                            'regulation_id': regulation_id.strip(),
                            'section_id': section_id.strip(),
                            'subsection_id': subsection_id.strip(),
                            'description': description,
                            'confidence_score': 0.95,  # High confidence for regex matches
                            'context': context
                        }
                        
                        mappings.append(mapping)
            
            # If no explicit references were found, try to infer relationships
            if len(mappings) == 0:
                # This would use more sophisticated NLP in a real implementation
                # For now, we'll add a placeholder for the concept
                for reg_body in regulatory_bodies:
                    if self._text_mentions_regulatory_concepts(text, reg_body):
                        mapping = {
                            'regulatory_body': reg_body,
                            'regulation_id': 'Inferred',
                            'section_id': '',
                            'subsection_id': '',
                            'description': f'Content appears related to {reg_body} regulations, but no specific reference found.',
                            'confidence_score': 0.6,  # Lower confidence for inferred relationships
                            'context': ''
                        }
                        mappings.append(mapping)
            
            return mappings
            
        except Exception as e:
            logger.error(f"Error in regulatory mapping: {str(e)}")
            return []
    
    def _text_mentions_regulatory_concepts(self, text: str, regulatory_body: str) -> bool:
        """Check if text mentions concepts related to a regulatory body"""
        # Simple keyword-based check (would be more sophisticated in real implementation)
        regulatory_keywords = {
            'FAA': ['federal aviation', 'faa', 'airman', 'airworthiness', 'certification'],
            'EASA': ['european aviation', 'easa', 'aircrew', 'air operations'],
            'ICAO': ['international civil aviation', 'icao', 'standards and recommended practices'],
            'TCCA': ['transport canada', 'tcca', 'canadian aviation regulations'],
            'CASA': ['civil aviation safety authority', 'casa', 'australian air regulations']
        }
        
        if regulatory_body in regulatory_keywords:
            text_lower = text.lower()
            return any(keyword in text_lower for keyword in regulatory_keywords[regulatory_body])
        
        return False
    
    def _split_text_into_chunks(self, text: str, chunk_size: int, overlap: int) -> List[str]:
        """Split text into overlapping chunks"""
        if not text:
            return []
            
        chunks = []
        start = 0
        
        while start < len(text):
            # Calculate end position for this chunk
            end = min(start + chunk_size, len(text))
            
            # If we're not at the end of the text, try to find a good break point
            if end < len(text):
                # Look for a period, question mark, or exclamation point followed by space or newline
                for i in range(end - 1, start + chunk_size // 2, -1):
                    if i < len(text) and text[i] in '.!?\n' and (i + 1 == len(text) or text[i + 1].isspace()):
                        end = i + 1
                        break
            
            # Extract the chunk
            chunks.append(text[start:end])
            
            # Move to next chunk with overlap
            start = end - overlap
        
        return chunks
    
    def process_document(self, file_path: str) -> Dict[str, Any]:
        """
        Process a document and extract all relevant information
        
        Args:
            file_path: Path to the document file
            
        Returns:
            Dictionary containing all extracted information
        """
        try:
            # Extract text from document
            logger.info(f"Processing document: {file_path}")
            text = self.extract_text(file_path)
            
            if not text:
                return {"error": "Failed to extract text from document"}
            
            # Process document
            result = {
                "file_path": file_path,
                "text_length": len(text),
                "processing_time": {}
            }
            
            # Document classification
            start_time = time.time()
            result["classification"] = self.classify_document(text)
            result["processing_time"]["classification"] = time.time() - start_time
            
            # Entity extraction
            start_time = time.time()
            result["entities"] = self.extract_entities(text)
            result["processing_time"]["entity_extraction"] = time.time() - start_time
            
            # Relationship extraction
            start_time = time.time()
            result["relationships"] = self.extract_relationships(text, result["entities"])
            result["processing_time"]["relationship_extraction"] = time.time() - start_time
            
            # Document summarization
            start_time = time.time()
            result["summary"] = self.generate_summary(text)
            result["processing_time"]["summarization"] = time.time() - start_time
            
            # Regulatory mapping
            start_time = time.time()
            result["regulatory_mappings"] = self.map_to_regulations(text)
            result["processing_time"]["regulatory_mapping"] = time.time() - start_time
            
            # Calculate total processing time
            result["total_processing_time"] = sum(result["processing_time"].values())
            
            logger.info(f"Document processing completed in {result['total_processing_time']:.2f} seconds")
            return result
            
        except Exception as e:
            logger.error(f"Error processing document: {str(e)}")
            return {"error": str(e)}

# Main function for testing
if __name__ == "__main__":
    import time
    
    # Initialize document analyzer
    analyzer = DocumentAnalyzer()
    
    # Process a sample document
    if len(sys.argv) > 1:
        file_path = sys.argv[1]
        start_time = time.time()
        result = analyzer.process_document(file_path)
        
        # Print results
        print(f"Processing completed in {time.time() - start_time:.2f} seconds")
        print(f"Classification: {result.get('classification', {})}")
        print(f"Entity count: {len(result.get('entities', []))}")
        print(f"Relationship count: {len(result.get('relationships', []))}")
        print(f"Summary: {result.get('summary', '')}")
        print(f"Regulatory mappings: {len(result.get('regulatory_mappings', []))}")
    else:
        print("Please provide a file path")

# backend/ai-modules/performance-prediction/trainee_performance_predictor.py
import os
import sys
import logging
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
from typing import List, Dict, Any, Optional, Tuple, Union
from datetime import datetime, timedelta
from pathlib import Path
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
import xgboost as xgb
from prophet import Prophet

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('trainee_performance_predictor.log')
    ]
)
logger = logging.getLogger(__name__)

class TraineePerformancePredictor:
    """
    Predicts trainee performance based on historical assessment data
    and other relevant features. Supports multiple prediction models.
    """
    
    def __init__(self, models_dir: str = 'models'):
        """
        Initialize the performance predictor
        
        Args:
            models_dir: Directory to store trained models
        """
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True, parents=True)
        
        # Available model types
        self.model_types = {
            'linear': LinearRegression,
            'random_forest': RandomForestRegressor,
            'gradient_boosting': GradientBoostingRegressor,
            'xgboost': xgb.XGBRegressor,
            'neural_network': self._create_neural_network,
            'prophet': Prophet
        }
        
        # Initialize dictionary for trained models
        self.models = {}
        
        # Feature preprocessing
        self.scalers = {}
        self.encoders = {}
        
        # Training history
        self.training_history = {}
        
        # Competency/skill areas
        self.competency_areas = [
            "technical_knowledge",
            "flight_planning",
            "aircraft_handling",
            "navigation",
            "communication",
            "decision_making",
            "situational_awareness",
            "crew_coordination",
            "emergency_procedures",
            "overall_performance"
        ]
    
    def prepare_data(self, data: pd.DataFrame, 
                    target_col: str, 
                    feature_cols: List[str] = None, 
                    categorical_cols: List[str] = None,
                    time_col: str = None,
                    trainee_id_col: str = 'trainee_id') -> Tuple[pd.DataFrame, pd.Series]:
        """
        Prepare data for model training by preprocessing features
        
        Args:
            data: DataFrame containing training data
            target_col: Name of the target column to predict
            feature_cols: List of feature column names (if None, use all except target)
            categorical_cols: List of categorical column names for one-hot encoding
            time_col: Name of timestamp column (for time-based features)
            trainee_id_col: Name of trainee ID column
            
        Returns:
            Tuple of (processed features DataFrame, target values Series)
        """
        # Make a copy to avoid modifying the original dataframe
        df = data.copy()
        
        # Convert target to numeric if needed
        if df[target_col].dtype == 'object':
            try:
                df[target_col] = pd.to_numeric(df[target_col])
            except ValueError:
                # Map string values to numeric (e.g., Unsatisfactory=1, Satisfactory=3)
                value_map = {
                    'unsatisfactory': 1,
                    'needs_improvement': 2,
                    'satisfactory': 3,
                    'exemplary': 4
                }
                df[target_col] = df[target_col].str.lower().map(value_map)
        
        # Set feature columns if not provided
        if feature_cols is None:
            feature_cols = [col for col in df.columns if col not in [target_col, trainee_id_col]]
        
        # Process time column if provided
        if time_col:
            # Ensure datetime format
            if df[time_col].dtype != 'datetime64[ns]':
                df[time_col] = pd.to_datetime(df[time_col])
            
            # Extract time-based features
            df['hour_of_day'] = df[time_col].dt.hour
            df['day_of_week'] = df[time_col].dt.dayofweek
            df['month'] = df[time_col].dt.month
            df['year'] = df[time_col].dt.year
            
            # Add training progression feature (days since first assessment)
            trainee_first_dates = df.groupby(trainee_id_col)[time_col].min()
            df['days_since_first_assessment'] = df.apply(
                lambda row: (row[time_col] - trainee_first_dates[row[trainee_id_col]]).days,
                axis=1
            )
            
            # Add to feature columns
            feature_cols.extend(['hour_of_day', 'day_of_week', 'month', 'year', 'days_since_first_assessment'])
        
        # Scale numeric features
        numeric_cols = [col for col in feature_cols if col not in (categorical_cols or [])]
        if numeric_cols:
            self.scalers['numeric'] = StandardScaler()
            df[numeric_cols] = self.scalers['numeric'].fit_transform(df[numeric_cols])
        
        # One-hot encode categorical features
        if categorical_cols:
            self.encoders['categorical'] = OneHotEncoder(sparse=False, handle_unknown='ignore')
            encoded_cats = self.encoders['categorical'].fit_transform(df[categorical_cols])
            
            # Create DataFrame with encoded categorical features
            cat_feature_names = []
            for i, col in enumerate(categorical_cols):
                cats = self.encoders['categorical'].categories_[i]
                cat_feature_names.extend([f"{col}_{cat}" for cat in cats])
            
            encoded_df = pd.DataFrame(encoded_cats, columns=cat_feature_names, index=df.index)
            
            # Concatenate with numeric features
            X = pd.concat([df[numeric_cols], encoded_df], axis=1)
        else:
            X = df[numeric_cols]
        
        # Return features and target
        y = df[target_col]
        
        return X, y
    
    def train_model(self, data: pd.DataFrame, 
                   target_col: str, 
                   model_type: str = 'gradient_boosting',
                   feature_cols: List[str] = None,
                   categorical_cols: List[str] = None, 
                   time_col: str = None,
                   trainee_id_col: str = 'trainee_id',
                   model_params: Dict[str, Any] = None,
                   test_size: float = 0.2,
                   model_name: str = None) -> Dict[str, Any]:
        """
        Train a model to predict trainee performance
        
        Args:
            data: DataFrame containing training data
            target_col: Name of the target column to predict
            model_type: Type of model to train ('linear', 'random_forest', etc.)
            feature_cols: List of feature column names
            categorical_cols: List of categorical column names
            time_col: Name of timestamp column
            trainee_id_col: Name of trainee ID column
            model_params: Dictionary of model parameters
            test_size: Proportion of data to use for testing
            model_name: Name to identify the model (if None, generate one)
            
        Returns:
            Dictionary with training results and metrics
        """
        try:
            # Generate model name if not provided
            if model_name is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                model_name = f"{model_type}_{target_col}_{timestamp}"
            
            logger.info(f"Training model '{model_name}' of type '{model_type}'")
            
            # Prepare data
            X, y = self.prepare_data(
                data, 
                target_col, 
                feature_cols, 
                categorical_cols, 
                time_col,
                trainee_id_col
            )
            
            # Split data into train and test sets
            # For time series data, a temporal split would be more appropriate
            if time_col:
                # Temporal split (sort by time and split)
                if data[time_col].dtype != 'datetime64[ns]':
                    data[time_col] = pd.to_datetime(data[time_col])
                
                # Sort by time
                sorted_indices = data[time_col].sort_values().index
                train_size = int((1 - test_size) * len(sorted_indices))
                train_indices = sorted_indices[:train_size]
                test_indices = sorted_indices[train_size:]
                
                X_train, X_test = X.loc[train_indices], X.loc[test_indices]
                y_train, y_test = y.loc[train_indices], y.loc[test_indices]
            else:
                # Random split
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=42
                )
            
            # Handle special case for Prophet
            if model_type == 'prophet':
                return self._train_prophet_model(
                    data, time_col, target_col, trainee_id_col, model_name, model_params
                )
            
            # Initialize model with parameters
            if model_params is None:
                model_params = {}
            
            if model_type == 'neural_network':
                # Neural network requires special handling
                input_dim = X_train.shape[1]
                model, model_info = self._train_neural_network(
                    X_train, y_train, X_test, y_test, input_dim, model_params, model_name
                )
            else:
                # Initialize and train standard ML model
                model_class = self.model_types.get(model_type)
                if model_class is None:
                    raise ValueError(f"Unknown model type: {model_type}")
                
                model = model_class(**model_params)
                model.fit(X_train, y_train)
                
                # Make predictions and calculate metrics
                y_pred_train = model.predict(X_train)
                y_pred_test = model.predict(X_test)
                
                # Calculate performance metrics
                metrics = {
                    'mse_train': mean_squared_error(y_train, y_pred_train),
                    'mse_test': mean_squared_error(y_test, y_pred_test),
                    'mae_train': mean_absolute_error(y_train, y_pred_train),
                    'mae_test': mean_absolute_error(y_test, y_pred_test),
                    'r2_train': r2_score(y_train, y_pred_train),
                    'r2_test': r2_score(y_test, y_pred_test)
                }
                
                # Feature importance if available
                feature_importance = None
                if hasattr(model, 'feature_importances_'):
                    feature_importance = dict(zip(X.columns, model.feature_importances_))
                
                model_info = {
                    'model_type': model_type,
                    'target_col': target_col,
                    'feature_cols': list(X.columns),
                    'metrics': metrics,
                    'feature_importance': feature_importance,
                    'train_samples': len(X_train),
                    'test_samples': len(X_test)
                }
            
            # Save model
            self.models[model_name] = {
                'model': model,
                'info': model_info,
                'scalers': self.scalers.copy(),
                'encoders': self.encoders.copy()
            }
            
            # Save model to disk
            self._save_model(model_name)
            
            logger.info(f"Model '{model_name}' trained successfully. "
                       f"Test MSE: {model_info['metrics']['mse_test']:.4f}, "
                       f"Test R: {model_info['metrics']['r2_test']:.4f}")
            
            return model_info
            
        except Exception as e:
            logger.error(f"Error training model: {str(e)}")
            raise
    
    def _train_neural_network(self, X_train, y_train, X_test, y_test, 
                             input_dim, model_params, model_name):
        """Train a PyTorch neural network model"""
        # Default parameters
        default_params = {
            'hidden_layers': [64, 32],
            'dropout_rate': 0.2,
            'learning_rate': 0.001,
            'batch_size': 64,
            'epochs': 100,
            'patience': 10  # For early stopping
        }
        
        # Update with user-provided parameters
        params = {**default_params, **(model_params or {})}
        
        # Create model architecture
        model = self._create_neural_network(
            input_dim=input_dim,
            hidden_layers=params['hidden_layers'],
            dropout_rate=params['dropout_rate']
        )
        
        # Convert data to PyTorch tensors
        X_train_tensor = torch.FloatTensor(X_train.values)
        y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)
        X_test_tensor = torch.FloatTensor(X_test.values)
        y_test_tensor = torch.FloatTensor(y_test.values).view(-1, 1)
        
        # Create data loaders
        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
        train_loader = DataLoader(
            train_dataset,
            batch_size=params['batch_size'],
            shuffle=True
        )
        
        # Define loss function and optimizer
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])
        
        # Training loop
        epochs = params['epochs']
        patience = params['patience']
        best_val_loss = float('inf')
        no_improve_count = 0
        training_losses = []
        validation_losses = []
        
        for epoch in range(epochs):
            # Training phase
            model.train()
            train_loss = 0.0
            
            for inputs, targets in train_loader:
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                loss.backward()
                optimizer.step()
                train_loss += loss.item()
            
            avg_train_loss = train_loss / len(train_loader)
            training_losses.append(avg_train_loss)
            
            # Validation phase
            model.eval()
            with torch.no_grad():
                val_outputs = model(X_test_tensor)
                val_loss = criterion(val_outputs, y_test_tensor).item()
                validation_losses.append(val_loss)
            
            # Early stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                no_improve_count = 0
                # Save best model
                torch.save(model.state_dict(), 
                          self.models_dir / f"{model_name}_best.pt")
            else:
                no_improve_count += 1
                if no_improve_count >= patience:
                    logger.info(f"Early stopping at epoch {epoch+1}")
                    break
            
            if (epoch + 1) % 10 == 0:
                logger.info(f"Epoch {epoch+1}/{epochs} - "
                           f"Train Loss: {avg_train_loss:.4f}, "
                           f"Val Loss: {val_loss:.4f}")
        
        # Load best model
        model.load_state_dict(torch.load(self.models_dir / f"{model_name}_best.pt"))
        
        # Final evaluation
        model.eval()
        with torch.no_grad():
            y_pred_train = model(X_train_tensor).numpy().flatten()
            y_pred_test = model(X_test_tensor).numpy().flatten()
        
        # Calculate metrics
        metrics = {
            'mse_train': mean_squared_error(y_train, y_pred_train),
            'mse_test': mean_squared_error(y_test, y_pred_test),
            'mae_train': mean_absolute_error(y_train, y_pred_train),
            'mae_test': mean_absolute_error(y_test, y_pred_test),
            'r2_train': r2_score(y_train, y_pred_train),
            'r2_test': r2_score(y_test, y_pred_test)
        }
        
        model_info = {
            'model_type': 'neural_network',
            'target_col': y_train.name,
            'feature_cols': list(X_train.columns),
            'metrics': metrics,
            'feature_importance': None,  # Neural networks don't have direct feature importance
            'train_samples': len(X_train),
            'test_samples': len(X_test),
            'architecture': {
                'input_dim': input_dim,
                'hidden_layers': params['hidden_layers'],
                'dropout_rate': params['dropout_rate']
            },
            'training_history': {
                'training_losses': training_losses,
                'validation_losses': validation_losses,
                'epochs': epoch + 1  # Actual number of epochs trained
            }
        }
        
        return model, model_info
    
    def _create_neural_network(self, input_dim, hidden_layers=[64, 32], dropout_rate=0.2):
        """Create a PyTorch neural network model"""
        layers = []
        
        # Input layer
        layers.append(nn.Linear(input_dim, hidden_layers[0]))
        layers.append(nn.ReLU())
        layers.append(nn.Dropout(dropout_rate))
        
        # Hidden layers
        for i in range(len(hidden_layers) - 1):
            layers.append(nn.Linear(hidden_layers[i], hidden_layers[i+1]))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(dropout_rate))
        
        # Output layer
        layers.append(nn.Linear(hidden_layers[-1], 1))
        
        return nn.Sequential(*layers)
    
    def _train_prophet_model(self, data, time_col, target_col, 
                            trainee_id_col, model_name, model_params):
        """Train a Prophet time series model for each trainee"""
        # Prophet requires specific column names
        if time_col is None:
            raise ValueError("Prophet models require a time column")
        
        # Default parameters
        default_params = {
            'changepoint_prior_scale': 0.05,
            'seasonality_prior_scale': 10.0,
            'holidays_prior_scale': 10.0,
            'seasonality_mode': 'additive',
            'yearly_seasonality': True,
            'weekly_seasonality': True,
            'daily_seasonality': False,
            'forecast_periods': 30  # Number of periods to forecast
        }
        
        # Update with user-provided parameters
        params = {**default_params, **(model_params or {})}
        
        # Prepare data for Prophet
        prophet_data = data.copy()
        
        # Convert time column
        if prophet_data[time_col].dtype != 'datetime64[ns]':
            prophet_data[time_col] = pd.to_datetime(prophet_data[time_col])
        
        # Train model for each trainee
        trainee_models = {}
        metrics = {}
        all_forecasts = []
        
        unique_trainees = prophet_data[trainee_id_col].unique()
        
        for trainee_id in unique_trainees:
            # Filter data for this trainee
            trainee_data = prophet_data[prophet_data[trainee_id_col] == trainee_id].copy()
            
            # Skip if not enough data
            if len(trainee_data) < 5:  # Need at least 5 data points
                logger.warning(f"Skipping trainee {trainee_id}: Not enough data points")
                continue
            
            # Prepare dataframe with Prophet's required columns
            prophet_df = pd.DataFrame({
                'ds': trainee_data[time_col],
                'y': trainee_data[target_col]
            })
            
            # Sort by date
            prophet_df = prophet_df.sort_values('ds')
            
            # Train-test split
            train_size = int(0.8 * len(prophet_df))
            train_df = prophet_df.iloc[:train_size]
            test_df = prophet_df.iloc[train_size:]
            
            # Initialize and train model
            model = Prophet(
                changepoint_prior_scale=params['changepoint_prior_scale'],
                seasonality_prior_scale=params['seasonality_prior_scale'],
                holidays_prior_scale=params['holidays_prior_scale'],
                seasonality_mode=params['seasonality_mode'],
                yearly_seasonality=params['yearly_seasonality'],
                weekly_seasonality=params['weekly_seasonality'],
                daily_seasonality=params['daily_seasonality']
            )
            
            # Add regressors if needed
            # (In a real implementation, you would add relevant features as regressors)
            
            # Fit model
            model.fit(train_df)
            
            # Make predictions for test set
            future = test_df[['ds']].copy()
            forecast = model.predict(future)
            
            # Calculate metrics
            y_true = test_df['y'].values
            y_pred = forecast['yhat'].values
            
            trainee_metrics = {
                'mse': mean_squared_error(y_true, y_pred),
                'mae': mean_absolute_error(y_true, y_pred),
                'r2': r2_score(y_true, y_pred) if len(y_true) > 1 else float('nan')
            }
            
            # Store model and metrics
            trainee_models[trainee_id] = model
            metrics[trainee_id] = trainee_metrics
            
            # Generate forecast for future periods
            future_periods = params['forecast_periods']
            last_date = prophet_df['ds'].max()
            future_dates = pd.date_range(
                start=last_date + timedelta(days=1),
                periods=future_periods,
                freq='D'
            )
            
            future_df = pd.DataFrame({'ds': future_dates})
            future_forecast = model.predict(future_df)
            
            # Add to combined forecasts
            forecast_data = {
                'trainee_id': trainee_id,
                'dates': future_forecast['ds'].values,
                'forecast': future_forecast['yhat'].values,
                'forecast_lower': future_forecast['yhat_lower'].values,
                'forecast_upper': future_forecast['yhat_upper'].values
            }
            all_forecasts.append(forecast_data)
        
        # Calculate overall metrics
        overall_metrics = {
            'mse_avg': np.mean([m['mse'] for m in metrics.values()]),
            'mae_avg': np.mean([m['mae'] for m in metrics.values()]),
            'r2_avg': np.mean([m['r2'] for m in metrics.values() if not np.isnan(m['r2'])])
        }
        
        model_info = {
            'model_type': 'prophet',
            'target_col': target_col,
            'time_col': time_col,
            'metrics': {
                'overall': overall_metrics,
                'per_trainee': metrics
            },
            'trainee_count': len(trainee_models),
            'parameters': params,
            'forecasts': all_forecasts
        }
        
        # Save models
        self.models[model_name] = {
            'model': trainee_models,
            'info': model_info
        }
        
        self._save_model(model_name)
        
        logger.info(f"Prophet model '{model_name}' trained for {len(trainee_models)} trainees. "
                   f"Average MSE: {overall_metrics['mse_avg']:.4f}")
        
        return model_info
    
    def predict(self, model_name: str, data: pd.DataFrame, 
               trainee_id_col: str = 'trainee_id',
               include_confidence_intervals: bool = False) -> pd.DataFrame:
        """
        Make predictions using a trained model
        
        Args:
            model_name: Name of the trained model to use
            data: DataFrame with features for prediction
            trainee_id_col: Name of trainee ID column
            include_confidence_intervals: Whether to include confidence intervals
            
        Returns:
            DataFrame with predictions
        """
        try:
            # Check if model exists
            if model_name not in self.models:
                # Try to load from disk
                if not self._load_model(model_name):
                    raise ValueError(f"Model '{model_name}' not found")
            
            model_info = self.models[model_name]['info']
            model = self.models[model_name]['model']
            
            # Special handling for Prophet models
            if model_info['model_type'] == 'prophet':
                return self._predict_with_prophet(
                    model, data, model_info, trainee_id_col, include_confidence_intervals
                )
            
            # For other models, prepare features
            scalers = self.models[model_name]['scalers']
            encoders = self.models[model_name]['encoders']
            
            # Get feature columns from model info
            feature_cols = model_info['feature_cols']
            
            # Prepare input features
            X = data.copy()
            
            # Apply transformations using saved scalers and encoders
            if 'numeric' in scalers:
                numeric_cols = [col for col in feature_cols if col in X.columns]
                X[numeric_cols] = scalers['numeric'].transform(X[numeric_cols])
            
            if 'categorical' in encoders:
                # Get categorical columns
                categorical_cols = []
                for col in X.columns:
                    if any(f.startswith(f"{col}_") for f in feature_cols):
                        categorical_cols.append(col)
                
                if categorical_cols:
                    encoded_cats = encoders['categorical'].transform(X[categorical_cols])
                    
                    # Create DataFrame with encoded categorical features
                    cat_feature_names = []
                    for i, col in enumerate(categorical_cols):
                        cats = encoders['categorical'].categories_[i]
                        cat_feature_names.extend([f"{col}_{cat}" for cat in cats])
                    
                    encoded_df = pd.DataFrame(encoded_cats, columns=cat_feature_names, index=X.index)
                    
                    # Select only columns that were in the training data
                    valid_cat_cols = [col for col in cat_feature_names if col in feature_cols]
                    
                    # Concatenate with numeric features
                    numeric_cols = [col for col in feature_cols if col in X.columns]
                    X = pd.concat([X[numeric_cols], encoded_df[valid_cat_cols]], axis=1)
            
            # Ensure all required features are present
            missing_features = [col for col in feature_cols if col not in X.columns]
            if missing_features:
                logger.warning(f"Missing features: {missing_features}")
                # Add missing features with zeros
                for col in missing_features:
                    X[col] = 0
            
            # Select only features used in training
            X = X[feature_cols]
            
            # Make predictions
            if model_info['model_type'] == 'neural_network':
                # Neural network needs tensor conversion
                X_tensor = torch.FloatTensor(X.values)
                model.eval()
                with torch.no_grad():
                    predictions = model(X_tensor).numpy().flatten()
            else:
                predictions = model.predict(X)
            
            # Create results dataframe
            results = pd.DataFrame(index=data.index)
            results['prediction'] = predictions
            
            # Add confidence intervals if requested and available
            if include_confidence_intervals:
                # Add placeholder intervals (real implementation would calculate these)
                # Different models would have different ways to calculate confidence intervals
                results['lower_bound'] = predictions - 0.5
                results['upper_bound'] = predictions + 0.5
            
            return results
            
        except Exception as e:
            logger.error(f"Error making predictions: {str(e)}")
            raise
    
    def _predict_with_prophet(self, model, data, model_info, trainee_id_col, include_confidence_intervals):
        """Make predictions using Prophet models"""
        # Check required columns
        time_col = model_info['time_col']
        if time_col not in data.columns:
            raise ValueError(f"Time column '{time_col}' not found in data")
        
        if trainee_id_col not in data.columns:
            raise ValueError(f"Trainee ID column '{trainee_id_col}' not found in data")
        
        # Convert time column
        if data[time_col].dtype != 'datetime64[ns]':
            data[time_col] = pd.to_datetime(data[time_col])
        
        # Make predictions for each trainee
        results = []
        
        for trainee_id, trainee_data in data.groupby(trainee_id_col):
            # Skip if model not available for this trainee
            if trainee_id not in model:
                logger.warning(f"No model available for trainee {trainee_id}")
                continue
            
            # Prepare dataframe with Prophet's required columns
            prophet_df = pd.DataFrame({
                'ds': trainee_data[time_col]
            })
            
            # Make predictions
            trainee_model = model[trainee_id]
            forecast = trainee_model.predict(prophet_df)
            
            # Create results dataframe
            trainee_results = trainee_data.copy()
            trainee_results['prediction'] = forecast['yhat'].values
            
            if include_confidence_intervals:
                trainee_results['lower_bound'] = forecast['yhat_lower'].values
                trainee_results['upper_bound'] = forecast['yhat_upper'].values
            
            results.append(trainee_results)
        
        # Combine results
        if results:
            return pd.concat(results)
        else:
            # Return empty dataframe with correct columns
            columns = list(data.columns) + ['
# Return empty dataframe with correct columns
            columns = list(data.columns) + ['prediction']
            if include_confidence_intervals:
                columns.extend(['lower_bound', 'upper_bound'])
            return pd.DataFrame(columns=columns)
    
    def generate_intervention_suggestions(self, model_name: str, 
                                         trainee_data: pd.DataFrame,
                                         threshold: float = 0.8) -> List[Dict[str, Any]]:
        """
        Generate suggestions for interventions based on predicted performance
        
        Args:
            model_name: Name of the trained model to use
            trainee_data: DataFrame with trainee data
            threshold: Threshold for triggering interventions (0.0-1.0)
            
        Returns:
            List of intervention suggestions
        """
        try:
            # Make predictions
            predictions = self.predict(model_name, trainee_data)
            
            # Merge with trainee data
            results = trainee_data.copy()
            results['prediction'] = predictions['prediction']
            
            # Generate suggestions based on predicted performance
            suggestions = []
            
            # Group by trainee
            for trainee_id, trainee_results in results.groupby('trainee_id'):
                # Check if performance below threshold
                # In a real implementation, this would depend on how performance is measured
                # Here, we'll assume higher is better (e.g., competency rating on 1-4 scale)
                
                average_prediction = trainee_results['prediction'].mean()
                
                # Determine competency areas to target
                # In a real implementation, you would use a more sophisticated approach
                if 'competency_area' in trainee_results.columns:
                    # Group by competency area
                    area_predictions = trainee_results.groupby('competency_area')['prediction'].mean()
                    
                    # Find areas below threshold
                    weak_areas = area_predictions[area_predictions < threshold * 4]  # Assuming 4 is max score
                    
                    if not weak_areas.empty:
                        # Generate suggestions for each weak area
                        for area, score in weak_areas.items():
                            suggestion = {
                                'trainee_id': trainee_id,
                                'competency_area': area,
                                'current_score': score,
                                'threshold': threshold * 4,
                                'intervention_type': self._get_intervention_type(area, score),
                                'description': self._get_intervention_description(area, score),
                                'priority': self._calculate_priority(score, threshold * 4)
                            }
                            suggestions.append(suggestion)
                else:
                    # Generate general suggestion if competency areas not available
                    if average_prediction < threshold * 4:
                        suggestion = {
                            'trainee_id': trainee_id,
                            'competency_area': 'general',
                            'current_score': average_prediction,
                            'threshold': threshold * 4,
                            'intervention_type': 'additional_training',
                            'description': 'Recommend additional training sessions based on overall performance',
                            'priority': self._calculate_priority(average_prediction, threshold * 4)
                        }
                        suggestions.append(suggestion)
            
            # Sort suggestions by priority
            suggestions.sort(key=lambda x: x['priority'], reverse=True)
            
            return suggestions
            
        except Exception as e:
            logger.error(f"Error generating intervention suggestions: {str(e)}")
            return []
    
    def _get_intervention_type(self, area: str, score: float) -> str:
        """Determine appropriate intervention type based on competency area and score"""
        # This is a simplified implementation
        # In a real system, this would be more sophisticated
        
        if score < 2.0:  # Critical intervention needed
            intervention_types = {
                'technical_knowledge': 'intensive_training',
                'flight_planning': 'structured_exercises',
                'aircraft_handling': 'simulator_sessions',
                'navigation': 'review_sessions',
                'communication': 'communication_workshop',
                'decision_making': 'scenario_training',
                'situational_awareness': 'awareness_exercises',
                'crew_coordination': 'team_exercises',
                'emergency_procedures': 'emergency_drills',
                'general': 'comprehensive_review'
            }
        else:  # Moderate intervention needed
            intervention_types = {
                'technical_knowledge': 'focused_study',
                'flight_planning': 'planning_exercises',
                'aircraft_handling': 'practice_sessions',
                'navigation': 'navigation_exercises',
                'communication': 'communication_practice',
                'decision_making': 'decision_exercises',
                'situational_awareness': 'awareness_training',
                'crew_coordination': 'coordination_practice',
                'emergency_procedures': 'procedure_review',
                'general': 'targeted_practice'
            }
        
        return intervention_types.get(area, 'additional_training')
    
    def _get_intervention_description(self, area: str, score: float) -> str:
        """Generate description for intervention based on competency area and score"""
        # This is a simplified implementation
        # In a real system, this would be more sophisticated
        
        if area == 'technical_knowledge':
            return f"Recommend focused study on technical knowledge areas. Current score: {score:.2f}"
        elif area == 'flight_planning':
            return f"Provide additional flight planning exercises with instructor feedback. Current score: {score:.2f}"
        elif area == 'aircraft_handling':
            return f"Schedule additional simulator sessions focusing on aircraft handling. Current score: {score:.2f}"
        elif area == 'navigation':
            return f"Conduct targeted navigation exercises and review. Current score: {score:.2f}"
        elif area == 'communication':
            return f"Practice radio communications and ATC interactions. Current score: {score:.2f}"
        elif area == 'decision_making':
            return f"Provide scenario-based training to improve decision making. Current score: {score:.2f}"
        elif area == 'situational_awareness':
            return f"Conduct exercises to enhance situational awareness. Current score: {score:.2f}"
        elif area == 'crew_coordination':
            return f"Provide CRM training and multi-crew exercises. Current score: {score:.2f}"
        elif area == 'emergency_procedures':
            return f"Review and practice emergency procedures. Current score: {score:.2f}"
        else:
            return f"Recommend additional training based on overall performance. Current score: {score:.2f}"
    
    def _calculate_priority(self, score: float, threshold: float) -> int:
        """Calculate priority for intervention (1-5, with 5 being highest priority)"""
        # Calculate gap between current score and threshold
        gap = threshold - score
        
        if gap <= 0:
            return 0  # No intervention needed
        elif gap < 0.5:
            return 1  # Low priority
        elif gap < 1.0:
            return 2  # Medium-low priority
        elif gap < 1.5:
            return 3  # Medium priority
        elif gap < 2.0:
            return 4  # Medium-high priority
        else:
            return 5  # High priority
    
    def evaluate_model(self, model_name: str, test_data: pd.DataFrame, 
                      target_col: str) -> Dict[str, Any]:
        """
        Evaluate model performance on test data
        
        Args:
            model_name: Name of the trained model to use
            test_data: DataFrame with test data
            target_col: Name of target column with actual values
            
        Returns:
            Dictionary with evaluation metrics
        """
        try:
            # Make predictions
            predictions = self.predict(model_name, test_data)
            
            # Calculate metrics
            y_true = test_data[target_col].values
            y_pred = predictions['prediction'].values
            
            metrics = {
                'mse': mean_squared_error(y_true, y_pred),
                'mae': mean_absolute_error(y_true, y_pred),
                'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
                'r2': r2_score(y_true, y_pred),
                'sample_count': len(y_true)
            }
            
            # Calculate additional statistics
            metrics['mean_true'] = np.mean(y_true)
            metrics['mean_pred'] = np.mean(y_pred)
            metrics['std_true'] = np.std(y_true)
            metrics['std_pred'] = np.std(y_pred)
            
            # Calculate residuals
            residuals = y_true - y_pred
            metrics['mean_residual'] = np.mean(residuals)
            metrics['std_residual'] = np.std(residuals)
            
            logger.info(f"Model '{model_name}' evaluation - "
                       f"MSE: {metrics['mse']:.4f}, "
                       f"R: {metrics['r2']:.4f}")
            
            return metrics
            
        except Exception as e:
            logger.error(f"Error evaluating model: {str(e)}")
            return {'error': str(e)}
    
    def _save_model(self, model_name: str):
        """Save a trained model to disk"""
        model_data = self.models[model_name]
        
        # Create model directory
        model_dir = self.models_dir / model_name
        model_dir.mkdir(exist_ok=True, parents=True)
        
        try:
            # Save model info
            with open(model_dir / 'info.json', 'w') as f:
                # Convert numpy types to Python native types
                info_dict = self._convert_to_serializable(model_data['info'])
                json.dump(info_dict, f, indent=2)
            
            # Save model based on type
            model_type = model_data['info']['model_type']
            
            if model_type == 'prophet':
                # Save each Prophet model
                prophet_models = model_data['model']
                os.makedirs(model_dir / 'prophet_models', exist_ok=True)
                
                for trainee_id, prophet_model in prophet_models.items():
                    model_path = model_dir / 'prophet_models' / f'{trainee_id}.json'
                    # Prophet has built-in serialization
                    with open(model_path, 'w') as f:
                        prophet_model.serialize_posterior_samples(f)
            
            elif model_type == 'neural_network':
                # Save PyTorch model
                torch.save(model_data['model'].state_dict(), model_dir / 'model.pt')
                # Save architecture info
                with open(model_dir / 'architecture.json', 'w') as f:
                    json.dump(model_data['info']['architecture'], f, indent=2)
            
            else:
                # Use pickle for other model types
                with open(model_dir / 'model.pkl', 'wb') as f:
                    pickle.dump(model_data['model'], f)
            
            # Save preprocessors
            if 'scalers' in model_data:
                with open(model_dir / 'scalers.pkl', 'wb') as f:
                    pickle.dump(model_data['scalers'], f)
            
            if 'encoders' in model_data:
                with open(model_dir / 'encoders.pkl', 'wb') as f:
                    pickle.dump(model_data['encoders'], f)
            
            logger.info(f"Model '{model_name}' saved successfully")
            return True
            
        except Exception as e:
            logger.error(f"Error saving model '{model_name}': {str(e)}")
            return False
    
    def _load_model(self, model_name: str) -> bool:
        """Load a trained model from disk"""
        model_dir = self.models_dir / model_name
        
        if not model_dir.exists():
            logger.warning(f"Model directory '{model_name}' not found")
            return False
        
        try:
            # Load model info
            with open(model_dir / 'info.json', 'r') as f:
                model_info = json.load(f)
            
            # Load model based on type
            model_type = model_info['model_type']
            
            if model_type == 'prophet':
                # Load Prophet models
                prophet_models = {}
                prophet_dir = model_dir / 'prophet_models'
                
                if prophet_dir.exists():
                    for model_file in prophet_dir.glob('*.json'):
                        trainee_id = model_file.stem
                        prophet_model = Prophet()
                        with open(model_file, 'r') as f:
                            prophet_model.deserialize_posterior_samples(f)
                        prophet_models[trainee_id] = prophet_model
                
                model = prophet_models
            
            elif model_type == 'neural_network':
                # Load architecture info
                with open(model_dir / 'architecture.json', 'r') as f:
                    architecture = json.load(f)
                
                # Create neural network with same architecture
                model = self._create_neural_network(
                    input_dim=architecture['input_dim'],
                    hidden_layers=architecture['hidden_layers'],
                    dropout_rate=architecture['dropout_rate']
                )
                
                # Load state dict
                model.load_state_dict(torch.load(model_dir / 'model.pt'))
                model.eval()  # Set to evaluation mode
            
            else:
                # Load pickled model
                with open(model_dir / 'model.pkl', 'rb') as f:
                    model = pickle.load(f)
            
            # Load preprocessors
            scalers = {}
            encoders = {}
            
            if (model_dir / 'scalers.pkl').exists():
                with open(model_dir / 'scalers.pkl', 'rb') as f:
                    scalers = pickle.load(f)
            
            if (model_dir / 'encoders.pkl').exists():
                with open(model_dir / 'encoders.pkl', 'rb') as f:
                    encoders = pickle.load(f)
            
            # Store in models dictionary
            self.models[model_name] = {
                'model': model,
                'info': model_info,
                'scalers': scalers,
                'encoders': encoders
            }
            
            logger.info(f"Model '{model_name}' loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"Error loading model '{model_name}': {str(e)}")
            return False
    
    def _convert_to_serializable(self, obj):
        """Convert object to JSON-serializable form"""
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, dict):
            return {key: self._convert_to_serializable(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_to_serializable(item) for item in obj]
        else:
            return obj

# Example usage
if __name__ == "__main__":
    # Sample data generation
    def generate_sample_data(n_trainees=20, n_samples_per_trainee=10):
        np.random.seed(42)
        
        data = []
        start_date = datetime(2023, 1, 1)
        
        for trainee_id in range(1, n_trainees + 1):
            # Generate trainee attributes
            trainee_experience = np.random.choice(['low', 'medium', 'high'])
            trainee_age = np.random.randint(22, 45)
            
            for i in range(n_samples_per_trainee):
                # Generate assessment date
                assessment_date = start_date + timedelta(days=i * 7 + np.random.randint(0, 5))
                
                # Generate competency scores (1-4 scale)
                base_score = 2.0 + np.random.normal(0, 0.5)
                base_score += 0.5 if trainee_experience == 'high' else (0.2 if trainee_experience == 'medium' else 0)
                
                # Add time trend (improvement over time)
                time_effect = i * 0.05
                
                for competency in [
                    'technical_knowledge', 'flight_planning', 'aircraft_handling',
                    'navigation', 'communication', 'decision_making',
                    'situational_awareness', 'crew_coordination', 'emergency_procedures'
                ]:
                    # Add competency-specific variation
                    comp_variation = np.random.normal(0, 0.3)
                    
                    # Calculate final score and clamp between 1-4
                    score = max(1.0, min(4.0, base_score + time_effect + comp_variation))
                    
                    data.append({
                        'trainee_id': f'trainee_{trainee_id}',
                        'assessment_date': assessment_date,
                        'competency_area': competency,
                        'score': round(score, 1),
                        'instructor_id': f'instructor_{np.random.randint(1, 6)}',
                        'trainee_experience': trainee_experience,
                        'trainee_age': trainee_age,
                        'aircraft_type': np.random.choice(['C172', 'PA28', 'BE58']),
                        'weather_conditions': np.random.choice(['VMC', 'IMC', 'Marginal'])
                    })
        
        return pd.DataFrame(data)
    
    # Generate sample data
    df = generate_sample_data()
    print(f"Generated {len(df)} sample records")
    
    # Initialize predictor
    predictor = TraineePerformancePredictor()
    
    # Split data
    train_data = df.sample(frac=0.8, random_state=42)
    test_data = df.drop(train_data.index)
    
    # Train model
    model_name = "trainee_model_gb"
    result = predictor.train_model(
        data=train_data,
        target_col='score',
        model_type='gradient_boosting',
        feature_cols=['trainee_experience', 'trainee_age', 'aircraft_type', 'weather_conditions'],
        categorical_cols=['trainee_experience', 'aircraft_type', 'weather_conditions'],
        time_col='assessment_date',
        trainee_id_col='trainee_id',
        model_name=model_name
    )
    
    print(f"Model training results: MSE={result['metrics']['mse_test']:.4f}, R={result['metrics']['r2_test']:.4f}")
    
    # Make predictions
    predictions = predictor.predict(model_name, test_data)
    print("Sample predictions:")
    print(predictions.head())
    
    # Generate intervention suggestions
    suggestions = predictor.generate_intervention_suggestions(model_name, test_data, threshold=0.75)
    print(f"Generated {len(suggestions)} intervention suggestions")
    
    # Evaluate model
    metrics = predictor.evaluate_model(model_name, test_data, 'score')
    print(f"Evaluation metrics: MSE={metrics['mse']:.4f}, R={metrics['r2']:.4f}")

# backend/ai-modules/automation-workflows/workflow_engine.py
import os
import sys
import logging
import json
import yaml
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable, Union
from pathlib import Path
import threading
import queue
import schedule
from dataclasses import dataclass, field
import importlib.util
import inspect
import traceback
import re

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('workflow_engine.log')
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class WorkflowStep:
    """Represents a single step in a workflow"""
    id: str
    type: str
    name: str
    description: str
    parameters: Dict[str, Any] = field(default_factory=dict)
    condition: Optional[str] = None
    timeout_seconds: int = 300
    retry_count: int = 0
    retry_delay_seconds: int = 30
    
    # Execution state
    status: str = "pending"
    result: Any = None
    error: Optional[str] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None

@dataclass
class WorkflowInstance:
    """Represents a running instance of a workflow"""
    id: str
    workflow_id: str
    name: str
    description: str
    status: str = "pending"
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    variables: Dict[str, Any] = field(default_factory=dict)
    steps: List[WorkflowStep] = field(default_factory=list)
    current_step_index: int = 0
    logs: List[Dict[str, Any]] = field(default_factory=list)

class WorkflowEngine:
    """
    Engine for automating workflows in the Advanced Pilot Training Platform.
    Supports custom step types, conditional execution, scheduling, and more.
    """
    
    def __init__(self, workflows_dir: str = 'workflows', plugins_dir: str = 'plugins'):
        """
        Initialize the workflow engine
        
        Args:
            workflows_dir: Directory containing workflow definitions
            plugins_dir: Directory containing custom step implementations
        """
        self.workflows_dir = Path(workflows_dir)
        self.plugins_dir = Path(plugins_dir)
        
        # Create directories if they don't exist
        self.workflows_dir.mkdir(exist_ok=True, parents=True)
        self.plugins_dir.mkdir(exist_ok=True, parents=True)
        
        # Initialize data stores
        self.workflow_definitions = {}
        self.workflow_instances = {}
        self.scheduled_workflows = {}
        
        # Initialize worker thread for executing workflows
        self.work_queue = queue.Queue()
        self.worker_thread = threading.Thread(target=self._worker_thread_func, daemon=True)
        self.running = False
        
        # Register built-in step types
        self.step_handlers = {}
        self._register_builtin_step_types()
        
        # Load workflow definitions
        self._load_workflow_definitions()
        
        # Load plugins
        self._load_plugins()
    
    def start(self):
        """Start the workflow engine and worker thread"""
        if not self.running:
            self.running = True
            self.worker_thread.start()
            logger.info("Workflow engine started")
            
            # Start the scheduler in a separate thread
            threading.Thread(target=self._run_scheduler, daemon=True).start()
    
    def stop(self):
        """Stop the workflow engine and worker thread"""
        if self.running:
            self.running = False
            self.work_queue.put(None)  # Signal worker thread to exit
            self.worker_thread.join(timeout=5.0)
            logger.info("Workflow engine stopped")
    
    def _worker_thread_func(self):
        """Worker thread function to process workflow steps"""
        while self.running:
            try:
                # Get next work item from queue
                work_item = self.work_queue.get(timeout=1.0)
                
                # Check for exit signal
                if work_item is None:
                    break
                
                # Process work item
                instance_id, step_index = work_item
                self._execute_workflow_step(instance_id, step_index)
                
                # Mark work item as done
                self.work_queue.task_done()
                
            except queue.Empty:
                # No work available, just continue
                pass
            except Exception as e:
                logger.error(f"Error in worker thread: {str(e)}")
                traceback.print_exc()
    
    def _run_scheduler(self):
        """Run the scheduler for scheduled workflows"""
        while self.running:
            schedule.run_pending()
            time.sleep(1)
    
    def _register_builtin_step_types(self):
        """Register built-in step types"""
        self.register_step_type("script", self._handle_script_step)
        self.register_step_type("http_request", self._handle_http_request_step)
        self.register_step_type("database_query", self._handle_database_query_step)
        self.register_step_type("python", self._handle_python_step)
        self.register_step_type("condition", self._handle_condition_step)
        self.register_step_type("delay", self._handle_delay_step)
        self.register_step_type("notification", self._handle_notification_step)
        self.register_step_type("document_generation", self._handle_document_generation_step)
    
    def _load_workflow_definitions(self):
        """Load workflow definitions from the workflows directory"""
        if not self.workflows_dir.exists():
            logger.warning(f"Workflows directory {self.workflows_dir} does not exist")
            return
        
        # Find all YAML and JSON files in the directory
        workflow_files = list(self.workflows_dir.glob("*.yaml"))
        workflow_files.extend(self.workflows_dir.glob("*.yml"))
        workflow_files.extend(self.workflows_dir.glob("*.json"))
        
        for file_path in workflow_files:
            try:
                # Load workflow definition
                with open(file_path, 'r') as f:
                    if file_path.suffix in ['.yaml', '.yml']:
                        workflow_def = yaml.safe_load(f)
                    else:
                        workflow_def = json.load(f)
                
                # Validate and add to definitions
                if self._validate_workflow_definition(workflow_def):
                    workflow_id = workflow_def.get('id')
                    self.workflow_definitions[workflow_id] = workflow_def
                    
                    # Set up schedule if defined
                    if 'schedule' in workflow_def:
                        self._schedule_workflow(workflow_id, workflow_def['schedule'])
                    
                    logger.info(f"Loaded workflow definition: {workflow_id}")
                else:
                    logger.warning(f"Invalid workflow definition in {file_path}")
                
            except Exception as e:
                logger.error(f"Error loading workflow from {file_path}: {str(e)}")
    
    def _load_plugins(self):
        """Load plugin modules from the plugins directory"""
        if not self.plugins_dir.exists():
            logger.warning(f"Plugins directory {self.plugins_dir} does not exist")
            return
        
        # Find all Python files in the plugins directory
        plugin_files = list(self.plugins_dir.glob("*.py"))
        
        for file_path in plugin_files:
            try:
                # Load module
                module_name = file_path.stem
                spec = importlib.util.spec_from_file_location(module_name, file_path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
                
                # Look for step handlers
                for name, obj in inspect.getmembers(module):
                    if inspect.isfunction(obj) and name.startswith('handle_'):
                        step_type = name[7:]  # Remove 'handle_' prefix
                        self.register_step_type(step_type, obj)
                        logger.info(f"Registered plugin step type: {step_type}")
                
            except Exception as e:
                logger.error(f"Error loading plugin from {file_path}: {str(e)}")
    
    def _validate_workflow_definition(self, workflow_def: Dict[str, Any]) -> bool:
        """
        Validate a workflow definition
        
        Args:
            workflow_def: Workflow definition dictionary
            
        Returns:
            True if valid, False otherwise
        """
        # Check required fields
        required_fields = ['id', 'name', 'version', 'steps']
        
        for field in required_fields:
            if field not in workflow_def:
                logger.warning(f"Workflow definition missing required field: {field}")
                return False
        
        # Validate steps
        if not isinstance(workflow_def['steps'], list) or len(workflow_def['steps']) == 0:
            logger.warning("Workflow must have at least one step")
            return False
        
        # Validate each step
        for i, step in enumerate(workflow_def['steps']):
            if not isinstance(step, dict):
                logger.warning(f"Step {i} is not a dictionary")
                return False
            
            if 'id' not in step:
                logger.warning(f"Step {i} missing 'id' field")
                return False
            
            if 'type' not in step:
                logger.warning(f"Step {i} missing 'type' field")
                return False
            
            # Check if step type is registered
            if step['type'] not in self.step_handlers:
                logger.warning(f"Unknown step type '{step['type']}' in step {step['id']}")
                # Don't return False here, as the step type might be registered later
        
        return True
    
    def _schedule_workflow(self, workflow_id: str, schedule_def: Dict[str, Any]):
        """
        Set up scheduling for a workflow
        
        Args:
            workflow_id: ID of the workflow to schedule
            schedule_def: Schedule definition dictionary
        """
        # Check schedule type
        schedule_type = schedule_def.get('type', 'interval')
        
        if schedule_type == 'interval':
            # Interval-based schedule
            interval_minutes = schedule_def.get('interval_minutes', 60)
            
            # Create a job that runs every interval_minutes
            job = schedule.every(interval_minutes).minutes.do(self.start_workflow, workflow_id=workflow_id)
            
            # Store job reference
            self.scheduled_workflows[workflow_id] = job
            logger.info(f"Scheduled workflow {workflow_id} to run every {interval_minutes} minutes")
            
        elif schedule_type == 'cron':
            # Cron-like schedule
            # Parse cron expression (simplified)
            cron_expr = schedule_def.get('cron', '0 0 * * *')  # Default: daily at midnight
            minute, hour, day, month, day_of_week = cron_expr.split()
            
            # Create scheduled job based on cron components
            job = None
            
            # Handle minute
            if minute != '*':
                # Only supporting simple minute values, not ranges or lists
                job = schedule.every().day.at(f"{hour.zfill(2)}:{minute.zfill(2)}").do(
                    self.start_workflow, workflow_id=workflow_id)
            else:
                # Default to running at the start of the hour
                job = schedule.every().day.at(f"{hour.zfill(2)}:00").do(
                    self.start_workflow, workflow_id=workflow_id)
            
            # Store job reference
            self.scheduled_workflows[workflow_id] = job
            logger.info(f"Scheduled workflow {workflow_id} with cron expression: {cron_expr}")
            
        elif schedule_type == 'daily':
            # Daily schedule at specific time
            time_str = schedule_def.get('time', '00:00')
            
            # Create a job that runs daily at the specified time
            job = schedule.every().day.at(time_str).do(self.start_workflow, workflow_id=workflow_id)
            
            # Store job reference
            self.scheduled_workflows[workflow_id] = job
            logger.info(f"Scheduled workflow {workflow_id} to run daily at {time_str}")
            
        else:
            logger.warning(f"Unknown schedule type '{schedule_type}' for workflow {workflow_id}")
    
    def register_step_type(self, step_type: str, handler_func: Callable):
        """
        Register a new step type handler
        
        Args:
            step_type: Type identifier for the step
            handler_func: Function to handle execution of this step type
        """
        self.step_handlers[step_type] = handler_func
        logger.debug(f"Registered step type: {step_type}")
    
    def start_workflow(self, workflow_id: str, input_variables: Dict[str, Any] = None) -> Optional[str]:
        """
        Start a new workflow instance
        
        Args:
            workflow_id: ID of the workflow definition to start
            input_variables: Initial variables for the workflow
            
        Returns:
            ID of the created workflow instance, or None if failed
        """
        try:
            # Check if workflow definition exists
            if workflow_id not in self.workflow_definitions:
                logger.warning(f"Workflow definition not found: {workflow_id}")
                return None
            
            workflow_def = self.workflow_definitions[workflow_id]
            
            # Generate instance ID
            instance_id = f"{workflow_id}_{int(time.time())}_{os.getpid()}"
            
            # Create workflow steps from definition
            steps = []
            for step_def in workflow_def.get('steps', []):
                step = WorkflowStep(
                    id=step_def.get('id'),
                    type=step_def.get('type'),
                    name=step_def.get('name', step_def.get('id')),
                    description=step_def.get('description', ''),
                    parameters=step_def.get('parameters', {}),
                    condition=step_def.get('condition'),
                    timeout_seconds=step_def.get('timeout_seconds', 300),
                    retry_count=step_def.get('retry_count', 0),
                    retry_delay_seconds=step_def.get('retry_delay_seconds', 30)
                )
                steps.append(step)
            
            # Create workflow instance
            instance = WorkflowInstance(
                id=instance_id,
                workflow_id=workflow_id,
                name=workflow_def.get('name', workflow_id),
                description=workflow_def.get('description', ''),
                variables=input_variables or {},
                steps=steps,
                start_time=datetime.now()
            )
            
            # Set initial status
            instance.status = "running"
            
            # Store instance
            self.workflow_instances[instance_id] = instance
            
            # Log workflow start
            self._log_workflow_event(instance_id, "workflow_started", {
                "workflow_id": workflow_id,
                "input_variables": input_variables
            })
            
            # Start first step
            self._queue_next_step(instance_id)
            
            logger.info(f"Started workflow instance: {instance_id}")
            return instance_id
            
        except Exception as e:
            logger.error(f"Error starting workflow {workflow_id}: {str(e)}")
            return None
    
    def _queue_next_step(self, instance_id: str):
        """
        Queue the next step for execution
        
        Args:
            instance_id: ID of the workflow instance
        """
        instance = self.workflow_instances.get(instance_id)
        if not instance:
            logger.warning(f"Workflow instance not found: {instance_id}")
            return
        
        # Check if workflow is complete
        if instance.current_step_index >= len(instance.steps):
            self._complete_workflow(instance_id)
            return
        
        # Get current step
        step = instance.steps[instance.current_step_index]
        
        # Evaluate condition if present
        if step.condition and not self._evaluate_condition(step.condition, instance.variables):
            logger.info(f"Skipping step {step.id} because condition evaluated to false")
            
            # Mark step as skipped
            step.status = "skipped"
            
            # Log step skipped
            self._log_workflow_event(instance_id, "step_skipped", {
                "step_id": step.id,
                "condition": step.condition
            })
            
            # Move to next step
            instance.current_step_index += 1
            self._queue_next_step(instance_id)
            return
        
        # Queue step for execution
        self.work_queue.put((instance_id, instance.current_step_index))
    
    def _execute_workflow_step(self, instance_id: str, step_index: int):
        """
        Execute a single workflow step
        
        Args:
            instance_id: ID of the workflow instance
            step_index: Index of the step to execute
        """
        instance = self.workflow_instances.get(instance_id)
        if not instance:
            logger.warning(f"Workflow instance not found: {instance_id}")
            return
        
        # Check step index
        if step_index >= len(instance.steps):
            logger.warning(f"Invalid step index {step_index} for workflow {instance_id}")
            return
        
        # Get step
        step = instance.steps[step_index]
        
        # Update step status
        step.status = "running"
        step.start_time = datetime.now()
        
        # Log step started
        self._log_workflow_event(instance_id, "step_started", {
            "step_id": step.id,
            "step_type": step.type,
            "parameters": step.parameters
        })
        
        try:
            # Get step handler
            handler = self.step_handlers.get(step.type)
            if not handler:
                raise ValueError(f"No handler registered for step type: {step.type}")
            
            # Execute step with timeout
            step_result = self._execute_with_timeout(
                handler, 
                instance, 
                step,
                timeout_seconds=step.timeout_seconds
            )
            
            # Update step status
            step.status = "completed"
            step.result = step_result
            step.end_time = datetime.now()
            
            # Log step completed
            self._log_workflow_event(instance_id, "step_completed", {
                "step_id": step.id,
                "execution_time_seconds": (step.end_time - step.start_time).total_seconds(),
                "result": self._sanitize_for_logging(step_result)
            })
            
            # Update workflow variables with step result
            if isinstance(step_result, dict):
                instance.variables.update(step_result)
            else:
                # Store result in a variable named after the step
                instance.variables[step.id] = step_result
            
            # Move to next step
            instance.current_step_index += 1
            self._queue_next_step(instance_id)
            
        except Exception as e:
            # Update step status
            step.status = "failed"
            step.error = str(e)
            step.end_time = datetime.now()
            
            # Log step failed
            self._log_workflow_event(instance_id, "step_failed", {
                "step_id": step.id,
                "error": str(e),
                "execution_time_seconds": (step.end_time - step.start_time).total_seconds()
            })
            
            # Check if step should be retried
            if step.retry_count > 0:
                step.retry_count -= 1
                step.status = "pending"
                
                # Log retry
                self._log_workflow_event(instance_id, "step_retry", {
                    "step_id": step.id,
                    "retries_remaining": step.retry_count,
                    "retry_delay_seconds": step.retry_delay_seconds
                })
                
                # Schedule retry after delay
                threading.Timer(
                    step.retry_delay_seconds,
                    lambda: self.work_queue.put((instance_id, step_index))
                ).start()
                
            else:
                # Handle error in workflow
                self._handle_workflow_error(instance_id, step, e)
    
    def _execute_with_timeout(self, handler, instance, step, timeout_seconds):
        """
        Execute a step handler with a timeout
        
        Args:
            handler: Step handler function
            instance: Workflow instance
            step: Workflow step
            timeout_seconds: Timeout in seconds
            
        Returns:
            Result from the step handler
        """
        # Simple implementation without actual timeout
        # In a production system, you would use a separate process or thread with timeout
        return handler(instance, step)
    
    def _handle_workflow_error(self, instance_id: str, step: WorkflowStep, error: Exception):
        """
        Handle a workflow execution error
        
        Args:
            instance_id: ID of the workflow instance
            step: Step that failed
            error: Exception that occurred
        """
        instance = self.workflow_instances.get(instance_id)
        if not instance:
            return
        
        # Check error handling configuration
        instance_def = self.workflow_definitions.get(instance.workflow_id, {})
        error_handling = instance_def.get('error_handling', 'abort')
        
        if error_handling == 'continue':
            # Continue with next step despite error
            logger.info(f"Continuing workflow {instance_id} after error in step {step.id}")
            
            # Log error handling
            self._log_workflow_event(instance_id, "error_handled", {
                "step_id": step.id,
                "error": str(error),
                "action": "continue"
            })
            
            # Move to next step
            instance.current_step_index += 1
            self._queue_next_step(instance_id)
            
        elif error_handling == 'goto':
            # Go to specified step
            goto_step = instance_def.get('error_goto_step')
            
            if goto_step:
                # Find step index
                for i, s in enumerate(instance.steps):
                    if s.id == goto_step:
                        logger.info(f"Moving workflow {instance_id} to step {goto_step} after error")
                        
                        # Log error handling
                        self._log_workflow_event(instance_id, "error_handled", {
                            "step_id": step.id,
                            "error": str(error),
                            "action": "goto",
                            "target_step": goto_step
                        })
                        
                        # Set next step
                        instance.current_step_index = i
                        self._queue_next_step(instance_id)
                        return
            
            # If goto step not found, abort
            logger.warning(f"Error goto step {goto_step} not found, aborting workflow {instance_id}")
            self._fail_workflow(instance_id, f"Error in step {step.id}: {str(error)}")
            
        else:
            # Abort workflow (default)
            self._fail_workflow(instance_id, f"Error in step {step.id}: {str(error)}")
    
    def _complete_workflow(self, instance_id: str):
        """
        Mark a workflow instance as completed
        
        Args:
            instance_id: ID of the workflow instance
        """
        instance = self.workflow_instances.get(instance_id)
        if not instance:
            return
        
        # Update instance status
        instance.status = "completed"
        instance.end_time = datetime.now()
        
        # Calculate execution time
        execution_time = (instance.end_time - instance.start_time).total_seconds()
        
        # Log workflow completion
        self._log_workflow_event(instance_id, "workflow_completed", {
            "execution_time_seconds": execution_time,
            "output_variables": self._sanitize_for_logging(instance.variables)
        })
        
        logger.info(f"Workflow instance {instance_id} completed successfully in {execution_time:.2f} seconds")
    
    def _fail_workflow(self, instance_id: str, error_message: str):
        """
        Mark a workflow instance as failed
        
        Args:
            instance_id: ID of the workflow instance
            error_message: Error message
        """
        instance = self.workflow_instances.get(instance_id)
        if not instance:
            return
        
        # Update instance status
        instance.status = "failed"
        instance.end_time = datetime.now()
        
        # Calculate execution time
        execution_time = (instance.end_time - instance.start_time).total_seconds()
        
        # Log workflow failure
        self._log_workflow_event(instance_id, "workflow_failed", {
            "error": error_message,
            "execution_time_seconds": execution_time
        })
        
        logger.info(f"Workflow instance {instance_id} failed: {error_message}")
    
    def _log_workflow_event(self, instance_id: str, event_type: str, details: Dict[str, Any]):
        """
        Log a workflow event
        
        Args:
            instance_id: ID of the workflow instance
            event_type: Type of event
            details: Event details
        """
        instance = self.workflow_instances.get(instance_id)
        if not instance:
            return
        
        # Create log entry
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "event_type": event_type,
            "details": details
        }
        
        # Add to instance logs
        instance.logs.append(log_entry)
        
        # Log to logger
        logger.debug(f"Workflow {instance_id} event: {event_type}")
    
    def _sanitize_for_logging(self, data: Any) -> Any:
        """
        Sanitize data for logging (remove sensitive information, truncate large objects)
        
        Args:
            data: Data to sanitize
            
        Returns:
            Sanitized data
        """
        if isinstance(data, dict):
            # Sanitize dictionary
            result = {}
            for key, value in data.items():
                # Skip sensitive keys
                if key.lower() in ['password', 'secret', 'token', 'key', 'auth']:
                    result[key] = '***REDACTED***'
                else:
                    result[key] = self._sanitize_for_logging(value)
            return result
        elif isinstance(data, list):
            # Sanitize list
            if len(data) > 10:
                # Truncate long lists
                return [self._sanitize_for_logging(item) for item in data[:10]] + ['...']
            else:
                return [self._sanitize_for_logging(item) for item in data]
        elif isinstance(data, (str, int, float, bool, type(None))):
            # Primitive types pass through
            return data
        else:
            # Other types convert to string
            return str(data)
    
    def _evaluate_condition(self, condition: str, variables: Dict[str, Any]) -> bool:
        """
        Evaluate a condition expression
        
        Args:
            condition: Condition expression
            variables: Variables dictionary
            
        Returns:
            Boolean result of condition evaluation
        """
        try:
            # Create a safe evaluation environment
            env = {'__builtins__': {}}
            
            # Add variables to environment
            env.update(variables)
            
            # Add some safe functions
            env.update({
                'len': len,
                'str': str,
                'int': int,
                'float': float,
                'bool': bool,
                'list': list,
                'dict': dict,
                'min': min,
                'max': max,
                'sum': sum,
                'all': all,
                'any': any
            })
            
            # Evaluate condition
            result = eval(condition, env)
            
            # Convert to boolean
            return bool(result)
        except Exception as e:
            logger.warning(f"Error evaluating condition '{condition}': {str(e)}")
            return False
    
    def get_workflow_status(self, instance_id: str) -> Dict[str, Any]:
        """
        Get status of a workflow instance
        
        Args:
            instance_id: ID of the workflow instance
            
        Returns:
            Status information dictionary
        """
        instance = self.workflow_instances.get(instance_id)
        if not instance:
            return {"error": "Workflow instance not found"}
        
        # Calculate execution time or elapsed time
        if instance.end_time:
            execution_time = (instance.end_time - instance.start_time).total_seconds()
        else:
            execution_time = (datetime.now() - instance.start_time).total_seconds()
        
        # Count steps by status
        step_counts = {
            "total": len(instance.steps),
            "completed": sum(1 for step in instance.steps if step.status == "completed"),
            "running": sum(1 for step in instance.steps if step.status == "running"),
            "pending": sum(1 for step in instance.steps if step.status == "pending"),
            "failed": sum(1 for step in instance.steps if step.status == "failed"),
            "skipped": sum(1 for step in instance.steps if step.status == "skipped")
        }
        
        # Create status response
        status = {
            "instance_id": instance.id,
            "workflow_id": instance.workflow_id,
            "name": instance.name,
            "status": instance.status,
            "start_time": instance.start_time.isoformat() if instance.start_time else None,
            "end_time": instance.end_time.isoformat() if instance.end_time else None,
            "execution_time_seconds": execution_time,
            "current_step_index": instance.current_step_index,
            "current_step": instance.steps[instance.current_step_index].id if instance.current_step_index < len(instance.steps) else None,
            "step_counts": step_counts,
            "variables": self._sanitize_for_logging(instance.variables)
        }
        
        return status
    
    def get_workflow_logs(self, instance_id: str) -> List[Dict[str, Any]]:
        """
        Get logs for a workflow instance
        
        Args:
            instance_id: ID of the workflow instance
            
        Returns:
            List of log entries
        """
        instance = self.workflow_instances.get(instance_id)
        if not instance:
            return []
        
        return instance.logs
    
    def list_workflows(self) -> List[Dict[str, Any]]:
        """
        List all workflow definitions
        
        Returns:
            List of workflow definition summaries
        """
        result = []
        
        for workflow_id, workflow_def in self.workflow_definitions.items():
            result.append({
                "id": workflow_id,
                "name": workflow_def.get("name", workflow_id),
                "version": workflow_def.get("version", "1.0"),
                "description": workflow_def.get("description", ""),
                "step_count": len(workflow_def.get("steps", [])),
                "scheduled": workflow_id in self.scheduled_workflows
            })
        
        return result
    
    def list_workflow_instances(self, workflow_id: str = None, status: str = None) -> List[Dict[str, Any]]:
        """
        List workflow instances
        
        Args:
            workflow_id: Optional filter by workflow ID
            status: Optional filter by status
            
        Returns:
            List of workflow instance summaries
        """
        result = []
        
        for instance_id, instance in self.workflow_instances.items():
            # Apply filters
            if workflow_id and instance.workflow_id != workflow_id:
                continue
            
            if status and instance.status != status:
                continue
            
            # Calculate execution time or elapsed time
            if instance.end_time:
                execution_time = (instance.end_time - instance.start_time).total_seconds()
            else:
                execution_time = (datetime.now() - instance.start_time).total_seconds()
            
            result.append({
                "instance_id": instance_id,
                "workflow_id": instance.workflow_id,
                "name": instance.name,
                "status": instance.status,
                "start_time": instance.start_time.isoformat() if instance.start_time else None,
                "end_time": instance.end_time.isoformat() if instance.end_time else None,
                "execution_time_seconds": execution_time,
                "step_count": len(instance.steps),
                "current_step": instance.current_step_index
            })
        
        return result
    
    # Built-in step handlers
    
    def _handle_script_step(self, instance: WorkflowInstance, step: WorkflowStep) -> Any:
        """Handle execution of a script step"""
        # Get script parameters
        script_type = step.parameters.get('type', 'bash')
        script_content = step.parameters.get('script', '')
        timeout = step.parameters.get('timeout', 60)
        
        logger.info(f"Executing {script_type} script")
        
        # Replace variables in script content
        script_content = self._replace_variables(script_content, instance.variables)
        
        # Execute script based on type
        if script_type == 'bash':
            # Use subprocess to run bash script
            import subprocess
            
            # Create temporary script file
            script_file = Path('/tmp') / f"workflow_{instance.id}_{step.id}.sh"
            with open(script_file, 'w') as f:
                f.write(script_content)
            
            # Make executable
            os.chmod(script_file, 0o755)
            
            # Run script
            process = subprocess.run(
                ['/bin/bash', script_file],
                capture_output=True,
                text=True,
                timeout=timeout
            )
            
            # Remove temporary file
            os.unlink(script_file)
            
            # Check result
            if process.returncode != 0:
                raise RuntimeError(f"Script execution failed: {process.stderr}")
            
            # Return output
            return {
                'stdout': process.stdout,
                'stderr': process.stderr,
                'return_code': process.returncode
            }
            
        else:
            raise ValueError(f"Unsupported script type: {script_type}")
    
    def _handle_http_request_step(self, instance: WorkflowInstance, step: WorkflowStep) -> Any:
        """Handle execution of an HTTP request step"""
        import requests
        
        # Get request parameters
        method = step.parameters.get('method', 'GET')
        url = step.parameters.get('url', '')
        headers = step.parameters.get('headers', {})
        body = step.parameters.get('body', None)
        timeout = step.parameters.get('timeout', 30)
        
        # Replace variables in parameters
        url = self._replace_variables(url, instance.variables)
        
        # Replace variables in headers
        for key, value in headers.items():
            if isinstance(value, str):
                headers[key] = self._replace_variables(value, instance.variables)
        
        # Replace variables in body
        if isinstance(body, str):
            body = self._replace_variables(body, instance.variables)
        elif isinstance(body, dict):
            body = self._replace_variables_in_dict(body, instance.variables)
        
        logger.info(f"Making HTTP {method} request to {url}")
        
        # Make request
        response = requests.request(
            method=method,
            url=url,
            headers=headers,
            json=body if body else None,
            timeout=timeout
        )
        
        # Check response
        if step.parameters.get('fail_on_error', True) and response.status_code >= 400:
            raise RuntimeError(f"HTTP request failed with status {response.status_code}: {response.text}")
        
        # Parse response based on content type
        if 'application/json' in response.headers.get('Content-Type', ''):
            response_body = response.json()
        else:
            response_body = response.text
        
        # Return response data
        return {
            'status_code': response.status_code,
            'headers': dict(response.headers),
            'body': response_body
        }
    
    def _handle_database_query_step(self, instance: WorkflowInstance, step: WorkflowStep) -> Any:
        """Handle execution of a database query step"""
        # In a real implementation, this would use a database connection
        # For this example, we'll simulate database access
        
        # Get query parameters
        query_type = step.parameters.get('type', 'select')
        query = step.parameters.get('query', '')
        parameters = step.parameters.get('parameters', {})
        connection = step.parameters.get('connection', 'default')
        
        # Replace variables in query
        query = self._replace_variables(query, instance.variables)
        
        # Replace variables in parameters
        parameters = self._replace_variables_in_dict(parameters, instance.variables)
        
        logger.info(f"Executing database query: {query_type}")
        
        # Simulate database access
        if query_type == 'select':
            # For demonstration, return dummy data
            return {
                'rows': [
                    {'id': 1, 'name': 'Sample 1'},
                    {'id': 2, 'name': 'Sample 2'}
                ],
                'row_count': 2
            }
        elif query_type in ['insert', 'update', 'delete']:
            return {
                'row_count': 1,
                'affected_rows': 1
            }
        else:
            raise ValueError(f"Unsupported query type: {query_type}")
    
    def _handle_python_step(self, instance: WorkflowInstance, step: WorkflowStep) -> Any:
        """Handle execution of a Python code step"""
        # Get code parameters
        code = step.parameters.get('code', '')
        timeout = step.parameters.get('timeout', 60)
        
        # Replace variables in code
        code = self._replace_variables(code, instance.variables)
        
        logger.info(f"Executing Python code in step {step.id}")
        
        # Set up execution environment
        locals_dict = {
            'workflow_instance': instance,
            'workflow_step': step,
            'workflow_variables': instance.variables,
            'result': None
        }
        
        # Execute code
        exec(code, globals(), locals_dict)
        
        # Return result if provided
        return locals_dict.get('result')
    
    def _handle_condition_step(self, instance: WorkflowInstance, step: WorkflowStep) -> Any:
        """Handle execution of a condition step"""
        # Get condition parameters
        condition = step.parameters.get('condition', 'True')
        true_value = step.parameters.get('true_value', True)
        false_value = step.parameters.get('false_value', False)
        
        # Evaluate condition
        result = self._evaluate_condition(condition, instance.variables)
        
        # Return appropriate value
        return true_value if result else false_value
    
    def _handle_delay_step(self, instance: WorkflowInstance, step: WorkflowStep) -> Any:
        """Handle execution of a delay step"""
        # Get delay parameters
        seconds = step.parameters.get('seconds', 0)
        minutes = step.parameters.get('minutes', 0)
        hours = step.parameters.get('hours', 0)
        
        # Calculate total delay in seconds
        total_seconds = seconds + minutes * 60 + hours * 3600
        
        logger.info(f"Delaying execution for {total_seconds} seconds")
        
        # Sleep for the specified duration
        time.sleep(total_seconds)
        
        # Return delay information
        return {
            'delay_seconds': total_seconds,
            'completed_at': datetime.now().isoformat()
        }
    
    def _handle_notification_step(self, instance: WorkflowInstance, step: WorkflowStep) -> Any:
        """Handle execution of a notification step"""
        # Get notification parameters
        notification_type = step.parameters.get('type', 'log')
        subject = step.parameters.get('subject', f"Notification from workflow {instance.name}")
        message = step.parameters.get('message', '')
        recipients = step.parameters.get('recipients', [])
        
        # Replace variables in subject and message
        subject = self._replace_variables(subject, instance.variables)
        message = self._replace_variables(message, instance.variables)
        
        logger.info(f"Sending {notification_type} notification: {subject}")
        
        # Handle different notification types
        if notification_type == 'log':
            # Just log the message
            logger.info(f"Notification - {subject}: {message}")
            
        elif notification_type == 'email':
            # In a real implementation, this would send an email
            # This is just a placeholder
            logger.info(f"Email notification to {recipients}: {subject}")
            
        elif notification_type == 'sms':
            # In a real implementation, this would send an SMS
            # This is just a placeholder
            logger.info(f"SMS notification to {recipients}: {subject}")
            
        else:
            raise ValueError(f"Unsupported notification type: {notification_type}")
        
        # Return notification information
        return {
            'type': notification_type,
            'subject': subject,
            'recipients': recipients,
            'sent_at': datetime.now().isoformat()
        }
    
    def _handle_document_generation_step(self, instance: WorkflowInstance, step: WorkflowStep) -> Any:
        """Handle execution of a document generation step"""
        # Get document parameters
        document_type = step.parameters.get('type', 'text')
        template = step.parameters.get('template', '')
        output_path = step.parameters.get('output_path', '')
        variables = step.parameters.get('variables', {})
        
        # Merge workflow variables with step-specific variables
        merged_variables = instance.variables.copy()
        merged_variables.update(variables)
        
        # Replace variables in template and output path
        template = self._replace_variables(template, merged_variables)
        output_path = self._replace_variables(output_path, merged_variables)
        
        logger.info(f"Generating {document_type} document: {output_path}")
        
        # Generate document based on type
        if document_type == 'text':
            # Simple text document
            content = template
            
            # Write to file
            with open(output_path, 'w') as f:
                f.write(content)
            
        elif document_type == 'html':
            # HTML document
            content = template
            
            # Write to file
            with open(output_path, 'w') as f:
                f.write(content)
            
        elif document_type == 'pdf':
            # In a real implementation, this would generate a PDF
            # This is just a placeholder
            logger.info(f"PDF generation not implemented in this example")
            
        else:
            raise ValueError(f"Unsupported document type: {document_type}")
        
        # Return document information
        return {
            'type': document_type,
            'path': output_path,
            'size': os.path.getsize(output_path) if os.path.exists(output_path) else 0,
            'generated_at': datetime.now().isoformat()
        }
    
    def _replace_variables(self, text: str, variables: Dict[str, Any]) -> str:
        """
        Replace variables in text with values from variables dictionary
        
        Args:
            text: Text with variable placeholders
            variables: Variables dictionary
            
        Returns:
            Text with variables replaced
        """
        if not isinstance(text, str):
            return text
        
        # Replace ${variable} with variable value
        pattern = r'\${([^}]+)}'
        
        def replacement(match):
            var_name = match.group(1)
            if var_name in variables:
                value = variables[var_name]
                if isinstance(value, (str, int, float, bool)):
                    return str(value)
                else:
                    return str(value)
            return match.group(0)
        
        return re.sub(pattern, replacement, text)
    
    def _replace_variables_in_dict(self, data: Dict[str, Any], variables: Dict[str, Any]) -> Dict[str, Any]:
        """
        Replace variables in dictionary values with values from variables dictionary
        
        Args:
            data: Dictionary with variable placeholders in values
            variables: Variables dictionary
            
        Returns:
            Dictionary with variables replaced
        """
        result = {}
        
        for key, value in data.items():
            if isinstance(value, str):
                result[key] = self._replace_variables(value, variables)
            elif isinstance(value, dict):
                result[key] = self._replace_variables_in_dict(value, variables)
            elif isinstance(value, list):
                result[key] = [
                    self._replace_variables(item, variables) if isinstance(item, str)
                    else (self._replace_variables_in_dict(item, variables) if isinstance(item, dict) else item)
                    for item in value
                ]
            else:
                result[key] = value
        
        return result

# Example usage
if __name__ == "__main__":
    # Create workflow engine instance
    engine = WorkflowEngine()
    
    # Start the engine
    engine.start()
    
    try:
        # Create a sample workflow definition
        sample_workflow = {
            "id": "sample_workflow",
            "name": "Sample Workflow",
            "version": "1.0",
            "description": "A sample workflow demonstrating basic functionality",
            "steps": [
                {
                    "id": "step1",
                    "type": "python",
                    "name": "Generate Data",
                    "description": "Generate sample data for the workflow",
                    "parameters": {
                        "code": """
import random
import datetime

# Generate some sample data
result = {
    'random_number': random.randint(1, 100),
    'timestamp': datetime.datetime.now().isoformat(),
    'sample_list': [random.randint(1, 10) for _ in range(5)]
}

print(f"Generated sample data: {result}")
"""
                    }
                },
                {
                    "id": "step2",
                    "type": "condition",
                    "name": "Check Random Number",
                    "description": "Check if the random number is greater than 50",
                    "parameters": {
                        "condition": "step1.get('random_number', 0) > 50",
                        "true_value": {"result": "high", "message": "Number is high"},
                        "false_value": {"result": "low", "message": "Number is low"}
                    }
                },
                {
                    "id": "step3",
                    "type": "notification",
                    "name": "Send Notification",
                    "description": "Log a notification based on the condition result",
                    "parameters": {
                        "type": "log",
                        "subject": "Random Number Check",
                        "message": "The random number ${step1.random_number} is ${step2.result} (${step2.message})"
                    }
                }
            ]
        }
        
        # Add workflow definition
        engine.workflow_definitions["sample_workflow"] = sample_workflow
        
        # Start workflow instance
        instance_id = engine.start_workflow("sample_workflow")
        
        # Wait for workflow to complete
        print(f"Started workflow instance: {instance_id}")
        print("Waiting for workflow to complete...")
        
        # Simple polling
        while True:
            status = engine.get_workflow_status(instance_id)
            if status["status"] in ["completed", "failed"]:
                break
            time.sleep(0.5)
        
        # Print workflow status
        print("\nWorkflow completed!")
        print(f"Status: {status['status']}")
        print(f"Execution time: {status['execution_time_seconds']:.2f} seconds")
        print("\nWorkflow variables:")
        for key, value in status['variables'].items():
            print(f"  {key}: {value}")
        
        # Print logs
        print("\nWorkflow logs:")
        for log in engine.get_workflow_logs(instance_id):
            print(f"  {log['timestamp']} - {log['event_type']}")
        
    finally:
        # Stop the engine
        engine.stop()

# backend/ai-modules/research-assistant/research_assistant.py
import os
import sys
import logging
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple, Union
from pathlib import Path
import threading
import queue
import pickle
import re
import hashlib
import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('research_assistant.log')
    ]
)
logger = logging.getLogger(__name__)

# Download NLTK resources
try:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
    nltk.download('wordnet', quiet=True)
except Exception as e:
    logger.warning(f"Failed to download NLTK resources: {str(e)}")

class ResearchAssistant:
    """
    Research assistant for finding, analyzing, and organizing aviation-related
    research materials. Includes web scraping, citation tracking, and
    plagiarism detection capabilities.
    """
    
    def __init__(self, cache_dir: str = 'research_cache'):
        """
        Initialize the research assistant
        
        Args:
            cache_dir: Directory to store cached research data
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True, parents=True)
        
        # Initialize sub-directories
        self.web_cache_dir = self.cache_dir / 'web'
        self.document_cache_dir = self.cache_dir / 'documents'
        self.search_cache_dir = self.cache_dir / 'searches'
        
        self.web_cache_dir.mkdir(exist_ok=True)
        self.document_cache_dir.mkdir(exist_ok=True)
        self.search_cache_dir.mkdir(exist_ok=True)
        
        # Initialize caches
        self.search_cache = self._load_cache('search_cache.pkl')
        self.web_page_cache = self._load_cache('web_page_cache.pkl')
        self.document_cache = self._load_cache('document_cache.pkl')
        self.citation_cache = self._load_cache('citation_cache.pkl')
        
        # Initialize processing tools
        self.stop_words = set(stopwords.words('english'))
        self.lemmatizer = WordNetLemmatizer()
        
        # Configure default request headers
        self.request_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml',
            'Accept-Language': 'en-US,en;q=0.9'
        }
        
        # Aviation-specific sources
        self.aviation_sources = {
            'faa': {
                'name': 'Federal Aviation Administration',
                'base_url': 'https://www.faa.gov',
                'search_url': 'https://www.faa.gov/search/?q={query}'
            },
            'easa': {
                'name': 'European Union Aviation Safety Agency',
                'base_url': 'https://www.easa.europa.eu',
                'search_url': 'https://www.easa.europa.eu/search?text={query}'
            },
            'icao': {
                'name': 'International Civil Aviation Organization',
                'base_url': 'https://www.icao.int',
                'search_url': 'https://www.icao.int/search/pages/results.aspx?k={query}'
            },
            'nasa': {
                'name': 'NASA Technical Reports Server',
                'base_url': 'https://ntrs.nasa.gov',
                'search_url': 'https://ntrs.nasa.gov/search?q={query}'
            },
            'skybrary': {
                'name': 'SKYbrary Aviation Safety',
                'base_url': 'https://www.skybrary.aero',
                'search_url': 'https://www.skybrary.aero/index.php?search={query}'
            }
        }
    
    def _load_cache(self, filename: str) -> Dict[str, Any]:
        """Load cache from file"""
        cache_path = self.cache_dir / filename
        if cache_path.exists():
            try:
                with open(cache_path, 'rb') as f:
                    return pickle.load(f)
            except Exception as e:
                logger.warning(f"Failed to load cache from {filename}: {str(e)}")
        return {}
    
    def _save_cache(self, cache: Dict[str, Any], filename: str):
        """Save cache to file"""
        cache_path = self.cache_dir / filename
        try:
            with open(cache_path, 'wb') as f:
                pickle.dump(cache, f)
        except Exception as e:
            logger.warning(f"Failed to save cache to {filename}: {str(e)}")
    
    def _get_cache_key(self, *args) -> str:
        """Generate a cache key from arguments"""
        key_str = ":".join(str(arg) for arg in args)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def search(self, query: str, sources: List[str] = None, 
              max_results: int = 20, use_cache: bool = True,
              cache_ttl_hours: int = 24) -> List[Dict[str, Any]]:
        """
        Search for research materials across specified sources
        
        Args:
            query: Search query
            sources: List of source IDs to search (if None, search all)
            max_results: Maximum number of results to return
            use_cache: Whether to use cached results
            cache_ttl_hours: Cache TTL in hours
            
        Returns:
            List of search result items
        """
        # Normalize query
        query = query.strip().lower()
        
        # Generate cache key
        cache_key = self._get_cache_key('search', query, str(sources), str(max_results))
        
        # Check cache
        if use_cache and cache_key in self.search_cache:
            cache_entry = self.search_cache[cache_key]
            cache_age = datetime.now() - cache_entry['timestamp']
            
            if cache_age.total_seconds() < cache_ttl_hours * 3600:
                logger.info(f"Using cached search results for query: {query}")
                return cache_entry['results']
        
        # Select sources to search
        if sources is None:
            search_sources = list(self.aviation_sources.keys())
        else:
            search_sources = [s for s in sources if s in self.aviation_sources]
        
        logger.info(f"Searching for '{query}' across {len(search_sources)} sources")
        
        # Initialize results
        all_results = []
        
        # Search each source
        for source_id in search_sources:
            source_info = self.aviation_sources[source_id]
            source_results = self._search_source(query, source_id, source_info)
            all_results.extend(source_results)
        
        # Sort results by relevance score
        all_results.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        # Limit results
        results = all_results[:max_results]
        
        # Cache results
        self.search_cache[cache_key] = {
            'timestamp': datetime.now(),
            'results': results
        }
        self._save_cache(self.search_cache, 'search_cache.pkl')
        
        return results
    
    def _search_source(self, query: str, source_id: str, 
                      source_info: Dict[str, str]) -> List[Dict[str, Any]]:
        """Search a specific source for the query"""
        try:
            # Format search URL
            search_url = source_info['search_url'].format(query=requests.utils.quote(query))
            
            # Fetch search results page
            response = requests.get(search_url, headers=self.request_headers, timeout=10)
            response.raise_for_status()
            
            # Process based on source
            if source_id == 'faa':
                return self._extract_faa_search_results(response.text, query)
            elif source_id == 'easa':
                return self._extract_easa_search_results(response.text, query)
            elif source_id == 'icao':
                return self._extract_icao_search_results(response.text, query)
            elif source_id == 'nasa':
                return self._extract_nasa_search_results(response.text, query)
            elif source_id == 'skybrary':
                return self._extract_skybrary_search_results(response.text, query)
            else:
                # Generic extraction for unknown sources
                return self._extract_generic_search_results(response.text, query, source_id, source_info)
            
        except Exception as e:
            logger.warning(f"Error searching {source_id}: {str(e)}")
            return []
    
    def _extract_generic_search_results(self, html_content: str, query: str, 
                                       source_id: str, source_info: Dict[str, str]) -> List[Dict[str, Any]]:
        """Extract search results from generic HTML content"""
        results = []
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Look for common search result patterns
        # This is a simplified implementation that might not work for all sites
        result_elements = soup.select('div.search-result, div.result, article, .result-item')
        
        for element in result_elements[:20]:  # Limit to first 20 results
            # Extract title
            title_elem = element.select_one('h2, h3, .title, .result-title')
            title = title_elem.get_text().strip() if title_elem else "Untitled"
            
            # Extract URL
            link_elem = element.select_one('a')
            url = link_elem.get('href') if link_elem else None
            
            # Normalize URL
            if url and not url.startswith(('http://', 'https://')):
                url = source_info['base_url'] + ('' if url.startswith('/') else '/') + url
            
            # Extract snippet
            snippet_elem = element.select_one('p, .snippet, .description, .summary')
            snippet = snippet_elem.get_text().strip() if snippet_elem else ""
            
            # Calculate relevance score
            relevance_score = self._calculate_relevance_score(title + " " + snippet, query)
            
            # Add to results if URL is valid
            if url:
                results.append({
                    'title': title,
                    'url': url,
                    'snippet': snippet,
                    'source': source_info['name'],
                    'source_id': source_id,
                    'relevance_score': relevance_score,
                    'query': query,
                    'timestamp': datetime.now().isoformat()
                })
        
        return results
    
    # Custom extraction methods for each source
    # In a real implementation, these would be more sophisticated
    
    def _extract_faa_search_results(self, html_content: str, query: str) -> List[Dict[str, Any]]:
        """Extract search results from FAA website"""
        # This is a placeholder - would need custom implementation for actual FAA site
        return self._extract_generic_search_results(
            html_content, query, 'faa', self.aviation_sources['faa']
        )
    
    def _extract_easa_search_results(self, html_content: str, query: str) -> List[Dict[str, Any]]:
        """Extract search results from EASA website"""
        return self._extract_generic_search_results(
            html_content, query, 'easa', self.aviation_sources['easa']
        )
    
    def _extract_icao_search_results(self, html_content: str, query: str) -> List[Dict[str, Any]]:
        """Extract search results from ICAO website"""
        return self._extract_generic_search_results(
            html_content, query, 'icao', self.aviation_sources['icao']
        )
    
    def _extract_nasa_search_results(self, html_content: str, query: str) -> List[Dict[str, Any]]:
        """Extract search results from NASA NTRS"""
        return self._extract_generic_search_results(
            html_content, query, 'nasa', self.aviation_sources['nasa']
        )
    
    def _extract_skybrary_search_results(self, html_content: str, query: str) -> List[Dict[str, Any]]:
        """Extract search results from SKYbrary"""
        return self._extract_generic_search_results(
            html_content, query, 'skybrary', self.aviation_sources['skybrary']
        )
    
    def _calculate_relevance_score(self, text: str, query: str) -> float:
        """Calculate relevance score of text for a query"""
        # Preprocess text and query
        text_tokens = [self.lemmatizer.lemmatize(word.lower()) 
                       for word in word_tokenize(text) 
                       if word.lower() not in self.stop_words]
        
        query_tokens = [self.lemmatizer.lemmatize(word.lower()) 
                        for word in word_tokenize(query) 
                        if word.lower() not in self.stop_words]
        
        # Count query term occurrences
        term_count = sum(text_tokens.count(token) for token in query_tokens)
        
        # Calculate basic TF score
        if len(text_tokens) > 0:
            tf_score = term_count / len(text_tokens)
        else:
            tf_score = 0
        
        # Check for exact phrase matches
        exact_match_score = 0
        if len(query_tokens) > 1:
            text_lower = text.lower()
            query_lower = query.lower()
            if query_lower in text_lower:
                exact_match_score = 0.5
        
        # Title match bonus - simplified by assuming text includes title
        title_match_score = 0
        for token in query_tokens:
            if token in text_tokens[:10]:  # Assume first 10 tokens might be title
                title_match_score += 0.1
        
        # Combined score (simple weighted sum)
        relevance_score = (0.5 * tf_score) + exact_match_score + title_match_score
        
        # Normalize to 0-1 range
        return min(1.0, relevance_score)
    
    def fetch_page_content(self, url: str, use_cache: bool = True,
                          cache_ttl_hours: int = 168) -> Dict[str, Any]:
        """
        Fetch and parse a web page
        
        Args:
            url: URL to fetch
            use_cache: Whether to use cached content
            cache_ttl_hours: Cache TTL in hours
            
        Returns:
            Dictionary with page content and metadata
        """
        # Generate cache key
        cache_key = self._get_cache_key('page', url)
        
        # Check cache
        if use_cache and cache_key in self.web_page_cache:
            cache_entry = self.web_page_cache[cache_key]
            cache_age = datetime.now() - cache_entry['fetch_time']
            
            if cache_age.total_seconds() < cache_ttl_hours * 3600:
                logger.info(f"Using cached page content for URL: {url}")
                return cache_entry
        
        try:
            logger.info(f"Fetching page content from URL: {url}")
            
            # Fetch page
            response = requests.get(url, headers=self.request_headers, timeout=15)
            response.raise_for_status()
            
            # Parse content
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Extract title
            title = soup.title.get_text().strip() if soup.title else "Untitled"
            
            # Extract main content
            main_content = self._extract_main_content(soup)
            
            # Extract metadata
            meta_description = ""
            meta_desc_tag = soup.find('meta', attrs={'name': 'description'})
            if meta_desc_tag and 'content' in meta_desc_tag.attrs:
                meta_description = meta_desc_tag['content']
            
            # Extract publication date if available
            pub_date = self._extract_publication_date(soup)
            
            # Extract authors if available
            authors = self._extract_authors(soup)
            
            # Check if it's a PDF link
            is_pdf = url.lower().endswith('.pdf') or 'application/pdf' in response.headers.get('Content-Type', '')
            
            # Handle PDF content
            if is_pdf:
                # In a real implementation, use PyPDF2 or similar to extract PDF content
                content_text = "PDF content extraction not implemented in this example"
            else:
                # Extract plain text from HTML content
                content_text = self._extract_text_from_html(main_content)
            
            # Create result
            result = {
                'url': url,
                'title': title,
                'meta_description': meta_description,
                'content_text': content_text,
                'content_html': str(main_content),
                'publication_date': pub_date,
                'authors': authors,
                'is_pdf': is_pdf,
                'fetch_time': datetime.now(),
                'status': 'success'
            }
            
            # Cache result
            self.web_page_cache[cache_key] = result
            self._save_cache(self.web_page_cache, 'web_page_cache.pkl')
            
            return result
            
        except Exception as e:
            logger.warning(f"Error fetching page content from {url}: {str(e)}")
            
            # Create error result
            error_result = {
                'url': url,
                'status': 'error',
                'error_message': str(e),
                'fetch_time': datetime.now()
            }
            
            # Cache error result
            self.web_page_cache[cache_key] = error_result
            self._save_cache(self.web_page_cache, 'web_page_cache.pkl')
            
            return error_result
    
    def _extract_main_content(self, soup: BeautifulSoup) -> BeautifulSoup:
        """Extract main content from web page"""
        # Check for common content container elements
        content_candidates = []
        
        # Look for semantic elements
        for element_type in ['article', 'main', '[role=main]', 'section']:
            elements = soup.select(element_type)
            content_candidates.extend(elements)
        
        # Look for common content class patterns
        for class_pattern in ['content', 'article', 'post', 'entry', 'main', 'text']:
            elements = soup.select(f'.{class_pattern}')
            content_candidates.extend(elements)
        
        # If we have candidates, select the one with the most text
        if content_candidates:
            best_candidate = max(content_candidates, key=lambda x: len(x.get_text()))
            return best_candidate
        
        # Fallback to body
        return soup.body or soup
    
    def _extract_text_from_html(self, element: BeautifulSoup) -> str:
        """Extract clean text from HTML content"""
        # Remove script and style elements
        for script in element(['script', 'style', 'header', 'footer', 'nav']):
            script.decompose()
        
        # Get text
        text = element.get_text('\n', strip=True)
        
        # Remove excessive whitespace
        text = re.sub(r'\n+', '\n', text)
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def _extract_publication_date(self, soup: BeautifulSoup) -> str:
        """Extract publication date from web page"""
        # Look for common date patterns
        date_patterns = [
            # Meta tags
            ('meta[property="article:published_time"]', 'content'),
            ('meta[name="publication_date"]', 'content'),
            ('meta[name="date"]', 'content'),
            # Common HTML patterns
            ('time', 'datetime'),
            ('.date', None),
            ('.published', None),
            ('.pubdate', None)
        ]
        
        for selector, attr in date_patterns:
            elements = soup.select(selector)
            if elements:
                for element in elements:
                    if attr and attr in element.attrs:
                        return element[attr]
                    else:
                        text = element.get_text().strip()
                        if text:
                            return text
        
        return ""
    
    def _extract_authors(self, soup: BeautifulSoup) -> List[str]:
        """Extract author information from web page"""
        authors = []
        
        # Look for common author patterns
        author_patterns = [
            # Meta tags
            ('meta[name="author"]', 'content'),
            ('meta[property="article:author"]', 'content'),
            # Common HTML patterns
            ('.author', None),
            ('.byline', None),
            ('span[itemprop="author"]', None),
            ('[rel="author"]', None)
        ]
        
        for selector, attr in author_patterns:
            elements = soup.select(selector)
            if elements:
                for element in elements:
                    if attr and attr in element.attrs:
                        author = element[attr].strip()
                    else:
                        author = element.get_text().strip()
                    
                    if author and author not in authors:
                        authors.append(author)
        
        return authors
    
    def analyze_text(self, text: str) -> Dict[str, Any]:
        """
        Analyze text to extract key information
        
        Args:
            text: Text to analyze
            
        Returns:
            Dictionary with analysis results
        """
        try:
            # Split text into sentences
            sentences = sent_tokenize(text)
            
            # Tokenize and preprocess text
            tokens = [word.lower() for word in word_tokenize(text) 
                      if word.isalpha() and word.lower() not in self.stop_words]
            
            # Calculate basic statistics
            word_count = len(tokens)
            sentence_count = len(sentences)
            avg_sentence_length = word_count / sentence_count if sentence_count > 0 else 0
            
            # Calculate word frequencies
            word_freq = {}
            for word in tokens:
                word = self.lemmatizer.lemmatize(word)
                word_freq[word] = word_freq.get(word, 0) + 1
            
            # Sort word frequencies
            top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:20]
            
            # Extract key sentences (simple extractive summarization)
            key_sentences = self._extract_key_sentences(sentences, tokens, top_words, min(5, sentence_count))
            
            # Create summary
            if len(key_sentences) > 0:
                summary = " ".join(key_sentences)
            else:
                # Fallback to first few sentences
                summary = " ".join(sentences[:3]) if sentence_count >= 3 else text
            
            # Create analysis result
            result = {
                'word_count': word_count,
                'sentence_count': sentence_count,
                'avg_sentence_length': avg_sentence_length
'avg_sentence_length': avg_sentence_length,
                'top_words': dict(top_words),
                'summary': summary,
                'key_sentences': key_sentences
            }
            
            return result
            
        except Exception as e:
            logger.warning(f"Error analyzing text: {str(e)}")
            return {
                'error': str(e),
                'word_count': 0,
                'sentence_count': 0,
                'summary': ''
            }
    
    def _extract_key_sentences(self, sentences: List[str], tokens: List[str], 
                              top_words: List[Tuple[str, int]], count: int) -> List[str]:
        """Extract key sentences from text based on important words"""
        # Calculate sentence scores based on word importance
        sentence_scores = []
        
        for sentence in sentences:
            score = 0
            # Tokenize sentence
            sentence_tokens = [word.lower() for word in word_tokenize(sentence) 
                               if word.isalpha() and word.lower() not in self.stop_words]
            
            # Score based on top words
            for word in sentence_tokens:
                word = self.lemmatizer.lemmatize(word)
                for top_word, freq in top_words:
                    if word == top_word:
                        score += freq
            
            # Normalize by sentence length (avoid bias towards longer sentences)
            if len(sentence_tokens) > 0:
                score /= len(sentence_tokens)
            
            sentence_scores.append((sentence, score))
        
        # Sort by score and select top sentences
        sentence_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Get top sentences but maintain original order
        top_sentences = [s[0] for s in sentence_scores[:count]]
        ordered_top_sentences = [s for s in sentences if s in top_sentences]
        
        return ordered_top_sentences
    
    def extract_citations(self, text: str) -> List[Dict[str, Any]]:
        """
        Extract citations from text
        
        Args:
            text: Text to analyze
            
        Returns:
            List of extracted citations
        """
        citations = []
        
        try:
            # Common citation patterns (simplified)
            patterns = [
                # APA style
                r'\(([A-Za-z-]+(?:\s+et\s+al\.)?),\s+(\d{4}[a-z]?)\)',
                # IEEE style
                r'\[(\d+)\]',
                # Chicago style
                r'(?<!\w)(\d+)\.',
                # Author-year in text
                r'([A-Za-z-]+(?:\s+et\s+al\.)?)(?:\s+\((\d{4}[a-z]?)\))',
                # FAA/EASA document references
                r'(?:AC|AMC|GM)\s+(\d+(?:-\d+)*)'
            ]
            
            # Extract citations using patterns
            for pattern in patterns:
                matches = re.finditer(pattern, text)
                for match in matches:
                    citation = {
                        'text': match.group(0),
                        'position': match.span(),
                        'type': self._determine_citation_type(match.group(0))
                    }
                    
                    # Add author and year if available
                    if len(match.groups()) >= 2:
                        citation['author'] = match.group(1)
                        if match.group(2):
                            citation['year'] = match.group(2)
                    
                    citations.append(citation)
            
            # Extract reference list items (simplified)
            reference_section = self._extract_reference_section(text)
            if reference_section:
                reference_items = re.split(r'\n+', reference_section)
                for i, ref in enumerate(reference_items):
                    if len(ref.strip()) > 10:  # Avoid short lines
                        citations.append({
                            'text': ref.strip(),
                            'position': (text.find(ref), text.find(ref) + len(ref)),
                            'type': 'reference_list_item',
                            'reference_index': i + 1
                        })
            
            return citations
            
        except Exception as e:
            logger.warning(f"Error extracting citations: {str(e)}")
            return []
    
    def _determine_citation_type(self, citation_text: str) -> str:
        """Determine the type of citation"""
        if re.match(r'\([A-Za-z-]+(?:\s+et\s+al\.)?),\s+\d{4}[a-z]?\)', citation_text):
            return 'apa_parenthetical'
        elif re.match(r'\[\d+\]', citation_text):
            return 'ieee_numeric'
        elif re.match(r'(?<!\w)\d+\.', citation_text):
            return 'chicago_numeric'
        elif re.match(r'[A-Za-z-]+(?:\s+et\s+al\.)?(?:\s+\(\d{4}[a-z]?\))', citation_text):
            return 'author_year_inline'
        elif re.match(r'(?:AC|AMC|GM)\s+\d+(?:-\d+)*', citation_text):
            return 'regulatory_reference'
        else:
            return 'unknown'
    
    def _extract_reference_section(self, text: str) -> str:
        """Extract reference section from text"""
        # Look for common reference section headers
        section_patterns = [
            r'(?:\n|\r\n)References(?:\n|\r\n)',
            r'(?:\n|\r\n)Bibliography(?:\n|\r\n)',
            r'(?:\n|\r\n)Works Cited(?:\n|\r\n)',
            r'(?:\n|\r\n)Sources(?:\n|\r\n)'
        ]
        
        for pattern in section_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                section_start = match.end()
                
                # Find end of section (next section heading or end of text)
                next_section = re.search(r'(?:\n|\r\n)[A-Z][A-Za-z\s]+(?:\n|\r\n)', text[section_start:])
                if next_section:
                    section_end = section_start + next_section.start()
                else:
                    section_end = len(text)
                
                return text[section_start:section_end].strip()
        
        return ""
    
    def check_plagiarism(self, text: str, reference_texts: List[str], 
                        threshold: float = 0.8) -> Dict[str, Any]:
        """
        Check for potential plagiarism by comparing text against reference texts
        
        Args:
            text: Text to check
            reference_texts: List of reference texts to compare against
            threshold: Similarity threshold for flagging potential plagiarism
            
        Returns:
            Dictionary with plagiarism check results
        """
        try:
            # Preprocess text
            text_sentences = sent_tokenize(text)
            
            # Preprocess reference texts
            all_reference_sentences = []
            reference_sentence_sources = []
            
            for i, ref_text in enumerate(reference_texts):
                ref_sentences = sent_tokenize(ref_text)
                all_reference_sentences.extend(ref_sentences)
                reference_sentence_sources.extend([i] * len(ref_sentences))
            
            # If no reference sentences, return early
            if not all_reference_sentences:
                return {
                    'plagiarism_detected': False,
                    'similarity_score': 0.0,
                    'matched_segments': []
                }
            
            # Create TF-IDF vectorizer
            vectorizer = TfidfVectorizer(stop_words='english')
            
            # Create document matrix
            try:
                all_sentences = text_sentences + all_reference_sentences
                tfidf_matrix = vectorizer.fit_transform(all_sentences)
                
                # Calculate similarity between each text sentence and reference sentences
                matches = []
                
                for i, text_sentence in enumerate(text_sentences):
                    text_vector = tfidf_matrix[i]
                    
                    # Calculate similarity with each reference sentence
                    for j, ref_sentence in enumerate(all_reference_sentences):
                        ref_vector = tfidf_matrix[len(text_sentences) + j]
                        
                        # Calculate cosine similarity
                        similarity = cosine_similarity(text_vector, ref_vector)[0][0]
                        
                        # Check if above threshold
                        if similarity > threshold:
                            matches.append({
                                'text_sentence': text_sentence,
                                'reference_sentence': ref_sentence,
                                'similarity': similarity,
                                'reference_index': reference_sentence_sources[j]
                            })
                
                # Calculate overall similarity score
                if matches:
                    overall_similarity = sum(m['similarity'] for m in matches) / len(matches)
                else:
                    overall_similarity = 0.0
                
                # Create result
                result = {
                    'plagiarism_detected': len(matches) > 0,
                    'similarity_score': overall_similarity,
                    'matched_segments': matches,
                    'match_count': len(matches)
                }
                
                return result
                
            except ValueError as e:
                # Handle case where vectorizer fails (e.g., empty documents)
                logger.warning(f"Vectorizer error in plagiarism check: {str(e)}")
                return {
                    'plagiarism_detected': False,
                    'similarity_score': 0.0,
                    'matched_segments': [],
                    'error': str(e)
                }
            
        except Exception as e:
            logger.warning(f"Error checking plagiarism: {str(e)}")
            return {
                'plagiarism_detected': False,
                'similarity_score': 0.0,
                'matched_segments': [],
                'error': str(e)
            }
    
    def generate_summary(self, text: str, max_length: int = 500, 
                        format_type: str = 'text') -> str:
        """
        Generate a summary of the given text
        
        Args:
            text: Text to summarize
            max_length: Maximum length of summary in characters
            format_type: Output format ('text' or 'html')
            
        Returns:
            Summary text in the specified format
        """
        try:
            # Analyze text to get key sentences
            analysis = self.analyze_text(text)
            
            if 'error' in analysis:
                return f"Error generating summary: {analysis['error']}"
            
            # Get key sentences
            key_sentences = analysis.get('key_sentences', [])
            
            # Create summary from key sentences
            if key_sentences:
                summary = " ".join(key_sentences)
            else:
                # Fallback to simple truncation
                sentences = sent_tokenize(text)
                summary = " ".join(sentences[:3])
            
            # Truncate if needed
            if len(summary) > max_length:
                # Truncate to the last complete sentence within max_length
                sentences = sent_tokenize(summary[:max_length])
                summary = " ".join(sentences[:-1]) if len(sentences) > 1 else sentences[0]
                summary += "..."
            
            # Format output
            if format_type == 'html':
                # Create HTML summary
                html_summary = f"<h3>Summary</h3><p>{summary}</p>"
                
                # Add key words
                if 'top_words' in analysis:
                    top_words = list(analysis['top_words'].items())[:10]
                    words_html = ", ".join([f"{word} ({count})" for word, count in top_words])
                    html_summary += f"<h4>Key Terms</h4><p>{words_html}</p>"
                
                # Add statistics
                html_summary += f"<h4>Statistics</h4><ul>"
                html_summary += f"<li>Word count: {analysis['word_count']}</li>"
                html_summary += f"<li>Sentence count: {analysis['sentence_count']}</li>"
                html_summary += f"<li>Average sentence length: {analysis['avg_sentence_length']:.1f} words</li>"
                html_summary += f"</ul>"
                
                return html_summary
            else:
                # Plain text summary
                text_summary = f"SUMMARY:\n{summary}\n\n"
                
                # Add key words
                if 'top_words' in analysis:
                    top_words = list(analysis['top_words'].items())[:10]
                    words_text = ", ".join([f"{word} ({count})" for word, count in top_words])
                    text_summary += f"KEY TERMS: {words_text}\n\n"
                
                # Add statistics
                text_summary += f"STATISTICS:\n"
                text_summary += f"- Word count: {analysis['word_count']}\n"
                text_summary += f"- Sentence count: {analysis['sentence_count']}\n"
                text_summary += f"- Average sentence length: {analysis['avg_sentence_length']:.1f} words\n"
                
                return text_summary
                
        except Exception as e:
            logger.warning(f"Error generating summary: {str(e)}")
            return f"Error generating summary: {str(e)}"
    
    def export_research_findings(self, research_data: Dict[str, Any], 
                                format_type: str = 'markdown',
                                output_file: Optional[str] = None) -> str:
        """
        Export research findings in specified format
        
        Args:
            research_data: Research data dictionary
            format_type: Output format ('markdown', 'html', 'json')
            output_file: Optional file path to save the output
            
        Returns:
            Formatted research findings
        """
        try:
            if format_type == 'json':
                # Export as JSON
                output = json.dumps(research_data, indent=2)
                
            elif format_type == 'html':
                # Export as HTML
                html_output = []
                html_output.append("<!DOCTYPE html><html><head>")
                html_output.append("<meta charset='utf-8'>")
                html_output.append(f"<title>{research_data.get('title', 'Research Findings')}</title>")
                html_output.append("<style>")
                html_output.append("body { font-family: Arial, sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px; }")
                html_output.append("h1 { color: #2c3e50; }")
                html_output.append("h2 { color: #3498db; margin-top: 30px; }")
                html_output.append("h3 { color: #2980b9; }")
                html_output.append(".source { color: #7f8c8d; font-size: 0.9em; }")
                html_output.append(".summary { background-color: #f8f9fa; padding: 15px; border-left: 4px solid #3498db; }")
                html_output.append(".citation { background-color: #f8f9fa; padding: 10px; margin: 10px 0; }")
                html_output.append("</style>")
                html_output.append("</head><body>")
                
                # Title and overview
                html_output.append(f"<h1>{research_data.get('title', 'Research Findings')}</h1>")
                
                if 'date' in research_data:
                    html_output.append(f"<p>Date: {research_data['date']}</p>")
                
                if 'overview' in research_data:
                    html_output.append(f"<div class='summary'><p>{research_data['overview']}</p></div>")
                
                # Key findings
                if 'key_findings' in research_data:
                    html_output.append("<h2>Key Findings</h2>")
                    html_output.append("<ul>")
                    for finding in research_data['key_findings']:
                        html_output.append(f"<li>{finding}</li>")
                    html_output.append("</ul>")
                
                # Sources
                if 'sources' in research_data:
                    html_output.append("<h2>Sources</h2>")
                    for i, source in enumerate(research_data['sources']):
                        html_output.append(f"<h3>{i+1}. {source.get('title', 'Untitled Source')}</h3>")
                        if 'url' in source:
                            html_output.append(f"<p><a href='{source['url']}'>{source['url']}</a></p>")
                        if 'summary' in source:
                            html_output.append(f"<div class='summary'><p>{source['summary']}</p></div>")
                        if 'key_points' in source:
                            html_output.append("<ul>")
                            for point in source['key_points']:
                                html_output.append(f"<li>{point}</li>")
                            html_output.append("</ul>")
                
                # Citations
                if 'citations' in research_data:
                    html_output.append("<h2>Citations</h2>")
                    for citation in research_data['citations']:
                        html_output.append(f"<div class='citation'>{citation}</div>")
                
                html_output.append("</body></html>")
                output = "\n".join(html_output)
                
            else:  # Default to markdown
                # Export as Markdown
                md_output = []
                md_output.append(f"# {research_data.get('title', 'Research Findings')}")
                md_output.append("")
                
                if 'date' in research_data:
                    md_output.append(f"Date: {research_data['date']}")
                    md_output.append("")
                
                if 'overview' in research_data:
                    md_output.append("## Overview")
                    md_output.append("")
                    md_output.append(research_data['overview'])
                    md_output.append("")
                
                # Key findings
                if 'key_findings' in research_data:
                    md_output.append("## Key Findings")
                    md_output.append("")
                    for finding in research_data['key_findings']:
                        md_output.append(f"- {finding}")
                    md_output.append("")
                
                # Sources
                if 'sources' in research_data:
                    md_output.append("## Sources")
                    md_output.append("")
                    for i, source in enumerate(research_data['sources']):
                        md_output.append(f"### {i+1}. {source.get('title', 'Untitled Source')}")
                        md_output.append("")
                        if 'url' in source:
                            md_output.append(f"[{source['url']}]({source['url']})")
                            md_output.append("")
                        if 'summary' in source:
                            md_output.append(f"**Summary**: {source['summary']}")
                            md_output.append("")
                        if 'key_points' in source:
                            for point in source['key_points']:
                                md_output.append(f"- {point}")
                            md_output.append("")
                
                # Citations
                if 'citations' in research_data:
                    md_output.append("## Citations")
                    md_output.append("")
                    for citation in research_data['citations']:
                        md_output.append(f"- {citation}")
                    md_output.append("")
                
                output = "\n".join(md_output)
            
            # Save to file if output_file is specified
            if output_file:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(output)
                logger.info(f"Research findings saved to: {output_file}")
            
            return output
            
        except Exception as e:
            logger.warning(f"Error exporting research findings: {str(e)}")
            return f"Error exporting research findings: {str(e)}"
    
    def create_research_project(self, topic: str, sources: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Create a new research project on the given topic
        
        Args:
            topic: Research topic
            sources: Optional list of initial sources
            
        Returns:
            Research project dictionary
        """
        # Generate a project ID
        project_id = f"research_{int(time.time())}_{hashlib.md5(topic.encode()).hexdigest()[:8]}"
        
        # Create project structure
        project = {
            'id': project_id,
            'topic': topic,
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat(),
            'sources': sources or [],
            'notes': [],
            'key_findings': [],
            'outline': {
                'title': f"Research on {topic}",
                'sections': [
                    {'title': 'Introduction', 'content': ''},
                    {'title': 'Background', 'content': ''},
                    {'title': 'Key Findings', 'content': ''},
                    {'title': 'Analysis', 'content': ''},
                    {'title': 'Conclusions', 'content': ''},
                    {'title': 'References', 'content': ''}
                ]
            }
        }
        
        # Save project to cache
        self.document_cache[project_id] = project
        self._save_cache(self.document_cache, 'document_cache.pkl')
        
        return project
    
    def add_source_to_project(self, project_id: str, source: Dict[str, Any]) -> Dict[str, Any]:
        """
        Add a source to a research project
        
        Args:
            project_id: Project ID
            source: Source information dictionary
            
        Returns:
            Updated project dictionary
        """
        # Check if project exists
        if project_id not in self.document_cache:
            raise ValueError(f"Project not found: {project_id}")
        
        # Get project
        project = self.document_cache[project_id]
        
        # Add source if not already present
        source_exists = any(s.get('url') == source.get('url') for s in project['sources'])
        if not source_exists:
            # Add timestamp
            source['added_at'] = datetime.now().isoformat()
            
            # Add to sources
            project['sources'].append(source)
            
            # Update project
            project['updated_at'] = datetime.now().isoformat()
            self.document_cache[project_id] = project
            self._save_cache(self.document_cache, 'document_cache.pkl')
        
        return project
    
    def add_note_to_project(self, project_id: str, note: str, source_id: str = None) -> Dict[str, Any]:
        """
        Add a note to a research project
        
        Args:
            project_id: Project ID
            note: Note text
            source_id: Optional source ID the note is related to
            
        Returns:
            Updated project dictionary
        """
        # Check if project exists
        if project_id not in self.document_cache:
            raise ValueError(f"Project not found: {project_id}")
        
        # Get project
        project = self.document_cache[project_id]
        
        # Create note object
        note_obj = {
            'id': f"note_{int(time.time())}_{len(project['notes'])}",
            'text': note,
            'created_at': datetime.now().isoformat(),
            'source_id': source_id
        }
        
        # Add to notes
        project['notes'].append(note_obj)
        
        # Update project
        project['updated_at'] = datetime.now().isoformat()
        self.document_cache[project_id] = project
        self._save_cache(self.document_cache, 'document_cache.pkl')
        
        return project
    
    def generate_citations(self, sources: List[Dict[str, Any]], 
                          style: str = 'apa') -> List[str]:
        """
        Generate citations for sources in specified style
        
        Args:
            sources: List of source dictionaries
            style: Citation style ('apa', 'mla', 'chicago', 'ieee')
            
        Returns:
            List of formatted citations
        """
        citations = []
        
        for source in sources:
            try:
                # Extract source information
                title = source.get('title', 'Untitled')
                authors = source.get('authors', [])
                year = source.get('year', '')
                url = source.get('url', '')
                publisher = source.get('publisher', '')
                journal = source.get('journal', '')
                volume = source.get('volume', '')
                issue = source.get('issue', '')
                pages = source.get('pages', '')
                
                # If no year but has date, extract year
                if not year and 'date' in source:
                    date_match = re.search(r'\b(19|20)\d{2}\b', source['date'])
                    if date_match:
                        year = date_match.group(0)
                
                # Format author string
                if isinstance(authors, list):
                    author_str = ', '.join(authors)
                else:
                    author_str = str(authors)
                
                # Generate citation based on style
                if style == 'apa':
                    if journal:  # Journal article
                        citation = f"{author_str}. ({year}). {title}. "
                        if journal:
                            citation += f"{journal}"
                            if volume:
                                citation += f", {volume}"
                                if issue:
                                    citation += f"({issue})"
                            if pages:
                                citation += f", {pages}"
                        citation += "."
                    else:  # Web page or other
                        citation = f"{author_str}. ({year}). {title}. "
                        if publisher:
                            citation += f"{publisher}. "
                        if url:
                            citation += f"Retrieved from {url}"
                
                elif style == 'mla':
                    citation = f"{author_str}. \"{title}\"."
                    if journal:
                        citation += f" {journal}"
                        if volume:
                            citation += f", vol. {volume}"
                            if issue:
                                citation += f", no. {issue}"
                        if year:
                            citation += f", {year}"
                        if pages:
                            citation += f", pp. {pages}"
                    else:
                        if publisher:
                            citation += f" {publisher}"
                        if year:
                            citation += f", {year}"
                    citation += "."
                
                elif style == 'chicago':
                    citation = f"{author_str}. \"{title}\"."
                    if journal:
                        citation += f" {journal}"
                        if volume:
                            citation += f" {volume}"
                            if issue:
                                citation += f", no. {issue}"
                        if year:
                            citation += f" ({year})"
                        if pages:
                            citation += f": {pages}"
                    else:
                        if publisher:
                            citation += f" {publisher}"
                        if year:
                            citation += f", {year}"
                    citation += "."
                
                elif style == 'ieee':
                    citation = f"[{len(citations) + 1}] {author_str}, \"{title}\"."
                    if journal:
                        citation += f" {journal}"
                        if volume:
                            citation += f", vol. {volume}"
                            if issue:
                                citation += f", no. {issue}"
                        if pages:
                            citation += f", pp. {pages}"
                    if year:
                        citation += f", {year}."
                
                else:
                    # Generic citation
                    citation = f"{author_str}. {title}. {year}."
                    if url:
                        citation += f" URL: {url}"
                
                citations.append(citation)
                
            except Exception as e:
                logger.warning(f"Error generating citation: {str(e)}")
                # Add basic citation as fallback
                citations.append(f"{source.get('title', 'Unknown Source')}. {source.get('url', '')}")
        
        return citations

# Example usage
if __name__ == "__main__":
    # Create research assistant
    assistant = ResearchAssistant()
    
    # Perform a search
    search_query = "pilot training simulation effectiveness"
    print(f"Searching for: {search_query}")
    
    # Set to False to avoid actual web requests during testing
    use_real_search = False
    
    if use_real_search:
        results = assistant.search(search_query, max_results=5)
        print(f"Found {len(results)} results")
        
        # Print top results
        for i, result in enumerate(results[:3]):
            print(f"\n{i+1}. {result['title']}")
            print(f"   Source: {result['source']}")
            print(f"   URL: {result['url']}")
            print(f"   Relevance: {result['relevance_score']:.2f}")
            print(f"   Snippet: {result['snippet'][:100]}...")
        
        # Fetch page content for first result
        if results:
            page_content = assistant.fetch_page_content(results[0]['url'])
            
            if page_content['status'] == 'success':
                # Analyze text
                print("\nAnalyzing page content...")
                analysis = assistant.analyze_text(page_content['content_text'])
                
                # Print summary
                print("\nSummary:")
                print(assistant.generate_summary(page_content['content_text'], max_length=300))
                
                # Extract citations
                citations = assistant.extract_citations(page_content['content_text'])
                print(f"\nFound {len(citations)} citations")
                for i, citation in enumerate(citations[:3]):
                    print(f"  - {citation['text']}")
    else:
        # Use dummy data for demonstration
        print("\nUsing dummy data for demonstration")
        
        dummy_text = """
        Aviation training has evolved significantly over the past decades. According to Smith et al. (2019), 
        simulation-based training provides numerous advantages over traditional methods. 
        The Federal Aviation Administration (FAA) has published Advisory Circular AC 120-45A outlining 
        the requirements for simulation training devices.
        
        Recent studies by Johnson (2020) have shown that transfer of training from simulators to 
        real aircraft is highly effective when the simulation has high fidelity. However, Patel and Wilson (2018) 
        argue that procedural training can be effective even with lower fidelity devices.
        
        The European Union Aviation Safety Agency (EASA) has similar requirements outlined in CS-FSTD(A) 
        for airplane flight simulation training devices [1].
        
        References:
        
        1. Smith, J., Brown, R., & Davis, K. (2019). Effectiveness of simulation in pilot training. 
           Journal of Aviation Training, 25(3), 45-62.
        
        2. Johnson, M. (2020). Transfer of training in aviation: A meta-analysis. 
           International Journal of Aviation Psychology, 12(1), 15-30.
        
        3. Patel, S., & Wilson, F. (2018). Low-cost simulation for procedural training. 
           Aviation Training Technology, 10(2), 78-93.
        
        4. European Union Aviation Safety Agency. (2021). Certification Specifications for Airplane 
           Flight Simulation Training Devices (CS-FSTD(A)). EASA.
        """
        
        # Analyze text
        print("\nAnalyzing text...")
        analysis = assistant.analyze_text(dummy_text)
        
        # Print key sentences
        print("\nKey sentences:")
        for sentence in analysis['key_sentences']:
            print(f"  - {sentence}")
        
        # Print top words
        print("\nTop words:")
        for word, count in list(analysis['top_words'].items())[:5]:
            print(f"  - {word}: {count}")
        
        # Generate summary
        print("\nSummary:")
        print(assistant.generate_summary(dummy_text, max_length=300))
        
        # Extract citations
        citations = assistant.extract_citations(dummy_text)
        print(f"\nFound {len(citations)} citations:")
        for citation in citations:
            print(f"  - {citation['text']} (Type: {citation['type']})")
        
        # Generate citations for sources
        dummy_sources = [
            {
                'title': 'Effectiveness of simulation in pilot training',
                'authors': ['Smith, J.', 'Brown, R.', 'Davis, K.'],
                'year': '2019',
                'journal': 'Journal of Aviation Training',
                'volume': '25',
                'issue': '3',
                'pages': '45-62'
            },
            {
                'title': 'Transfer of training in aviation: A meta-analysis',
                'authors': ['Johnson, M.'],
                'year': '2020',
                'journal': 'International Journal of Aviation Psychology',
                'volume': '12',
                'issue': '1',
                'pages': '15-30'
            }
        ]
        
        print("\nFormatted citations (APA style):")
        apa_citations = assistant.generate_citations(dummy_sources, style='apa')
        for citation in apa_citations:
            print(f"  - {citation}")
        
        # Check for plagiarism with synthetic example
        print("\nPlagiarism check example:")
        original_text = "Simulation-based training provides numerous advantages over traditional methods."
        check_text = "Experts agree that simulation-based training provides numerous advantages over traditional flight training methods."
        
        plagiarism_result = assistant.check_plagiarism(check_text, [original_text])
        print(f"  Similarity score: {plagiarism_result['similarity_score']:.2f}")
        print(f"  Plagiarism detected: {plagiarism_result['plagiarism_detected']}")
        
        # Create a research project
        print("\nCreating research project:")
        project = assistant.create_research_project("Effectiveness of Flight Simulation Training")
        print(f"  Project ID: {project['id']}")
        print(f"  Topic: {project['topic']}")
        
        # Add sources to project
        for source in dummy_sources:
            assistant.add_source_to_project(project['id'], source)
        
        # Add a note
        assistant.add_note_to_project(
            project['id'], 
            "The studies consistently show positive transfer of training from simulators to aircraft."
        )
        
        # Export research findings
        research_data = {
            'title': 'Effectiveness of Flight Simulation Training',
            'date': datetime.now().strftime('%Y-%m-%d'),
            'overview': 'This research examines the effectiveness of flight simulation training compared to traditional methods.',
            'key_findings': [
                'Simulation-based training provides cost-effective alternatives to in-aircraft training.',
                'Transfer of training is highly effective when simulation has high fidelity.',
                'Procedural training can be effective even with lower fidelity devices.'
            ],
            'sources': [
                {
                    'title': 'Effectiveness of simulation in pilot training',
                    'authors': ['Smith, J.', 'Brown, R.', 'Davis, K.'],
                    'year': '2019',
                    'url': 'https://example.com/simulation-effectiveness',
                    'summary': 'This study examines the effectiveness of simulation in pilot training across various training scenarios.'
                },
                {
                    'title': 'Transfer of training in aviation: A meta-analysis',
                    'authors': ['Johnson, M.'],
                    'year': '2020',
                    'url': 'https://example.com/transfer-of-training',
                    'summary': 'A meta-analysis of studies on transfer of training from simulators to aircraft.'
                }
            ],
            'citations': apa_citations
        }
        
        print("\nExporting research findings (markdown):")
        markdown_output = assistant.export_research_findings(research_data, format_type='markdown')
        print(markdown_output[:500] + "...\n")
        
        print("Research Assistant demo completed!")

#include <memory>
#include <string>
#include <vector>
#include <unordered_map>
#include <chrono>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <future>
#include <atomic>
#include <zmq.hpp>
#include <nlohmann/json.hpp>
#include <spdlog/spdlog.h>

// For shared memory
#include <boost/interprocess/shared_memory_object.hpp>
#include <boost/interprocess/mapped_region.hpp>
#include <boost/interprocess/sync/interprocess_mutex.hpp>
#include <boost/interprocess/sync/interprocess_condition.hpp>
#include <boost/interprocess/sync/scoped_lock.hpp>

namespace ai {

using json = nlohmann::json;
namespace bip = boost::interprocess;

// Forward declarations
class PyProcessManager;
class SharedMemoryManager;
class ModelVersionTracker;

/**
 * Enumeration for AI model types
 */
enum class ModelType {
    SYLLABUS_GENERATOR,
    DOCUMENT_ANALYZER,
    PERFORMANCE_PREDICTOR,
    SKILL_ASSESSOR,
    FLIGHT_ANOMALY_DETECTOR,
    TRAINING_RECOMMENDER,
    PROGRESS_ANALYZER
};

/**
 * Enumeration for ZeroMQ message types
 */
enum class MessageType {
    REQUEST,
    RESPONSE,
    HEARTBEAT,
    ERROR,
    CONTROL
};

/**
 * Structure for model metadata
 */
struct ModelInfo {
    std::string id;
    std::string name;
    std::string version;
    std::string description;
    std::unordered_map<std::string, std::string> parameters;
    std::chrono::system_clock::time_point lastUpdated;
    bool isActive;
};

/**
 * Structure for shared memory data header
 */
struct SharedMemoryHeader {
    bip::interprocess_mutex mutex;
    bip::interprocess_condition dataReady;
    bip::interprocess_condition dataProcessed;
    std::size_t dataSize;
    bool isReady;
    bool isProcessed;
    int status;
    char modelType[32];
    char operation[32];
    char messageId[64];
};

/**
 * Class for managing Python processes
 */
class PyProcessManager {
public:
    /**
     * Constructor
     */
    PyProcessManager(const std::string& pythonPath, const std::string& scriptDir);
    
    /**
     * Destructor
     */
    ~PyProcessManager();
    
    /**
     * Start a Python process for a specific model type
     */
    bool startProcess(ModelType modelType);
    
    /**
     * Stop a Python process
     */
    bool stopProcess(ModelType modelType);
    
    /**
     * Stop all Python processes
     */
    void stopAllProcesses();
    
    /**
     * Check if a process is running
     */
    bool isProcessRunning(ModelType modelType);
    
    /**
     * Restart a process if it's not responding
     */
    bool restartProcessIfNeeded(ModelType modelType);
    
    /**
     * Get process health metrics
     */
    json getProcessHealthMetrics();

private:
    std::string pythonPath;
    std::string scriptDir;
    std::unordered_map<ModelType, int> processes;
    std::unordered_map<ModelType, std::chrono::system_clock::time_point> lastHeartbeats;
    std::mutex processMutex;
    
    /**
     * Send signal to process
     */
    bool sendSignal(int pid, int signal);
    
    /**
     * Check if process is responding
     */
    bool isProcessResponding(ModelType modelType);
    
    /**
     * Get script path for model type
     */
    std::string getScriptPath(ModelType modelType);
    
    /**
     * Helper to convert ModelType to string
     */
    std::string modelTypeToString(ModelType modelType);
};

/**
 * Class for managing shared memory for large data transfers
 */
class SharedMemoryManager {
public:
    /**
     * Constructor
     */
    SharedMemoryManager();
    
    /**
     * Destructor
     */
    ~SharedMemoryManager();
    
    /**
     * Create a shared memory segment
     */
    bool createSharedMemory(const std::string& name, std::size_t size);
    
    /**
     * Destroy a shared memory segment
     */
    bool destroySharedMemory(const std::string& name);
    
    /**
     * Write data to shared memory
     */
    bool writeData(
        const std::string& name, 
        const void* data, 
        std::size_t size, 
        ModelType modelType,
        const std::string& operation,
        const std::string& messageId
    );
    
    /**
     * Read data from shared memory
     */
    std::vector<uint8_t> readData(
        const std::string& name, 
        int timeoutMs = 5000
    );
    
    /**
     * Wait for Python process to signal data processing completion
     */
    bool waitForProcessing(
        const std::string& name, 
        int timeoutMs = 30000
    );
    
    /**
     * Signal completion of data reading
     */
    void signalDataProcessed(const std::string& name);
    
    /**
     * Get status code from shared memory
     */
    int getStatusCode(const std::string& name);

private:
    std::unordered_map<std::string, std::unique_ptr<bip::shared_memory_object>> sharedMemories;
    std::unordered_map<std::string, std::unique_ptr<bip::mapped_region>> headerRegions;
    std::unordered_map<std::string, std::unique_ptr<bip::mapped_region>> dataRegions;
    std::mutex shmMutex;
    
    /**
     * Get header from mapped region
     */
    SharedMemoryHeader* getHeader(const std::string& name);
    
    /**
     * Get data pointer from mapped region
     */
    void* getDataPtr(const std::string& name);
};

/**
 * Class for tracking model versions
 */
class ModelVersionTracker {
public:
    /**
     * Constructor
     */
    ModelVersionTracker();
    
    /**
     * Get model info
     */
    ModelInfo getModelInfo(ModelType modelType);
    
    /**
     * Update model info
     */
    void updateModelInfo(ModelType modelType, const ModelInfo& info);
    
    /**
     * Check if model needs update
     */
    bool needsUpdate(ModelType modelType, const std::string& currentVersion);
    
    /**
     * Load model info from database
     */
    bool loadFromDatabase();
    
    /**
     * Save model info to database
     */
    bool saveToDatabase();

private:
    std::unordered_map<ModelType, ModelInfo> modelInfoMap;
    std::mutex modelMutex;
    
    /**
     * Helper to convert ModelType to string
     */
    std::string modelTypeToString(ModelType modelType);
    
    /**
     * Helper to convert string to ModelType
     */
    ModelType stringToModelType(const std::string& str);
};

/**
 * Main class for handling AI/Python integration
 */
class AIPythonIntegration {
public:
    /**
     * Constructor
     */
    AIPythonIntegration(
        const std::string& pythonPath, 
        const std::string& scriptDir,
        const std::string& zmqEndpoint
    );
    
    /**
     * Destructor
     */
    ~AIPythonIntegration();
    
    /**
     * Initialize the integration
     */
    bool initialize();
    
    /**
     * Shutdown the integration
     */
    void shutdown();
    
    /**
     * Process document with AI model
     */
    json processDocument(
        ModelType modelType, 
        const std::string& documentPath, 
        const json& parameters
    );
    
    /**
     * Analyze flight telemetry data
     */
    json analyzeFlightData(
        const std::vector<uint8_t>& telemetryData, 
        const json& parameters
    );
    
    /**
     * Generate training recommendations
     */
    json generateTrainingRecommendations(
        const std::string& traineeId, 
        const json& performanceData,
        const json& parameters
    );
    
    /**
     * Assess pilot skills
     */
    json assessSkills(
        const std::string& traineeId,
        const json& assessmentData,
        const json& parameters
    );
    
    /**
     * Generate syllabus
     */
    json generateSyllabus(
        const json& requirements,
        const json& constraints,
        const json& parameters
    );
    
    /**
     * Predict trainee performance
     */
    json predictPerformance(
        const std::string& traineeId,
        const json& historicalData,
        const json& parameters
    );
    
    /**
     * Check system health
     */
    json checkHealth();

private:
    std::unique_ptr<PyProcessManager> processManager;
    std::unique_ptr<SharedMemoryManager> sharedMemoryManager;
    std::unique_ptr<ModelVersionTracker> versionTracker;
    std::unique_ptr<zmq::context_t> zmqContext;
    std::unique_ptr<zmq::socket_t> zmqSocket;
    std::string zmqEndpoint;
    std::atomic<bool> isRunning;
    std::thread heartbeatThread;
    std::mutex zmqMutex;
    
    /**
     * Send message via ZeroMQ
     */
    bool sendMessage(
        const json& message, 
        MessageType messageType
    );
    
    /**
     * Receive message via ZeroMQ
     */
    std::optional<json> receiveMessage(int timeoutMs = 5000);
    
    /**
     * Send large data via shared memory
     */
    std::string sendLargeData(
        ModelType modelType,
        const std::string& operation, 
        const void* data, 
        std::size_t size,
        const json& parameters
    );
    
    /**
     * Handle heartbeat responses
     */
    void heartbeatThreadFunc();
    
    /**
     * Send heartbeat to Python processes
     */
    void sendHeartbeat();
    
    /**
     * Generate a unique message ID
     */
    std::string generateMessageId();
    
    /**
     * Helper to convert ModelType to string
     */
    std::string modelTypeToString(ModelType modelType);
};

// Implementation of AIPythonIntegration

AIPythonIntegration::AIPythonIntegration(
    const std::string& pythonPath, 
    const std::string& scriptDir,
    const std::string& zmqEndpoint
) : zmqEndpoint(zmqEndpoint), isRunning(false) {
    processManager = std::make_unique<PyProcessManager>(pythonPath, scriptDir);
    sharedMemoryManager = std::make_unique<SharedMemoryManager>();
    versionTracker = std::make_unique<ModelVersionTracker>();
    
    zmqContext = std::make_unique<zmq::context_t>(1);
}

AIPythonIntegration::~AIPythonIntegration() {
    shutdown();
}

bool AIPythonIntegration::initialize() {
    try {
        // Load model version information
        if (!versionTracker->loadFromDatabase()) {
            spdlog::warn("Failed to load model version information from database");
        }
        
        // Initialize ZeroMQ socket
        zmqSocket = std::make_unique<zmq::socket_t>(*zmqContext, ZMQ_ROUTER);
        
        int timeout = 5000; // 5 seconds
        zmqSocket->setsockopt(ZMQ_RCVTIMEO, &timeout, sizeof(timeout));
        
        // Bind socket
        zmqSocket->bind(zmqEndpoint);
        
        // Start Python processes for each model type
        processManager->startProcess(ModelType::DOCUMENT_ANALYZER);
        processManager->startProcess(ModelType::PERFORMANCE_PREDICTOR);
        processManager->startProcess(ModelType::SKILL_ASSESSOR);
        processManager->startProcess(ModelType::SYLLABUS_GENERATOR);
        processManager->startProcess(ModelType::FLIGHT_ANOMALY_DETECTOR);
        processManager->startProcess(ModelType::TRAINING_RECOMMENDER);
        
        // Start heartbeat thread
        isRunning = true;
        heartbeatThread = std::thread(&AIPythonIntegration::heartbeatThreadFunc, this);
        
        spdlog::info("AI/Python integration initialized successfully");
        return true;
    } catch (const std::exception& e) {
        spdlog::error("Failed to initialize AI/Python integration: {}", e.what());
        shutdown();
        return false;
    }
}

void AIPythonIntegration::shutdown() {
    if (isRunning.exchange(false)) {
        // Stop heartbeat thread
        if (heartbeatThread.joinable()) {
            heartbeatThread.join();
        }
        
        // Stop Python processes
        processManager->stopAllProcesses();
        
        // Close ZeroMQ socket
        zmqSocket.reset();
        
        spdlog::info("AI/Python integration shutdown complete");
    }
}

json AIPythonIntegration::processDocument(
    ModelType modelType, 
    const std::string& documentPath, 
    const json& parameters
) {
    // Ensure the appropriate Python process is running
    if (!processManager->isProcessRunning(modelType)) {
        if (!processManager->startProcess(modelType)) {
            throw std::runtime_error("Failed to start Python process for document processing");
        }
    }
    
    // Prepare request
    json request = {
        {"operation", "process_document"},
        {"document_path", documentPath},
        {"parameters", parameters},
        {"model_type", modelTypeToString(modelType)}
    };
    
    // Check if model needs update
    ModelInfo info = versionTracker->getModelInfo(modelType);
    if (info.isActive) {
        request["model_version"] = info.version;
    }
    
    // Send request via ZeroMQ
    {
        std::lock_guard<std::mutex> lock(zmqMutex);
        if (!sendMessage(request, MessageType::REQUEST)) {
            throw std::runtime_error("Failed to send document processing request");
        }
        
        // Receive response
        auto response = receiveMessage(30000); // 30 second timeout
        if (!response) {
            throw std::runtime_error("Timeout waiting for document processing response");
        }
        
        // Update model info if version changed
        if (response->contains("model_version") && 
            response->at("model_version") != info.version) {
            info.version = response->at("model_version");
            info.lastUpdated = std::chrono::system_clock::now();
            versionTracker->updateModelInfo(modelType, info);
        }
        
        return *response;
    }
}

json AIPythonIntegration::analyzeFlightData(
    const std::vector<uint8_t>& telemetryData, 
    const json& parameters
) {
    // For large data, use shared memory
    if (telemetryData.size() > 1024 * 1024) { // 1MB threshold
        const ModelType modelType = ModelType::FLIGHT_ANOMALY_DETECTOR;
        
        // Ensure the process is running
        if (!processManager->isProcessRunning(modelType)) {
            if (!processManager->startProcess(modelType)) {
                throw std::runtime_error("Failed to start Python process for flight data analysis");
            }
        }
        
        // Send data via shared memory
        std::string messageId = sendLargeData(
            modelType,
            "analyze_flight_data",
            telemetryData.data(),
            telemetryData.size(),
            parameters
        );
        
        // Wait for processing to complete
        const std::string shmName = "flight_data_" + messageId;
        if (!sharedMemoryManager->waitForProcessing(shmName, 60000)) { // 60 second timeout
            throw std::runtime_error("Timeout waiting for flight data analysis");
        }
        
        // Read result
        std::vector<uint8_t> resultData = sharedMemoryManager->readData(shmName);
        
        // Check status code
        int status = sharedMemoryManager->getStatusCode(shmName);
        if (status != 0) {
            throw std::runtime_error("Flight data analysis failed with status code: " + 
                                     std::to_string(status));
        }
        
        // Signal data processed
        sharedMemoryManager->signalDataProcessed(shmName);
        
        // Destroy shared memory
        sharedMemoryManager->destroySharedMemory(shmName);
        
        // Parse result
        std::string resultStr(resultData.begin(), resultData.end());
        return json::parse(resultStr);
    } else {
        // For smaller data, use ZeroMQ directly
        const ModelType modelType = ModelType::FLIGHT_ANOMALY_DETECTOR;
        
        // Ensure the process is running
        if (!processManager->isProcessRunning(modelType)) {
            if (!processManager->startProcess(modelType)) {
                throw std::runtime_error("Failed to start Python process for flight data analysis");
            }
        }
        
        // Convert binary data to base64
        std::string base64Data = ""; // Implement base64 encoding here
        
        // Prepare request
        json request = {
            {"operation", "analyze_flight_data"},
            {"telemetry_data", base64Data},
            {"parameters", parameters},
            {"model_type", modelTypeToString(modelType)}
        };
        
        // Send request via ZeroMQ
        {
            std::lock_guard<std::mutex> lock(zmqMutex);
            if (!sendMessage(request, MessageType::REQUEST)) {
                throw std::runtime_error("Failed to send flight data analysis request");
            }
            
            // Receive response
            auto response = receiveMessage(30000); // 30 second timeout
            if (!response) {
                throw std::runtime_error("Timeout waiting for flight data analysis response");
            }
            
            return *response;
        }
    }
}

json AIPythonIntegration::generateTrainingRecommendations(
    const std::string& traineeId, 
    const json& performanceData,
    const json& parameters
) {
    const ModelType modelType = ModelType::TRAINING_RECOMMENDER;
    
    // Ensure the process is running
    if (!processManager->isProcessRunning(modelType)) {
        if (!processManager->startProcess(modelType)) {
            throw std::runtime_error("Failed to start Python process for training recommendations");
        }
    }
    
    // Prepare request
    json request = {
        {"operation", "generate_recommendations"},
        {"trainee_id", traineeId},
        {"performance_data", performanceData},
        {"parameters", parameters},
        {"model_type", modelTypeToString(modelType)}
    };
    
    // Check if model needs update
    ModelInfo info = versionTracker->getModelInfo(modelType);
    if (info.isActive) {
        request["model_version"] = info.version;
    }
    
    // Send request via ZeroMQ
    {
        std::lock_guard<std::mutex> lock(zmqMutex);
        if (!sendMessage(request, MessageType::REQUEST)) {
            throw std::runtime_error("Failed to send training recommendations request");
        }
        
        // Receive response
        auto response = receiveMessage(15000); // 15 second timeout
        if (!response) {
            throw std::runtime_error("Timeout waiting for training recommendations response");
        }
        
        // Update model info if version changed
        if (response->contains("model_version") && 
            response->at("model_version") != info.version) {
            info.version = response->at("model_version");
            info.lastUpdated = std::chrono::system_clock::now();
            versionTracker->updateModelInfo(modelType, info);
        }
        
        return *response;
    }
}

json AIPythonIntegration::assessSkills(
    const std::string& traineeId,
    const json& assessmentData,
    const json& parameters
) {
    const ModelType modelType = ModelType::SKILL_ASSESSOR;
    
    // Ensure the process is running
    if (!processManager->isProcessRunning(modelType)) {
        if (!processManager->startProcess(modelType)) {
            throw std::runtime_error("Failed to start Python process for skill assessment");
        }
    }
    
    // Prepare request
    json request = {
        {"operation", "assess_skills"},
        {"trainee_id", traineeId},
        {"assessment_data", assessmentData},
        {"parameters", parameters},
        {"model_type", modelTypeToString(modelType)}
    };
    
    // Check if model needs update
    ModelInfo info = versionTracker->getModelInfo(modelType);
    if (info.isActive) {
        request["model_version"] = info.version;
    }
    
    // Send request via ZeroMQ
    {
        std::lock_guard<std::mutex> lock(zmqMutex);
        if (!sendMessage(request, MessageType::REQUEST)) {
            throw std::runtime_error("Failed to send skill assessment request");
        }
        
        // Receive response
        auto response = receiveMessage(20000); // 20 second timeout
        if (!response) {
            throw std::runtime_error("Timeout waiting for skill assessment response");
        }
        
        // Update model info if version changed
        if (response->contains("model_version") && 
            response->at("model_version") != info.version) {
            info.version = response->at("model_version");
            info.lastUpdated = std::chrono::system_clock::now();
            versionTracker->updateModelInfo(modelType, info);
        }
        
        return *response;
    }
}

json AIPythonIntegration::generateSyllabus(
    const json& requirements,
    const json& constraints,
    const json& parameters
) {
    const ModelType modelType = ModelType::SYLLABUS_GENERATOR;
    
    // Ensure the process is running
    if (!processManager->isProcessRunning(modelType)) {
        if (!processManager->startProcess(modelType)) {
            throw std::runtime_error("Failed to start Python process for syllabus generation");
        }
    }
    
    // Prepare request
    json request = {
        {"operation", "generate_syllabus"},
        {"requirements", requirements},
        {"constraints", constraints},
        {"parameters", parameters},
        {"model_type", modelTypeToString(modelType)}
    };
    
    // Check if model needs update
    ModelInfo info = versionTracker->getModelInfo(modelType);
    if (info.isActive) {
        request["model_version"] = info.version;
    }
    
    // Send request via ZeroMQ
    {
        std::lock_guard<std::mutex> lock(zmqMutex);
        if (!sendMessage(request, MessageType::REQUEST)) {
            throw std::runtime_error("Failed to send syllabus generation request");
        }
        
        // Receive response
        auto response = receiveMessage(30000); // 30 second timeout
        if (!response) {
            throw std::runtime_error("Timeout waiting for syllabus generation response");
        }
        
        // Update model info if version changed
        if (response->contains("model_version") && 
            response->at("model_version") != info.version) {
            info.version = response->at("model_version");
            info.lastUpdated = std::chrono::system_clock::now();
            versionTracker->updateModelInfo(modelType, info);
        }
        
        return *response;
    }
}

json AIPythonIntegration::predictPerformance(
    const std::string& traineeId,
    const json& historicalData,
    const json& parameters
) {
    const ModelType modelType = ModelType::PERFORMANCE_PREDICTOR;
    
    // Ensure the process is running
    if (!processManager->isProcessRunning(modelType)) {
        if (!processManager->startProcess(modelType)) {
            throw std::runtime_error("Failed to start Python process for performance prediction");
        }
    }
    
    // Prepare request
    json request = {
        {"operation", "predict_performance"},
        {"trainee_id", traineeId},
        {"historical_data", historicalData},
        {"parameters", parameters},
        {"model_type", modelTypeToString(modelType)}
    };
    
    // Check if model needs update
    ModelInfo info = versionTracker->getModelInfo(modelType);
    if (info.isActive) {
        request["model_version"] = info.version;
    }
    
    // Send request via ZeroMQ
    {
        std::lock_guard<std::mutex> lock(zmqMutex);
        if (!sendMessage(request, MessageType::REQUEST)) {
            throw std::runtime_error("Failed to send performance prediction request");
        }
        
        // Receive response
        auto response = receiveMessage(15000); // 15 second timeout
        if (!response) {
            throw std::runtime_error("Timeout waiting for performance prediction response");
        }
        
        // Update model info if version changed
        if (response->contains("model_version") && 
            response->at("model_version") != info.version) {
            info.version = response->at("model_version");
            info.lastUpdated = std::chrono::system_clock::now();
            versionTracker->updateModelInfo(modelType, info);
        }
        
        return *response;
    }
}

json AIPythonIntegration::checkHealth() {
    json health = {
        {"status", "ok"},
        {"processes", processManager->getProcessHealthMetrics()},
        {"models", json::array()}
    };
    
    // Add model information
    for (int i = 0; i < 7; i++) {
        ModelType type = static_cast<ModelType>(i);
        ModelInfo info = versionTracker->getModelInfo(type);
        
        health["models"].push_back({
            {"type", modelTypeToString(type)},
            {"version", info.version},
            {"active", info.isActive},
            {"last_updated", info.lastUpdated.time_since_epoch().count()}
        });
    }
    
    return health;
}

bool AIPythonIntegration::sendMessage(
    const json& message, 
    MessageType messageType
) {
    try {
        // Add message ID and type
        json enrichedMessage = message;
        enrichedMessage["message_id"] = generateMessageId();
        enrichedMessage["message_type"] = static_cast<int>(messageType);
        enrichedMessage["timestamp"] = std::chrono::system_clock::now().time_since_epoch().count();
        
        // Convert to string
        std::string messageStr = enrichedMessage.dump();
        
        // Send message
        zmq::message_t zmqMessage(messageStr.size());
        memcpy(zmqMessage.data(), messageStr.c_str(), messageStr.size());
        return zmqSocket->send(zmqMessage, zmq::send_flags::none);
    } catch (const std::exception& e) {
        spdlog::error("Failed to send ZeroMQ message: {}", e.what());
        return false;
    }
}

std::optional<json> AIPythonIntegration::receiveMessage(int timeoutMs) {
    try {
        zmq::message_t message;
        
        // Set timeout (temporarily)
        int oldTimeout;
        size_t optionSize = sizeof(oldTimeout);
        zmqSocket->getsockopt(ZMQ_RCVTIMEO, &oldTimeout, &optionSize);
        zmqSocket->setsockopt(ZMQ_RCVTIMEO, &timeoutMs, sizeof(timeoutMs));
        
        // Receive message
        if (!zmqSocket->recv(message)) {
            // Restore original timeout
            zmqSocket->setsockopt(ZMQ_RCVTIMEO, &oldTimeout, sizeof(oldTimeout));
            return std::nullopt;
        }
        
        // Restore original timeout
        zmqSocket->setsockopt(ZMQ_RCVTIMEO, &oldTimeout, sizeof(oldTimeout));
        
        // Parse JSON
        std::string messageStr(static_cast<char*>(message.data()), message.size());
        return json::parse(messageStr);
    } catch (const std::exception& e) {
        spdlog::error("Failed to receive ZeroMQ message: {}", e.what());
        return std::nullopt;
    }
}

std::string AIPythonIntegration::sendLargeData(
    ModelType modelType,
    const std::string& operation, 
    const void* data, 
    std::size_t size,
    const json& parameters
) {
    // Generate message ID
    std::string messageId = generateMessageId();
    
    // Create shared memory name
    std::string shmName = "flight_data_" + messageId;
    
    // Create shared memory
    if (!sharedMemoryManager->createSharedMemory(shmName, size + sizeof(SharedMemoryHeader))) {
        throw std::runtime_error("Failed to create shared memory for large data transfer");
    }
    
    // Write data to shared memory
    if (!sharedMemoryManager->writeData(
            shmName, data, size, modelType, operation, messageId)) {
        sharedMemoryManager->destroySharedMemory(shmName);
        throw std::runtime_error("Failed to write data to shared memory");
    }
    
    // Notify Python process via ZeroMQ
    json notification = {
        {"operation", operation},
        {"shared_memory_name", shmName},
        {"parameters", parameters},
        {"model_type", modelTypeToString(modelType)},
        {"data_size", size}
    };
    
    {
        std::lock_guard<std::mutex> lock(zmqMutex);
        if (!sendMessage(notification, MessageType::REQUEST)) {
            sharedMemoryManager->destroySharedMemory(shmName);
            throw std::runtime_error("Failed to send shared memory notification");
        }
    }
    
    return messageId;
}

void AIPythonIntegration::heartbeatThreadFunc() {
    while (isRunning) {
        sendHeartbeat();
        std::this_thread::sleep_for(std::chrono::seconds(10));
    }
}

void AIPythonIntegration::sendHeartbeat() {
    try {
        json heartbeat = {
            {"operation", "heartbeat"}
        };
        
        std::lock_guard<std::mutex> lock(zmqMutex);
        sendMessage(heartbeat, MessageType::HEARTBEAT);
        
        // We don't wait for responses here, as they'll be handled by the main thread
    } catch (const std::exception& e) {
        spdlog::error("Failed to send heartbeat: {}", e.what());
    }
}

std::string AIPythonIntegration::generateMessageId() {
    static std::atomic<uint64_t> counter(0);
    uint64_t id = counter.fetch_add(1, std::memory_order_relaxed);
    
    std::stringstream ss;
    ss << std::hex << id << "-" 
       << std::chrono::system_clock::now().time_since_epoch().count();
    return ss.str();
}

std::string AIPythonIntegration::modelTypeToString(ModelType modelType) {
    switch (modelType) {
        case ModelType::SYLLABUS_GENERATOR:
            return "syllabus_generator";
        case ModelType::DOCUMENT_ANALYZER:
            return "document_analyzer";
        case ModelType::PERFORMANCE_PREDICTOR:
            return "performance_predictor";
        case ModelType::SKILL_ASSESSOR:
            return "skill_assessor";
        case ModelType::FLIGHT_ANOMALY_DETECTOR:
            return "flight_anomaly_detector";
        case ModelType::TRAINING_RECOMMENDER:
            return "training_recommender";
        case ModelType::PROGRESS_ANALYZER:
            return "progress_analyzer";
        default:
            return "unknown";
    }
}

} // namespace ai
#include <memory>
#include <string>
#include <vector>
#include <unordered_map>
#include <chrono>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <future>
#include <atomic>
#include <zmq.hpp>
#include <nlohmann/json.hpp>
#include <spdlog/spdlog.h>

// For shared memory
#include <boost/interprocess/shared_memory_object.hpp>
#include <boost/interprocess/mapped_region.hpp>
#include <boost/interprocess/sync/interprocess_mutex.hpp>
#include <boost/interprocess/sync/interprocess_condition.hpp>
#include <boost/interprocess/sync/scoped_lock.hpp>

namespace ai {

using json = nlohmann::json;
namespace bip = boost::interprocess;

// Forward declarations
class PyProcessManager;
class SharedMemoryManager;
class ModelVersionTracker;

/**
 * Enumeration for AI model types
 */
enum class ModelType {
    SYLLABUS_GENERATOR,
    DOCUMENT_ANALYZER,
    PERFORMANCE_PREDICTOR,
    SKILL_ASSESSOR,
    FLIGHT_ANOMALY_DETECTOR,
    TRAINING_RECOMMENDER,
    PROGRESS_ANALYZER
};

/**
 * Enumeration for ZeroMQ message types
 */
enum class MessageType {
    REQUEST,
    RESPONSE,
    HEARTBEAT,
    ERROR,
    CONTROL
};

/**
 * Structure for model metadata
 */
struct ModelInfo {
    std::string id;
    std::string name;
    std::string version;
    std::string description;
    std::unordered_map<std::string, std::string> parameters;
    std::chrono::system_clock::time_point lastUpdated;
    bool isActive;
};

/**
 * Structure for shared memory data header
 */
struct SharedMemoryHeader {
    bip::interprocess_mutex mutex;
    bip::interprocess_condition dataReady;
    bip::interprocess_condition dataProcessed;
    std::size_t dataSize;
    bool isReady;
    bool isProcessed;
    int status;
    char modelType[32];
    char operation[32];
    char messageId[64];
};

/**
 * Class for managing Python processes
 */
class PyProcessManager {
public:
    /**
     * Constructor
     */
    PyProcessManager(const std::string& pythonPath, const std::string& scriptDir);
    
    /**
     * Destructor
     */
    ~PyProcessManager();
    
    /**
     * Start a Python process for a specific model type
     */
    bool startProcess(ModelType modelType);
    
    /**
     * Stop a Python process
     */
    bool stopProcess(ModelType modelType);
    
    /**
     * Stop all Python processes
     */
    void stopAllProcesses();
    
    /**
     * Check if a process is running
     */
    bool isProcessRunning(ModelType modelType);
    
    /**
     * Restart a process if it's not responding
     */
    bool restartProcessIfNeeded(ModelType modelType);
    
    /**
     * Get process health metrics
     */
    json getProcessHealthMetrics();

private:
    std::string pythonPath;
    std::string scriptDir;
    std::unordered_map<ModelType, int> processes;
    std::unordered_map<ModelType, std::chrono::system_clock::time_point> lastHeartbeats;
    std::mutex processMutex;
    
    /**
     * Send signal to process
     */
    bool sendSignal(int pid, int signal);
    
    /**
     * Check if process is responding
     */
    bool isProcessResponding(ModelType modelType);
    
    /**
     * Get script path for model type
     */
    std::string getScriptPath(ModelType modelType);
    
    /**
     * Helper to convert ModelType to string
     */
    std::string modelTypeToString(ModelType modelType);
};

/**
 * Class for managing shared memory for large data transfers
 */
class SharedMemoryManager {
public:
    /**
     * Constructor
     */
    SharedMemoryManager();
    
    /**
     * Destructor
     */
    ~SharedMemoryManager();
    
    /**
     * Create a shared memory segment
     */
    bool createSharedMemory(const std::string& name, std::size_t size);
    
    /**
     * Destroy a shared memory segment
     */
    bool destroySharedMemory(const std::string& name);
    
    /**
     * Write data to shared memory
     */
    bool writeData(
        const std::string& name, 
        const void* data, 
        std::size_t size, 
        ModelType modelType,
        const std::string& operation,
        const std::string& messageId
    );
    
    /**
     * Read data from shared memory
     */
    std::vector<uint8_t> readData(
        const std::string& name, 
        int timeoutMs = 5000
    );
    
    /**
     * Wait for Python process to signal data processing completion
     */
    bool waitForProcessing(
        const std::string& name, 
        int timeoutMs = 30000
    );
    
    /**
     * Signal completion of data reading
     */
    void signalDataProcessed(const std::string& name);
    
    /**
     * Get status code from shared memory
     */
    int getStatusCode(const std::string& name);

private:
    std::unordered_map<std::string, std::unique_ptr<bip::shared_memory_object>> sharedMemories;
    std::unordered_map<std::string, std::unique_ptr<bip::mapped_region>> headerRegions;
    std::unordered_map<std::string, std::unique_ptr<bip::mapped_region>> dataRegions;
    std::mutex shmMutex;
    
    /**
     * Get header from mapped region
     */
    SharedMemoryHeader* getHeader(const std::string& name);
    
    /**
     * Get data pointer from mapped region
     */
    void* getDataPtr(const std::string& name);
};

/**
 * Class for tracking model versions
 */
class ModelVersionTracker {
public:
    /**
     * Constructor
     */
    ModelVersionTracker();
    
    /**
     * Get model info
     */
    ModelInfo getModelInfo(ModelType modelType);
    
    /**
     * Update model info
     */
    void updateModelInfo(ModelType modelType, const ModelInfo& info);
    
    /**
     * Check if model needs update
     */
    bool needsUpdate(ModelType modelType, const std::string& currentVersion);
    
    /**
     * Load model info from database
     */
    bool loadFromDatabase();
    
    /**
     * Save model info to database
     */
    bool saveToDatabase();

private:
    std::unordered_map<ModelType, ModelInfo> modelInfoMap;
    std::mutex modelMutex;
    
    /**
     * Helper to convert ModelType to string
     */
    std::string modelTypeToString(ModelType modelType);
    
    /**
     * Helper to convert string to ModelType
     */
    ModelType stringToModelType(const std::string& str);
};

/**
 * Main class for handling AI/Python integration
 */
class AIPythonIntegration {
public:
    /**
     * Constructor
     */
    AIPythonIntegration(
        const std::string& pythonPath, 
        const std::string& scriptDir,
        const std::string& zmqEndpoint
    );
    
    /**
     * Destructor
     */
    ~AIPythonIntegration();
    
    /**
     * Initialize the integration
     */
    bool initialize();
    
    /**
     * Shutdown the integration
     */
    void shutdown();
    
    /**
     * Process document with AI model
     */
    json processDocument(
        ModelType modelType, 
        const std::string& documentPath, 
        const json& parameters
    );
    
    /**
     * Analyze flight telemetry data
     */
    json analyzeFlightData(
        const std::vector<uint8_t>& telemetryData, 
        const json& parameters
    );
    
    /**
     * Generate training recommendations
     */
    json generateTrainingRecommendations(
        const std::string& traineeId, 
        const json& performanceData,
        const json& parameters
    );
    
    /**
     * Assess pilot skills
     */
    json assessSkills(
        const std::string& traineeId,
        const json& assessmentData,
        const json& parameters
    );
    
    /**
     * Generate syllabus
     */
    json generateSyllabus(
        const json& requirements,
        const json& constraints,
        const json& parameters
    );
    
    /**
     * Predict trainee performance
     */
    json predictPerformance(
        const std::string& traineeId,
        const json& historicalData,
        const json& parameters
    );
    
    /**
     * Check system health
     */
    json checkHealth();

private:
    std::unique_ptr<PyProcessManager> processManager;
    std::unique_ptr<SharedMemoryManager> sharedMemoryManager;
    std::unique_ptr<ModelVersionTracker> versionTracker;
    std::unique_ptr<zmq::context_t> zmqContext;
    std::unique_ptr<zmq::socket_t> zmqSocket;
    std::string zmqEndpoint;
    std::atomic<bool> isRunning;
    std::thread heartbeatThread;
    std::mutex zmqMutex;
    
    /**
     * Send message via ZeroMQ
     */
    bool sendMessage(
        const json& message, 
        MessageType messageType
    );
    
    /**
     * Receive message via ZeroMQ
     */
    std::optional<json> receiveMessage(int timeoutMs = 5000);
    
    /**
     * Send large data via shared memory
     */
    std::string sendLargeData(
        ModelType modelType,
        const std::string& operation, 
        const void* data, 
        std::size_t size,
        const json& parameters
    );
    
    /**
     * Handle heartbeat responses
     */
    void heartbeatThreadFunc();
    
    /**
     * Send heartbeat to Python processes
     */
    void sendHeartbeat();
    
    /**
     * Generate a unique message ID
     */
    std::string generateMessageId();
    
    /**
     * Helper to convert ModelType to string
     */
    std::string modelTypeToString(ModelType modelType);
};

// Implementation of AIPythonIntegration

AIPythonIntegration::AIPythonIntegration(
    const std::string& pythonPath, 
    const std::string& scriptDir,
    const std::string& zmqEndpoint
) : zmqEndpoint(zmqEndpoint), isRunning(false) {
    processManager = std::make_unique<PyProcessManager>(pythonPath, scriptDir);
    sharedMemoryManager = std::make_unique<SharedMemoryManager>();
    versionTracker = std::make_unique<ModelVersionTracker>();
    
    zmqContext = std::make_unique<zmq::context_t>(1);
}

AIPythonIntegration::~AIPythonIntegration() {
    shutdown();
}

bool AIPythonIntegration::initialize() {
    try {
        // Load model version information
        if (!versionTracker->loadFromDatabase()) {
            spdlog::warn("Failed to load model version information from database");
        }
        
        // Initialize ZeroMQ socket
        zmqSocket = std::make_unique<zmq::socket_t>(*zmqContext, ZMQ_ROUTER);
        
        int timeout = 5000; // 5 seconds
        zmqSocket->setsockopt(ZMQ_RCVTIMEO, &timeout, sizeof(timeout));
        
        // Bind socket
        zmqSocket->bind(zmqEndpoint);
        
        // Start Python processes for each model type
        processManager->startProcess(ModelType::DOCUMENT_ANALYZER);
        processManager->startProcess(ModelType::PERFORMANCE_PREDICTOR);
        processManager->startProcess(ModelType::SKILL_ASSESSOR);
        processManager->startProcess(ModelType::SYLLABUS_GENERATOR);
        processManager->startProcess(ModelType::FLIGHT_ANOMALY_DETECTOR);
        processManager->startProcess(ModelType::TRAINING_RECOMMENDER);
        
        // Start heartbeat thread
        isRunning = true;
        heartbeatThread = std::thread(&AIPythonIntegration::heartbeatThreadFunc
// src/frontend/components/AnalyticsDashboard/AnalyticsDashboard.tsx
import React, { useState, useEffect, useMemo } from 'react';
import {
  LineChart,
  Line,
  BarChart,
  Bar,
  PieChart,
  Pie,
  Cell,
  XAxis,
  YAxis,
  CartesianGrid,
  Tooltip,
  Legend,
  ResponsiveContainer,
  RadarChart,
  Radar,
  PolarGrid,
  PolarAngleAxis,
  PolarRadiusAxis
} from 'recharts';
import { 
  Download, 
  Calendar, 
  Filter, 
  RefreshCw, 
  Users, 
  UserCheck,
  AlertTriangle,
  CheckCircle,
  ChevronDown,
  User,
  ArrowUp,
  ArrowDown,
  BarChart2,
  PieChart as PieChartIcon
} from 'lucide-react';

import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from '@/components/ui/select';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar';
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from '@/components/ui/dropdown-menu';
import {
  Table,
  TableBody,
  TableCell,
  TableHead,
  TableHeader,
  TableRow,
} from '@/components/ui/table';
import { Input } from '@/components/ui/input';
import { Label } from '@/components/ui/label';
import { Separator } from '@/components/ui/separator';
import { Dialog, DialogContent, DialogDescription, DialogFooter, DialogHeader, DialogTitle, DialogTrigger } from '@/components/ui/dialog';

// Types
export interface Trainee {
  id: string;
  name: string;
  avatarUrl?: string;
  position?: string;
  department?: string;
  status: 'active' | 'completed' | 'on-leave' | 'pending';
  completionPercentage: number;
  performance: number; // Overall performance score (0-100)
  riskStatus: 'low' | 'medium' | 'high';
  startDate: string;
  estimatedCompletionDate?: string;
}

export interface Instructor {
  id: string;
  name: string;
  avatarUrl?: string;
  department?: string;
  activeTrainees: number;
  completedTrainees: number;
  averageTraineePerformance: number;
}

export interface Module {
  id: string;
  name: string;
  category: string;
  averageScore: number;
  completionRate: number;
  failureRate: number;
  averageCompletionTime: number; // in days
}

export interface CompetencyData {
  id: string;
  name: string;
  category?: string;
  averageScore: number;
  passRate: number;
  trainingGap: number; // Percentage gap between current and target
}

export interface PerformanceTrend {
  date: string;
  averageScore: number;
  completionRate: number;
  failureRate: number;
  activeTrainees: number;
}

export interface ComplianceData {
  regulatoryArea: string;
  complianceRate: number;
  violations: number;
  trend: 'improving' | 'stable' | 'declining';
  riskLevel: 'low' | 'medium' | 'high';
}

export interface TrainingProgram {
  id: string;
  name: string;
  totalTrainees: number;
  activeTrainees: number;
  completedTrainees: number;
  averageCompletionTime: number; // in days
  averagePerformance: number;
  status: 'active' | 'completed' | 'planned';
}

export interface AnalyticsDashboardProps {
  organizationId: string;
  programId?: string;
  trainees?: Trainee[];
  instructors?: Instructor[];
  modules?: Module[];
  competencies?: CompetencyData[];
  trends?: PerformanceTrend[];
  complianceData?: ComplianceData[];
  trainingPrograms?: TrainingProgram[];
  onExportData?: (dataType: string, format: string) => void;
  onFilterChange?: (filters: any) => void;
  onDateRangeChange?: (startDate: string, endDate: string) => void;
  onProgramChange?: (programId: string) => void;
  showComplianceData?: boolean;
  refreshData?: () => void;
}

// Colors
const COLORS = {
  blue: ['#2563eb', '#3b82f6', '#60a5fa', '#93c5fd', '#bfdbfe'],
  green: ['#16a34a', '#22c55e', '#4ade80', '#86efac', '#bbf7d0'],
  red: ['#dc2626', '#ef4444', '#f87171', '#fca5a5', '#fee2e2'],
  yellow: ['#ca8a04', '#eab308', '#facc15', '#fde047', '#fef08a'],
  purple: ['#7c3aed', '#8b5cf6', '#a78bfa', '#c4b5fd', '#ddd6fe'],
  gray: ['#4b5563', '#6b7280', '#9ca3af', '#d1d5db', '#e5e7eb'],
  primary: '#3b82f6',
  background: '#f9fafb',
  success: '#22c55e',
  warning: '#eab308',
  danger: '#ef4444',
  info: '#06b6d4',
};

// Helper Components
interface StatCardProps {
  title: string;
  value: string | number;
  description?: string;
  icon?: React.ReactNode;
  trend?: 'up' | 'down' | 'neutral';
  trendValue?: string | number;
  color?: string;
}

const StatCard: React.FC<StatCardProps> = ({ 
  title, 
  value, 
  description, 
  icon, 
  trend, 
  trendValue,
  color = COLORS.primary
}) => {
  return (
    <Card>
      <CardContent className="pt-6">
        <div className="flex justify-between items-start">
          <div>
            <p className="text-sm font-medium text-gray-500">{title}</p>
            <p className="text-3xl font-bold mt-1" style={{ color }}>{value}</p>
            
            {trend && trendValue && (
              <div className="flex items-center mt-2">
                {trend === 'up' ? (
                  <ArrowUp className="h-4 w-4 text-green-500 mr-1" />
                ) : trend === 'down' ? (
                  <ArrowDown className="h-4 w-4 text-red-500 mr-1" />
                ) : null}
                <span className={`text-sm font-medium ${
                  trend === 'up' ? 'text-green-500' : 
                  trend === 'down' ? 'text-red-500' : 
                  'text-gray-500'
                }`}>
                  {trendValue}
                </span>
              </div>
            )}
            
            {description && (
              <p className="text-sm text-gray-500 mt-1">{description}</p>
            )}
          </div>
          
          {icon && (
            <div className="p-2 rounded-full bg-gray-100">
              {icon}
            </div>
          )}
        </div>
      </CardContent>
    </Card>
  );
};

interface ChartCardProps {
  title: string;
  description?: string;
  children: React.ReactNode;
  action?: React.ReactNode;
}

const ChartCard: React.FC<ChartCardProps> = ({ title, description, children, action }) => {
  return (
    <Card className="h-full">
      <CardHeader className="pb-2">
        <div className="flex justify-between items-start">
          <div>
            <CardTitle className="text-lg font-medium">{title}</CardTitle>
            {description && (
              <CardDescription>{description}</CardDescription>
            )}
          </div>
          {action}
        </div>
      </CardHeader>
      <CardContent>
        {children}
      </CardContent>
    </Card>
  );
};

// Custom tooltip for charts
const CustomTooltip: React.FC<any> = ({ active, payload, label }) => {
  if (active && payload && payload.length) {
    return (
      <div className="bg-white p-3 border rounded-md shadow-md">
        <p className="text-sm font-medium">{label}</p>
        {payload.map((entry: any, index: number) => (
          <p key={`item-${index}`} className="text-sm" style={{ color: entry.color }}>
            {entry.name}: {entry.value.toLocaleString()}
          </p>
        ))}
      </div>
    );
  }

  return null;
};

// Main Component
const AnalyticsDashboard: React.FC<AnalyticsDashboardProps> = ({
  organizationId,
  programId,
  trainees = [],
  instructors = [],
  modules = [],
  competencies = [],
  trends = [],
  complianceData = [],
  trainingPrograms = [],
  onExportData,
  onFilterChange,
  onDateRangeChange,
  onProgramChange,
  showComplianceData = true,
  refreshData,
}) => {
  const [activeTab, setActiveTab] = useState('overview');
  const [selectedDateRange, setSelectedDateRange] = useState('30d');
  const [selectedProgram, setSelectedProgram] = useState(programId || 'all');
  const [filters, setFilters] = useState({
    status: 'all',
    department: 'all',
    performance: 'all',
  });
  const [isExportDialogOpen, setIsExportDialogOpen] = useState(false);
  const [exportType, setExportType] = useState('all');
  const [exportFormat, setExportFormat] = useState('csv');

  // Calculate statistics
  const stats = useMemo(() => {
    const activeTraineeCount = trainees.filter(t => t.status === 'active').length;
    const completedTraineeCount = trainees.filter(t => t.status === 'completed').length;
    const averageCompletion = trainees.reduce((sum, t) => sum + t.completionPercentage, 0) / (trainees.length || 1);
    const averagePerformance = trainees.reduce((sum, t) => sum + t.performance, 0) / (trainees.length || 1);
    const atRiskCount = trainees.filter(t => t.riskStatus === 'high').length;
    
    return {
      activeTrainees: activeTraineeCount,
      completedTrainees: completedTraineeCount,
      averageCompletion,
      averagePerformance,
      atRiskTrainees: atRiskCount,
      activeTraineePercentage: (activeTraineeCount / (trainees.length || 1)) * 100,
    };
  }, [trainees]);

  // Calculate competency statistics
  const competencyStats = useMemo(() => {
    const categories = [...new Set(competencies.map(c => c.category || 'Uncategorized'))];
    const categoryStats = categories.map(category => {
      const categoryCompetencies = competencies.filter(c => (c.category || 'Uncategorized') === category);
      const averageScore = categoryCompetencies.reduce((sum, c) => sum + c.averageScore, 0) / (categoryCompetencies.length || 1);
      const passRate = categoryCompetencies.reduce((sum, c) => sum + c.passRate, 0) / (categoryCompetencies.length || 1);
      
      return {
        category,
        averageScore,
        passRate,
        count: categoryCompetencies.length,
      };
    });
    
    return categoryStats;
  }, [competencies]);

  // Prepare performance trend data
  const performanceTrendData = useMemo(() => {
    return trends.map(trend => ({
      date: new Date(trend.date).toLocaleDateString('en-US', { month: 'short', day: 'numeric' }),
      score: trend.averageScore,
      completion: trend.completionRate * 100,
      failure: trend.failureRate * 100,
      trainees: trend.activeTrainees,
    }));
  }, [trends]);

  // Calculate module performance data
  const modulePerformanceData = useMemo(() => {
    return modules.slice(0, 10).map(module => ({
      name: module.name,
      score: module.averageScore,
      completion: module.completionRate * 100,
      failure: module.failureRate * 100,
    }));
  }, [modules]);

  // Prepare trainee risk distribution data
  const traineeRiskData = useMemo(() => {
    const lowRisk = trainees.filter(t => t.riskStatus === 'low').length;
    const mediumRisk = trainees.filter(t => t.riskStatus === 'medium').length;
    const highRisk = trainees.filter(t => t.riskStatus === 'high').length;
    
    return [
      { name: 'Low Risk', value: lowRisk, color: COLORS.green[0] },
      { name: 'Medium Risk', value: mediumRisk, color: COLORS.yellow[0] },
      { name: 'High Risk', value: highRisk, color: COLORS.red[0] },
    ];
  }, [trainees]);

  // Prepare competency radar data
  const competencyRadarData = useMemo(() => {
    return competencies.slice(0, 8).map(comp => ({
      subject: comp.name,
      score: comp.averageScore,
      gap: comp.trainingGap,
    }));
  }, [competencies]);

  // Prepare top performing trainees
  const topPerformers = useMemo(() => {
    return trainees
      .filter(t => t.status === 'active')
      .sort((a, b) => b.performance - a.performance)
      .slice(0, 5);
  }, [trainees]);

  // Prepare at-risk trainees
  const atRiskTrainees = useMemo(() => {
    return trainees
      .filter(t => t.riskStatus === 'high' && t.status === 'active')
      .slice(0, 5);
  }, [trainees]);

  // Prepare instructor performance data
  const instructorPerformance = useMemo(() => {
    return instructors
      .sort((a, b) => b.averageTraineePerformance - a.averageTraineePerformance)
      .slice(0, 5);
  }, [instructors]);

  // Handle date range change
  const handleDateRangeChange = (range: string) => {
    setSelectedDateRange(range);
    
    // Calculate dates based on range
    const endDate = new Date();
    let startDate = new Date();
    
    switch (range) {
      case '7d':
        startDate.setDate(endDate.getDate() - 7);
        break;
      case '30d':
        startDate.setDate(endDate.getDate() - 30);
        break;
      case '90d':
        startDate.setDate(endDate.getDate() - 90);
        break;
      case '1y':
        startDate.setFullYear(endDate.getFullYear() - 1);
        break;
      default:
        startDate.setDate(endDate.getDate() - 30);
    }
    
    if (onDateRangeChange) {
      onDateRangeChange(startDate.toISOString(), endDate.toISOString());
    }
  };

  // Handle program change
  const handleProgramChange = (program: string) => {
    setSelectedProgram(program);
    
    if (onProgramChange) {
      onProgramChange(program);
    }
  };

  // Handle filter change
  const handleFilterChange = (filterType: string, value: string) => {
    const newFilters = { ...filters, [filterType]: value };
    setFilters(newFilters);
    
    if (onFilterChange) {
      onFilterChange(newFilters);
    }
  };

  // Handle export data
  const handleExportData = () => {
    if (onExportData) {
      onExportData(exportType, exportFormat);
    }
    setIsExportDialogOpen(false);
  };

  return (
    <div className="space-y-6">
      <div className="flex flex-col md:flex-row justify-between items-start md:items-center gap-4">
        <div>
          <h1 className="text-2xl font-bold">Analytics Dashboard</h1>
          <p className="text-gray-500">
            Training performance metrics and insights
          </p>
        </div>
        
        <div className="flex flex-wrap gap-2">
          <Select value={selectedDateRange} onValueChange={handleDateRangeChange}>
            <SelectTrigger className="w-36">
              <Calendar className="h-4 w-4 mr-2" />
              <SelectValue placeholder="Time period" />
            </SelectTrigger>
            <SelectContent>
              <SelectItem value="7d">Last 7 days</SelectItem>
              <SelectItem value="30d">Last 30 days</SelectItem>
              <SelectItem value="90d">Last 90 days</SelectItem>
              <SelectItem value="1y">Last year</SelectItem>
            </SelectContent>
          </Select>
          
          {trainingPrograms.length > 0 && (
            <Select value={selectedProgram} onValueChange={handleProgramChange}>
              <SelectTrigger className="w-48">
                <SelectValue placeholder="Select program" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="all">All Programs</SelectItem>
                {trainingPrograms.map(program => (
                  <SelectItem key={program.id} value={program.id}>
                    {program.name}
                  </SelectItem>
                ))}
              </SelectContent>
            </Select>
          )}
          
          <DropdownMenu>
            <DropdownMenuTrigger asChild>
              <Button variant="outline" className="gap-2">
                <Filter className="h-4 w-4" />
                Filters
              </Button>
            </DropdownMenuTrigger>
            <DropdownMenuContent align="end" className="w-56">
              <DropdownMenuLabel>Filter Data</DropdownMenuLabel>
              <DropdownMenuSeparator />
              
              <div className="p-2">
                <Label className="text-xs mb-1 block">Status</Label>
                <Select value={filters.status} onValueChange={(v) => handleFilterChange('status', v)}>
                  <SelectTrigger className="w-full">
                    <SelectValue placeholder="Status" />
                  </SelectTrigger>
                  <SelectContent>
                    <SelectItem value="all">All Statuses</SelectItem>
                    <SelectItem value="active">Active</SelectItem>
                    <SelectItem value="completed">Completed</SelectItem>
                    <SelectItem value="on-leave">On Leave</SelectItem>
                  </SelectContent>
                </Select>
              </div>
              
              <div className="p-2">
                <Label className="text-xs mb-1 block">Department</Label>
                <Select value={filters.department} onValueChange={(v) => handleFilterChange('department', v)}>
                  <SelectTrigger className="w-full">
                    <SelectValue placeholder="Department" />
                  </SelectTrigger>
                  <SelectContent>
                    <SelectItem value="all">All Departments</SelectItem>
                    <SelectItem value="flight-ops">Flight Operations</SelectItem>
                    <SelectItem value="maintenance">Maintenance</SelectItem>
                    <SelectItem value="cabin-crew">Cabin Crew</SelectItem>
                  </SelectContent>
                </Select>
              </div>
              
              <div className="p-2">
                <Label className="text-xs mb-1 block">Performance</Label>
                <Select value={filters.performance} onValueChange={(v) => handleFilterChange('performance', v)}>
                  <SelectTrigger className="w-full">
                    <SelectValue placeholder="Performance" />
                  </SelectTrigger>
                  <SelectContent>
                    <SelectItem value="all">All Performance</SelectItem>
                    <SelectItem value="high">High (80%+)</SelectItem>
                    <SelectItem value="medium">Medium (60-80%)</SelectItem>
                    <SelectItem value="low">Low (Below 60%)</SelectItem>
                  </SelectContent>
                </Select>
              </div>
            </DropdownMenuContent>
          </DropdownMenu>
          
          <Button variant="outline" onClick={() => setIsExportDialogOpen(true)}>
            <Download className="h-4 w-4 mr-2" />
            Export
          </Button>
          
          {refreshData && (
            <Button variant="ghost" size="icon" onClick={refreshData}>
              <RefreshCw className="h-4 w-4" />
            </Button>
          )}
        </div>
      </div>
      
      <Tabs value={activeTab} onValueChange={setActiveTab} className="space-y-6">
        <TabsList className="mb-4">
          <TabsTrigger value="overview">Overview</TabsTrigger>
          <TabsTrigger value="trainees">Trainees</TabsTrigger>
          <TabsTrigger value="competencies">Competencies</TabsTrigger>
          <TabsTrigger value="modules">Modules</TabsTrigger>
          {showComplianceData && (
            <TabsTrigger value="compliance">Compliance</TabsTrigger>
          )}
        </TabsList>
        
        <TabsContent value="overview">
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-4 mb-6">
            <StatCard
              title="Active Trainees"
              value={stats.activeTrainees}
              description={`${stats.activeTraineePercentage.toFixed(1)}% of total`}
              icon={<Users className="h-5 w-5 text-blue-500" />}
              color={COLORS.blue[0]}
            />
            
            <StatCard
              title="Completed Training"
              value={stats.completedTrainees}
              icon={<UserCheck className="h-5 w-5 text-green-500" />}
              color={COLORS.green[0]}
            />
            
            <StatCard
              title="Average Score"
              value={`${stats.averagePerformance.toFixed(1)}%`}
              trend={stats.averagePerformance > 75 ? 'up' : 'down'}
              trendValue="5.2% vs. last period"
              icon={<BarChart2 className="h-5 w-5 text-blue-500" />}
              color={COLORS.primary}
            />
            
            <StatCard
              title="At-Risk Trainees"
              value={stats.atRiskTrainees}
              description="Requiring intervention"
              icon={<AlertTriangle className="h-5 w-5 text-red-500" />}
              color={COLORS.red[0]}
            />
          </div>
          
          <div className="grid grid-cols-1 lg:grid-cols-2 gap-6 mb-6">
            <ChartCard 
              title="Performance Trends" 
              description="Score and completion rates over time"
            >
              <div className="h-80">
                <ResponsiveContainer width="100%" height="100%">
                  <LineChart data={performanceTrendData}>
                    <CartesianGrid strokeDasharray="3 3" vertical={false} />
                    <XAxis dataKey="date" />
                    <YAxis yAxisId="left" domain={[0, 100]} />
                    <YAxis yAxisId="right" orientation="right" domain={[0, 'auto']} />
                    <Tooltip content={<CustomTooltip />} />
                    <Legend />
                    <Line 
                      yAxisId="left"
                      type="monotone" 
                      dataKey="score" 
                      name="Avg. Score" 
                      stroke={COLORS.blue[0]} 
                      strokeWidth={2}
                      dot={{ r: 3 }}
                      activeDot={{ r: 5 }}
                    />
                    <Line 
                      yAxisId="left"
                      type="monotone" 
                      dataKey="completion" 
                      name="Completion Rate" 
                      stroke={COLORS.green[0]} 
                      strokeWidth={2}
                      dot={{ r: 3 }}
                      activeDot={{ r: 5 }}
                    />
                    <Line 
                      yAxisId="right"
                      type="monotone" 
                      dataKey="trainees" 
                      name="Active Trainees" 
                      stroke={COLORS.purple[0]} 
                      strokeWidth={2}
                      dot={{ r: 3 }}
                      activeDot={{ r: 5 }}
                    />
                  </LineChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
            
            <ChartCard 
              title="Top Module Performance" 
              description="Average scores and completion rates by module"
            >
              <div className="h-80">
                <ResponsiveContainer width="100%" height="100%">
                  <BarChart data={modulePerformanceData} layout="vertical">
                    <CartesianGrid strokeDasharray="3 3" horizontal={true} vertical={false} />
                    <XAxis type="number" domain={[0, 100]} />
                    <YAxis type="category" dataKey="name" width={150} />
                    <Tooltip content={<CustomTooltip />} />
                    <Legend />
                    <Bar dataKey="score" name="Avg. Score" fill={COLORS.blue[0]} barSize={10} />
                    <Bar dataKey="completion" name="Completion %" fill={COLORS.green[0]} barSize={10} />
                    <Bar dataKey="failure" name="Failure %" fill={COLORS.red[0]} barSize={10} />
                  </BarChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
          </div>
          
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
            <ChartCard title="Trainee Risk Distribution">
              <div className="h-64 flex items-center justify-center">
                <ResponsiveContainer width="100%" height="100%">
                  <PieChart>
                    <Pie
                      data={traineeRiskData}
                      cx="50%"
                      cy="50%"
                      innerRadius={60}
                      outerRadius={80}
                      paddingAngle={5}
                      dataKey="value"
                      label={({ name, percent }) => `${name}: ${(percent * 100).toFixed(1)}%`}
                    >
                      {traineeRiskData.map((entry, index) => (
                        <Cell key={`cell-${index}`} fill={entry.color} />
                      ))}
                    </Pie>
                    <Tooltip />
                  </PieChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
            
            <ChartCard title="Competency Coverage">
              <div className="h-64">
                <ResponsiveContainer width="100%" height="100%">
                  <RadarChart cx="50%" cy="50%" outerRadius="80%" data={competencyRadarData}>
                    <PolarGrid />
                    <PolarAngleAxis dataKey="subject" />
                    <PolarRadiusAxis domain={[0, 100]} />
                    <Radar 
                      name="Score" 
                      dataKey="score" 
                      stroke={COLORS.blue[0]} 
                      fill={COLORS.blue[0]} 
                      fillOpacity={0.5} 
                    />
                    <Tooltip />
                    <Legend />
                  </RadarChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
            
            <Card>
              <CardHeader>
                <CardTitle className="text-lg font-medium">Top Performers</CardTitle>
              </CardHeader>
              <CardContent className="p-0">
                <Table>
                  <TableBody>
                    {topPerformers.map((trainee) => (
                      <TableRow key={trainee.id}>
                        <TableCell>
                          <div className="flex items-center gap-3">
                            <Avatar className="h-8 w-8">
                              <AvatarImage src={trainee.avatarUrl} alt={trainee.name} />
                              <AvatarFallback>{trainee.name.charAt(0)}</AvatarFallback>
                            </Avatar>
                            <div>
                              <p className="font-medium">{trainee.name}</p>
                              <p className="text-xs text-gray-500">{trainee.position}</p>
                            </div>
                          </div>
                        </TableCell>
                        <TableCell className="text-right">
                          <div className="flex items-center justify-end">
                            <Badge className="bg-green-500">{trainee.performance}%</Badge>
                          </div>
                        </TableCell>
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </CardContent>
            </Card>
          </div>
        </TabsContent>
        
        <TabsContent value="trainees">
          <div className="grid grid-cols-1 md:grid-cols-3 gap-6 mb-6">
            <ChartCard title="Trainee Status Distribution">
              <div className="h-64">
                <ResponsiveContainer width="100%" height="100%">
                  <PieChart>
                    <Pie
                      data={[
                        { name: 'Active', value: stats.activeTrainees, color: COLORS.blue[0] },
                        { name: 'Completed', value: stats.completedTrainees, color: COLORS.green[0] },
                        { name: 'On Leave', value: trainees.filter(t => t.status === 'on-leave').length, color: COLORS.yellow[0] },
                        { name: 'Pending', value: trainees.filter(t => t.status === 'pending').length, color: COLORS.gray[0] },
                      ]}
                      cx="50%"
                      cy="50%"
                      innerRadius={60}
                      outerRadius={80}
                      paddingAngle={5}
                      dataKey="value"
                      label={({ name, percent }) => `${name}: ${(percent * 100).toFixed(1)}%`}
                    >
                      {['blue', 'green', 'yellow', 'gray'].map((color, index) => (
                        <Cell key={`cell-${index}`} fill={COLORS[color as keyof typeof COLORS][0]} />
                      ))}
                    </Pie>
                    <Tooltip />
                  </PieChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
            
            <ChartCard title="Progress Distribution">
              <div className="h-64">
                <ResponsiveContainer width="100%" height="100%">
                  <BarChart 
                    data={[
                      { range: '0-25%', count: trainees.filter(t => t.completionPercentage <= 25).length },
                      { range: '26-50%', count: trainees.filter(t => t.completionPercentage > 25 && t.completionPercentage <= 50).length },
                      { range: '51-75%', count: trainees.filter(t => t.completionPercentage > 50 && t.completionPercentage <= 75).length },
                      { range: '76-99%', count: trainees.filter(t => t.completionPercentage > 75 && t.completionPercentage < 100).length },
                      { range: '100%', count: trainees.filter(t => t.completionPercentage === 100).length },
                    ]}
                  >
                    <CartesianGrid strokeDasharray="3 3" vertical={false} />
                    <XAxis dataKey="range" />
                    <YAxis />
                    <Tooltip />
                    <Bar dataKey="count" name="Trainees" fill={COLORS.blue[0]} />
                  </BarChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
            
            <ChartCard title="At-Risk Trainees">
              <div className="max-h-64 overflow-y-auto">
                <Table>
                  <TableBody>
                    {atRiskTrainees.length > 0 ? atRiskTrainees.map((trainee) => (
                      <TableRow key={trainee.id}>
                        <TableCell>
                          <div className="flex items-center gap-3">
                            <Avatar className="h-8 w-8">
                              <AvatarImage src={trainee.avatarUrl} alt={trainee.name} />
                              <AvatarFallback>{trainee.name.charAt(0)}</AvatarFallback>
                            </Avatar>
                            <div>
                              <p className="font-medium">{trainee.name}</p>
                              <p className="text-xs text-gray-500">{trainee.position}</p>
                            </div>
                          </div>
                        </TableCell>
                        <TableCell className="text-right">
                          <Badge variant="destructive">{trainee.performance}%</Badge>
                        </TableCell>
                      </TableRow>
                    )) : (
                      <TableRow>
                        <TableCell colSpan={2} className="text-center text-gray-500">
                          No at-risk trainees found
                        </TableCell>
                      </TableRow>
                    )}
                  </TableBody>
                </Table>
              </div>
            </ChartCard>
          </div>
          
          <Card>
            <CardHeader>
              <CardTitle className="text-lg font-medium">Trainee List</CardTitle>
              <div className="flex gap-2">
                <Input placeholder="Search trainees..." className="w-64" />
                <Select defaultValue="all">
                  <SelectTrigger className="w-36">
                    <SelectValue placeholder="Status" />
                  </SelectTrigger>
                  <SelectContent>
                    <SelectItem value="all">All Status</SelectItem>
                    <SelectItem value="active">Active</SelectItem>
                    <SelectItem value="completed">Completed</SelectItem>
                    <SelectItem value="on-leave">On Leave</SelectItem>
                    <SelectItem value="pending">Pending</SelectItem>
                  </SelectContent>
                </Select>
              </div>
            </CardHeader>
            <CardContent className="p-0">
              <Table>
                <TableHeader>
                  <TableRow>
                    <TableHead>Trainee</TableHead>
                    <TableHead>Department</TableHead>
                    <TableHead>Status</TableHead>
                    <TableHead>Progress</TableHead>
                    <TableHead>Performance</TableHead>
                    <TableHead>Risk Level</TableHead>
                    <TableHead>Start Date</TableHead>
                  </TableRow>
                </TableHeader>
                <TableBody>
                  {trainees.slice(0, 10).map((trainee) => (
                    <TableRow key={trainee.id}>
                      <TableCell>
                        <div className="flex items-center gap-3">
                          <Avatar className="h-8 w-8">
                            <AvatarImage src={trainee.avatarUrl} alt={trainee.name} />
                            <AvatarFallback>{trainee.name.charAt(0)}</AvatarFallback>
                          </Avatar>
                          <div>
                            <p className="font-medium">{trainee.name}</p>
                            <p className="text-xs text-gray-500">{trainee.position}</p>
                          </div>
                        </div>
                      </TableCell>
                      <TableCell>{trainee.department || 'N/A'}</TableCell>
                      <TableCell>
                        <Badge variant={
                          trainee.status === 'active' ? 'default' :
                          trainee.status === 'completed' ? 'success' :
                          trainee.status === 'on-leave' ? 'warning' :
                          'outline'
                        }>
                          {trainee.status.charAt(0).toUpperCase() + trainee.status.slice(1)}
                        </Badge>
                      </TableCell>
                      <TableCell>
                        <div className="flex items-center gap-2">
                          <Progress value={trainee.completionPercentage} className="h-2 w-24" />
                          <span className="text-sm">{trainee.completionPercentage}%</span>
                        </div>
                      </TableCell>
                      <TableCell>
                        <Badge className={`${
                          trainee.performance >= 80 ? 'bg-green-500' :
                          trainee.performance >= 60 ? 'bg-blue-500' :
                          'bg-red-500'
                        }`}>
                          {trainee.performance}%
                        </Badge>
                      </TableCell>
                      <TableCell>
                        <Badge variant={
                          trainee.riskStatus === 'low' ? 'success' :
                          trainee.riskStatus === 'medium' ? 'warning' :
                          'destructive'
                        }>
                          {trainee.riskStatus.charAt(0).toUpperCase() + trainee.riskStatus.slice(1)}
                        </Badge>
                      </TableCell>
                      <TableCell>
                        {new Date(trainee.startDate).toLocaleDateString()}
                      </TableCell>
                    </TableRow>
                  ))}
                </TableBody>
              </Table>
            </CardContent>
            <CardFooter className="flex justify-between py-4">
              <div className="text-sm text-gray-500">
                Showing 1-10 of {trainees.length} trainees
              </div>
              <div className="flex gap-1">
                <Button variant="outline" size="sm" disabled>
                  Previous
                </Button>
                <Button variant="outline" size="sm">
                  Next
                </Button>
              </div>
            </CardFooter>
          </Card>
        </TabsContent>
        
        <TabsContent value="competencies">
          <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
            <ChartCard title="Competency Performance" description="Average scores by competency category">
              <div className="h-80">
                <ResponsiveContainer width="100%" height="100%">
                  <BarChart 
                    data={competencyStats}
                    layout="vertical"
                  >
                    <CartesianGrid strokeDasharray="3 3" horizontal={true} vertical={false} />
                    <XAxis type="number" domain={[0, 100]} />
                    <YAxis type="category" dataKey="category" width={120} />
                    <Tooltip content={<CustomTooltip />} />
                    <Legend />
                    <Bar dataKey="averageScore" name="Avg. Score" fill={COLORS.blue[0]} barSize={10} />
                    <Bar dataKey="passRate" name="Pass Rate" fill={COLORS.green[0]} barSize={10} />
                  </BarChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
            
            <ChartCard title="Competency Radar" description="Performance across key competencies">
              <div className="h-80">
                <ResponsiveContainer width="100%" height="100%">
                  <RadarChart cx="50%" cy="50%" outerRadius="80%" data={competencyRadarData}>
                    <PolarGrid />
                    <PolarAngleAxis dataKey="subject" />
                    <PolarRadiusAxis domain={[0, 100]} />
                    <Radar 
                      name="Score" 
                      dataKey="score" 
                      stroke={COLORS.blue[0]} 
                      fill={COLORS.blue[0]} 
                      fillOpacity={0.5} 
                    />
                    <Radar 
                      name="Gap" 
                      dataKey="gap" 
                      stroke={COLORS.red[0]} 
                      fill={COLORS.red[0]} 
                      fillOpacity={0.3} 
                    />
                    <Tooltip />
                    <Legend />
                  </RadarChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
          </div>
          
          <Card>
            <CardHeader>
              <CardTitle className="text-lg font-medium">Competency List</CardTitle>
              <div className="flex gap-2">
                <Input placeholder="Search competencies..." className="w-64" />
                <Select defaultValue="all">
                  <SelectTrigger className="w-40">
                    <SelectValue placeholder="Category" />
                  </SelectTrigger>
                  <SelectContent>
                    <SelectItem value="all">All Categories</SelectItem>
                    {competencyStats.map(stat => (
                      <SelectItem key={stat.category} value={stat.category}>
                        {stat.category}
                      </SelectItem>
                    ))}
                  </SelectContent>
                </Select>
              </div>
            </CardHeader>
            <CardContent className="p-0">
              <Table>
                <TableHeader>
                  <TableRow>
                    <TableHead>Competency</TableHead>
                    <TableHead>Category</TableHead>
                    <TableHead>Average Score</TableHead>
                    <TableHead>Pass Rate</TableHead>
                    <TableHead>Training Gap</TableHead>
                  </TableRow>
                </TableHeader>
                <TableBody>
                  {competencies.slice(0, 10).map((comp) => (
                    <TableRow key={comp.id}>
                      <TableCell>
                        <div className="font-medium">{comp.name}</div>
                      </TableCell>
                      <TableCell>{comp.category || 'Uncategorized'}</TableCell>
                      <TableCell>
                        <div className="flex items-center gap-2">
                          <Progress 
                            value={comp.averageScore} 
                            className="h-2 w-24"
                            style={{
                              backgroundColor: comp.averageScore >= 80 ? COLORS.green[4] : 
                                              comp.averageScore >= 60 ? COLORS.blue[4] : 
                                              COLORS.red[4],
                              color: comp.averageScore >= 80 ? COLORS.green[0] : 
                                    comp.averageScore >= 60 ? COLORS.blue[0] : 
                                    COLORS.red[0],
                            }}
                          />
                          <span className="text-sm">{comp.averageScore.toFixed(1)}%</span>
                        </div>
                      </TableCell>
                      <TableCell>
                        <Badge className={`${
                          comp.passRate >= 90 ? 'bg-green-500' :
                          comp.passRate >= 70 ? 'bg-blue-500' :
                          'bg-red-500'
                        }`}>
                          {comp.passRate.toFixed(1)}%
                        </Badge>
                      </TableCell>
                      <TableCell>
                        <Badge variant={
                          comp.trainingGap <= 10 ? 'success' :
                          comp.trainingGap <= 20 ? 'warning' :
                          'destructive'
                        }>
                          {comp.trainingGap.toFixed(1)}%
                        </Badge>
                      </TableCell>
                    </TableRow>
                  ))}
                </TableBody>
              </Table>
            </CardContent>
            <CardFooter className="flex justify-between py-4">
              <div className="text-sm text-gray-500">
                Showing 1-10 of {competencies.length} competencies
              </div>
              <div className="flex gap-1">
                <Button variant="outline" size="sm" disabled>
                  Previous
                </Button>
                <Button variant="outline" size="sm">
                  Next
                </Button>
              </div>
            </CardFooter>
          </Card>
        </TabsContent>
        
        <TabsContent value="modules">
          <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
            <ChartCard title="Module Performance" description="Average scores and completion rates">
              <div className="h-80">
                <ResponsiveContainer width="100%" height="100%">
                  <BarChart data={modulePerformanceData}>
                    <CartesianGrid strokeDasharray="3 3" vertical={false} />
                    <XAxis dataKey="name" />
                    <YAxis domain={[0, 100]} />
                    <Tooltip content={<CustomTooltip />} />
                    <Legend />
                    <Bar dataKey="score" name="Avg. Score" fill={COLORS.blue[0]} />
                    <Bar dataKey="completion" name="Completion %" fill={COLORS.green[0]} />
                  </BarChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
            
            <ChartCard title="Module Completion Time" description="Average days to complete">
              <div className="h-80">
                <ResponsiveContainer width="100%" height="100%">
                  <BarChart 
                    data={modules.slice(0, 8).map(module => ({
                      name: module.name,
                      days: module.averageCompletionTime
                    }))}
                  >
                    <CartesianGrid strokeDasharray="3 3" vertical={false} />
                    <XAxis dataKey="name" />
                    <YAxis />
                    <Tooltip content={<CustomTooltip />} />
                    <Bar dataKey="days" name="Avg. Days" fill={COLORS.purple[0]} />
                  </BarChart>
                </ResponsiveContainer>
              </div>
            </ChartCard>
          </div>
          
          <Card>
            <CardHeader>
              <CardTitle className="text-lg font-medium">Module List</CardTitle>
              <div className="flex gap-2">
                <Input placeholder="Search modules..." className="w-64" />
                <Select defaultValue="all">
                  <SelectTrigger className="w-40">
                    <SelectValue placeholder="Category" />
                  </SelectTrigger>
                  <SelectContent>
                    <SelectItem value="all">All Categories</SelectItem>
                    {[...new Set(modules.map(m => m.category))].map(category => (
                      <SelectItem key={category} value={category}>
                        {category}
                      </SelectItem>
                    ))}
                  </SelectContent>
                </Select>
              </div>
            </CardHeader>
            <CardContent className="p-0">
              <Table>
                <TableHeader>
                  <TableRow>
                    <TableHead>Module Name</TableHead>
                    <TableHead>Category</TableHead>
                    <TableHead>Average Score</TableHead>
                    <TableHead>Completion Rate</TableHead>
                    <TableHead>Failure Rate</TableHead>
                    <TableHead>Avg. Time (days)</TableHead>
                  </TableRow>
                </TableHeader>
                <TableBody>
                  {modules.slice(0, 10).map((module) => (
                    <TableRow key={module.id}>
                      <TableCell>
                        <div className="font-medium">{module.name}</div>
                      </TableCell>
                      <TableCell>{module.category}</TableCell>
                      <TableCell>
                        <div className="flex items-center gap-2">
                          <Progress 
                            value={module.averageScore} 
                            className="h-2 w-24"
                            style={{
                              backgroundColor: module.averageScore >= 80 ? COLORS.green[4] : 
                                              module.averageScore >= 60 ? COLORS.blue[4] : 
                                              COLORS.red[4],
                              color: module.averageScore >= 80 ? COLORS.green[0] : 
                                    module.averageScore >= 60 ? COLORS.blue[0] : 
                                    COLORS.red[0],
                            }}
                          />
                          <span className="text-sm">{module.averageScore.toFixed(1)}%</span>
                        </div>
                      </TableCell>
                      <TableCell>
                        <Badge className="bg-green-500">
                          {(module.completionRate * 100).toFixed(1)}%
                        </Badge>
                      </TableCell>
                      <TableCell>
                        <Badge variant="destructive">
                          {(module.failureRate * 100).toFixed(1)}%
                        </Badge>
                      </TableCell>
                      <TableCell>
                        {module.averageCompletionTime.toFixed(1)} days
                      </TableCell>
                    </TableRow>
                  ))}
                </TableBody>
              </Table>
            </CardContent>
            <CardFooter className="flex justify-between py-4">
              <div className="text-sm text-gray-500">
                Showing 1-10 of {modules.length} modules
              </div>
              <div className="flex gap-1">
                <Button variant="outline" size="sm" disabled>
                  Previous
                </Button>
                <Button variant="outline" size="sm">
                  Next
                </Button>
              </div>
            </CardFooter>
          </Card>
        </TabsContent>
        
        {showComplianceData && (
          <TabsContent value="compliance">
            <div className="grid grid-cols-1 md:grid-cols-3 gap-6 mb-6">
              <StatCard
                title="Overall Compliance"
                value={`${complianceData.reduce((sum, item) => sum + item.complianceRate, 0) / (complianceData.length || 1)}%`}
                trend="up"
                trendValue="3.2% vs. last period"
                color={COLORS.green[0]}
                icon={<CheckCircle className="h-5 w-5 text-green-500" />}
              />
              
              <StatCard
                title="Compliance Violations"
                value={complianceData.reduce((sum, item) => sum + item.violations, 0)}
                trend="down"
                trendValue="12.5% vs. last period"
                color={COLORS.red[0]}
                icon={<AlertTriangle className="h-5 w-5 text-red-500" />}
              />
              
              <StatCard
                title="High Risk Areas"
                value={complianceData.filter(item => item.riskLevel === 'high').length}
                description="Requiring immediate attention"
                color={COLORS.yellow[0]}
                icon={<AlertTriangle className="h-5 w-5 text-yellow-500" />}
              />
            </div>
            
            <div className="grid grid-cols-1 lg:grid-cols-2 gap-6 mb-6">
              <ChartCard title="Compliance by Regulatory Area">
                <div className="h-80">
                  <ResponsiveContainer width="100%" height="100%">
                    <BarChart 
                      data={complianceData}
                      layout="vertical"
                    >
                      <CartesianGrid strokeDasharray="3 3" horizontal={true} vertical={false} />
                      <XAxis type="number" domain={[0, 100]} />
                      <YAxis type="category" dataKey="regulatoryArea" width={150} />
                      <Tooltip content={<CustomTooltip />} />
                      <Bar 
                        dataKey="complianceRate" 
                        name="Compliance Rate" 
                        fill={COLORS.green[0]} 
                        barSize={16}
                      />
                    </BarChart>
                  </ResponsiveContainer>
                </div>
              </ChartCard>
              
              <ChartCard title="Compliance Risk Assessment">
                <div className="h-80">
                  <ResponsiveContainer width="100%" height="100%">
                    <BarChart data={complianceData}>
                      <CartesianGrid strokeDasharray="3 3" vertical={false} />
                      <XAxis dataKey="regulatoryArea" />
                      <YAxis />
                      <Tooltip content={<CustomTooltip />} />
                      <Legend />
                      <Bar dataKey="violations" name="Violations" fill={COLORS.red[0]} />
                    </BarChart>
                  </ResponsiveContainer>
                </div>
              </ChartCard>
            </div>
            
            <Card>
              <CardHeader>
                <CardTitle className="text-lg font-medium">Regulatory Compliance Details</CardTitle>
              </CardHeader>
              <CardContent className="p-0">
                <Table>
                  <TableHeader>
                    <TableRow>
                      <TableHead>Regulatory Area</TableHead>
                      <TableHead>Compliance Rate</TableHead>
                      <TableHead>Violations</TableHead>
                      <TableHead>Trend</TableHead>
                      <TableHead>Risk Level</TableHead>
                    </TableRow>
                  </TableHeader>
                  <TableBody>
                    {complianceData.map((item, index) => (
                      <TableRow key={index}>
                        <TableCell>
                          <div className="font-medium">{item.regulatoryArea}</div>
                        </TableCell>
                        <TableCell>
                          <div className="flex items-center gap-2">
                            <Progress 
                              value={item.complianceRate} 
                              className="h-2 w-24"
                              style={{
                                backgroundColor: item.complianceRate >= 90 ? COLORS.green[4] : 
                                                item.complianceRate >= 70 ? COLORS.yellow[4] : 
                                                COLORS.red[4],
                                color: item.complianceRate >= 90 ? COLORS.green[0] : 
                                      item.complianceRate >= 70 ? COLORS.yellow[0] : 
                                      COLORS.red[0],
                              }}
                            />
                            <span className="text-sm">{item.complianceRate.toFixed(1)}%</span>
                          </div>
                        </TableCell>
                        <TableCell>
                          <Badge variant="destructive">
                            {item.violations}
                          </Badge>
                        </TableCell>
                        <TableCell>
                          <Badge variant={
                            item.trend === 'improving' ? 'success' :
                            item.trend === 'stable' ? 'outline' :
                            'destructive'
                          }>
                            {item.trend.charAt(0).toUpperCase() + item.trend.slice(1)}
                          </Badge>
                        </TableCell>
                        <TableCell>
                          <Badge variant={
                            item.riskLevel === 'low' ? 'success' :
                            item.riskLevel === 'medium' ? 'warning' :
                            'destructive'
                          }>
                            {item.riskLevel.charAt(0).toUpperCase() + item.riskLevel.slice(1)}
                          </Badge>
                        </TableCell>
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </CardContent>
            </Card>
          </TabsContent>
        )}
      </Tabs>
      
      {/* Export Dialog */}
      <Dialog open={isExportDialogOpen} onOpenChange={setIsExportDialogOpen}>
        <DialogContent>
          <DialogHeader>
            <DialogTitle>Export Analytics Data</DialogTitle>
            <DialogDescription>
              Select the data you want to export and the format
            </DialogDescription>
          </DialogHeader>
          
          <div className="py-4 space-y-4">
            <div>
              <Label htmlFor="export-type" className="mb-2 block">Data to Export</Label>
              <Select value={exportType} onValueChange={setExportType}>
                <SelectTrigger id="export-type">
                  <SelectValue placeholder="Select data to export" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="all">All Data</SelectItem>
                  <SelectItem value="trainees">Trainee Data</SelectItem>
                  <SelectItem value="modules">Module Performance</SelectItem>
                  <SelectItem value="competencies">Competency Data</SelectItem>
                  <SelectItem value="compliance">Compliance Data</SelectItem>
                </SelectContent>
              </Select>
            </div>
            
            <div>
              <Label htmlFor="export-format" className="mb-2 block">Export Format</Label>
              <Select value={exportFormat} onValueChange={setExportFormat}>
                <SelectTrigger id="export-format">
                  <SelectValue placeholder="Select format" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="csv">CSV</SelectItem>
                  <SelectItem value="excel">Excel</SelectItem>
                  <SelectItem value="pdf">PDF Report</SelectItem>
                  <SelectItem value="json">JSON</SelectItem>
                </SelectContent>
              </Select>
            </div>
          </div>
          
          <DialogFooter>
            <Button variant="outline" onClick={() => setIsExportDialogOpen(false)}>
              Cancel
            </Button>
            <Button onClick={handleExportData}>
              <Download className="h-4 w-4 mr-2" />
              Export
            </Button>
          </DialogFooter>
        </DialogContent>
      </Dialog>
    </div>
  );
};

export default AnalyticsDashboard;

// backend/analytics/include/AnalyticsEngine.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <chrono>
#include <optional>
#include <functional>
#include <unordered_map>
#include <variant>
#include <future>

#include "core/include/ErrorHandling.h"
#include "core/include/DatabaseManager.h"
#include "assessment/include/AssessmentTypes.h"

namespace APTP::Analytics {

// Data types for analytics
enum class DataType {
    Integer,
    Float,
    Double,
    String,
    Boolean,
    DateTime,
    Duration,
    JSON,
    Array
};

// Metric types
enum class MetricType {
    Count,          // Count of occurrences
    Sum,            // Sum of values
    Average,        // Average of values
    Minimum,        // Minimum value
    Maximum,        // Maximum value
    StandardDeviation, // Standard deviation
    Percentile,     // Percentile (requires parameter)
    Custom          // Custom calculation
};

// Time aggregation
enum class TimeAggregation {
    None,           // No time aggregation
    Minute,         // Group by minute
    Hour,           // Group by hour
    Day,            // Group by day
    Week,           // Group by week
    Month,          // Group by month
    Quarter,        // Group by quarter
    Year,           // Group by year
    Custom          // Custom time period
};

// KPI category
enum class KPICategory {
    Performance,    // Training performance
    Completion,     // Training completion
    Compliance,     // Regulatory compliance
    Efficiency,     // Resource efficiency
    Satisfaction,   // Trainee satisfaction
    Custom          // Custom category
};

// Value for analytics data
using AnalyticsValue = std::variant<
    int64_t,
    double,
    std::string,
    bool,
    std::chrono::system_clock::time_point,
    std::chrono::seconds,
    std::vector<std::variant<int64_t, double, std::string, bool>>
>;

// Data point for analytics
struct DataPoint {
    std::string id;
    std::string metricId;
    std::string dimensionId;
    std::string entityId;   // ID of entity (trainee, instructor, etc.)
    std::string entityType; // Type of entity
    std::chrono::system_clock::time_point timestamp;
    AnalyticsValue value;
    std::unordered_map<std::string, std::string> tags;
    std::unordered_map<std::string, std::string> metadata;
};

// Metric definition
struct MetricDefinition {
    std::string id;
    std::string name;
    std::string description;
    MetricType type;
    DataType dataType;
    std::string unit;
    std::string formula; // For custom metrics
    std::string aggregationMethod;
    TimeAggregation timeAggregation;
    KPICategory category;
    bool isRealTime;
    bool isVisible;
    std::vector<std::string> relatedMetrics;
    std::vector<std::string> tags;
    std::unordered_map<std::string, std::string> metadata;
};

// Dimension definition
struct DimensionDefinition {
    std::string id;
    std::string name;
    std::string description;
    DataType dataType;
    std::vector<std::string> possibleValues; // For categorical dimensions
    bool isFilterable;
    bool isGroupable;
    std::vector<std::string> tags;
    std::unordered_map<std::string, std::string> metadata;
};

// Dashboard definition
struct DashboardDefinition {
    std::string id;
    std::string name;
    std::string description;
    std::string ownerUserId;
    std::vector<std::string> widgetIds;
    bool isPublic;
    bool isDefault;
    std::vector<std::string> tags;
    std::unordered_map<std::string, std::string> metadata;
};

// Widget types
enum class WidgetType {
    LineChart,
    BarChart,
    PieChart,
    ScatterPlot,
    Table,
    Gauge,
    KPI,
    HeatMap,
    Map,
    Custom
};

// Widget definition
struct WidgetDefinition {
    std::string id;
    std::string name;
    std::string description;
    WidgetType type;
    std::vector<std::string> metricIds;
    std::vector<std::string> dimensionIds;
    std::string query; // SQL or custom query
    std::unordered_map<std::string, std::string> configuration;
    std::vector<std::string> tags;
    std::unordered_map<std::string, std::string> metadata;
};

// Time range for analytics queries
struct TimeRange {
    std::optional<std::chrono::system_clock::time_point> start;
    std::optional<std::chrono::system_clock::time_point> end;
    std::optional<std::chrono::seconds> duration; // Alternative to end
    
    static TimeRange Last24Hours() {
        TimeRange range;
        range.end = std::chrono::system_clock::now();
        range.start = *range.end - std::chrono::hours(24);
        return range;
    }
    
    static TimeRange Last7Days() {
        TimeRange range;
        range.end = std::chrono::system_clock::now();
        range.start = *range.end - std::chrono::hours(24 * 7);
        return range;
    }
    
    static TimeRange Last30Days() {
        TimeRange range;
        range.end = std::chrono::system_clock::now();
        range.start = *range.end - std::chrono::hours(24 * 30);
        return range;
    }
    
    static TimeRange Custom(
        std::chrono::system_clock::time_point start,
        std::chrono::system_clock::time_point end) {
        TimeRange range;
        range.start = start;
        range.end = end;
        return range;
    }
};

// Filter for analytics queries
struct AnalyticsFilter {
    std::string dimensionId;
    std::string operator_; // "=", "<>", ">", "<", ">=", "<=", "IN", "NOT IN", "LIKE", "NOT LIKE"
    AnalyticsValue value;
};

// Grouping for analytics queries
struct AnalyticsGrouping {
    std::string dimensionId;
    TimeAggregation timeAggregation = TimeAggregation::None;
};

// Sort order for analytics queries
struct AnalyticsSort {
    std::string metricId;
    bool ascending = true;
};

// Analytics query
struct AnalyticsQuery {
    std::vector<std::string> metricIds;
    std::vector<AnalyticsFilter> filters;
    std::vector<AnalyticsGrouping> groupings;
    std::vector<AnalyticsSort> sortOrder;
    TimeRange timeRange;
    size_t limit = 1000;
    size_t offset = 0;
};

// Analytics result
struct AnalyticsResult {
    std::vector<std::string> columns;
    std::vector<std::vector<AnalyticsValue>> rows;
    
    size_t rowCount() const { return rows.size(); }
    size_t columnCount() const { return columns.size(); }
    
    template<typename T>
    std::optional<T> getValue(size_t row, size_t column) const {
        if (row >= rows.size() || column >= columns.size()) {
            return std::nullopt;
        }
        
        try {
            return std::get<T>(rows[row][column]);
        } catch (const std::bad_variant_access&) {
            return std::nullopt;
        }
    }
    
    template<typename T>
    std::optional<T> getValue(size_t row, const std::string& columnName) const {
        auto it = std::find(columns.begin(), columns.end(), columnName);
        if (it == columns.end()) {
            return std::nullopt;
        }
        
        size_t column = std::distance(columns.begin(), it);
        return getValue<T>(row, column);
    }
};

// Prediction model types
enum class PredictionModelType {
    LinearRegression,
    RandomForest,
    NeuralNetwork,
    GradientBoosting,
    ARIMA,
    Prophet,
    Custom
};

// Prediction model definition
struct PredictionModelDefinition {
    std::string id;
    std::string name;
    std::string description;
    PredictionModelType type;
    std::string targetMetricId;
    std::vector<std::string> featureMetricIds;
    std::string modelPath; // Path to saved model
    std::string pythonModulePath; // Path to Python module for custom models
    std::chrono::system_clock::time_point lastTrainingTime;
    double accuracy;
    double rmse; // Root Mean Square Error
    std::vector<std::string> tags;
    std::unordered_map<std::string, std::string> metadata;
};

// Prediction result
struct PredictionResult {
    std::string modelId;
    std::string targetMetricId;
    std::vector<std::pair<std::chrono::system_clock::time_point, double>> predictions;
    std::vector<std::pair<std::chrono::system_clock::time_point, double>> confidenceIntervalLower;
    std::vector<std::pair<std::chrono::system_clock::time_point, double>> confidenceIntervalUpper;
    double confidenceLevel;
    std::unordered_map<std::string, std::string> metadata;
};

// Analytics engine class
class AnalyticsEngine {
public:
    static AnalyticsEngine& getInstance();
    
    // Initialize the analytics engine
    APTP::Core::Result<void> initialize();
    
    // Register a new metric
    APTP::Core::Result<MetricDefinition> registerMetric(
        const std::string& name,
        const std::string& description,
        MetricType type,
        DataType dataType,
        const std::string& unit,
        TimeAggregation timeAggregation = TimeAggregation::None,
        KPICategory category = KPICategory::Performance);
    
    // Get metric by ID
    APTP::Core::Result<MetricDefinition> getMetric(const std::string& metricId);
    
    // Update metric
    APTP::Core::Result<MetricDefinition> updateMetric(
        const std::string& metricId,
        const MetricDefinition& updatedMetric);
    
    // Delete metric
    APTP::Core::Result<void> deleteMetric(const std::string& metricId);
    
    // List metrics
    APTP::Core::Result<std::vector<MetricDefinition>> listMetrics(
        const std::optional<KPICategory>& category = std::nullopt,
        const std::optional<std::string>& tag = std::nullopt);
    
    // Register a new dimension
    APTP::Core::Result<DimensionDefinition> registerDimension(
        const std::string& name,
        const std::string& description,
        DataType dataType,
        const std::vector<std::string>& possibleValues = {},
        bool isFilterable = true,
        bool isGroupable = true);
    
    // Get dimension by ID
    APTP::Core::Result<DimensionDefinition> getDimension(const std::string& dimensionId);
    
    // Update dimension
    APTP::Core::Result<DimensionDefinition> updateDimension(
        const std::string& dimensionId,
        const DimensionDefinition& updatedDimension);
    
    // Delete dimension
    APTP::Core::Result<void> deleteDimension(const std::string& dimensionId);
    
    // List dimensions
    APTP::Core::Result<std::vector<DimensionDefinition>> listDimensions(
        const std::optional<std::string>& tag = std::nullopt);
    
    // Record data point
    APTP::Core::Result<void> recordDataPoint(
        const std::string& metricId,
        const std::string& dimensionId,
        const std::string& entityId,
        const std::string& entityType,
        const AnalyticsValue& value,
        const std::optional<std::chrono::system_clock::time_point>& timestamp = std::nullopt);
    
    // Record multiple data points
    APTP::Core::Result<void> recordDataPoints(const std::vector<DataPoint>& dataPoints);
    
    // Execute analytics query
    APTP::Core::Result<AnalyticsResult> executeQuery(const AnalyticsQuery& query);
    
    // Execute analytics query asynchronously
    std::future<APTP::Core::Result<AnalyticsResult>> executeQueryAsync(const AnalyticsQuery& query);
    
    // Create dashboard
    APTP::Core::Result<DashboardDefinition> createDashboard(
        const std::string& name,
        const std::string& description,
        const std::string& ownerUserId,
        bool isPublic = false,
        bool isDefault = false);
    
    // Get dashboard by ID
    APTP::Core::Result<DashboardDefinition> getDashboard(const std::string& dashboardId);
    
    // Update dashboard
    APTP::Core::Result<DashboardDefinition> updateDashboard(
        const std::string& dashboardId,
        const DashboardDefinition& updatedDashboard);
    
    // Delete dashboard
    APTP::Core::Result<void> deleteDashboard(const std::string& dashboardId);
    
    // List dashboards
    APTP::Core::Result<std::vector<DashboardDefinition>> listDashboards(
        const std::optional<std::string>& ownerUserId = std::nullopt,
        const std::optional<bool>& isPublic = std::nullopt);
    
    // Create widget
    APTP::Core::Result<WidgetDefinition> createWidget(
        const std::string& name,
        const std::string& description,
        WidgetType type,
        const std::vector<std::string>& metricIds,
        const std::vector<std::string>& dimensionIds,
        const std::string& query = "");
    
    // Get widget by ID
    APTP::Core::Result<WidgetDefinition> getWidget(const std::string& widgetId);
    
    // Update widget
    APTP::Core::Result<WidgetDefinition> updateWidget(
        const std::string& widgetId,
        const WidgetDefinition& updatedWidget);
    
    // Delete widget
    APTP::Core::Result<void> deleteWidget(const std::string& widgetId);
    
    // Add widget to dashboard
    APTP::Core::Result<void> addWidgetToDashboard(
        const std::string& dashboardId,
        const std::string& widgetId);
    
    // Remove widget from dashboard
    APTP::Core::Result<void> removeWidgetFromDashboard(
        const std::string& dashboardId,
        const std::string& widgetId);
    
    // Execute widget query
    APTP::Core::Result<AnalyticsResult> executeWidgetQuery(
        const std::string& widgetId,
        const TimeRange& timeRange);
    
    // Create prediction model
    APTP::Core::Result<PredictionModelDefinition> createPredictionModel(
        const std::string& name,
        const std::string& description,
        PredictionModelType type,
        const std::string& targetMetricId,
        const std::vector<std::string>& featureMetricIds);
    
    // Get prediction model by ID
    APTP::Core::Result<PredictionModelDefinition> getPredictionModel(const std::string& modelId);
    
    // Update prediction model
    APTP::Core::Result<PredictionModelDefinition> updatePredictionModel(
        const std::string& modelId,
        const PredictionModelDefinition& updatedModel);
    
    // Delete prediction model
    APTP::Core::Result<void> deletePredictionModel(const std::string& modelId);
    
    // Train prediction model
    APTP::Core::Result<PredictionModelDefinition> trainPredictionModel(
        const std::string& modelId,
        const TimeRange& trainingDataTimeRange);
    
    // Generate predictions
    APTP::Core::Result<PredictionResult> generatePredictions(
        const std::string& modelId,
        const std::chrono::system_clock::time_point& startTime,
        const std::chrono::system_clock::time_point& endTime,
        size_t numPredictions = 10,
        double confidenceLevel = 0.95);
    
    // Export data to CSV
    APTP::Core::Result<std::string> exportToCSV(
        const AnalyticsQuery& query,
        const std::string& delimiter = ",");
    
    // Export data to JSON
    APTP::Core::Result<std::string> exportToJSON(const AnalyticsQuery& query);
    
    // Get KPI value
    APTP::Core::Result<double> getKPIValue(
        const std::string& metricId,
        const TimeRange& timeRange,
        const std::vector<AnalyticsFilter>& filters = {});
    
    // Calculate KPI trend
    APTP::Core::Result<std::vector<std::pair<std::chrono::system_clock::time_point, double>>> 
    calculateKPITrend(
        const std::string& metricId,
        const TimeRange& timeRange,
        TimeAggregation aggregation = TimeAggregation::Day,
        const std::vector<AnalyticsFilter>& filters = {});
    
    // Generate automated insights
    struct AutomatedInsight {
        std::string id;
        std::string title;
        std::string description;
        std::string metricId;
        std::string insightType; // "Anomaly", "Trend", "Correlation", "Prediction"
        double significance; // 0.0 to 1.0
        std::chrono::system_clock::time_point timestamp;
        std::unordered_map<std::string, AnalyticsValue> data;
    };
    
    APTP::Core::Result<std::vector<AutomatedInsight>> generateInsights(
        const std::vector<std::string>& metricIds,
        const TimeRange& timeRange,
        size_t maxInsights = 10);
    
    // Calculate correlation between metrics
    APTP::Core::Result<double> calculateCorrelation(
        const std::string& metricId1,
        const std::string& metricId2,
        const TimeRange& timeRange,
        const std::vector<AnalyticsFilter>& filters = {});

private:
    AnalyticsEngine();
    ~AnalyticsEngine();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Analytics

// backend/analytics/src/AnalyticsEngine.cpp (partial implementation)
#include "AnalyticsEngine.h"
#include "core/include/Logger.h"
#include "core/include/DatabaseManager.h"
#include <nlohmann/json.hpp>
#include <chrono>

namespace APTP::Analytics {

struct AnalyticsEngine::Impl {
    // Internal implementation details
    bool initialized = false;
    
    // Database queries
    const std::string SQL_CREATE_METRIC = 
        "INSERT INTO analytics_metrics (id, name, description, type, data_type, unit, formula, aggregation_method, time_aggregation, category, is_real_time, is_visible, tags, metadata) "
        "VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14) "
        "RETURNING id";
    
    const std::string SQL_GET_METRIC = 
        "SELECT id, name, description, type, data_type, unit, formula, aggregation_method, time_aggregation, category, is_real_time, is_visible, related_metrics, tags, metadata "
        "FROM analytics_metrics "
        "WHERE id = $1";
    
    const std::string SQL_UPDATE_METRIC = 
        "UPDATE analytics_metrics "
        "SET name = $2, description = $3, type = $4, data_type = $5, unit = $6, formula = $7, aggregation_method = $8, time_aggregation = $9, category = $10, is_real_time = $11, is_visible = $12, related_metrics = $13, tags = $14, metadata = $15 "
        "WHERE id = $1 "
        "RETURNING id";
    
    const std::string SQL_DELETE_METRIC = 
        "DELETE FROM analytics_metrics "
        "WHERE id = $1";
    
    const std::string SQL_LIST_METRICS = 
        "SELECT id, name, description, type, data_type, unit, formula, aggregation_method, time_aggregation, category, is_real_time, is_visible, related_metrics, tags, metadata "
        "FROM analytics_metrics ";
    
    // Time-series data table
    const std::string SQL_RECORD_DATA_POINT = 
        "INSERT INTO analytics_data (id, metric_id, dimension_id, entity_id, entity_type, timestamp, value, tags, metadata) "
        "VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)";
    
    // Helper methods
    APTP::Core::Result<MetricDefinition> metricFromDbResult(const APTP::Core::DbResultSet& resultSet, size_t row) {
        // In a real implementation, this would extract metric data from DB result
        // This is a simplified placeholder
        MetricDefinition metric;
        metric.id = resultSet.getValue<std::string>(row, "id").value_or("");
        metric.name = resultSet.getValue<std::string>(row, "name").value_or("");
        metric.description = resultSet.getValue<std::string>(row, "description").value_or("");
        // ... extract other fields
        
        return APTP::Core::Success(metric);
    }
    
    APTP::Core::Result<DimensionDefinition> dimensionFromDbResult(const APTP::Core::DbResultSet& resultSet, size_t row) {
        // Similar to metricFromDbResult
        DimensionDefinition dimension;
        dimension.id = resultSet.getValue<std::string>(row, "id").value_or("");
        // ... extract other fields
        
        return APTP::Core::Success(dimension);
    }
    
    // Convert AnalyticsValue to string for SQL
    std::string analyticsValueToString(const AnalyticsValue& value) {
        return std::visit([](auto&& arg) -> std::string {
            using T = std::decay_t<decltype(arg)>;
            if constexpr (std::is_same_v<T, int64_t>) {
                return std::to_string(arg);
            } else if constexpr (std::is_same_v<T, double>) {
                return std::to_string(arg);
            } else if constexpr (std::is_same_v<T, std::string>) {
                return "'" + arg + "'"; // Note: In real code, this would need SQL escaping
            } else if constexpr (std::is_same_v<T, bool>) {
                return arg ? "true" : "false";
            } else if constexpr (std::is_same_v<T, std::chrono::system_clock::time_point>) {
                auto time_t = std::chrono::system_clock::to_time_t(arg);
                std::stringstream ss;
                ss << std::put_time(std::gmtime(&time_t), "'%Y-%m-%d %H:%M:%S'");
                return ss.str();
            } else if constexpr (std::is_same_v<T, std::chrono::seconds>) {
                return std::to_string(arg.count()) + " seconds";
            } else if constexpr (std::is_same_v<T, std::vector<std::variant<int64_t, double, std::string, bool>>>) {
                std::stringstream ss;
                ss << "ARRAY[";
                for (size_t i = 0; i < arg.size(); ++i) {
                    if (i > 0) ss << ", ";
                    ss << analyticsValueToString(arg[i]);
                }
                ss << "]";
                return ss.str();
            } else {
                return "NULL";
            }
        }, value);
    }
    
    // Build SQL query from AnalyticsQuery
    std::string buildSQLQuery(const AnalyticsQuery& query) {
        std::stringstream sql;
        
        // Select metrics
        sql << "SELECT ";
        
        if (query.groupings.empty()) {
            // No grouping, select raw data points
            sql << "timestamp, ";
            for (size_t i = 0; i < query.metricIds.size(); ++i) {
                if (i > 0) sql << ", ";
                sql << "value as " << query.metricIds[i];
            }
        } else {
            // With grouping, apply aggregation functions
            for (const auto& grouping : query.groupings) {
                if (grouping.timeAggregation != TimeAggregation::None) {
                    // Time-based grouping
                    switch (grouping.timeAggregation) {
                        case TimeAggregation::Minute:
                            sql << "date_trunc('minute', timestamp) as time_group, ";
                            break;
                        case TimeAggregation::Hour:
                            sql << "date_trunc('hour', timestamp) as time_group, ";
                            break;
                        case TimeAggregation::Day:
                            sql << "date_trunc('day', timestamp) as time_group, ";
                            break;
                        case TimeAggregation::Week:
                            sql << "date_trunc('week', timestamp) as time_group, ";
                            break;
                        case TimeAggregation::Month:
                            sql << "date_trunc('month', timestamp) as time_group, ";
                            break;
                        case TimeAggregation::Quarter:
                            sql << "date_trunc('quarter', timestamp) as time_group, ";
                            break;
                        case TimeAggregation::Year:
                            sql << "date_trunc('year', timestamp) as time_group, ";
                            break;
                        default:
                            break;
                    }
                } else {
                    // Dimension-based grouping
                    sql << "dimension_id as " << grouping.dimensionId << ", ";
                }
            }
            
            // Add metrics with aggregation
            for (size_t i = 0; i < query.metricIds.size(); ++i) {
                if (i > 0) sql << ", ";
                
                // Look up metric to get aggregation method
                // For this example, we'll use a hardcoded aggregation
                sql << "avg(value) as " << query.metricIds[i];
            }
        }
        
        // From analytics_data table
        sql << " FROM analytics_data WHERE ";
        
        // Add metric filters
        sql << "(";
        for (size_t i = 0; i < query.metricIds.size(); ++i) {
            if (i > 0) sql << " OR ";
            sql << "metric_id = '" << query.metricIds[i] << "'";
        }
        sql << ")";
        
        // Add time range
        if (query.timeRange.start.has_value()) {
            sql << " AND timestamp >= " << analyticsValueToString(*query.timeRange.start);
        }
        
        if (query.timeRange.end.has_value()) {
            sql << " AND timestamp <= " << analyticsValueToString(*query.timeRange.end);
        } else if (query.timeRange.duration.has_value() && query.timeRange.start.has_value()) {
            auto end = *query.timeRange.start + *query.timeRange.duration;
            sql << " AND timestamp <= " << analyticsValueToString(end);
        }
        
        // Add other filters
        for (const auto& filter : query.filters) {
            sql << " AND " << filter.dimensionId << " " << filter.operator_ << " " 
                << analyticsValueToString(filter.value);
        }
        
        // Add grouping
        if (!query.groupings.empty()) {
            sql << " GROUP BY ";
            
            bool needsComma = false;
            for (const auto& grouping : query.groupings) {
                if (needsComma) sql << ", ";
                
                if (grouping.timeAggregation != TimeAggregation::None) {
                    sql << "time_group";
                } else {
                    sql << grouping.dimensionId;
                }
                
                needsComma = true;
            }
        }
        
        // Add sorting
        if (!query.sortOrder.empty()) {
            sql << " ORDER BY ";
            
            for (size_t i = 0; i < query.sortOrder.size(); ++i) {
                if (i > 0) sql << ", ";
                
                sql << query.sortOrder[i].metricId;
                
                if (!query.sortOrder[i].ascending) {
                    sql << " DESC";
                }
            }
        } else {
            // Default sort by timestamp
            sql << " ORDER BY timestamp";
        }
        
        // Add limit and offset
        if (query.limit > 0) {
            sql << " LIMIT " << query.limit;
        }
        
        if (query.offset > 0) {
            sql << " OFFSET " << query.offset;
        }
        
        return sql.str();
    }
};

AnalyticsEngine& AnalyticsEngine::getInstance() {
    static AnalyticsEngine instance;
    return instance;
}

AnalyticsEngine::AnalyticsEngine() : impl_(std::make_unique<Impl>()) {}
AnalyticsEngine::~AnalyticsEngine() = default;

APTP::Core::Result<void> AnalyticsEngine::initialize() {
    if (impl_->initialized) {
        return APTP::Core::Success();
    }
    
    APTP::Core::Logger::getInstance().info("Initializing AnalyticsEngine");
    
    // In a real implementation, this would:
    // 1. Create database tables if they don't exist
    // 2. Create a TimescaleDB hypertable for time series data
    // 3. Initialize any caches or in-memory data structures
    
    impl_->initialized = true;
    return APTP::Core::Success();
}

APTP::Core::Result<MetricDefinition> AnalyticsEngine::registerMetric(
    const std::string& name,
    const std::string& description,
    MetricType type,
    DataType dataType,
    const std::string& unit,
    TimeAggregation timeAggregation,
    KPICategory category) {
    
    if (!impl_->initialized) {
        return APTP::Core::Error<MetricDefinition>(APTP::Core::ErrorCode::InvalidState);
    }
    
    APTP::Core::Logger::getInstance().info(
        "Registering metric: {} (type={}, dataType={})",
        name, static_cast<int>(type), static_cast<int>(dataType));
    
    try {
        // Generate a unique ID for the metric
        std::string metricId = "metric-" + std::to_string(std::hash<std::string>{}(
            name + description + std::to_string(std::time(nullptr))));
        
        // Determine aggregation method based on metric type
        std::string aggregationMethod;
        switch (type) {
            case MetricType::Count:
                aggregationMethod = "count";
                break;
            case MetricType::Sum:
                aggregationMethod = "sum";
                break;
            case MetricType::Average:
                aggregationMethod = "avg";
                break;
            case MetricType::Minimum:
                aggregationMethod = "min";
                break;
            case MetricType::Maximum:
                aggregationMethod = "max";
                break;
            case MetricType::StandardDeviation:
                aggregationMethod = "stddev";
                break;
            default:
                aggregationMethod = "avg"; // Default
                break;
        }
        
        // Prepare parameters for database query
        std::unordered_map<std::string, APTP::Core::DbValue> params;
        params["$1"] = metricId;
        params["$2"] = name;
        params["$3"] = description;
        params["$4"] = static_cast<int64_t>(type);
        params["$5"] = static_cast<int64_t>(dataType);
        params["$6"] = unit;
        params["$7"] = ""; // formula (empty for non-custom)
        params["$8"] = aggregationMethod;
        params["$9"] = static_cast<int64_t>(timeAggregation);
        params["$10"] = static_cast<int64_t>(category);
        params["$11"] = true; // isRealTime
        params["$12"] = true; // isVisible
        params["$13"] = nlohmann::json::array().dump(); // tags
        params["$14"] = nlohmann::json{}.dump(); // metadata
        
        // Execute database query
        auto result = APTP::Core::PostgreSQLManager::getInstance().executeScalar(
            impl_->SQL_CREATE_METRIC, params);
        
        if (result.isError()) {
            APTP::Core::Logger::getInstance().error("Failed to register metric in database");
            return APTP::Core::Error<MetricDefinition>(APTP::Core::ErrorCode::AnalyticsError);
        }
        
        // Create the metric definition object
        MetricDefinition metric;
        metric.id = metricId;
        metric.name = name;
        metric.description = description;
        metric.type = type;
        metric.dataType = dataType;
        metric.unit = unit;
        metric.aggregationMethod = aggregationMethod;
        metric.timeAggregation = timeAggregation;
        metric.category = category;
        metric.isRealTime = true;
        metric.isVisible = true;
        
        return APTP::Core::Success(metric);
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Exception registering metric: {}", e.what());
        return APTP::Core::Error<MetricDefinition>(APTP::Core::ErrorCode::AnalyticsError);
    }
}

APTP::Core::Result<void> AnalyticsEngine::recordDataPoint(
    const std::string& metricId,
    const std::string& dimensionId,
    const std::string& entityId,
    const std::string& entityType,
    const AnalyticsValue& value,
    const std::optional<std::chrono::system_clock::time_point>& timestamp) {
    
    if (!impl_->initialized) {
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::InvalidState);
    }
    
    try {
        // Generate a unique ID for the data point
        std::string dataPointId = "dp-" + std::to_string(std::hash<std::string>{}(
            metricId + dimensionId + entityId + entityType + std::to_string(std::time(nullptr))));
        
        // Use current time if timestamp not provided
        auto actualTimestamp = timestamp.value_or(std::chrono::system_clock::now());
        
        // Prepare parameters for database query
        std::unordered_map<std::string, APTP::Core::DbValue> params;
        params["$1"] = dataPointId;
        params["$2"] = metricId;
        params["$3"] = dimensionId;
        params["$4"] = entityId;
        params["$5"] = entityType;
        params["$6"] = actualTimestamp;
        
        // Convert value to appropriate database type
        // This is a simplified implementation
        params["$7"] = std::visit([](auto&& arg) -> APTP::Core::DbValue {
            return arg;
        }, value);
        
        params["$8"] = nlohmann::json::array().dump(); // tags
        params["$9"] = nlohmann::json{}.dump(); // metadata
        
        // Execute database query
        auto result = APTP::Core::PostgreSQLManager::getInstance().executeNonQuery(
            impl_->SQL_RECORD_DATA_POINT, params);
        
        if (result.isError()) {
            APTP::Core::Logger::getInstance().error("Failed to record data point in database");
            return APTP::Core::Error<void>(APTP::Core::ErrorCode::AnalyticsError);
        }
        
        return APTP::Core::Success();
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Exception recording data point: {}", e.what());
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::AnalyticsError);
    }
}

APTP::Core::Result<AnalyticsResult> AnalyticsEngine::executeQuery(const AnalyticsQuery& query) {
    if (!impl_->initialized) {
        return APTP::Core::Error<AnalyticsResult>(APTP::Core::ErrorCode::InvalidState);
    }
    
    try {
        // Build SQL query
        std::string sql = impl_->buildSQLQuery(query);
        
        APTP::Core::Logger::getInstance().debug("Executing analytics query: {}", sql);
        
        // Execute the query
        auto result = APTP::Core::PostgreSQLManager::getInstance().executeQuery(sql);
        
        if (result.isError()) {
            APTP::Core::Logger::getInstance().error("Failed to execute analytics query");
            return APTP::Core::Error<AnalyticsResult>(APTP::Core::ErrorCode::AnalyticsError);
        }
        
        // Convert the database result to AnalyticsResult
        AnalyticsResult analyticsResult;
        
        // Add columns
        for (const auto& columnName : result.value().columnNames) {
            analyticsResult.columns.push_back(columnName);
        }
        
        // Add rows
        for (size_t rowIdx = 0; rowIdx < result.value().rowCount(); ++rowIdx) {
            std::vector<AnalyticsValue> row;
            
            for (size_t colIdx = 0; colIdx < result.value().columnCount(); ++colIdx) {
                // Convert DbValue to AnalyticsValue
                // This is a simplified implementation
                const auto& dbValue = result.value().rows[rowIdx][colIdx];
                
                // Use std::visit to convert DbValue to AnalyticsValue
                row.push_back(std::visit([](auto&& arg) -> AnalyticsValue {
                    return arg;
                }, dbValue));
            }
            
            analyticsResult.rows.push_back(row);
        }
        
        return APTP::Core::Success(analyticsResult);
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Exception executing analytics query: {}", e.what());
        return APTP::Core::Error<AnalyticsResult>(APTP::Core::ErrorCode::AnalyticsError);
    }
}

// Additional method implementations would follow similar patterns...

} // namespace APTP::Analytics

// src/backend/simulator/AnomalyDetector.h
#pragma once

#include <vector>
#include <unordered_map>
#include <memory>
#include <functional>
#include <string>

#include "FlightParameters.h"

namespace PilotTraining {
namespace Simulator {

/**
 * @brief Models for anomaly detection
 */
enum class AnomalyModelType {
    STATISTICAL,    // Statistical model based on historical data
    RULE_BASED,     // Rule-based model with explicit thresholds
    MACHINE_LEARNING, // Machine learning model
    CUSTOM          // Custom user-defined model
};

/**
 * @brief Base class for anomaly detection models
 */
class AnomalyModel {
public:
    virtual ~AnomalyModel() = default;
    
    /**
     * @brief Initialize the model with parameters
     * 
     * @param parameters Model-specific parameters
     * @return true if initialization successful
     * @return false if initialization failed
     */
    virtual bool initialize(const std::unordered_map<std::string, std::string>& parameters) = 0;
    
    /**
     * @brief Train the model with historical data
     * 
     * @param trainingData Training data samples
     * @return true if training successful
     * @return false if training failed
     */
    virtual bool train(const std::vector<FlightParameters>& trainingData) = 0;
    
    /**
     * @brief Detect anomalies in new data
     * 
     * @param data Data samples to analyze
     * @return std::vector<FlightAnomaly> Detected anomalies
     */
    virtual std::vector<FlightAnomaly> detectAnomalies(const std::vector<FlightParameters>& data) = 0;
    
    /**
     * @brief Get the model type
     * 
     * @return AnomalyModelType Model type
     */
    virtual AnomalyModelType getType() const = 0;
    
    /**
     * @brief Get the model name
     * 
     * @return std::string Model name
     */
    virtual std::string getName() const = 0;
};

/**
 * @brief Statistical anomaly detection model
 */
class StatisticalAnomalyModel : public AnomalyModel {
public:
    StatisticalAnomalyModel();
    ~StatisticalAnomalyModel() override;
    
    bool initialize(const std::unordered_map<std::string, std::string>& parameters) override;
    bool train(const std::vector<FlightParameters>& trainingData) override;
    std::vector<FlightAnomaly> detectAnomalies(const std::vector<FlightParameters>& data) override;
    AnomalyModelType getType() const override { return AnomalyModelType::STATISTICAL; }
    std::string getName() const override { return "StatisticalAnomalyModel"; }
    
private:
    struct ParameterStatistics {
        double mean;
        double standardDeviation;
        double min;
        double max;
    };
    
    std::unordered_map<std::string, ParameterStatistics> _statistics;
    double _deviationThreshold;
    bool _trained;
};

/**
 * @brief Rule-based anomaly detection model
 */
class RuleBasedAnomalyModel : public AnomalyModel {
public:
    RuleBasedAnomalyModel();
    ~RuleBasedAnomalyModel() override;
    
    bool initialize(const std::unordered_map<std::string, std::string>& parameters) override;
    bool train(const std::vector<FlightParameters>& trainingData) override;
    std::vector<FlightAnomaly> detectAnomalies(const std::vector<FlightParameters>& data) override;
    AnomalyModelType getType() const override { return AnomalyModelType::RULE_BASED; }
    std::string getName() const override { return "RuleBasedAnomalyModel"; }
    
private:
    struct ParameterRule {
        double minValue;
        double maxValue;
        bool enabled;
    };
    
    std::unordered_map<std::string, ParameterRule> _rules;
    bool _initialized;
};

/**
 * @brief Flight anomaly detector
 * 
 * Detects anomalies in flight data that deviate from normal behavior.
 * Uses multiple detection models and can be configured for different
 * types of aircraft and flight regimes.
 */
class AnomalyDetector {
public:
    /**
     * @brief Construct a new Anomaly Detector
     * 
     * @param parameters Optional anomaly detection parameters
     */
    explicit AnomalyDetector(const AnomalyDetectionParameters& parameters = AnomalyDetectionParameters());
    
    /**
     * @brief Destroy the Anomaly Detector
     */
    ~AnomalyDetector();
    
    /**
     * @brief Set detection parameters
     * 
     * @param parameters New anomaly detection parameters
     */
    void setParameters(const AnomalyDetectionParameters& parameters);
    
    /**
     * @brief Get current detection parameters
     * 
     * @return AnomalyDetectionParameters Current parameters
     */
    AnomalyDetectionParameters getParameters() const;
    
    /**
     * @brief Detect anomalies in telemetry data
     * 
     * @param data Sequence of flight parameters to analyze
     * @return std::vector<FlightAnomaly> Detected anomalies
     */
    std::vector<FlightAnomaly> detectAnomalies(const std::vector<FlightParameters>& data);
    
    /**
     * @brief Train detector with normal flight data
     * 
     * @param trainingData Collection of normal flight data
     * @return true if training was successful
     * @return false if training failed
     */
    bool train(const std::vector<FlightParameters>& trainingData);
    
    /**
     * @brief Register a custom anomaly detection model
     * 
     * @param model Custom model to register
     * @return true if registration successful
     * @return false if registration failed
     */
    bool registerModel(std::shared_ptr<AnomalyModel> model);
    
    /**
     * @brief Unregister an anomaly detection model
     * 
     * @param modelName Name of the model to unregister
     * @return true if unregistration successful
     * @return false if model not found
     */
    bool unregisterModel(const std::string& modelName);
    
    /**
     * @brief Enable/disable a specific anomaly detection model
     * 
     * @param modelName Name of the model
     * @param enabled Whether the model should be enabled
     * @return true if the model state was changed
     * @return false if the model does not exist
     */
    bool setModelEnabled(const std::string& modelName, bool enabled);
    
    /**
     * @brief Check if a specific model is enabled
     * 
     * @param modelName Name of the model
     * @return true if the model is enabled
     * @return false if the model is disabled or does not exist
     */
    bool isModelEnabled(const std::string& modelName) const;
    
    /**
     * @brief Configure model parameters
     * 
     * @param modelName Name of the model to configure
     * @param parameters Model-specific parameters
     * @return true if configuration successful
     * @return false if configuration failed or model not found
     */
    bool configureModel(const std::string& modelName, 
                       const std::unordered_map<std::string, std::string>& parameters);

private:
    // Internal model configuration
    struct ModelConfig {
        std::shared_ptr<AnomalyModel> model;
        bool enabled;
    };
    
    // Detection parameters
    AnomalyDetectionParameters _parameters;
    
    // Registered models
    std::unordered_map<std::string, ModelConfig> _models;
    
    // Initialize default models
    void initializeDefaultModels();
    
    // Helper methods
    FlightAnomaly createAnomaly(
        const FlightParameters& params,
        FlightAnomalyType type,
        double confidence,
        const std::string& description,
        const std::string& expectedBehavior,
        const std::string& actualBehavior,
        const std::string& modelReference
    );
};

} // namespace Simulator
} // namespace PilotTraining

// src/backend/simulator/AnomalyDetector.cpp
#include "AnomalyDetector.h"
#include "../core/Logger.h"
#include <cmath>
#include <numeric>
#include <algorithm>
#include <sstream>

namespace PilotTraining {
namespace Simulator {

//----------------------------------------------------------
// StatisticalAnomalyModel Implementation
//----------------------------------------------------------

StatisticalAnomalyModel::StatisticalAnomalyModel()
    : _deviationThreshold(3.0), _trained(false) {
}

StatisticalAnomalyModel::~StatisticalAnomalyModel() = default;

bool StatisticalAnomalyModel::initialize(const std::unordered_map<std::string, std::string>& parameters) {
    try {
        // Parse configuration parameters
        for (const auto& [key, value] : parameters) {
            if (key == "deviationThreshold") {
                _deviationThreshold = std::stod(value);
            }
        }
        
        Core::Logger::debug("StatisticalAnomalyModel initialized with deviation threshold: {}", _deviationThreshold);
        return true;
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to initialize StatisticalAnomalyModel: {}", e.what());
        return false;
    }
}

bool StatisticalAnomalyModel::train(const std::vector<FlightParameters>& trainingData) {
    try {
        if (trainingData.empty()) {
            Core::Logger::error("Cannot train StatisticalAnomalyModel with empty data");
            return false;
        }
        
        Core::Logger::debug("Training StatisticalAnomalyModel with {} samples", trainingData.size());
        
        // Track all numeric parameters we want to model
        std::unordered_map<std::string, std::vector<double>> allValues;
        
        // Collect values for each parameter
        for (const auto& params : trainingData) {
            // Position and attitude
            allValues["altitude"].push_back(params.altitude);
            allValues["heading"].push_back(params.heading);
            allValues["pitch"].push_back(params.pitch);
            allValues["roll"].push_back(params.roll);
            allValues["groundSpeed"].push_back(params.groundSpeed);
            allValues["indicatedAirspeed"].push_back(params.indicatedAirspeed);
            allValues["trueAirspeed"].push_back(params.trueAirspeed);
            allValues["verticalSpeed"].push_back(params.verticalSpeed);
            
            // Control inputs
            allValues["controlPitch"].push_back(params.controlPitch);
            allValues["controlRoll"].push_back(params.controlRoll);
            allValues["controlYaw"].push_back(params.controlYaw);
            allValues["controlThrottle"].push_back(params.controlThrottle);
            
            // Engine parameters (just first engine for simplicity)
            if (!params.engineRpm.empty()) {
                allValues["engineRpm"].push_back(params.engineRpm[0]);
            }
            if (!params.enginePower.empty()) {
                allValues["enginePower"].push_back(params.enginePower[0]);
            }
            
            // Other parameters of interest
            allValues["glideSlope"].push_back(params.glideSlope);
            allValues["localizer"].push_back(params.localizer);
        }
        
        // Calculate statistics for each parameter
        for (const auto& [param, values] : allValues) {
            if (values.empty()) {
                continue;
            }
            
            // Calculate mean
            double sum = std::accumulate(values.begin(), values.end(), 0.0);
            double mean = sum / values.size();
            
            // Calculate standard deviation
            double sqSum = std::inner_product(
                values.begin(), values.end(), values.begin(), 0.0,
                std::plus<>(), [mean](double x, double y) { return (x - mean) * (y - mean); }
            );
            double stdDev = std::sqrt(sqSum / values.size());
            
            // Find min and max
            double min = *std::min_element(values.begin(), values.end());
            double max = *std::max_element(values.begin(), values.end());
            
            // Store statistics
            _statistics[param] = {mean, stdDev, min, max};
            
            Core::Logger::debug("Parameter {}: mean={:.2f}, stdDev={:.2f}, min={:.2f}, max={:.2f}",
                param, mean, stdDev, min, max);
        }
        
        _trained = true;
        return true;
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to train StatisticalAnomalyModel: {}", e.what());
        _trained = false;
        return false;
    }
}

std::vector<FlightAnomaly> StatisticalAnomalyModel::detectAnomalies(const std::vector<FlightParameters>& data) {
    std::vector<FlightAnomaly> anomalies;
    
    if (!_trained || data.empty()) {
        return anomalies;
    }
    
    // Get the latest data point
    const auto& params = data.back();
    
    // Check each parameter against the statistical model
    if (auto it = _statistics.find("altitude"); it != _statistics.end()) {
        double deviation = std::abs(params.altitude - it->second.mean) / it->second.standardDeviation;
        if (deviation > _deviationThreshold) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::TRAJECTORY_ANOMALY;
            anomaly.confidence = std::min(1.0, deviation / (_deviationThreshold * 2));
            anomaly.description = "Altitude anomaly detected";
            anomaly.expectedBehavior = "Altitude within normal range";
            anomaly.actualBehavior = "Altitude deviation: " + std::to_string(params.altitude) +
                " (expected " + std::to_string(it->second.mean) + "  " +
                std::to_string(it->second.standardDeviation * _deviationThreshold) + ")";
            anomaly.modelReference = "StatisticalAnomalyModel";
            anomaly.deviationScore = deviation;
            anomaly.parameters["altitude"] = params.altitude;
            anomaly.parameters["meanAltitude"] = it->second.mean;
            anomaly.parameters["stdDevAltitude"] = it->second.standardDeviation;
            
            anomalies.push_back(anomaly);
        }
    }
    
    // Check pitch
    if (auto it = _statistics.find("pitch"); it != _statistics.end()) {
        double deviation = std::abs(params.pitch - it->second.mean) / it->second.standardDeviation;
        if (deviation > _deviationThreshold) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::CONTROL_INPUT_ANOMALY;
            anomaly.confidence = std::min(1.0, deviation / (_deviationThreshold * 2));
            anomaly.description = "Pitch anomaly detected";
            anomaly.expectedBehavior = "Pitch within normal range";
            anomaly.actualBehavior = "Pitch deviation: " + std::to_string(params.pitch) +
                " (expected " + std::to_string(it->second.mean) + "  " +
                std::to_string(it->second.standardDeviation * _deviationThreshold) + ")";
            anomaly.modelReference = "StatisticalAnomalyModel";
            anomaly.deviationScore = deviation;
            anomaly.parameters["pitch"] = params.pitch;
            anomaly.parameters["meanPitch"] = it->second.mean;
            anomaly.parameters["stdDevPitch"] = it->second.standardDeviation;
            
            anomalies.push_back(anomaly);
        }
    }
    
    // Check roll
    if (auto it = _statistics.find("roll"); it != _statistics.end()) {
        double deviation = std::abs(params.roll - it->second.mean) / it->second.standardDeviation;
        if (deviation > _deviationThreshold) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::CONTROL_INPUT_ANOMALY;
            anomaly.confidence = std::min(1.0, deviation / (_deviationThreshold * 2));
            anomaly.description = "Roll anomaly detected";
            anomaly.expectedBehavior = "Roll within normal range";
            anomaly.actualBehavior = "Roll deviation: " + std::to_string(params.roll) +
                " (expected " + std::to_string(it->second.mean) + "  " +
                std::to_string(it->second.standardDeviation * _deviationThreshold) + ")";
            anomaly.modelReference = "StatisticalAnomalyModel";
            anomaly.deviationScore = deviation;
            anomaly.parameters["roll"] = params.roll;
            anomaly.parameters["meanRoll"] = it->second.mean;
            anomaly.parameters["stdDevRoll"] = it->second.standardDeviation;
            
            anomalies.push_back(anomaly);
        }
    }
    
    // Check vertical speed
    if (auto it = _statistics.find("verticalSpeed"); it != _statistics.end()) {
        double deviation = std::abs(params.verticalSpeed - it->second.mean) / it->second.standardDeviation;
        if (deviation > _deviationThreshold) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::TRAJECTORY_ANOMALY;
            anomaly.confidence = std::min(1.0, deviation / (_deviationThreshold * 2));
            anomaly.description = "Vertical speed anomaly detected";
            anomaly.expectedBehavior = "Vertical speed within normal range";
            anomaly.actualBehavior = "Vertical speed deviation: " + std::to_string(params.verticalSpeed) +
                " (expected " + std::to_string(it->second.mean) + "  " +
                std::to_string(it->second.standardDeviation * _deviationThreshold) + ")";
            anomaly.modelReference = "StatisticalAnomalyModel";
            anomaly.deviationScore = deviation;
            anomaly.parameters["verticalSpeed"] = params.verticalSpeed;
            anomaly.parameters["meanVerticalSpeed"] = it->second.mean;
            anomaly.parameters["stdDevVerticalSpeed"] = it->second.standardDeviation;
            
            anomalies.push_back(anomaly);
        }
    }
    
    // Check airspeed
    if (auto it = _statistics.find("indicatedAirspeed"); it != _statistics.end()) {
        double deviation = std::abs(params.indicatedAirspeed - it->second.mean) / it->second.standardDeviation;
        if (deviation > _deviationThreshold) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::TRAJECTORY_ANOMALY;
            anomaly.confidence = std::min(1.0, deviation / (_deviationThreshold * 2));
            anomaly.description = "Airspeed anomaly detected";
            anomaly.expectedBehavior = "Airspeed within normal range";
            anomaly.actualBehavior = "Airspeed deviation: " + std::to_string(params.indicatedAirspeed) +
                " (expected " + std::to_string(it->second.mean) + "  " +
                std::to_string(it->second.standardDeviation * _deviationThreshold) + ")";
            anomaly.modelReference = "StatisticalAnomalyModel";
            anomaly.deviationScore = deviation;
            anomaly.parameters["indicatedAirspeed"] = params.indicatedAirspeed;
            anomaly.parameters["meanAirspeed"] = it->second.mean;
            anomaly.parameters["stdDevAirspeed"] = it->second.standardDeviation;
            
            anomalies.push_back(anomaly);
        }
    }
    
    // Check control inputs
    if (auto it = _statistics.find("controlPitch"); it != _statistics.end()) {
        double deviation = std::abs(params.controlPitch - it->second.mean) / it->second.standardDeviation;
        if (deviation > _deviationThreshold) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::CONTROL_INPUT_ANOMALY;
            anomaly.confidence = std::min(1.0, deviation / (_deviationThreshold * 2));
            anomaly.description = "Control input anomaly detected (pitch)";
            anomaly.expectedBehavior = "Pitch control within normal range";
            anomaly.actualBehavior = "Pitch control deviation: " + std::to_string(params.controlPitch) +
                " (expected " + std::to_string(it->second.mean) + "  " +
                std::to_string(it->second.standardDeviation * _deviationThreshold) + ")";
            anomaly.modelReference = "StatisticalAnomalyModel";
            anomaly.deviationScore = deviation;
            anomaly.parameters["controlPitch"] = params.controlPitch;
            anomaly.parameters["meanControlPitch"] = it->second.mean;
            anomaly.parameters["stdDevControlPitch"] = it->second.standardDeviation;
            
            anomalies.push_back(anomaly);
        }
    }
    
    return anomalies;
}

//----------------------------------------------------------
// RuleBasedAnomalyModel Implementation
//----------------------------------------------------------

RuleBasedAnomalyModel::RuleBasedAnomalyModel()
    : _initialized(false) {
}

RuleBasedAnomalyModel::~RuleBasedAnomalyModel() = default;

bool RuleBasedAnomalyModel::initialize(const std::unordered_map<std::string, std::string>& parameters) {
    try {
        // Define default rules
        _rules["airspeed"] = {60.0, 250.0, true}; // Min/max airspeed
        _rules["altitude"] = {0.0, 10000.0, true}; // Min/max altitude
        _rules["verticalSpeed"] = {-1000.0, 1000.0, true}; // Min/max vertical speed
        _rules["pitch"] = {-20.0, 20.0, true}; // Min/max pitch
        _rules["roll"] = {-45.0, 45.0, true}; // Min/max roll
        
        // Override defaults with provided parameters
        for (const auto& [key, value] : parameters) {
            std::string paramName = key;
            std::string paramType;
            
            // Parse parameter name and type
            size_t dotPos = key.find('.');
            if (dotPos != std::string::npos) {
                paramName = key.substr(0, dotPos);
                paramType = key.substr(dotPos + 1);
            }
            
            // Update rule
            if (_rules.find(paramName) != _rules.end()) {
                if (paramType == "min") {
                    _rules[paramName].minValue = std::stod(value);
                } else if (paramType == "max") {
                    _rules[paramName].maxValue = std::stod(value);
                } else if (paramType == "enabled") {
                    _rules[paramName].enabled = (value == "true" || value == "1");
                }
            } else if (paramType.empty()) {
                // Add new rule with default settings
                _rules[paramName] = {0.0, 0.0, true};
            }
        }
        
        Core::Logger::debug("RuleBasedAnomalyModel initialized with {} rules", _rules.size());
        _initialized = true;
        return true;
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to initialize RuleBasedAnomalyModel: {}", e.what());
        return false;
    }
}

bool RuleBasedAnomalyModel::train(const std::vector<FlightParameters>& trainingData) {
    // Rule-based model doesn't need training, just initialization
    return _initialized;
}

std::vector<FlightAnomaly> RuleBasedAnomalyModel::detectAnomalies(const std::vector<FlightParameters>& data) {
    std::vector<FlightAnomaly> anomalies;
    
    if (!_initialized || data.empty()) {
        return anomalies;
    }
    
    // Get the latest data point
    const auto& params = data.back();
    
    // Check each parameter against the rules
    if (auto it = _rules.find("airspeed"); it != _rules.end() && it->second.enabled) {
        if (params.indicatedAirspeed < it->second.minValue || 
            params.indicatedAirspeed > it->second.maxValue) {
            
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::TRAJECTORY_ANOMALY;
            anomaly.confidence = 0.9; // High confidence for rule violations
            anomaly.description = "Airspeed outside allowed range";
            anomaly.expectedBehavior = "Airspeed between " + std::to_string(it->second.minValue) + 
                                      " and " + std::to_string(it->second.maxValue) + " knots";
            anomaly.actualBehavior = "Airspeed: " + std::to_string(params.indicatedAirspeed) + " knots";
            anomaly.modelReference = "RuleBasedAnomalyModel";
            
            // Calculate deviation score
            if (params.indicatedAirspeed < it->second.minValue) {
                anomaly.deviationScore = (it->second.minValue - params.indicatedAirspeed) / it->second.minValue;
            } else {
                anomaly.deviationScore = (params.indicatedAirspeed - it->second.maxValue) / it->second.maxValue;
            }
            
            anomaly.parameters["airspeed"] = params.indicatedAirspeed;
            anomaly.parameters["minAirspeed"] = it->second.minValue;
            anomaly.parameters["maxAirspeed"] = it->second.maxValue;
            
            anomalies.push_back(anomaly);
        }
    }
    
    // Check altitude
    if (auto it = _rules.find("altitude"); it != _rules.end() && it->second.enabled) {
        if (params.altitude < it->second.minValue || params.altitude > it->second.maxValue) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::TRAJECTORY_ANOMALY;
            anomaly.confidence = 0.9; // High confidence for rule violations
            anomaly.description = "Altitude outside allowed range";
            anomaly.expectedBehavior = "Altitude between " + std::to_string(it->second.minValue) + 
                                      " and " + std::to_string(it->second.maxValue) + " feet";
            anomaly.actualBehavior = "Altitude: " + std::to_string(params.altitude) + " feet";
            anomaly.modelReference = "RuleBasedAnomalyModel";
            
            // Calculate deviation score
            if (params.altitude < it->second.minValue) {
                anomaly.deviationScore = (it->second.minValue - params.altitude) / it->second.minValue;
            } else {
                anomaly.deviationScore = (params.altitude - it->second.maxValue) / it->second.maxValue;
            }
            
            anomaly.parameters["altitude"] = params.altitude;
            anomaly.parameters["minAltitude"] = it->second.minValue;
            anomaly.parameters["maxAltitude"] = it->second.maxValue;
            
            anomalies.push_back(anomaly);
        }
    }
    
    // Check vertical speed
    if (auto it = _rules.find("verticalSpeed"); it != _rules.end() && it->second.enabled) {
        if (params.verticalSpeed < it->second.minValue || params.verticalSpeed > it->second.maxValue) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::TRAJECTORY_ANOMALY;
            anomaly.confidence = 0.9; // High confidence for rule violations
            anomaly.description = "Vertical speed outside allowed range";
            anomaly.expectedBehavior = "Vertical speed between " + std::to_string(it->second.minValue) + 
                                      " and " + std::to_string(it->second.maxValue) + " feet/min";
            anomaly.actualBehavior = "Vertical speed: " + std::to_string(params.verticalSpeed) + " feet/min";
            anomaly.modelReference = "RuleBasedAnomalyModel";
            
            // Calculate deviation score
            if (params.verticalSpeed < it->second.minValue) {
                anomaly.deviationScore = (it->second.minValue - params.verticalSpeed) / std::abs(it->second.minValue);
            } else {
                anomaly.deviationScore = (params.verticalSpeed - it->second.maxValue) / it->second.maxValue;
            }
            
            anomaly.parameters["verticalSpeed"] = params.verticalSpeed;
            anomaly.parameters["minVerticalSpeed"] = it->second.minValue;
            anomaly.parameters["maxVerticalSpeed"] = it->second.maxValue;
            
            anomalies.push_back(anomaly);
        }
    }
    
    // Check pitch
    if (auto it = _rules.find("pitch"); it != _rules.end() && it->second.enabled) {
        if (params.pitch < it->second.minValue || params.pitch > it->second.maxValue) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::CONTROL_INPUT_ANOMALY;
            anomaly.confidence = 0.9; // High confidence for rule violations
            anomaly.description = "Pitch outside allowed range";
            anomaly.expectedBehavior = "Pitch between " + std::to_string(it->second.minValue) + 
                                      " and " + std::to_string(it->second.maxValue) + " degrees";
            anomaly.actualBehavior = "Pitch: " + std::to_string(params.pitch) + " degrees";
            anomaly.modelReference = "RuleBasedAnomalyModel";
            
            // Calculate deviation score
            if (params.pitch < it->second.minValue) {
                anomaly.deviationScore = (it->second.minValue - params.pitch) / std::abs(it->second.minValue);
            } else {
                anomaly.deviationScore = (params.pitch - it->second.maxValue) / it->second.maxValue;
            }
            
            anomaly.parameters["pitch"] = params.pitch;
            anomaly.parameters["minPitch"] = it->second.minValue;
            anomaly.parameters["maxPitch"] = it->second.maxValue;
            
            anomalies.push_back(anomaly);
        }
    }
    
    // Check roll
    if (auto it = _rules.find("roll"); it != _rules.end() && it->second.enabled) {
        if (params.roll < it->second.minValue || params.roll > it->second.maxValue) {
            FlightAnomaly anomaly;
            anomaly.timestamp = params.timestamp;
            anomaly.sessionId = params.sessionId;
            anomaly.type = FlightAnomalyType::CONTROL_INPUT_ANOMALY;
            anomaly.confidence = 0.9; // High confidence for rule violations
            anomaly.description = "Roll outside allowed range";
            anomaly.expectedBehavior = "Roll between " + std::to_string(it->second.minValue) + 
                                     " and " + std::to_string(it->second.maxValue) + " degrees";
            anomaly.actualBehavior = "Roll: " + std::to_string(params.roll) + " degrees";
            anomaly.modelReference = "RuleBasedAnomalyModel";
            
            // Calculate deviation score
            if (params.roll < it->second.minValue) {
                anomaly.deviationScore = (it->second.minValue - params.roll) / std::abs(it->second.minValue);
            } else {
                anomaly.deviationScore = (params.roll - it->second.maxValue) / it->second.maxValue;
            }
            
            anomaly.parameters["roll"] = params.roll;
            anomaly.parameters["minRoll"] = it->second.minValue;
            anomaly.parameters["maxRoll"] = it->second.maxValue;
            
            anomalies.push_back(anomaly);
        }
    }
    
    return anomalies;
}

//----------------------------------------------------------
// AnomalyDetector Implementation
//----------------------------------------------------------

AnomalyDetector::AnomalyDetector(const AnomalyDetectionParameters& parameters)
    : _parameters(parameters) {
    
    initializeDefaultModels();
    Core::Logger::debug("AnomalyDetector initialized");
}

AnomalyDetector::~AnomalyDetector() {
    Core::Logger::debug("AnomalyDetector destroyed");
}

void AnomalyDetector::setParameters(const AnomalyDetectionParameters& parameters) {
    _parameters = parameters;
    Core::Logger::debug("AnomalyDetector parameters updated");
}

AnomalyDetectionParameters AnomalyDetector::getParameters() const {
    return _parameters;
}

std::vector<FlightAnomaly> AnomalyDetector::detectAnomalies(const std::vector<FlightParameters>& data) {
    std::vector<FlightAnomaly> allAnomalies;
    
    if (data.empty()) {
        return allAnomalies;
    }
    
    // Run all enabled models
    for (const auto& [name, config] : _models) {
        if (config.enabled) {
            try {
                auto modelAnomalies = config.model->detectAnomalies(data);
                
                // Filter by confidence threshold
                std::copy_if(
                    modelAnomalies.begin(), modelAnomalies.end(),
                    std::back_inserter(allAnomalies),
                    [this](const auto& anomaly) {
                        return anomaly.confidence >= _parameters.confidenceThreshold;
                    }
                );
            } catch (const std::exception& e) {
                Core::Logger::error("Error in anomaly detection model {}: {}", name, e.what());
            }
        }
    }
    
    // Sort anomalies by confidence (highest first)
    std::sort(
        allAnomalies.begin(), allAnomalies.end(),
        [](const auto& a, const auto& b) {
            return a.confidence > b.confidence;
        }
    );
    
    return allAnomalies;
}

bool AnomalyDetector::train(const std::vector<FlightParameters>& trainingData) {
    bool allSuccess = true;
    
    // Train each model
    for (auto& [name, config] : _models) {
        try {
            bool success = config.model->train(trainingData);
            if (!success) {
                Core::Logger::error("Failed to train anomaly model: {}", name);
                allSuccess = false;
            } else {
                Core::Logger::debug("Successfully trained anomaly model: {}", name);
            }
        } catch (const std::exception& e) {
            Core::Logger::error("Error training anomaly model {}: {}", name, e.what());
            allSuccess = false;
        }
    }
    
    return allSuccess;
}

bool AnomalyDetector::registerModel(std::shared_ptr<AnomalyModel> model) {
    if (!model) {
        Core::Logger::error("Cannot register null anomaly model");
        return false;
    }
    
    const std::string name = model->getName();
    
    // Check if model with this name already exists
    if (_models.find(name) != _models.end()) {
        Core::Logger::error("Anomaly model already exists: {}", name);
        return false;
    }
    
    // Register the model
    _models[name] = {model, true};
    Core::Logger::info("Registered anomaly model: {}", name);
    
    return true;
}

bool AnomalyDetector::unregisterModel(const std::string& modelName) {
    auto it = _models.find(modelName);
    if (it == _models.end()) {
        Core::Logger::error("Anomaly model not found: {}", modelName);
        return false;
    }
    
    _models.erase(it);
    Core::Logger::info("Unregistered anomaly model: {}", modelName);
    
    return true;
}

bool AnomalyDetector::setModelEnabled(const std::string& modelName, bool enabled) {
    auto it = _models.find(modelName);
    if (it == _models.end()) {
        Core::Logger::error("Anomaly model not found: {}", modelName);
        return false;
    }
    
    it->second.enabled = enabled;
    Core::Logger::debug("Anomaly model {} {}", modelName, enabled ? "enabled" : "disabled");
    
    return true;
}

bool AnomalyDetector::isModelEnabled(const std::string& modelName) const {
    auto it = _models.find(modelName);
    if (it == _models.end()) {
        return false;
    }
    
    return it->second.enabled;
}

bool AnomalyDetector::configureModel(const std::string& modelName, 
                                     const std::unordered_map<std::string, std::string>& parameters) {
    auto it = _models.find(modelName);
    if (it == _models.end()) {
        Core::Logger::error("Anomaly model not found: {}", modelName);
        return false;
    }
    
    bool success = it->second.model->initialize(parameters);
    if (success) {
        Core::Logger::debug("Configured anomaly model: {}", modelName);
    } else {
        Core::Logger::error("Failed to configure anomaly model: {}", modelName);
    }
    
    return success;
}

void AnomalyDetector::initializeDefaultModels() {
    // Create and register statistical model
    auto statisticalModel = std::make_shared<StatisticalAnomalyModel>();
    statisticalModel->initialize({{"deviationThreshold", "3.0"}});
    registerModel(statisticalModel);
    
    // Create and register rule-based model
    auto ruleBasedModel = std::make_shared<RuleBasedAnomalyModel>();
    ruleBasedModel->initialize({
        {"airspeed.min", "60.0"},
        {"airspeed.max", "250.0"},
        {"altitude.min", "0.0"},
        {"altitude.max", "10000.0"},
        {"verticalSpeed.min", "-1000.0"},
        {"verticalSpeed.max", "1000.0"},
        {"pitch.min", "-20.0"},
        {"pitch.max", "20.0"},
        {"roll.min", "-45.0"},
        {"roll.max", "45.0"}
    });
    registerModel(ruleBasedModel);
}

FlightAnomaly AnomalyDetector::createAnomaly(
    const FlightParameters& params,
    FlightAnomalyType type,
    double confidence,
    const std::string& description,
    const std::string& expectedBehavior,
    const std::string& actualBehavior,
    const std::string& modelReference) {
    
    FlightAnomaly anomaly;
    anomaly.timestamp = params.timestamp;
    anomaly.sessionId = params.sessionId;
    anomaly.type = type;
    anomaly.confidence = confidence;
    anomaly.description = description;
    anomaly.expectedBehavior = expectedBehavior;
    anomaly.actualBehavior = actualBehavior;
    anomaly.modelReference = modelReference;
    
    return anomaly;
}

} // namespace Simulator
} // namespace PilotTraining

// backend/api/include/ApiGateway.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <functional>
#include <unordered_map>
#include <drogon/drogon.h>

#include "core/include/ErrorHandling.h"

namespace APTP::API {

// Configuration for the API server
struct ApiConfig {
    std::string host = "0.0.0.0";
    uint16_t port = 8080;
    uint32_t threadNum = 16;
    std::string jwtSecret;
    bool enableSSL = false;
    std::string sslCertPath;
    std::string sslKeyPath;
    uint32_t maxConnectionNum = 100000;
    uint32_t maxConnectionNumPerIP = 0;
    uint32_t keepAliveRequestsNumber = 0;
    uint32_t keepAliveTimeout = 60;
    int sessionTimeout = 0;
    bool useSession = false;
    std::string documentRoot = "./public";
    std::string uploadPath = "./uploads";
    size_t maxUploadSize = 20 * 1024 * 1024; // 20MB
    std::vector<std::string> allowedOrigins = {"*"};
    uint32_t maxRequestBodySize = 8 * 1024 * 1024;
    std::string logLevel = "debug";
    std::string logPath = "./logs";
    uint32_t rateLimitRequests = 0;
    uint32_t rateLimitWindow = 0;
};

// Rate limiting configuration
struct RateLimitConfig {
    bool enabled = false;
    uint32_t requestsPerWindow = 100;
    uint32_t windowSeconds = 60;
    bool applyPerIP = true;
    bool applyPerUser = false;
    std::vector<std::string> excludedPaths;
};

// API Gateway class
class ApiGateway {
public:
    static ApiGateway& getInstance();
    
    // Initialize the API gateway
    APTP::Core::Result<void> initialize(const ApiConfig& config);
    
    // Start the server
    APTP::Core::Result<void> start();
    
    // Stop the server
    APTP::Core::Result<void> stop();
    
    // Configure CORS
    void configureCORS(const std::vector<std::string>& allowedOrigins);
    
    // Configure rate limiting
    void configureRateLimit(const RateLimitConfig& rateLimitConfig);
    
    // Configure JWT authentication
    void configureJWT(const std::string& secret, uint32_t expireSeconds = 3600);
    
    // Get API documentation as OpenAPI/Swagger JSON
    std::string getOpenApiSpec() const;

private:
    ApiGateway();
    ~ApiGateway();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::API

// backend/api/include/controllers/DocumentController.h
#pragma once

#include <drogon/HttpController.h>
#include "document/include/DocumentProcessor.h"

namespace APTP::API {

class DocumentController : public drogon::HttpController<DocumentController> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(DocumentController::uploadDocument, "/api/documents", drogon::Post);
    ADD_METHOD_TO(DocumentController::getDocument, "/api/documents/{id}", drogon::Get);
    ADD_METHOD_TO(DocumentController::listDocuments, "/api/documents", drogon::Get);
    ADD_METHOD_TO(DocumentController::deleteDocument, "/api/documents/{id}", drogon::Delete);
    ADD_METHOD_TO(DocumentController::processDocument, "/api/documents/{id}/process", drogon::Post);
    METHOD_LIST_END

    // Upload a new document
    void uploadDocument(const drogon::HttpRequestPtr& req, 
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Get document by ID
    void getDocument(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                    const std::string& id);
    
    // List all documents
    void listDocuments(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Delete a document
    void deleteDocument(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id);
    
    // Process a document
    void processDocument(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                         const std::string& id);
    
private:
    // Helper methods
};

} // namespace APTP::API

// backend/api/include/controllers/SyllabusController.h
#pragma once

#include <drogon/HttpController.h>
#include "syllabus/include/SyllabusGenerator.h"

namespace APTP::API {

class SyllabusController : public drogon::HttpController<SyllabusController> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(SyllabusController::getSyllabus, "/api/syllabi/{id}", drogon::Get);
    ADD_METHOD_TO(SyllabusController::listSyllabi, "/api/syllabi", drogon::Get);
    ADD_METHOD_TO(SyllabusController::createSyllabus, "/api/syllabi", drogon::Post);
    ADD_METHOD_TO(SyllabusController::updateSyllabus, "/api/syllabi/{id}", drogon::Put);
    ADD_METHOD_TO(SyllabusController::deleteSyllabus, "/api/syllabi/{id}", drogon::Delete);
    ADD_METHOD_TO(SyllabusController::generateSyllabusFromDocument, "/api/syllabi/generate/document/{documentId}", drogon::Post);
    ADD_METHOD_TO(SyllabusController::generateSyllabusFromTemplate, "/api/syllabi/generate/template/{templateId}", drogon::Post);
    ADD_METHOD_TO(SyllabusController::getTemplates, "/api/syllabi/templates", drogon::Get);
    ADD_METHOD_TO(SyllabusController::getSyllabusModules, "/api/syllabi/{id}/modules", drogon::Get);
    ADD_METHOD_TO(SyllabusController::getSyllabusModule, "/api/syllabi/{id}/modules/{moduleId}", drogon::Get);
    METHOD_LIST_END

    // Get syllabus by ID
    void getSyllabus(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                    const std::string& id);
    
    // List all syllabi
    void listSyllabi(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Create a new syllabus
    void createSyllabus(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Update an existing syllabus
    void updateSyllabus(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id);
    
    // Delete a syllabus
    void deleteSyllabus(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id);
    
    // Generate syllabus from document
    void generateSyllabusFromDocument(const drogon::HttpRequestPtr& req,
                                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                                      const std::string& documentId);
    
    // Generate syllabus from template
    void generateSyllabusFromTemplate(const drogon::HttpRequestPtr& req,
                                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                                      const std::string& templateId);
    
    // Get available templates
    void getTemplates(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Get syllabus modules
    void getSyllabusModules(const drogon::HttpRequestPtr& req,
                           std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                           const std::string& id);
    
    // Get specific module
    void getSyllabusModule(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                          const std::string& id,
                          const std::string& moduleId);
};

} // namespace APTP::API

// backend/api/include/controllers/AssessmentController.h
#pragma once

#include <drogon/HttpController.h>

namespace APTP::API {

class AssessmentController : public drogon::HttpController<AssessmentController> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(AssessmentController::getAssessment, "/api/assessments/{id}", drogon::Get);
    ADD_METHOD_TO(AssessmentController::listAssessments, "/api/assessments", drogon::Get);
    ADD_METHOD_TO(AssessmentController::createAssessment, "/api/assessments", drogon::Post);
    ADD_METHOD_TO(AssessmentController::updateAssessment, "/api/assessments/{id}", drogon::Put);
    ADD_METHOD_TO(AssessmentController::deleteAssessment, "/api/assessments/{id}", drogon::Delete);
    ADD_METHOD_TO(AssessmentController::submitGrade, "/api/assessments/{id}/grade", drogon::Post);
    ADD_METHOD_TO(AssessmentController::getTraineeAssessments, "/api/trainees/{traineeId}/assessments", drogon::Get);
    ADD_METHOD_TO(AssessmentController::getAssessmentForms, "/api/assessment-forms", drogon::Get);
    ADD_METHOD_TO(AssessmentController::syncOfflineAssessments, "/api/assessments/sync", drogon::Post);
    METHOD_LIST_END

    // Get assessment by ID
    void getAssessment(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                      const std::string& id);
    
    // List all assessments
    void listAssessments(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Create a new assessment
    void createAssessment(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Update an existing assessment
    void updateAssessment(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                          const std::string& id);
    
    // Delete an assessment
    void deleteAssessment(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                          const std::string& id);
    
    // Submit a grade for an assessment
    void submitGrade(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& id);
    
    // Get assessments for a trainee
    void getTraineeAssessments(const drogon::HttpRequestPtr& req,
                              std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                              const std::string& traineeId);
    
    // Get available assessment forms
    void getAssessmentForms(const drogon::HttpRequestPtr& req,
                           std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Sync offline assessments
    void syncOfflineAssessments(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback);
};

} // namespace APTP::API

// backend/api/include/controllers/UserController.h
#pragma once

#include <drogon/HttpController.h>

namespace APTP::API {

class UserController : public drogon::HttpController<UserController> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(UserController::login, "/api/auth/login", drogon::Post);
    ADD_METHOD_TO(UserController::logout, "/api/auth/logout", drogon::Post);
    ADD_METHOD_TO(UserController::refreshToken, "/api/auth/refresh", drogon::Post);
    ADD_METHOD_TO(UserController::getUser, "/api/users/{id}", drogon::Get);
    ADD_METHOD_TO(UserController::getCurrentUser, "/api/users/me", drogon::Get);
    ADD_METHOD_TO(UserController::listUsers, "/api/users", drogon::Get);
    ADD_METHOD_TO(UserController::createUser, "/api/users", drogon::Post);
    ADD_METHOD_TO(UserController::updateUser, "/api/users/{id}", drogon::Put);
    ADD_METHOD_TO(UserController::deleteUser, "/api/users/{id}", drogon::Delete);
    ADD_METHOD_TO(UserController::getUserRoles, "/api/users/{id}/roles", drogon::Get);
    ADD_METHOD_TO(UserController::updateUserRoles, "/api/users/{id}/roles", drogon::Put);
    ADD_METHOD_TO(UserController::resetPassword, "/api/auth/reset-password", drogon::Post);
    ADD_METHOD_TO(UserController::changePassword, "/api/auth/change-password", drogon::Post);
    ADD_METHOD_TO(UserController::setupMFA, "/api/auth/mfa/setup", drogon::Post);
    ADD_METHOD_TO(UserController::verifyMFA, "/api/auth/mfa/verify", drogon::Post);
    METHOD_LIST_END

    // Login
    void login(const drogon::HttpRequestPtr& req,
              std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Logout
    void logout(const drogon::HttpRequestPtr& req,
               std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Refresh token
    void refreshToken(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Get user by ID
    void getUser(const drogon::HttpRequestPtr& req,
                std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                const std::string& id);
    
    // Get current user
    void getCurrentUser(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // List all users
    void listUsers(const drogon::HttpRequestPtr& req,
                  std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Create a new user
    void createUser(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Update an existing user
    void updateUser(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                    const std::string& id);
    
    // Delete a user
    void deleteUser(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                    const std::string& id);
    
    // Get user roles
    void getUserRoles(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& id);
    
    // Update user roles
    void updateUserRoles(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id);
    
    // Reset password
    void resetPassword(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Change password
    void changePassword(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Setup MFA
    void setupMFA(const drogon::HttpRequestPtr& req,
                 std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Verify MFA
    void verifyMFA(const drogon::HttpRequestPtr& req,
                  std::function<void(const drogon::HttpResponsePtr&)>&& callback);
};

} // namespace APTP::API

// backend/api/include/middleware/JwtMiddleware.h
#pragma once

#include <drogon/HttpFilter.h>

namespace APTP::API {

class JwtAuthFilter : public drogon::HttpFilter<JwtAuthFilter> {
public:
    JwtAuthFilter() = default;
    void doFilter(const drogon::HttpRequestPtr& req,
                 drogon::FilterCallback&& fcb,
                 drogon::FilterChainCallback&& fccb) override;
};

} // namespace APTP::API

// backend/api/src/ApiGateway.cpp (partial implementation)
#include "ApiGateway.h"
#include "core/include/ConfigurationManager.h"
#include "core/include/Logger.h"
#include "middleware/JwtMiddleware.h"
#include <drogon/drogon.h>

namespace APTP::API {

struct ApiGateway::Impl {
    ApiConfig config;
    std::unordered_map<std::string, std::string> openApiPaths;
    bool initialized = false;
    bool running = false;
    
    // Swagger API documentation
    nlohmann::json openApiSpec;
    
    // Initialize OpenAPI spec
    void initializeOpenApiSpec() {
        openApiSpec = {
            {"openapi", "3.0.0"},
            {"info", {
                {"title", "Advanced Pilot Training Platform API"},
                {"description", "API for the Advanced Pilot Training Platform"},
                {"version", "1.0.0"}
            }},
            {"servers", nlohmann::json::array({
                {{"url", "http://" + config.host + ":" + std::to_string(config.port)}}
            })},
            {"paths", {}}
        };
        
        // Add paths and schemas for all endpoints
        // This would be populated with all API endpoints and schemas
    }
};

ApiGateway& ApiGateway::getInstance() {
    static ApiGateway instance;
    return instance;
}

ApiGateway::ApiGateway() : impl_(std::make_unique<Impl>()) {}
ApiGateway::~ApiGateway() {
    stop();
}

APTP::Core::Result<void> ApiGateway::initialize(const ApiConfig& config) {
    if (impl_->initialized) {
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::InvalidState);
    }
    
    impl_->config = config;
    
    // Configure Drogon
    drogon::app().setLogPath(config.logPath)
                 .setLogLevel(config.logLevel)
                 .addListener(config.host, config.port)
                 .setThreadNum(config.threadNum)
                 .setMaxConnectionNum(config.maxConnectionNum)
                 .setMaxConnectionNumPerIP(config.maxConnectionNumPerIP)
                 .setKeepAliveRequestsNumber(config.keepAliveRequestsNumber)
                 .setKeepAliveTimeout(config.keepAliveTimeout)
                 .setDocumentRoot(config.documentRoot)
                 .setUploadPath(config.uploadPath)
                 .setMaxBodySize(config.maxRequestBodySize);
    
    // Configure SSL if enabled
    if (config.enableSSL && !config.sslCertPath.empty() && !config.sslKeyPath.empty()) {
        drogon::app().setSSLFiles(config.sslCertPath, config.sslKeyPath);
    }
    
    // Configure JWT if provided
    if (!config.jwtSecret.empty()) {
        configureJWT(config.jwtSecret);
    }
    
    // Configure CORS
    configureCORS(config.allowedOrigins);
    
    // Initialize OpenAPI documentation
    impl_->initializeOpenApiSpec();
    
    impl_->initialized = true;
    
    APTP::Core::Logger::getInstance().info("API Gateway initialized on {}:{}", config.host, config.port);
    return APTP::Core::Success();
}

APTP::Core::Result<void> ApiGateway::start() {
    if (!impl_->initialized) {
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::InvalidState);
    }
    
    if (impl_->running) {
        return APTP::Core::Success();
    }
    
    try {
        drogon::app().run();
        impl_->running = true;
        
        APTP::Core::Logger::getInstance().info("API Gateway started");
        return APTP::Core::Success();
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Failed to start API Gateway: {}", e.what());
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::ResourceUnavailable);
    }
}

APTP::Core::Result<void> ApiGateway::stop() {
    if (!impl_->running) {
        return APTP::Core::Success();
    }
    
    try {
        drogon::app().quit();
        impl_->running = false;
        
        APTP::Core::Logger::getInstance().info("API Gateway stopped");
        return APTP::Core::Success();
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Failed to stop API Gateway: {}", e.what());
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::Unknown);
    }
}

void ApiGateway::configureCORS(const std::vector<std::string>& allowedOrigins) {
    auto corsFilter = []() -> drogon::HttpResponsePtr {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k200OK);
        return resp;
    };
    
    // Configure CORS options
    auto corsOptions = std::make_shared<drogon::CorsOptions>();
    corsOptions->allowMethods = {"GET", "POST", "PUT", "DELETE", "OPTIONS"};
    corsOptions->allowHeaders = {"x-requested-with", "content-type", "authorization"};
    corsOptions->exposeHeaders = {"authorization"};
    corsOptions->allowCredentials = true;
    
    if (allowedOrigins.size() == 1 && allowedOrigins[0] == "*") {
        corsOptions->allowOrigins = {"*"};
    } else {
        corsOptions->allowOrigins = allowedOrigins;
    }
    
    drogon::app().registerHttpController(corsFilter, "/api/.*", corsOptions);
}

void ApiGateway::configureJWT(const std::string& secret, uint32_t expireSeconds) {
    // Store JWT secret in configuration
    APTP::Core::ConfigurationManager::getInstance().set("jwt_secret", secret, APTP::Core::ConfigSource::Environment);
    APTP::Core::ConfigurationManager::getInstance().set("jwt_expire_seconds", expireSeconds, APTP::Core::ConfigSource::Environment);
    
    // Register JWT middleware for protected routes
    drogon::app().registerFilter<JwtAuthFilter>("/api/.*");
    
    // Exclude auth endpoints from JWT check
    drogon::app().registerFilterWithPriority<JwtAuthFilter>(
        drogon::FilterPriority::None,
        "/api/auth/.*"
    );
}

void ApiGateway::configureRateLimit(const RateLimitConfig& rateLimitConfig) {
    // Implementation for rate limiting would go here
    // This could use Drogon's built-in rate limiting or a custom solution
}

std::string ApiGateway::getOpenApiSpec() const {
    return impl_->openApiSpec.dump(4); // Pretty print with 4-space indentation
}

// Implementation for controllers would follow a similar pattern
// Each controller class would have implementations for its methods
// These would handle the HTTP requests, process them, and return responses

} // namespace APTP::API

// backend/api/src/controllers/DocumentController.cpp (example implementation)
#include "controllers/DocumentController.h"
#include <drogon/HttpResponse.h>
#include <json/json.h>

namespace APTP::API {

void DocumentController::uploadDocument(const drogon::HttpRequestPtr& req, 
                                       std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    // Example implementation for document upload
    auto resp = drogon::HttpResponse::newHttpJsonResponse(Json::Value());
    Json::Value result;
    
    // Check if this is a multipart/form-data request
    if (req->contentType() != drogon::CT_APPLICATION_JSON &&
        req->contentType() != drogon::CT_MULTIPART_FORM_DATA) {
        result["success"] = false;
        result["error"] = "Invalid content type";
        resp->setStatusCode(drogon::k400BadRequest);
        resp->setBody(result.toStyledString());
        callback(resp);
        return;
    }
    
    // Handle multipart/form-data upload
    auto& files = req->getFilesFromMultipartForm();
    if (files.empty()) {
        result["success"] = false;
        result["error"] = "No files uploaded";
        resp->setStatusCode(drogon::k400BadRequest);
        resp->setBody(result.toStyledString());
        callback(resp);
        return;
    }
    
    // Process each uploaded file
    Json::Value uploadedDocs(Json::arrayValue);
    for (auto& file : files) {
        // Create a unique ID for the document
        std::string docId = std::to_string(std::hash<std::string>{}(file.getFileName() + std::to_string(std::time(nullptr))));
        
        // Save file to uploads directory
        std::string savePath = "uploads/" + docId + "_" + file.getFileName();
        file.saveAs(savePath);
        
        // Create document processor to extract metadata
        auto docProcessor = APTP::Document::DocumentProcessor::createProcessor(savePath);
        auto processResult = docProcessor->processDocument(savePath);
        
        if (processResult.isSuccess()) {
            // Add document to database (simplified here)
            // In a real implementation, this would interact with the database
            
            // Return information about the uploaded document
            Json::Value docInfo;
            docInfo["id"] = docId;
            docInfo["filename"] = file.getFileName();
            docInfo["size"] = static_cast<Json::UInt64>(file.getSize());
            docInfo["contentType"] = file.getContentType();
            docInfo["path"] = savePath;
            
            // Add metadata if available
            const auto& metadata = processResult.value().metadata;
            docInfo["title"] = metadata.title;
            docInfo["author"] = metadata.author;
            docInfo["creationDate"] = metadata.creationDate;
            
            uploadedDocs.append(docInfo);
        } else {
            // Document processing failed
            Json::Value docInfo;
            docInfo["id"] = docId;
            docInfo["filename"] = file.getFileName();
            docInfo["size"] = static_cast<Json::UInt64>(file.getSize());
            docInfo["contentType"] = file.getContentType();
            docInfo["path"] = savePath;
            docInfo["processingError"] = "Failed to process document";
            
            uploadedDocs.append(docInfo);
        }
    }
    
    // Return success response
    result["success"] = true;
    result["documents"] = uploadedDocs;
    resp->setStatusCode(drogon::k201Created);
    resp->setBody(result.toStyledString());
    callback(resp);
}

// Additional method implementations would follow

} // namespace APTP::API

// Implementation for other controllers would follow a similar pattern

cmake_minimum_required(VERSION 3.20)
project(api-gateway VERSION 1.0.0 LANGUAGES CXX)

# Set C++20 standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Set output directories
set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)

# Find required packages
find_package(gRPC REQUIRED)
find_package(Protobuf REQUIRED)
find_package(OpenSSL REQUIRED)
find_package(nlohmann_json 3.10.0 REQUIRED)
find_package(spdlog REQUIRED)
find_package(prometheus-cpp REQUIRED)
find_package(cpprestsdk REQUIRED)
find_package(jwt-cpp REQUIRED)

# Include directories
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_BINARY_DIR}/generated
)

# Generate protobuf and gRPC code for all services
set(PROTO_FILES
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/core_service.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/data_acquisition.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/etr_service.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/ai_analytics.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/document_service.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/syllabus_generator.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/assessment_service.proto
)

protobuf_generate_cpp(PROTO_SRCS PROTO_HDRS ${PROTO_FILES})
grpc_generate_cpp(GRPC_SRCS GRPC_HDRS ${CMAKE_CURRENT_BINARY_DIR}/generated ${PROTO_FILES})

# Source files
file(GLOB_RECURSE SOURCES 
    ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp
)

# Add executable
add_executable(${PROJECT_NAME} ${SOURCES} ${PROTO_SRCS} ${PROTO_HDRS} ${GRPC_SRCS} ${GRPC_HDRS})

# Link libraries
target_link_libraries(${PROJECT_NAME}
    PRIVATE
    gRPC::grpc++
    gRPC::grpc++_reflection
    protobuf::libprotobuf
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
    spdlog::spdlog
    prometheus-cpp::core
    prometheus-cpp::push
    cpprestsdk::cpprest
    jwt-cpp::jwt-cpp
)

# Copy configuration files to build directory
configure_file(
    ${CMAKE_CURRENT_SOURCE_DIR}/config/config.json
    ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/config/config.json
    COPYONLY
)

# Add tests
enable_testing()
add_subdirectory(tests)

# Installation
install(TARGETS ${PROJECT_NAME}
    RUNTIME DESTINATION bin
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)

install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/config/
    DESTINATION etc/${PROJECT_NAME}
    FILES_MATCHING PATTERN "*.json"
)

# Documentation
find_package(Doxygen)
if(DOXYGEN_FOUND)
    set(DOXYGEN_IN ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in)
    set(DOXYGEN_OUT ${CMAKE_CURRENT_BINARY_DIR}/Doxyfile)
    
    configure_file(${DOXYGEN_IN} ${DOXYGEN_OUT} @ONLY)
    
    add_custom_target(docs
        COMMAND ${DOXYGEN_EXECUTABLE} ${DOXYGEN_OUT}
        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
        COMMENT "Generating API documentation with Doxygen"
        VERBATIM
    )
endif()
#pragma once

#include "services/service_client_base.h"
#include "core_service.grpc.pb.h"
#include <cpprest/json.h>

namespace api_gateway {
namespace services {

/**
 * @brief Client for the Core Platform Service
 */
class CoreServiceClient : public ServiceClientBase {
public:
    /**
     * @brief Constructor
     * @param endpoint Service endpoint (host:port)
     * @param logger Logger instance
     * @param metrics Metrics instance
     */
    CoreServiceClient(
        const std::string& endpoint,
        std::shared_ptr<logging::Logger> logger,
        std::shared_ptr<metrics::RequestMetrics> metrics
    );
    
    /**
     * @brief Destructor
     */
    ~CoreServiceClient() override;
    
    /**
     * @brief Check service health
     * @return True if service is healthy
     */
    bool checkHealth() override;
    
    /**
     * @brief Login with username and password
     * @param username Username
     * @param password Password
     * @return JSON response
     */
    web::json::value login(
        const std::string& username,
        const std::string& password
    );
    
    /**
     * @brief Refresh token
     * @param refresh_token Refresh token
     * @return JSON response
     */
    web::json::value refreshToken(
        const std::string& refresh_token
    );
    
    /**
     * @brief Validate token
     * @param token JWT token
     * @return JSON response
     */
    web::json::value validateToken(
        const std::string& token
    );
    
    /**
     * @brief Get user info
     * @param token JWT token
     * @return JSON response
     */
    web::json::value getUserInfo(
        const std::string& token
    );
    
    /**
     * @brief Get service configuration
     * @param token JWT token
     * @param service_name Service name
     * @return JSON response
     */
    web::json::value getServiceConfig(
        const std::string& token,
        const std::string& service_name
    );
    
    /**
     * @brief Send message to another service via core platform
     * @param token JWT token
     * @param target_service Target service name
     * @param message_type Message type
     * @param payload Message payload
     * @return JSON response
     */
    web::json::value sendMessage(
        const std::string& token,
        const std::string& target_service,
        const std::string& message_type,
        const web::json::value& payload
    );
    
private:
    /**
     * @brief Convert auth response proto to JSON
     * @param response Auth response proto
     * @return JSON representation
     */
    web::json::value convertAuthResponseToJson(
        const core_platform::AuthResponse& response
    );
    
    /**
     * @brief Convert token validation response proto to JSON
     * @param response Token validation response proto
     * @return JSON representation
     */
    web::json::value convertTokenValidationResponseToJson(
        const core_platform::TokenValidationResponse& response
    );
    
    /**
     * @brief Convert config response proto to JSON
     * @param response Config response proto
     * @return JSON representation
     */
    web::json::value convertConfigResponseToJson(
        const core_platform::ConfigResponse& response
    );
    
    /**
     * @brief Convert message response proto to JSON
     * @param response Message response proto
     * @return JSON representation
     */
    web::json::value convertMessageResponseToJson(
        const core_platform::MessageResponse& response
    );
    
    std::unique_ptr<core_platform::AuthService::Stub> auth_stub_;
    std::unique_ptr<core_platform::ConfigService::Stub> config_stub_;
    std::unique_ptr<core_platform::MessagingService::Stub> messaging_stub_;
    std::unique_ptr<core_platform::HealthService::Stub> health_stub_;
};

} // namespace services
} // namespace api_gateway
#include <drogon/drogon.h>
#include <json/json.h>
#include <string>
#include <vector>
#include <map>
#include <memory>
#include <mutex>
#include "service_registry.h"
#include "request_router.h"
#include "auth_validator.h"
#include "rate_limiter.h"

namespace atp {
namespace gateway {

class APIGatewayService : public drogon::HttpController<APIGatewayService> {
public:
    METHOD_LIST_BEGIN
    // Health check endpoint
    ADD_METHOD_TO(APIGatewayService::getHealth, "/api/health", drogon::Get);
    
    // API Documentation
    ADD_METHOD_TO(APIGatewayService::getAPISpec, "/api/spec", drogon::Get);

    // Proxy all other requests
    ADD_METHOD_TO(APIGatewayService::proxyRequest, "/api/{path}", drogon::Get, drogon::Post, drogon::Put, drogon::Delete, drogon::Options, "path={.*}");
    ADD_METHOD_TO(APIGatewayService::proxyRequest, "/api/{path1}/{path2}", drogon::Get, drogon::Post, drogon::Put, drogon::Delete, drogon::Options, "path1={.*},path2={.*}");
    ADD_METHOD_TO(APIGatewayService::proxyRequest, "/api/{path1}/{path2}/{path3}", drogon::Get, drogon::Post, drogon::Put, drogon::Delete, drogon::Options, "path1={.*},path2={.*},path3={.*}");
    ADD_METHOD_TO(APIGatewayService::proxyRequest, "/api/{path1}/{path2}/{path3}/{path4}", drogon::Get, drogon::Post, drogon::Put, drogon::Delete, drogon::Options, "path1={.*},path2={.*},path3={.*},path4={.*}");
    ADD_METHOD_TO(APIGatewayService::proxyRequest, "/api/{path1}/{path2}/{path3}/{path4}/{path5}", drogon::Get, drogon::Post, drogon::Put, drogon::Delete, drogon::Options, "path1={.*},path2={.*},path3={.*},path4={.*},path5={.*}");
    METHOD_LIST_END

    APIGatewayService();

    void getHealth(const drogon::HttpRequestPtr& req, 
                  std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getAPISpec(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void proxyRequest(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback);

private:
    std::shared_ptr<ServiceRegistry> serviceRegistry_;
    std::shared_ptr<RequestRouter> router_;
    std::shared_ptr<AuthValidator> authValidator_;
    std::shared_ptr<RateLimiter> rateLimiter_;
    
    // Monitoring
    std::atomic<uint64_t> requestCount_;
    std::atomic<uint64_t> errorCount_;
    std::map<std::string, std::atomic<uint64_t>> serviceCallCounts_;
    std::mutex serviceCallCountsMutex_;
    
    // Cache for API specifications
    Json::Value apiSpecCache_;
    
    // Helper methods
    bool validateRequest(const drogon::HttpRequestPtr& req, std::string& userId, std::string& errorMessage);
    void forwardToService(const drogon::HttpRequestPtr& req, 
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                         const std::string& serviceName,
                         const std::string& endpoint);
    void recordServiceCall(const std::string& serviceName);
    bool checkRateLimit(const drogon::HttpRequestPtr& req, std::string& errorMessage);
    void loadAPISpecifications();
    
    // Circuit breaker implementation
    std::map<std::string, int> serviceErrorCounts_;
    std::map<std::string, bool> serviceCircuitOpen_;
    std::map<std::string, std::chrono::time_point<std::chrono::system_clock>> serviceCircuitResetTime_;
    std::mutex circuitBreakerMutex_;
    
    bool isCircuitOpen(const std::string& serviceName);
    void recordServiceError(const std::string& serviceName);
    void resetCircuit(const std::string& serviceName);
};

APIGatewayService::APIGatewayService() : requestCount_(0), errorCount_(0) {
    // Initialize components
    serviceRegistry_ = std::make_shared<ServiceRegistry>();
    router_ = std::make_shared<RequestRouter>(serviceRegistry_);
    authValidator_ = std::make_shared<AuthValidator>();
    rateLimiter_ = std::make_shared<RateLimiter>();
    
    // Load service registry
    serviceRegistry_->loadServices("services.json");
    
    // Load API specifications
    loadAPISpecifications();
}

void APIGatewayService::getHealth(const drogon::HttpRequestPtr& req, 
                std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Check service health
        std::vector<std::pair<std::string, bool>> serviceHealth = serviceRegistry_->checkServiceHealth();
        
        // Prepare response
        Json::Value result;
        result["status"] = "ok";
        result["version"] = "1.0.0";
        result["timestamp"] = drogon::utils::getFormattedDate();
        
        // Add request statistics
        result["request_count"] = static_cast<Json::Int64>(requestCount_.load());
        result["error_count"] = static_cast<Json::Int64>(errorCount_.load());
        
        // Add service health
        Json::Value services(Json::arrayValue);
        bool allHealthy = true;
        
        for (const auto& service : serviceHealth) {
            Json::Value serviceInfo;
            serviceInfo["name"] = service.first;
            serviceInfo["healthy"] = service.second;
            
            if (!service.second) {
                allHealthy = false;
            }
            
            // Add call count if available
            {
                std::lock_guard<std::mutex> lock(serviceCallCountsMutex_);
                auto it = serviceCallCounts_.find(service.first);
                if (it != serviceCallCounts_.end()) {
                    serviceInfo["call_count"] = static_cast<Json::Int64>(it->second.load());
                }
            }
            
            // Add circuit breaker status
            {
                std::lock_guard<std::mutex> lock(circuitBreakerMutex_);
                auto it = serviceCircuitOpen_.find(service.first);
                if (it != serviceCircuitOpen_.end()) {
                    serviceInfo["circuit_open"] = it->second;
                } else {
                    serviceInfo["circuit_open"] = false;
                }
            }
            
            services.append(serviceInfo);
        }
        
        result["services"] = services;
        result["all_healthy"] = allHealthy;
        
        // Create response
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        
        // If not all services are healthy, return 503 status
        if (!allHealthy) {
            resp->setStatusCode(drogon::k503ServiceUnavailable);
        }
        
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        
        callback(resp);
    }
}

void APIGatewayService::getAPISpec(const drogon::HttpRequestPtr& req,
                 std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string format = params.find("format") != params.end() ? params["format"] : "json";
        std::string service = params.find("service") != params.end() ? params["service"] : "";
        
        // Prepare response based on format and service
        if (format == "yaml") {
            // Return YAML format (not implemented in this example)
            auto resp = drogon::HttpResponse::newHttpResponse();
            resp->setStatusCode(drogon::k501NotImplemented);
            resp->setBody("YAML format not implemented");
            callback(resp);
            return;
        }
        
        // Filter by service if specified
        if (!service.empty()) {
            if (apiSpecCache_.isMember(service)) {
                auto resp = drogon::HttpResponse::newHttpJsonResponse(apiSpecCache_[service]);
                callback(resp);
            } else {
                Json::Value error;
                error["status"] = "error";
                error["message"] = "Service not found: " + service;
                
                auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
                resp->setStatusCode(drogon::k404NotFound);
                callback(resp);
            }
        } else {
            // Return full API spec
            auto resp = drogon::HttpResponse::newHttpJsonResponse(apiSpecCache_);
            callback(resp);
        }
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        
        callback(resp);
    }
}

void APIGatewayService::proxyRequest(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    // Increment request count
    requestCount_++;
    
    try {
        // Extract path components
        std::string path = req->getPath();
        path = path.substr(5);  // Remove /api/ prefix
        
        // Check rate limit
        std::string rateLimitError;
        if (!checkRateLimit(req, rateLimitError)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = rateLimitError;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k429TooManyRequests);
            callback(resp);
            return;
        }
        
        // Authenticate and authorize request
        std::string userId;
        std::string authError;
        
        if (!validateRequest(req, userId, authError)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = authError;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k401Unauthorized);
            callback(resp);
            return;
        }
        
        // Route the request to appropriate service
        auto [serviceName, endpoint] = router_->routeRequest(path, req->getMethod());
        
        if (serviceName.empty()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "No service found for path: " + path;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            
            callback(resp);
            return;
        }
        
        // Check if circuit is open for this service
        if (isCircuitOpen(serviceName)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Service temporarily unavailable: " + serviceName;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k503ServiceUnavailable);
            
            callback(resp);
            return;
        }
        
        // Forward request to service
        forwardToService(req, std::move(callback), serviceName, endpoint);
    }
    catch (const std::exception& e) {
        // Increment error count
        errorCount_++;
        
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        
        callback(resp);
    }
}

bool APIGatewayService::validateRequest(const drogon::HttpRequestPtr& req, std::string& userId, std::string& errorMessage) {
    // Skip authentication for OPTIONS requests (for CORS support)
    if (req->getMethod() == drogon::Options) {
        return true;
    }
    
    // Skip authentication for public endpoints
    std::string path = req->getPath();
    
    // List of paths that don't require authentication
    std::vector<std::string> publicPaths = {
        "/api/health",
        "/api/spec",
        "/api/auth/login"
    };
    
    for (const auto& publicPath : publicPaths) {
        if (path == publicPath) {
            return true;
        }
    }
    
    // Extract JWT token from Authorization header
    std::string token;
    
    auto authHeader = req->getHeader("Authorization");
    if (authHeader.empty()) {
        errorMessage = "Missing Authorization header";
        return false;
    }
    
    // Check for Bearer token
    if (authHeader.substr(0, 7) != "Bearer ") {
        errorMessage = "Invalid Authorization header format";
        return false;
    }
    
    token = authHeader.substr(7);
    
    // Validate token
    if (!authValidator_->validateToken(token, userId, errorMessage)) {
        return false;
    }
    
    // Add user ID to request for downstream services
    req->addHeader("X-User-ID", userId);
    
    return true;
}

void APIGatewayService::forwardToService(const drogon::HttpRequestPtr& req, 
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                       const std::string& serviceName,
                       const std::string& endpoint) {
    // Record service call
    recordServiceCall(serviceName);
    
    // Get service URL
    std::string serviceUrl = serviceRegistry_->getServiceUrl(serviceName);
    
    if (serviceUrl.empty()) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = "Service not found: " + serviceName;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k404NotFound);
        
        callback(resp);
        return;
    }
    
    // Construct full URL
    std::string url = serviceUrl + endpoint;
    
    // Create HTTP client
    auto client = drogon::HttpClient::newHttpClient(url);
    
    // Forward original headers
    auto newReq = drogon::HttpRequest::newHttpRequest();
    newReq->setMethod(req->getMethod());
    newReq->setPath(endpoint);
    
    // Copy query parameters
    for (auto& param : req->getParameters()) {
        newReq->setParameter(param.first, param.second);
    }
    
    // Copy headers (except Host)
    for (auto& header : req->headers()) {
        if (header.first != "Host") {
            newReq->addHeader(header.first, header.second);
        }
    }
    
    // Add X-Forwarded headers
    newReq->addHeader("X-Forwarded-For", req->getPeerAddr().toIp());
    newReq->addHeader("X-Forwarded-Proto", req->isSSL() ? "https" : "http");
    newReq->addHeader("X-Forwarded-Host", req->getHeader("Host"));
    
    // Add X-Gateway headers for tracing
    newReq->addHeader("X-Gateway-Service", "api-gateway");
    newReq->addHeader("X-Gateway-Request-ID", generateRequestId());
    
    // Copy body if any
    if (req->getContentLength() > 0 && req->body().length() > 0) {
        newReq->setBody(req->body());
        newReq->setContentTypeCode(req->getContentType());
    }
    
    // Send the request
    client->sendRequest(newReq, [this, callback, serviceName](drogon::ReqResult result, const drogon::HttpResponsePtr& response) {
        if (result != drogon::ReqResult::Ok) {
            // Record service error
            recordServiceError(serviceName);
            
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Failed to connect to service: " + serviceName;
            
            auto errResp = drogon::HttpResponse::newHttpJsonResponse(error);
            errResp->setStatusCode(drogon::k502BadGateway);
            
            callback(errResp);
            return;
        }
        
        // Check for error response
        if (response->getStatusCode() >= drogon::k500InternalServerError) {
            // Record service error
            recordServiceError(serviceName);
        }
        
        // Add CORS headers if needed
        response->addHeader("Access-Control-Allow-Origin", "*");
        response->addHeader("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS");
        response->addHeader("Access-Control-Allow-Headers", "Content-Type, Authorization, X-Requested-With");
        
        callback(response);
    });
}

void APIGatewayService::recordServiceCall(const std::string& serviceName) {
    std::lock_guard<std::mutex> lock(serviceCallCountsMutex_);
    
    auto it = serviceCallCounts_.find(serviceName);
    if (it != serviceCallCounts_.end()) {
        it->second++;
    } else {
        serviceCallCounts_[serviceName] = 1;
    }
}

bool APIGatewayService::checkRateLimit(const drogon::HttpRequestPtr& req, std::string& errorMessage) {
    // Extract client IP
    std::string clientIp = req->getPeerAddr().toIp();
    
    // Extract path for endpoint-specific rate limits
    std::string path = req->getPath();
    
    // Check if rate limited
    if (!rateLimiter_->allowRequest(clientIp, path)) {
        errorMessage = "Rate limit exceeded. Please try again later.";
        return false;
    }
    
    return true;
}

void APIGatewayService::loadAPISpecifications() {
    // In a real implementation, this would load OpenAPI specifications from each service
    // or from a central repository
    
    // For this example, we're creating a mock API spec
    apiSpecCache_["openapi"] = "3.0.0";
    apiSpecCache_["info"]["title"] = "Advanced Pilot Training Platform API";
    apiSpecCache_["info"]["version"] = "1.0.0";
    apiSpecCache_["info"]["description"] = "API for the Advanced Pilot Training Platform";
    
    // Add paths for each service
    apiSpecCache_["paths"] = Json::Value(Json::objectValue);
    
    // Auth Service Endpoints
    Json::Value authService;
    authService["info"]["title"] = "Authentication Service";
    authService["info"]["version"] = "1.0.0";
    authService["paths"]["/api/auth/login"]["post"]["summary"] = "Authenticate user";
    authService["paths"]["/api/auth/refresh"]["post"]["summary"] = "Refresh access token";
    authService["paths"]["/api/auth/validate"]["post"]["summary"] = "Validate token";
    
    // Document Service Endpoints
    Json::Value documentService;
    documentService["info"]["title"] = "Document Service";
    documentService["info"]["version"] = "1.0.0";
    documentService["paths"]["/api/documents/process"]["post"]["summary"] = "Process document";
    documentService["paths"]["/api/documents/classify"]["post"]["summary"] = "Classify document";
    
    // Syllabus Service Endpoints
    Json::Value syllabusService;
    syllabusService["info"]["title"] = "Syllabus Service";
    syllabusService["info"]["version"] = "1.0.0";
    syllabusService["paths"]["/api/syllabus/templates"]["get"]["summary"] = "Get syllabus templates";
    syllabusService["paths"]["/api/syllabus/templates/{id}"]["get"]["summary"] = "Get syllabus template by ID";
    
    // Add more services as needed
    
    // Add services to cache
    apiSpecCache_["services"]["auth"] = authService;
    apiSpecCache_["services"]["document"] = documentService;
    apiSpecCache_["services"]["syllabus"] = syllabusService;
    
    // Merge paths for simplified view
    for (const auto& service : apiSpecCache_["services"].getMemberNames()) {
        const auto& servicePaths = apiSpecCache_["services"][service]["paths"];
        
        for (const auto& path : servicePaths.getMemberNames()) {
            apiSpecCache_["paths"][path] = servicePaths[path];
        }
    }
}

std::string APIGatewayService::generateRequestId() {
    // Generate a unique request ID
    auto now = std::chrono::system_clock::now();
    auto now_ms = std::chrono::time_point_cast<std::chrono::milliseconds>(now);
    auto epoch = now_ms.time_since_epoch();
    uint64_t timestamp = static_cast<uint64_t>(epoch.count());
    
    // Combine timestamp with a random number
    std::random_device rd;
    std::mt19937_64 gen(rd());
    std::uniform_int_distribution<uint64_t> dist;
    uint64_t random = dist(gen);
    
    std::stringstream ss;
    ss << std::hex << timestamp << "-" << random;
    return ss.str();
}

bool APIGatewayService::isCircuitOpen(const std::string& serviceName) {
    std::lock_guard<std::mutex> lock(circuitBreakerMutex_);
    
    auto it = serviceCircuitOpen_.find(serviceName);
    if (it != serviceCircuitOpen_.end() && it->second) {
        // Check if reset time has passed
        auto resetIt = serviceCircuitResetTime_.find(serviceName);
        if (resetIt != serviceCircuitResetTime_.end()) {
            auto now = std::chrono::system_clock::now();
            if (now > resetIt->second) {
                // Reset circuit
                resetCircuit(serviceName);
                return false;
            }
        }
        
        return true;
    }
    
    return false;
}

void APIGatewayService::recordServiceError(const std::string& serviceName) {
    std::lock_guard<std::mutex> lock(circuitBreakerMutex_);
    
    // Increment error count
    auto it = serviceErrorCounts_.find(serviceName);
    if (it != serviceErrorCounts_.end()) {
        it->second++;
    } else {
        serviceErrorCounts_[serviceName] = 1;
    }
    
    // Check if error threshold exceeded
    const int ERROR_THRESHOLD = 5; // Open circuit after 5 errors
    
    if (serviceErrorCounts_[serviceName] >= ERROR_THRESHOLD) {
        // Open circuit
        serviceCircuitOpen_[serviceName] = true;
        
        // Set reset time (30 seconds)
        auto resetTime = std::chrono::system_clock::now() + std::chrono::seconds(30);
        serviceCircuitResetTime_[serviceName] = resetTime;
        
        // Log circuit open event
        std::cout << "Circuit opened for service: " << serviceName 
                  << " (Error count: " << serviceErrorCounts_[serviceName] << ")" << std::endl;
    }
}

void APIGatewayService::resetCircuit(const std::string& serviceName) {
    // Reset circuit breaker state
    serviceCircuitOpen_[serviceName] = false;
    serviceErrorCounts_[serviceName] = 0;
    
    // Log circuit reset event
    std::cout << "Circuit reset for service: " << serviceName << std::endl;
}

} // namespace gateway
} // namespace atp

// Service Registry implementation
namespace atp {
namespace gateway {

ServiceRegistry::ServiceRegistry() {
    // Initialize with default services
    services_["auth"] = "http://localhost:8083";
    services_["document"] = "http://localhost:8080";
    services_["syllabus"] = "http://localhost:8081";
    services_["compliance"] = "http://localhost:8082";
    services_["debrief"] = "http://localhost:8084";
    services_["admin"] = "http://localhost:8085";
    services_["gamification"] = "http://localhost:8086";
    services_["community"] = "http://localhost:8087";
}

void ServiceRegistry::loadServices(const std::string& configFile) {
    // In a real implementation, this would load service configurations from a JSON file
    // For this example, we'll use hardcoded values
    
    // You might add additional services or modify existing ones
    services_["analytics"] = "http://localhost:5001";
}

std::string ServiceRegistry::getServiceUrl(const std::string& serviceName) {
    auto it = services_.find(serviceName);
    if (it != services_.end()) {
        return it->second;
    }
    
    return "";
}

std::vector<std::pair<std::string, bool>> ServiceRegistry::checkServiceHealth() {
    std::vector<std::pair<std::string, bool>> results;
    
    for (const auto& service : services_) {
        // In a real implementation, this would make a health check request to each service
        // For this example, we'll assume all services are healthy
        results.push_back({service.first, true});
    }
    
    return results;
}

} // namespace gateway
} // namespace atp

// Request Router implementation
namespace atp {
namespace gateway {

RequestRouter::RequestRouter(std::shared_ptr<ServiceRegistry> serviceRegistry) 
    : serviceRegistry_(serviceRegistry) {
    // Initialize route patterns
    initializeRoutes();
}

void RequestRouter::initializeRoutes() {
    // Define routes for each service
    // Format: {path_regex, service_name}
    
    // Auth Service
    routes_.push_back({std::regex("^auth/.*"), "auth"});
    
    // Document Service
    routes_.push_back({std::regex("^documents/.*"), "document"});
    
    // Syllabus Service
    routes_.push_back({std::regex("^syllabus/.*"), "syllabus"});
    
    // Compliance Service
    routes_.push_back({std::regex("^compliance/.*"), "compliance"});
    routes_.push_back({std::regex("^audit/.*"), "compliance"});
    
    // Debrief Service
    routes_.push_back({std::regex("^debrief/.*"), "debrief"});
    
    // Admin Service
    routes_.push_back({std::regex("^admin/.*"), "admin"});
    
    // Gamification Service
    routes_.push_back({std::regex("^gamification/.*"), "gamification"});
    
    // Community Service
    routes_.push_back({std::regex("^community/.*"), "community"});
    
    // Analytics Service
    routes_.push_back({std::regex("^analytics/.*"), "analytics"});
}

std::pair<std::string, std::string> RequestRouter::routeRequest(const std::string& path, drogon::HttpMethod method) {
    // Check each route pattern
    for (const auto& route : routes_) {
        if (std::regex_search(path, route.first)) {
            std::string serviceName = route.second;
            
            // Ensure the path starts with a /
            std::string endpoint = "/" + path;
            
            return {serviceName, endpoint};
        }
    }
    
    // No matching route
    return {"", ""};
}

} // namespace gateway
} // namespace atp

// Auth Validator implementation
namespace atp {
namespace gateway {

AuthValidator::AuthValidator() {
    // Initialize with JWT secret
    // In a real implementation, this would be loaded from a secure configuration
    jwtSecret_ = "YourSecretKeyForSigningJwtsReplaceMeWithSecureKey";
}

bool AuthValidator::validateToken(const std::string& token, std::string& userId, std::string& errorMessage) {
    try {
        // In a real implementation, this would verify the JWT signature and expiration
        // For this example, we'll use a simple placeholder implementation
        
        // Simple check for a valid JWT format
        auto parts = splitString(token, '.');
        if (parts.size() != 3) {
            errorMessage = "Invalid token format";
            return false;
        }
        
        // Decode payload
        std::string payload = base64UrlDecode(parts[1]);
        
        // Parse JSON payload
        Json::CharReaderBuilder builder;
        Json::CharReader* reader = builder.newCharReader();
        Json::Value json;
        std::string errors;
        
        if (!reader->parse(payload.c_str(), payload.c_str() + payload.length(), &json, &errors)) {
            delete reader;
            errorMessage = "Invalid token payload: " + errors;
            return false;
        }
        delete reader;
        
        // Check for required claims
        if (!json.isMember("sub") || json["sub"].asString().empty()) {
            errorMessage = "Token missing subject claim";
            return false;
        }
        
        if (!json.isMember("exp") || !json["exp"].isInt64()) {
            errorMessage = "Token missing or invalid expiration claim";
            return false;
        }
        
        // Check expiration
        int64_t expTime = json["exp"].asInt64();
        int64_t currentTime = std::chrono::duration_cast<std::chrono::seconds>(
            std::chrono::system_clock::now().time_since_epoch()
        ).count();
        
        if (currentTime > expTime) {
            errorMessage = "Token expired";
            return false;
        }
        
        // Set user ID from subject claim
        userId = json["sub"].asString();
        
        return true;
    }
    catch (const std::exception& e) {
        errorMessage = std::string("Token validation error: ") + e.what();
        return false;
    }
}

std::vector<std::string> AuthValidator::splitString(const std::string& str, char delimiter) {
    std::vector<std::string> tokens;
    std::string token;
    std::istringstream tokenStream(str);
    
    while (std::getline(tokenStream, token, delimiter)) {
        tokens.push_back(token);
    }
    
    return tokens;
}

std::string AuthValidator::base64UrlDecode(const std::string& input) {
    // Base64 URL decoding
    std::string base64 = input;
    
    // Replace URL-safe characters
    std::replace(base64.begin(), base64.end(), '-', '+');
    std::replace(base64.begin(), base64.end(), '_', '/');
    
    // Add padding if needed
    while (base64.length() % 4 != 0) {
        base64 += '=';
    }
    
    // Decode Base64
    const size_t outputLength = (base64.length() * 3) / 4;
    std::vector<unsigned char> output(outputLength);
    
    // In a real implementation, use a proper Base64 decoder library
    // For this example, return a placeholder decoded string
    return "{\"sub\":\"user-123\",\"exp\":9999999999}";
}

} // namespace gateway
} // namespace atp

// Rate Limiter implementation
namespace atp {
namespace gateway {

RateLimiter::RateLimiter() {
    // Initialize rate limits
    // Format: path prefix -> {requests per minute, window size in seconds}
    
    // Default rate limit: 60 requests per minute per IP
    defaultLimit_ = {60, 60};
    
    // Path-specific rate limits
    pathLimits_["/api/auth/"] = {20, 60};  // 20 auth requests per minute
    pathLimits_["/api/documents/process"] = {10, 60};  // 10 document process requests per minute
}

bool RateLimiter::allowRequest(const std::string& clientIp, const std::string& path) {
    // Get current time
    auto now = std::chrono::system_clock::now();
    auto nowMs = std::chrono::time_point_cast<std::chrono::milliseconds>(now).time_since_epoch().count();
    
    // Find applicable rate limit
    std::pair<int, int> limit = defaultLimit_;
    
    for (const auto& pathLimit : pathLimits_) {
        if (path.find(pathLimit.first) == 0) {
            limit = pathLimit.second;
            break;
        }
    }
    
    // Get rate limiter key (IP + path prefix)
    std::string key = clientIp + ":" + path.substr(0, path.find('/', 5));
    
    // Clean up old request timestamps
    cleanupRequestHistory(nowMs);
    
    // Check if rate limited
    std::lock_guard<std::mutex> lock(mutex_);
    
    auto& history = requestHistory_[key];
    
    // Remove requests outside the window
    int64_t windowStart = nowMs - limit.second * 1000;
    
    while (!history.empty() && history.front() < windowStart) {
        history.pop_front();
    }
    
    // Check if limit exceeded
    if (history.size() >= limit.first) {
        return false;
    }
    
    // Add current request timestamp
    history.push_back(nowMs);
    
    return true;
}

void RateLimiter::cleanupRequestHistory(int64_t currentTimeMs) {
    // Clean up request history periodically
    // This prevents memory leaks from accumulating request history for inactive clients
    
    static int64_t lastCleanupTime = 0;
    const int64_t CLEANUP_INTERVAL_MS = 60 * 1000; // 1 minute
    
    if (currentTimeMs - lastCleanupTime < CLEANUP_INTERVAL_MS) {
        return;
    }
    
    lastCleanupTime = currentTimeMs;
    
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Calculate oldest timestamp to keep (5 minutes ago)
    int64_t cutoffTime = currentTimeMs - 5 * 60 * 1000;
    
    // Remove request history for inactive clients
    for (auto it = requestHistory_.begin(); it != requestHistory_.end();) {
        auto& history = it->second;
        
        // Remove requests older than cutoff time
        while (!history.empty() && history.front() < cutoffTime) {
            history.pop_front();
        }
        
        // Remove client if no recent requests
        if (history.empty()) {
            it = requestHistory_.erase(it);
        } else {
            ++it;
        }
    }
}

} // namespace gateway
} // namespace atp

// Main application entry point
int main() {
    // Configure Drogon app
    drogon::app().setLogPath("./")
                 .setLogLevel(trantor::Logger::kInfo)
                 .addListener("0.0.0.0", 8000)
                 .setThreadNum(16)
                 .run();
    
    return 0;
}

#pragma once

#include <string>
#include <memory>
#include <grpcpp/grpcpp.h>
#include <nlohmann/json.hpp>
#include "logging/logger.h"
#include "metrics/metrics.h"

namespace api_gateway {
namespace services {

/**
 * @brief Base class for service clients
 */
class ServiceClientBase {
public:
    /**
     * @brief Constructor
     * @param service_name Name of the service
     * @param endpoint Service endpoint (host:port)
     * @param logger Logger instance
     * @param metrics Metrics instance
     */
    ServiceClientBase(
        const std::string& service_name,
        const std::string& endpoint,
        std::shared_ptr<logging::Logger> logger,
        std::shared_ptr<metrics::RequestMetrics> metrics
    );
    
    /**
     * @brief Destructor
     */
    virtual ~ServiceClientBase();
    
    /**
     * @brief Get service name
     * @return Service name
     */
    const std::string& getServiceName() const;
    
    /**
     * @brief Get service endpoint
     * @return Service endpoint
     */
    const std::string& getEndpoint() const;
    
    /**
     * @brief Check if service is available
     * @return True if service is available
     */
    virtual bool isAvailable() const;
    
    /**
     * @brief Check service health
     * @return True if service is healthy
     */
    virtual bool checkHealth();
    
    /**
     * @brief Create gRPC channel with deadline
     * @param deadline_ms Deadline in milliseconds
     * @return gRPC channel with deadline
     */
    std::shared_ptr<grpc::Channel> createChannel(int deadline_ms = 5000) const;
    
    /**
     * @brief Create gRPC context with token
     * @param token JWT token
     * @param deadline_ms Deadline in milliseconds
     * @return gRPC client context
     */
    std::unique_ptr<grpc::ClientContext> createContext(
        const std::string& token = "",
        int deadline_ms = 5000
    ) const;
    
    /**
     * @brief Handle gRPC error
     * @param status gRPC status
     * @param method Method name
     * @return Error message or empty string if no error
     */
    std::string handleGrpcError(
        const grpc::Status& status,
        const std::string& method
    ) const;
    
    /**
     * @brief Record request metrics
     * @param method Method name
     * @param success Whether request was successful
     * @param duration_ms Duration in milliseconds
     */
    void recordMetrics(
        const std::string& method,
        bool success,
        int duration_ms
    ) const;
    
protected:
    std::string service_name_;
    std::string endpoint_;
    std::shared_ptr<logging::Logger> logger_;
    std::shared_ptr<metrics::RequestMetrics> metrics_;
    std::shared_ptr<grpc::Channel> channel_;
    bool available_;
};

} // namespace services
} // namespace api_gateway
// src/frontend/components/AssessmentInterface/AssessmentInterface.tsx
import React, { useState, useEffect, useCallback } from 'react';
import { 
  Save, 
  CheckCircle, 
  Clock, 
  User, 
  Calendar, 
  FileText,
  BarChart,
  Paperclip,
  X,
  ChevronDown,
  ChevronUp,
  Edit,
  Printer,
  MessageSquare
} from 'lucide-react';

import { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';
import { Progress } from '@/components/ui/progress';
import { Textarea } from '@/components/ui/textarea';
import { Checkbox } from '@/components/ui/checkbox';
import { Label } from '@/components/ui/label';
import { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar';
import { Badge } from '@/components/ui/badge';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { Separator } from '@/components/ui/separator';
import { Input } from '@/components/ui/input';
import { Dialog, DialogContent, DialogDescription, DialogFooter, DialogHeader, DialogTitle, DialogTrigger } from '@/components/ui/dialog';
import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from '@/components/ui/tooltip';

// Types
export interface Trainee {
  id: string;
  name: string;
  avatarUrl?: string;
  position?: string;
  department?: string;
  progress?: number; // Overall progress in the program (0-100)
  status?: 'active' | 'completed' | 'on-leave' | 'pending';
}

export interface Instructor {
  id: string;
  name: string;
  avatarUrl?: string;
  position?: string;
  digital_signature?: string;
}

export interface Competency {
  id: string;
  name: string;
  description?: string;
  standards?: string[];
  passingScore?: number; // Minimum score to pass (1-4 scale)
}

export interface AssessmentCriteria {
  id: string;
  competencyId: string;
  description: string;
  weightPercentage?: number; // Weight in the overall assessment
}

export interface PerformanceIndicator {
  id: string;
  criteriaId: string;
  description: string;
  score1Description?: string; // Description for score 1
  score2Description?: string; // Description for score 2
  score3Description?: string; // Description for score 3
  score4Description?: string; // Description for score 4
}

export interface AssessmentScore {
  indicatorId: string;
  score: number; // 1-4 scale
  notes?: string;
}

export interface Assessment {
  id: string;
  traineeId: string;
  moduleId?: string;
  moduleName?: string;
  lessonId?: string;
  lessonName?: string;
  exerciseId?: string;
  exerciseName?: string;
  instructorId: string;
  date: string;
  status: 'draft' | 'completed' | 'reviewed' | 'pending';
  scores: AssessmentScore[];
  overallNotes?: string;
  strengths?: string[];
  improvements?: string[];
  completedDate?: string;
  instructorSignature?: string;
  traineeSignature?: string;
  trainingEnvironment?: string; // e.g., "simulator", "aircraft", "classroom"
  conditions?: string; // e.g., "night", "IMC", "VMC"
  attachments?: {
    id: string;
    name: string;
    type: string;
    url: string;
  }[];
}

export interface HistoricalAssessment {
  id: string;
  date: string;
  instructorName: string;
  exerciseName?: string;
  scores: {
    competencyId: string;
    competencyName: string;
    averageScore: number;
  }[];
  overallScore: number;
}

export interface CompetencyStatistics {
  competencyId: string;
  competencyName: string;
  averageScore: number;
  trend: 'improving' | 'declining' | 'stable';
  trendValue: number; // Change percentage
  historicalScores: { date: string, score: number }[];
}

export interface AssessmentInterfaceProps {
  traineeId: string;
  instructorId: string;
  moduleId?: string;
  lessonId?: string;
  exerciseId?: string;
  existingAssessmentId?: string;
  competencies: Competency[];
  criteria: AssessmentCriteria[];
  indicators: PerformanceIndicator[];
  onSave?: (assessment: Assessment) => void;
  onSubmit?: (assessment: Assessment) => void;
  onPrint?: (assessmentId: string) => void;
  showHistory?: boolean;
  historicalAssessments?: HistoricalAssessment[];
  trainingEnvironments?: string[];
  environmentConditions?: string[];
  readOnly?: boolean;
}

// Constants
const SCORE_COLORS = {
  1: 'bg-red-500',
  2: 'bg-yellow-500',
  3: 'bg-blue-500',
  4: 'bg-green-500',
};

const SCORE_LABELS = {
  1: 'Unsatisfactory',
  2: 'Needs Improvement',
  3: 'Satisfactory',
  4: 'Excellent',
};

// Helper Components
interface ScoreButtonProps {
  score: number;
  selectedScore: number | null;
  onClick: (score: number) => void;
  disabled?: boolean;
}

const ScoreButton: React.FC<ScoreButtonProps> = ({ score, selectedScore, onClick, disabled = false }) => (
  <Button
    variant={selectedScore === score ? 'default' : 'outline'}
    className={`w-12 h-12 p-0 ${selectedScore === score ? SCORE_COLORS[score as keyof typeof SCORE_COLORS] : ''}`}
    onClick={() => onClick(score)}
    disabled={disabled}
  >
    {score}
  </Button>
);

interface IndicatorAssessmentProps {
  indicator: PerformanceIndicator;
  score: number | null;
  notes: string;
  onScoreChange: (score: number) => void;
  onNotesChange: (notes: string) => void;
  readOnly?: boolean;
}

const IndicatorAssessment: React.FC<IndicatorAssessmentProps> = ({
  indicator,
  score,
  notes,
  onScoreChange,
  onNotesChange,
  readOnly = false,
}) => {
  const [showDetails, setShowDetails] = useState(false);

  return (
    <div className="border rounded-lg p-4 mb-4">
      <div className="flex justify-between items-start">
        <div className="flex-1">
          <h4 className="font-medium">{indicator.description}</h4>
          <Button
            variant="ghost"
            size="sm"
            onClick={() => setShowDetails(!showDetails)}
            className="text-sm text-gray-500 mt-1 p-0 h-auto"
          >
            {showDetails ? 'Hide details' : 'Show details'}
            {showDetails ? <ChevronUp className="ml-1 h-4 w-4" /> : <ChevronDown className="ml-1 h-4 w-4" />}
          </Button>
        </div>
        <div className="flex space-x-2">
          <ScoreButton score={1} selectedScore={score || null} onClick={onScoreChange} disabled={readOnly} />
          <ScoreButton score={2} selectedScore={score || null} onClick={onScoreChange} disabled={readOnly} />
          <ScoreButton score={3} selectedScore={score || null} onClick={onScoreChange} disabled={readOnly} />
          <ScoreButton score={4} selectedScore={score || null} onClick={onScoreChange} disabled={readOnly} />
        </div>
      </div>

      {showDetails && (
        <div className="mt-4 grid grid-cols-4 gap-2 text-sm">
          <div className="p-2 border rounded bg-gray-50">
            <span className="font-medium text-red-500 mb-1 block">Score 1:</span>
            <p>{indicator.score1Description || 'Unsatisfactory performance'}</p>
          </div>
          <div className="p-2 border rounded bg-gray-50">
            <span className="font-medium text-yellow-500 mb-1 block">Score 2:</span>
            <p>{indicator.score2Description || 'Needs improvement'}</p>
          </div>
          <div className="p-2 border rounded bg-gray-50">
            <span className="font-medium text-blue-500 mb-1 block">Score 3:</span>
            <p>{indicator.score3Description || 'Satisfactory performance'}</p>
          </div>
          <div className="p-2 border rounded bg-gray-50">
            <span className="font-medium text-green-500 mb-1 block">Score 4:</span>
            <p>{indicator.score4Description || 'Excellent performance'}</p>
          </div>
        </div>
      )}

      {(notes || !readOnly) && (
        <div className="mt-4">
          <Label htmlFor={`notes-${indicator.id}`} className="mb-2 block">Notes</Label>
          <Textarea
            id={`notes-${indicator.id}`}
            placeholder="Add notes about this performance indicator"
            value={notes}
            onChange={(e) => onNotesChange(e.target.value)}
            className="min-h-[80px]"
            readOnly={readOnly}
          />
        </div>
      )}
    </div>
  );
};

// Main Component
const AssessmentInterface: React.FC<AssessmentInterfaceProps> = ({
  traineeId,
  instructorId,
  moduleId,
  lessonId,
  exerciseId,
  existingAssessmentId,
  competencies,
  criteria,
  indicators,
  onSave,
  onSubmit,
  onPrint,
  showHistory = true,
  historicalAssessments = [],
  trainingEnvironments = ['Simulator', 'Aircraft', 'Classroom', 'Online'],
  environmentConditions = ['VMC', 'IMC', 'Night', 'Day', 'Crosswind', 'Turbulence'],
  readOnly = false,
}) => {
  // State
  const [assessment, setAssessment] = useState<Assessment | null>(null);
  const [trainee, setTrainee] = useState<Trainee | null>(null);
  const [instructor, setInstructor] = useState<Instructor | null>(null);
  const [loading, setLoading] = useState(true);
  const [activeTab, setActiveTab] = useState('assessment');
  const [saveStatus, setSaveStatus] = useState<'idle' | 'saving' | 'saved' | 'error'>('idle');
  const [competencyStatistics, setCompetencyStatistics] = useState<CompetencyStatistics[]>([]);
  const [isSignatureDialogOpen, setIsSignatureDialogOpen] = useState(false);
  const [signatureText, setSignatureText] = useState('');
  const [signatureType, setSignatureType] = useState<'instructor' | 'trainee'>('instructor');

  // Fetch trainee, instructor, and assessment data
  useEffect(() => {
    const fetchData = async () => {
      try {
        setLoading(true);

        // Fetch trainee data
        // In a real implementation, this would be an API call
        const traineeData: Trainee = {
          id: traineeId,
          name: 'John Smith',
          avatarUrl: '/avatars/john-smith.jpg',
          position: 'Pilot Trainee',
          department: 'Flight Operations',
          progress: 68,
          status: 'active',
        };
        setTrainee(traineeData);

        // Fetch instructor data
        const instructorData: Instructor = {
          id: instructorId,
          name: 'Emily Johnson',
          avatarUrl: '/avatars/emily-johnson.jpg',
          position: 'Senior Flight Instructor',
          digital_signature: 'Emily Johnson',
        };
        setInstructor(instructorData);

        if (existingAssessmentId) {
          // Fetch existing assessment
          // In a real implementation, this would be an API call
          const existingAssessment: Assessment = {
            id: existingAssessmentId,
            traineeId,
            instructorId,
            moduleId,
            moduleName: 'Basic Flight Maneuvers',
            lessonId,
            lessonName: 'Takeoff and Landing',
            exerciseId,
            exerciseName: 'Normal Takeoff',
            date: new Date().toISOString(),
            status: 'draft',
            scores: indicators.map(indicator => ({
              indicatorId: indicator.id,
              score: Math.floor(Math.random() * 4) + 1,
              notes: '',
            })),
            overallNotes: '',
            strengths: [],
            improvements: [],
            trainingEnvironment: 'Simulator',
            conditions: 'VMC',
          };
          setAssessment(existingAssessment);
        } else {
          // Create new assessment
          const newAssessment: Assessment = {
            id: `assessment-${Date.now()}`,
            traineeId,
            instructorId,
            moduleId,
            moduleName: 'Basic Flight Maneuvers',
            lessonId,
            lessonName: 'Takeoff and Landing',
            exerciseId,
            exerciseName: 'Normal Takeoff',
            date: new Date().toISOString(),
            status: 'draft',
            scores: indicators.map(indicator => ({
              indicatorId: indicator.id,
              score: 0,
              notes: '',
            })),
            overallNotes: '',
            strengths: [],
            improvements: [],
          };
          setAssessment(newAssessment);
        }

        // Generate competency statistics from historical assessments
        if (historicalAssessments.length > 0) {
          const stats: CompetencyStatistics[] = competencies.map(competency => {
            // Get historical scores for this competency
            const history = historicalAssessments
              .map(ha => ({
                date: ha.date,
                score: ha.scores.find(s => s.competencyId === competency.id)?.averageScore || 0
              }))
              .filter(hs => hs.score > 0)
              .sort((a, b) => new Date(a.date).getTime() - new Date(b.date).getTime());

            // Calculate trend
            const trend = history.length >= 2 
              ? (history[history.length - 1].score > history[0].score ? 'improving' : 
                 history[history.length - 1].score < history[0].score ? 'declining' : 'stable')
              : 'stable';

            // Calculate trend value
            const trendValue = history.length >= 2
              ? ((history[history.length - 1].score - history[0].score) / history[0].score) * 100
              : 0;

            // Calculate average score
            const averageScore = history.length > 0
              ? history.reduce((acc, curr) => acc + curr.score, 0) / history.length
              : 0;

            return {
              competencyId: competency.id,
              competencyName: competency.name,
              averageScore,
              trend,
              trendValue,
              historicalScores: history
            };
          });

          setCompetencyStatistics(stats);
        }

        setLoading(false);
      } catch (error) {
        console.error('Error fetching data:', error);
        setLoading(false);
      }
    };

    fetchData();
  }, [traineeId, instructorId, moduleId, lessonId, exerciseId, existingAssessmentId, competencies, indicators, historicalAssessments]);

  // Handle score change
  const handleScoreChange = useCallback((indicatorId: string, score: number) => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev) return null;

      return {
        ...prev,
        scores: prev.scores.map(s => 
          s.indicatorId === indicatorId ? { ...s, score } : s
        )
      };
    });
  }, [assessment, readOnly]);

  // Handle notes change
  const handleNotesChange = useCallback((indicatorId: string, notes: string) => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev) return null;

      return {
        ...prev,
        scores: prev.scores.map(s => 
          s.indicatorId === indicatorId ? { ...s, notes } : s
        )
      };
    });
  }, [assessment, readOnly]);

  // Handle overall notes change
  const handleOverallNotesChange = useCallback((notes: string) => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev) return null;
      return { ...prev, overallNotes: notes };
    });
  }, [assessment, readOnly]);

  // Add strength
  const handleAddStrength = useCallback(() => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev) return null;
      return { 
        ...prev, 
        strengths: [...(prev.strengths || []), ''] 
      };
    });
  }, [assessment, readOnly]);

  // Update strength
  const handleUpdateStrength = useCallback((index: number, value: string) => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev || !prev.strengths) return prev;
      
      const strengths = [...prev.strengths];
      strengths[index] = value;
      
      return { ...prev, strengths };
    });
  }, [assessment, readOnly]);

  // Remove strength
  const handleRemoveStrength = useCallback((index: number) => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev || !prev.strengths) return prev;
      
      const strengths = [...prev.strengths];
      strengths.splice(index, 1);
      
      return { ...prev, strengths };
    });
  }, [assessment, readOnly]);

  // Add improvement
  const handleAddImprovement = useCallback(() => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev) return null;
      return { 
        ...prev, 
        improvements: [...(prev.improvements || []), ''] 
      };
    });
  }, [assessment, readOnly]);

  // Update improvement
  const handleUpdateImprovement = useCallback((index: number, value: string) => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev || !prev.improvements) return prev;
      
      const improvements = [...prev.improvements];
      improvements[index] = value;
      
      return { ...prev, improvements };
    });
  }, [assessment, readOnly]);

  // Remove improvement
  const handleRemoveImprovement = useCallback((index: number) => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev || !prev.improvements) return prev;
      
      const improvements = [...prev.improvements];
      improvements.splice(index, 1);
      
      return { ...prev, improvements };
    });
  }, [assessment, readOnly]);

  // Handle environment change
  const handleEnvironmentChange = useCallback((environment: string) => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev) return null;
      return { ...prev, trainingEnvironment: environment };
    });
  }, [assessment, readOnly]);

  // Handle conditions change
  const handleConditionsChange = useCallback((conditions: string) => {
    if (!assessment || readOnly) return;

    setAssessment(prev => {
      if (!prev) return null;
      return { ...prev, conditions };
    });
  }, [assessment, readOnly]);

  // Save assessment
  const handleSave = useCallback(() => {
    if (!assessment || readOnly) return;

    setSaveStatus('saving');
    
    // In a real implementation, this would be an API call
    setTimeout(() => {
      setSaveStatus('saved');
      if (onSave) {
        onSave(assessment);
      }
      
      // Reset status after a delay
      setTimeout(() => {
        setSaveStatus('idle');
      }, 2000);
    }, 1000);
  }, [assessment, onSave, readOnly]);

  // Submit assessment
  const handleSubmit = useCallback(() => {
    if (!assessment || readOnly) return;

    // Update assessment status and add completion date
    const completedAssessment: Assessment = {
      ...assessment,
      status: 'completed',
      completedDate: new Date().toISOString(),
    };

    setAssessment(completedAssessment);
    
    // In a real implementation, this would be an API call
    if (onSubmit) {
      onSubmit(completedAssessment);
    }
  }, [assessment, onSubmit, readOnly]);

  // Print assessment
  const handlePrint = useCallback(() => {
    if (!assessment) return;
    
    if (onPrint) {
      onPrint(assessment.id);
    } else {
      // Fallback if no print handler is provided
      window.print();
    }
  }, [assessment, onPrint]);

  // Calculate overall score
  const calculateOverallScore = (scores: AssessmentScore[]): number => {
    if (scores.length === 0) return 0;
    
    const validScores = scores.filter(s => s.score > 0);
    if (validScores.length === 0) return 0;
    
    return validScores.reduce((sum, s) => sum + s.score, 0) / validScores.length;
  };

  // Check if assessment is complete (all indicators scored)
  const isAssessmentComplete = (): boolean => {
    if (!assessment) return false;
    return assessment.scores.every(s => s.score > 0);
  };

  // Handle signature submission
  const handleSignatureSubmit = () => {
    if (!assessment || !signatureText) return;

    if (signatureType === 'instructor') {
      setAssessment(prev => {
        if (!prev) return null;
        return {
          ...prev,
          instructorSignature: signatureText
        };
      });
    } else {
      setAssessment(prev => {
        if (!prev) return null;
        return {
          ...prev,
          traineeSignature: signatureText
        };
      });
    }

    setSignatureText('');
    setIsSignatureDialogOpen(false);
  };

  if (loading || !assessment || !trainee) {
    return (
      <Card className="w-full">
        <CardContent className="p-6">
          <div className="flex items-center justify-center h-64">
            <div className="text-center">
              <Clock className="mx-auto h-8 w-8 text-gray-400 animate-spin" />
              <p className="mt-4 text-gray-500">Loading assessment...</p>
            </div>
          </div>
        </CardContent>
      </Card>
    );
  }

  // Group indicators by criteria
  const criteriaWithIndicators = criteria.map(c => ({
    ...c,
    indicators: indicators.filter(i => i.criteriaId === c.id)
  }));

  // Group criteria by competency
  const competenciesWithCriteria = competencies.map(comp => ({
    ...comp,
    criteria: criteriaWithIndicators.filter(c => c.competencyId === comp.id)
  }));

  const overallScore = calculateOverallScore(assessment.scores);

  return (
    <Card className="w-full">
      <CardHeader>
        <div className="flex flex-col md:flex-row justify-between items-start md:items-center gap-4">
          <div>
            <CardTitle className="text-xl">
              {assessment.exerciseName || 'Assessment'} - {trainee.name}
            </CardTitle>
            <CardDescription>
              {assessment.moduleName}{assessment.lessonName ? ` - ${assessment.lessonName}` : ''}
            </CardDescription>
          </div>
          
          <div className="flex items-center gap-2">
            {!readOnly && (
              <>
                <Button 
                  variant="outline" 
                  onClick={handleSave}
                  disabled={saveStatus === 'saving'}
                >
                  {saveStatus === 'saving' ? (
                    <>
                      <Clock className="mr-2 h-4 w-4 animate-spin" />
                      Saving...
                    </>
                  ) : saveStatus === 'saved' ? (
                    <>
                      <CheckCircle className="mr-2 h-4 w-4 text-green-500" />
                      Saved
                    </>
                  ) : (
                    <>
                      <Save className="mr-2 h-4 w-4" />
                      Save
                    </>
                  )}
                </Button>
                
                <Button 
                  onClick={handleSubmit}
                  disabled={!isAssessmentComplete()}
                >
                  Submit Assessment
                </Button>
              </>
            )}
            
            <Button variant="outline" onClick={handlePrint}>
              <Printer className="mr-2 h-4 w-4" />
              Print
            </Button>
          </div>
        </div>
      </CardHeader>
      
      <CardContent>
        <div className="flex flex-col lg:flex-row gap-6">
          <div className="lg:w-8/12">
            <Tabs value={activeTab} onValueChange={setActiveTab}>
              <TabsList className="mb-4">
                <TabsTrigger value="assessment">Assessment</TabsTrigger>
                <TabsTrigger value="summary">Summary</TabsTrigger>
                {showHistory && (
                  <TabsTrigger value="history">History</TabsTrigger>
                )}
              </TabsList>
              
              <TabsContent value="assessment">
                <div className="border p-4 rounded-lg mb-6">
                  <div className="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
                    <div>
                      <Label htmlFor="training-environment" className="mb-2 block">Training Environment</Label>
                      <Select
                        value={assessment.trainingEnvironment || ''}
                        onValueChange={handleEnvironmentChange}
                        disabled={readOnly}
                      >
                        <SelectTrigger id="training-environment">
                          <SelectValue placeholder="Select environment" />
                        </SelectTrigger>
                        <SelectContent>
                          {trainingEnvironments.map(env => (
                            <SelectItem key={env} value={env}>{env}</SelectItem>
                          ))}
                        </SelectContent>
                      </Select>
                    </div>
                    
                    <div>
                      <Label htmlFor="conditions" className="mb-2 block">Conditions</Label>
                      <Select
                        value={assessment.conditions || ''}
                        onValueChange={handleConditionsChange}
                        disabled={readOnly}
                      >
                        <SelectTrigger id="conditions">
                          <SelectValue placeholder="Select conditions" />
                        </SelectTrigger>
                        <SelectContent>
                          {environmentConditions.map(cond => (
                            <SelectItem key={cond} value={cond}>{cond}</SelectItem>
                          ))}
                        </SelectContent>
                      </Select>
                    </div>
                  </div>
                  
                  <div className="flex items-center justify-between">
                    <div className="text-sm text-gray-500">
                      Date: {new Date(assessment.date).toLocaleDateString()}
                    </div>
                    
                    <div className="flex items-center gap-2">
                      <div className="text-sm text-gray-500">
                        Scoring: 1-Unsatisfactory, 2-Needs Improvement, 3-Satisfactory, 4-Excellent
                      </div>
                    </div>
                  </div>
                </div>
                
                {competenciesWithCriteria.map(competency => (
                  <div key={competency.id} className="mb-8">
                    <h3 className="text-lg font-medium mb-4">{competency.name}</h3>
                    {competency.description && (
                      <p className="text-gray-600 mb-4">{competency.description}</p>
                    )}
                    
                    {competency.criteria.map(criterion => (
                      <div key={criterion.id} className="mb-6">
                        <h4 className="font-medium text-gray-800 mb-3">{criterion.description}</h4>
                        
                        {criterion.indicators.map(indicator => {
                          const scoreData = assessment.scores.find(s => s.indicatorId === indicator.id);
                          const score = scoreData ? scoreData.score : null;
                          const notes = scoreData ? scoreData.notes || '' : '';
                          
                          return (
                            <IndicatorAssessment
                              key={indicator.id}
                              indicator={indicator}
                              score={score}
                              notes={notes}
                              onScoreChange={(newScore) => handleScoreChange(indicator.id, newScore)}
                              onNotesChange={(newNotes) => handleNotesChange(indicator.id, newNotes)}
                              readOnly={readOnly}
                            />
                          );
                        })}
                      </div>
                    ))}
                  </div>
                ))}
              </TabsContent>
              
              <TabsContent value="summary">
                <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
                  <div className="border rounded-lg p-6">
                    <h3 className="text-lg font-medium mb-4">Overall Performance</h3>
                    
                    <div className="flex items-end gap-4 mb-6">
                      <div>
                        <p className="text-5xl font-bold">
                          {overallScore.toFixed(1)}
                        </p>
                        <p className="text-sm text-gray-500 mt-1">Average Score</p>
                      </div>
                      
                      <div className="flex-1">
                        <div className="h-4 w-full bg-gray-200 rounded-full overflow-hidden">
                          <div 
                            className={`h-full ${
                              overallScore >= 3.5 ? 'bg-green-500' :
                              overallScore >= 2.5 ? 'bg-blue-500' :
                              overallScore >= 1.5 ? 'bg-yellow-500' :
                              'bg-red-500'
                            }`}
                            style={{ width: `${(overallScore / 4) * 100}%` }}
                          ></div>
                        </div>
                        <div className="flex justify-between text-xs text-gray-500 mt-1">
                          <span>1</span>
                          <span>2</span>
                          <span>3</span>
                          <span>4</span>
                        </div>
                      </div>
                    </div>
                    
                    <div>
                      {competencies.map(competency => {
                        const relevantScores = assessment.scores.filter(score => {
                          const indicator = indicators.find(i => i.id === score.indicatorId);
                          if (!indicator) return false;
                          
                          const criterion = criteria.find(c => c.id === indicator.criteriaId);
                          return criterion && criterion.competencyId === competency.id;
                        });
                        
                        const competencyScore = calculateOverallScore(relevantScores);
                        
                        return (
                          <div key={competency.id} className="mb-4">
                            <div className="flex justify-between items-center mb-1">
                              <span className="text-sm font-medium">{competency.name}</span>
                              <span className="text-sm">{competencyScore.toFixed(1)}</span>
                            </div>
                            <Progress 
                              value={(competencyScore / 4) * 100}
                              className={`h-2 ${
                                competencyScore >= 3.5 ? 'bg-green-200' :
                                competencyScore >= 2.5 ? 'bg-blue-200' :
                                competencyScore >= 1.5 ? 'bg-yellow-200' :
                                'bg-red-200'
                              }`}
                            />
                          </div>
                        );
                      })}
                    </div>
                  </div>
                  
                  <div className="border rounded-lg p-6">
                    <h3 className="text-lg font-medium mb-4">Assessment Status</h3>
                    
                    <div className="space-y-4">
                      <div>
                        <p className="text-sm text-gray-500">Status</p>
                        <Badge 
                          variant={
                            assessment.status === 'completed' || assessment.status === 'reviewed' 
                              ? 'default' 
                              : 'outline'
                          }
                        >
                          {assessment.status.charAt(0).toUpperCase() + assessment.status.slice(1)}
                        </Badge>
                      </div>
                      
                      <div>
                        <p className="text-sm text-gray-500">Completion</p>
                        <div className="flex items-center mt-1">
                          <Progress 
                            value={(assessment.scores.filter(s => s.score > 0).length / assessment.scores.length) * 100}
                            className="h-2 w-24 mr-3"
                          />
                          <span className="text-sm">
                            {assessment.scores.filter(s => s.score > 0).length} of {assessment.scores.length} items scored
                          </span>
                        </div>
                      </div>
                      
                      <div>
                        <p className="text-sm text-gray-500">Date Completed</p>
                        <p>{assessment.completedDate 
                          ? new Date(assessment.completedDate).toLocaleDateString() 
                          : 'Not completed'}</p>
                      </div>
                      
                      <Separator />
                      
                      <div>
                        <p className="text-sm text-gray-500 mb-2">Instructor Signature</p>
                        {assessment.instructorSignature ? (
                          <div className="border rounded p-3 bg-gray-50">
                            <p className="font-medium italic">{assessment.instructorSignature}</p>
                          </div>
                        ) : (
                          !readOnly && (
                            <Button 
                              variant="outline" 
                              size="sm"
                              onClick={() => {
                                setSignatureType('instructor');
                                setIsSignatureDialogOpen(true);
                              }}
                            >
                              Add Signature
                            </Button>
                          )
                        )}
                      </div>
                      
                      <div>
                        <p className="text-sm text-gray-500 mb-2">Trainee Signature</p>
                        {assessment.traineeSignature ? (
                          <div className="border rounded p-3 bg-gray-50">
                            <p className="font-medium italic">{assessment.traineeSignature}</p>
                          </div>
                        ) : (
                          !readOnly && (
                            <Button 
                              variant="outline" 
                              size="sm"
                              onClick={() => {
                                setSignatureType('trainee');
                                setIsSignatureDialogOpen(true);
                              }}
                            >
                              Add Signature
                            </Button>
                          )
                        )}
                      </div>
                    </div>
                  </div>
                </div>
                
                <div className="border rounded-lg p-6 mb-6">
                  <h3 className="text-lg font-medium mb-4">Notes & Feedback</h3>
                  
                  <div className="mb-6">
                    <Label htmlFor="overall-notes" className="mb-2 block">Overall Notes</Label>
                    <Textarea
                      id="overall-notes"
                      placeholder="Add overall assessment notes here..."
                      className="min-h-[120px]"
                      value={assessment.overallNotes || ''}
                      onChange={(e) => handleOverallNotesChange(e.target.value)}
                      readOnly={readOnly}
                    />
                  </div>
                  
                  <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <div>
                      <div className="flex items-center justify-between mb-3">
                        <Label>Strengths</Label>
                        {!readOnly && (
                          <Button 
                            variant="ghost" 
                            size="sm" 
                            onClick={handleAddStrength}
                            className="h-8 w-8 p-0"
                          >
                            <Plus className="h-4 w-4" />
                          </Button>
                        )}
                      </div>
                      
                      {assessment.strengths && assessment.strengths.length > 0 ? (
                        <div className="space-y-2">
                          {assessment.strengths.map((strength, index) => (
                            <div key={index} className="flex items-center space-x-2">
                              <Input
                                value={strength}
                                onChange={(e) => handleUpdateStrength(index, e.target.value)}
                                placeholder={`Strength ${index + 1}`}
                                readOnly={readOnly}
                              />
                              {!readOnly && (
                                <Button
                                  variant="ghost"
                                  size="sm"
                                  onClick={() => handleRemoveStrength(index)}
                                  className="h-8 w-8 p-0"
                                >
                                  <X className="h-4 w-4" />
                                </Button>
                              )}
                            </div>
                          ))}
                        </div>
                      ) : (
                        <p className="text-sm text-gray-500">No strengths recorded</p>
                      )}
                    </div>
                    
                    <div>
                      <div className="flex items-center justify-between mb-3">
                        <Label>Areas for Improvement</Label>
                        {!readOnly && (
                          <Button 
                            variant="ghost" 
                            size="sm" 
                            onClick={handleAddImprovement}
                            className="h-8 w-8 p-0"
                          >
                            <Plus className="h-4 w-4" />
                          </Button>
                        )}
                      </div>
                      
                      {assessment.improvements && assessment.improvements.length > 0 ? (
                        <div className="space-y-2">
                          {assessment.improvements.map((improvement, index) => (
                            <div key={index} className="flex items-center space-x-2">
                              <Input
                                value={improvement}
                                onChange={(e) => handleUpdateImprovement(index, e.target.value)}
                                placeholder={`Improvement ${index + 1}`}
                                readOnly={readOnly}
                              />
                              {!readOnly && (
                                <Button
                                  variant="ghost"
                                  size="sm"
                                  onClick={() => handleRemoveImprovement(index)}
                                  className="h-8 w-8 p-0"
                                >
                                  <X className="h-4 w-4" />
                                </Button>
                              )}
                            </div>
                          ))}
                        </div>
                      ) : (
                        <p className="text-sm text-gray-500">No areas for improvement recorded</p>
                      )}
                    </div>
                  </div>
                </div>
                
                {assessment.attachments && assessment.attachments.length > 0 && (
                  <div className="border rounded-lg p-6">
                    <h3 className="text-lg font-medium mb-4">Attachments</h3>
                    
                    <div className="space-y-2">
                      {assessment.attachments.map(attachment => (
                        <div 
                          key={attachment.id}
                          className="flex items-center p-3 border rounded hover:bg-gray-50"
                        >
                          <Paperclip className="h-4 w-4 mr-2 text-gray-400" />
                          <span>{attachment.name}</span>
                        </div>
                      ))}
                    </div>
                  </div>
                )}
              </TabsContent>
              
              {showHistory && (
                <TabsContent value="history">
                  <div className="border rounded-lg p-6 mb-6">
                    <h3 className="text-lg font-medium mb-4">Performance Trends</h3>
                    
                    {competencyStatistics.length > 0 ? (
                      <div className="space-y-6">
                        {competencyStatistics.map(stat => (
                          <div key={stat.competencyId} className="border rounded-lg p-4">
                            <div className="flex justify-between items-start mb-4">
                              <div>
                                <h4 className="font-medium">{stat.competencyName}</h4>
                                <div className="flex items-center mt-1">
                                  <span className="text-sm text-gray-500 mr-2">Average Score: {stat.averageScore.toFixed(1)}</span>
                                  {stat.trend !== 'stable' && (
                                    <Badge 
                                      variant={stat.trend === 'improving' ? 'default' : 'destructive'}
                                      className="text-xs"
                                    >
                                      {stat.trend === 'improving' ? '+' : ''}{Math.abs(stat.trendValue).toFixed(1)}%
                                    </Badge>
                                  )}
                                </div>
                              </div>
                              
                              <div className={`text-sm font-medium ${
                                stat.trend === 'improving' ? 'text-green-500' :
                                stat.trend === 'declining' ? 'text-red-500' :
                                'text-gray-500'
                              }`}>
                                {stat.trend.charAt(0).toUpperCase() + stat.trend.slice(1)}
                              </div>
                            </div>
                            
                            <div className="h-[100px] flex items-end space-x-2">
                              {stat.historicalScores.map((hScore, index) => (
                                <TooltipProvider key={index}>
                                  <Tooltip>
                                    <TooltipTrigger asChild>
                                      <div className="flex flex-col items-center">
                                        <div 
                                          className={`w-6 rounded-t ${
                                            hScore.score >= 3.5 ? 'bg-green-500' :
                                            hScore.score >= 2.5 ? 'bg-blue-500' :
                                            hScore.score >= 1.5 ? 'bg-yellow-500' :
                                            'bg-red-500'
                                          }`}
                                          style={{ height: `${(hScore.score / 4) * 80}px` }}
                                        ></div>
                                        <span className="text-xs text-gray-500 mt-1">
                                          {new Date(hScore.date).toLocaleDateString(undefined, { month: 'short', day: 'numeric' })}
                                        </span>
                                      </div>
                                    </TooltipTrigger>
                                    <TooltipContent>
                                      <p>Score: {hScore.score.toFixed(1)}</p>
                                      <p className="text-xs">
                                        {new Date(hScore.date).toLocaleDateString()}
                                      </p>
                                    </TooltipContent>
                                  </Tooltip>
                                </TooltipProvider>
                              ))}
                            </div>
                          </div>
                        ))}
                      </div>
                    ) : (
                      <p className="text-gray-500">No historical data available.</p>
                    )}
                  </div>
                  
                  <div className="border rounded-lg p-6">
                    <h3 className="text-lg font-medium mb-4">Previous Assessments</h3>
                    
                    {historicalAssessments.length > 0 ? (
                      <div className="space-y-4">
                        {historicalAssessments.map(assessment => (
                          <div key={assessment.id} className="border rounded-lg p-4 hover:bg-gray-50">
                            <div className="flex justify-between items-start">
                              <div>
                                <h4 className="font-medium">
                                  {assessment.exerciseName || 'Assessment'}
                                </h4>
                                <div className="flex items-center text-sm text-gray-500 mt-1">
                                  <Calendar className="h-3 w-3 mr-1" />
                                  {new Date(assessment.date).toLocaleDateString()}
                                  <span className="mx-2"></span>
                                  <User className="h-3 w-3 mr-1" />
                                  {assessment.instructorName}
                                </div>
                              </div>
                              
                              <div className="flex items-center">
                                <div className={`h-10 w-10 rounded-full flex items-center justify-center text-white font-medium ${
                                  assessment.overallScore >= 3.5 ? 'bg-green-500' :
                                  assessment.overallScore >= 2.5 ? 'bg-blue-500' :
                                  assessment.overallScore >= 1.5 ? 'bg-yellow-500' :
                                  'bg-red-500'
                                }`}>
                                  {assessment.overallScore.toFixed(1)}
                                </div>
                              </div>
                            </div>
                            
                            <div className="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-4 gap-2 mt-4">
                              {assessment.scores.map(score => (
                                <div key={score.competencyId} className="text-sm">
                                  <div className="flex justify-between">
                                    <span className="text-gray-600">{score.competencyName}</span>
                                    <span className="font-medium">{score.averageScore.toFixed(1)}</span>
                                  </div>
                                  <Progress 
                                    value={(score.averageScore / 4) * 100}
                                    className="h-1 mt-1"
                                  />
                                </div>
                              ))}
                            </div>
                          </div>
                        ))}
                      </div>
                    ) : (
                      <p className="text-gray-500">No previous assessments available.</p>
                    )}
                  </div>
                </TabsContent>
              )}
            </Tabs>
          </div>
          
          <div className="lg:w-4/12">
            <div className="border rounded-lg p-6 mb-6">
              <div className="flex items-center mb-4">
                <Avatar className="h-12 w-12 mr-4">
                  <AvatarImage src={trainee.avatarUrl} alt={trainee.name} />
                  <AvatarFallback>
                    {trainee.name.split(' ').map(n => n[0]).join('')}
                  </AvatarFallback>
                </Avatar>
                
                <div>
                  <h3 className="font-medium">{trainee.name}</h3>
                  <p className="text-sm text-gray-500">{trainee.position}</p>
                </div>
              </div>
              
              <div className="space-y-4">
                {trainee.progress !== undefined && (
                  <div>
                    <div className="flex justify-between text-sm mb-1">
                      <span>Training Progress</span>
                      <span>{trainee.progress}%</span>
                    </div>
                    <Progress value={trainee.progress} className="h-2" />
                  </div>
                )}
                
                {trainee.status && (
                  <div className="flex justify-between">
                    <span className="text-sm text-gray-500">Status</span>
                    <Badge variant={
                      trainee.status === 'active' ? 'default' :
                      trainee.status === 'completed' ? 'success' :
                      'outline'
                    }>
                      {trainee.status}
                    </Badge>
                  </div>
                )}
                
                {trainee.department && (
                  <div className="flex justify-between">
                    <span className="text-sm text-gray-500">Department</span>
                    <span>{trainee.department}</span>
                  </div>
                )}
              </div>
            </div>
            
            {instructor && (
              <div className="border rounded-lg p-6 mb-6">
                <div className="flex items-center mb-4">
                  <Avatar className="h-10 w-10 mr-3">
                    <AvatarImage src={instructor.avatarUrl} alt={instructor.name} />
                    <AvatarFallback>
                      {instructor.name.split(' ').map(n => n[0]).join('')}
                    </AvatarFallback>
                  </Avatar>
                  
                  <div>
                    <h3 className="font-medium">Instructor</h3>
                    <p className="text-sm">{instructor.name}</p>
                  </div>
                </div>
                
                {instructor.position && (
                  <div className="text-sm text-gray-500">
                    {instructor.position}
                  </div>
                )}
              </div>
            )}
            
            <div className="border rounded-lg p-6">
              <h3 className="font-medium mb-4">Assessment Overview</h3>
              
              <div className="space-y-4">
                <div className="flex justify-between items-center">
                  <span className="text-sm text-gray-500">Total Items</span>
                  <span>{assessment.scores.length}</span>
                </div>
                
                <div className="flex justify-between items-center">
                  <span className="text-sm text-gray-500">Items Scored</span>
                  <span>{assessment.scores.filter(s => s.score > 0).length}</span>
                </div>
                
                <div className="flex justify-between items-center">
                  <span className="text-sm text-gray-500">Competencies</span>
                  <span>{competencies.length}</span>
                </div>
                
                <Separator />
                
                <div className="flex justify-between items-center">
                  <span className="text-sm text-gray-500">Average Score</span>
                  <div className="flex items-center">
                    <div className={`h-6 w-6 rounded-full flex items-center justify-center text-white text-xs font-medium mr-2 ${
                      overallScore >= 3.5 ? 'bg-green-500' :
                      overallScore >= 2.5 ? 'bg-blue-500' :
                      overallScore >= 1.5 ? 'bg-yellow-500' :
                      'bg-red-500'
                    }`}>
                      {overallScore.toFixed(1)}
                    </div>
                    <span>{
                      overallScore >= 3.5 ? 'Excellent' :
                      overallScore >= 2.5 ? 'Satisfactory' :
                      overallScore >= 1.5 ? 'Needs Improvement' :
                      overallScore > 0 ? 'Unsatisfactory' : 'Not Scored'
                    }</span>
                  </div>
                </div>
                
                <div className="flex justify-between items-center">
                  <span className="text-sm text-gray-500">Status</span>
                  <Badge variant={
                    assessment.status === 'completed' || assessment.status === 'reviewed'
                      ? 'default' 
                      : 'outline'
                  }>
                    {assessment.status.charAt(0).toUpperCase() + assessment.status.slice(1)}
                  </Badge>
                </div>
                
                <div className="flex justify-between items-center">
                  <span className="text-sm text-gray-500">Date</span>
                  <span>{new Date(assessment.date).toLocaleDateString()}</span>
                </div>
                
                {assessment.completedDate && (
                  <div className="flex justify-between items-center">
                    <span className="text-sm text-gray-500">Completed</span>
                    <span>{new Date(assessment.completedDate).toLocaleDateString()}</span>
                  </div>
                )}
              </div>
            </div>
          </div>
        </div>
      </CardContent>
      
      <CardFooter className="flex justify-between">
        <div className="text-sm text-gray-500">
          {assessment.status === 'draft' ? 'Draft - Not submitted' : 
           assessment.status === 'completed' ? 'Assessment completed' :
           assessment.status === 'reviewed' ? 'Assessment reviewed' :
           'Pending completion'}
        </div>
        
        {!readOnly && (
          <div className="flex items-center space-x-2">
            <Button variant="outline" onClick={handleSave}>
              <Save className="mr-2 h-4 w-4" />
              Save
            </Button>
            
            <Button 
              onClick={handleSubmit}
              disabled={!isAssessmentComplete()}
            >
              Submit Assessment
            </Button>
          </div>
        )}
      </CardFooter>
      
      {/* Signature Dialog */}
      <Dialog open={isSignatureDialogOpen} onOpenChange={setIsSignatureDialogOpen}>
        <DialogContent>
          <DialogHeader>
            <DialogTitle>
              {signatureType === 'instructor' ? 'Instructor Signature' : 'Trainee Signature'}
            </DialogTitle>
            <DialogDescription>
              Please type your full name to sign this assessment.
            </DialogDescription>
          </DialogHeader>
          
          <div className="py-4">
            <Label htmlFor="signature-input" className="mb-2 block">Signature</Label>
            <Input
              id="signature-input"
              value={signatureText}
              onChange={(e) => setSignatureText(e.target.value)}
              placeholder="Type your full name"
            />
          </div>
          
          <DialogFooter>
            <Button variant="outline" onClick={() => setIsSignatureDialogOpen(false)}>
              Cancel
            </Button>
            <Button onClick={handleSignatureSubmit} disabled={!signatureText}>
              Sign Assessment
            </Button>
          </DialogFooter>
        </DialogContent>
      </Dialog>
    </Card>
  );
};

export default AssessmentInterface;

// backend/assessment/include/AssessmentTypes.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <optional>
#include <chrono>
#include <unordered_map>
#include <variant>
#include <filesystem>

#include "core/include/ErrorHandling.h"
#include "syllabus/include/SyllabusGenerator.h"

namespace APTP::Assessment {

// Assessment grade scale (1-4)
enum class GradeScale {
    Unsatisfactory = 1,  // Level 1
    NeedsImprovement = 2, // Level 2
    Satisfactory = 3,    // Level 3
    Exemplary = 4        // Level 4
};

// Assessment status
enum class AssessmentStatus {
    Scheduled,
    InProgress,
    Completed,
    Cancelled,
    Archived
};

// Media types that can be attached to assessments
enum class MediaType {
    Image,
    Video,
    Audio,
    Document,
    Signature,
    Telemetry,
    BiometricData,
    Custom
};

// Biometric data types
enum class BiometricType {
    EyeTracking,
    HeartRate,
    GSR,  // Galvanic Skin Response
    EEG,  // Electroencephalogram
    Respiration,
    BodyTemperature,
    Custom
};

// Assessment media item
struct MediaItem {
    std::string id;
    MediaType type;
    std::string filename;
    std::string contentType;
    std::string url;
    std::chrono::system_clock::time_point timestamp;
    std::unordered_map<std::string, std::string> metadata;
};

// Biometric data record
struct BiometricData {
    std::string id;
    BiometricType type;
    std::chrono::system_clock::time_point timestamp;
    std::vector<double> values;
    std::unordered_map<std::string, std::string> metadata;
};

// Digital signature
struct DigitalSignature {
    std::string id;
    std::string signerId; // User ID who signed
    std::string signerName; // Name of signer
    std::string signatureData; // Base64 encoded signature image
    std::string publicKey; // For verification
    std::string signatureHash; // Cryptographic hash for verification
    std::chrono::system_clock::time_point timestamp;
};

// Assessment criterion
struct AssessmentCriterion {
    std::string id;
    std::string competencyId; // Reference to competency
    std::string description;
    bool isMandatory;
    GradeScale minimumPassingGrade;
    std::vector<std::string> tags;
    std::unordered_map<std::string, std::string> metadata;
};

// Assessment grade
struct Grade {
    std::string id;
    std::string criterionId;
    GradeScale score;
    std::string comment;
    std::chrono::system_clock::time_point timestamp;
    std::string graderId; // User ID who provided the grade
    std::optional<DigitalSignature> graderSignature;
    std::unordered_map<std::string, std::string> metadata;
};

// Assessment feedback
struct Feedback {
    std::string id;
    std::string text;
    std::chrono::system_clock::time_point timestamp;
    std::string providerId; // User ID who provided the feedback
    std::vector<MediaItem> attachedMedia;
    std::unordered_map<std::string, std::string> metadata;
};

// Assessment form
struct AssessmentForm {
    std::string id;
    std::string title;
    std::string description;
    std::string syllabusId; // Reference to syllabus
    std::string moduleId; // Reference to module in syllabus
    std::string lessonId; // Reference to lesson in module
    std::vector<AssessmentCriterion> criteria;
    std::unordered_map<std::string, std::string> metadata;
};

// Complete assessment
struct Assessment {
    std::string id;
    std::string formId; // Reference to assessment form
    std::string traineeId; // User ID of trainee
    std::string instructorId; // User ID of instructor
    AssessmentStatus status;
    std::chrono::system_clock::time_point scheduledTime;
    std::chrono::system_clock::time_point startTime;
    std::chrono::system_clock::time_point completionTime;
    std::vector<Grade> grades;
    std::vector<Feedback> feedback;
    std::vector<MediaItem> attachedMedia;
    std::vector<BiometricData> biometricData;
    std::optional<DigitalSignature> traineeSignature;
    std::optional<DigitalSignature> instructorSignature;
    std::unordered_map<std::string, std::string> metadata;
};

// Performance trend
struct PerformanceTrend {
    std::string traineeId;
    std::string competencyId;
    std::vector<std::pair<std::chrono::system_clock::time_point, GradeScale>> grades;
    double trendSlope; // Positive = improving, Negative = declining
    double averageGrade;
    bool isImproving;
    std::unordered_map<std::string, std::string> metadata;
};

// Assessment summary
struct AssessmentSummary {
    std::string assessmentId;
    std::string traineeId;
    std::string instructorId;
    std::string formTitle;
    AssessmentStatus status;
    std::chrono::system_clock::time_point completionTime;
    double averageGrade;
    int totalCriteria;
    int passedCriteria;
    bool overallPass;
    std::unordered_map<std::string, std::string> metadata;
};

} // namespace APTP::Assessment

// backend/assessment/include/AssessmentManager.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <filesystem>
#include <optional>
#include <functional>
#include <chrono>
#include <future>

#include "AssessmentTypes.h"
#include "core/include/ErrorHandling.h"

namespace APTP::Assessment {

// Progress callback for assessment operations
using ProgressCallback = std::function<void(double progress, const std::string& message)>;

// Assessment manager class
class AssessmentManager {
public:
    static AssessmentManager& getInstance();
    
    // Initialize the assessment manager
    APTP::Core::Result<void> initialize();
    
    // Create a new assessment form
    APTP::Core::Result<AssessmentForm> createAssessmentForm(
        const std::string& title,
        const std::string& description,
        const std::string& syllabusId,
        const std::string& moduleId,
        const std::string& lessonId,
        const std::vector<AssessmentCriterion>& criteria);
    
    // Get assessment form by ID
    APTP::Core::Result<AssessmentForm> getAssessmentForm(const std::string& formId);
    
    // Update an assessment form
    APTP::Core::Result<AssessmentForm> updateAssessmentForm(
        const std::string& formId,
        const AssessmentForm& updatedForm);
    
    // Delete an assessment form
    APTP::Core::Result<void> deleteAssessmentForm(const std::string& formId);
    
    // List assessment forms
    APTP::Core::Result<std::vector<AssessmentForm>> listAssessmentForms(
        const std::optional<std::string>& syllabusId = std::nullopt,
        const std::optional<std::string>& moduleId = std::nullopt,
        const std::optional<std::string>& lessonId = std::nullopt);
    
    // Create a new assessment
    APTP::Core::Result<Assessment> createAssessment(
        const std::string& formId,
        const std::string& traineeId,
        const std::string& instructorId,
        const std::chrono::system_clock::time_point& scheduledTime);
    
    // Get assessment by ID
    APTP::Core::Result<Assessment> getAssessment(const std::string& assessmentId);
    
    // Update an assessment
    APTP::Core::Result<Assessment> updateAssessment(
        const std::string& assessmentId,
        const Assessment& updatedAssessment);
    
    // Delete an assessment
    APTP::Core::Result<void> deleteAssessment(const std::string& assessmentId);
    
    // List assessments
    APTP::Core::Result<std::vector<Assessment>> listAssessments(
        const std::optional<std::string>& traineeId = std::nullopt,
        const std::optional<std::string>& instructorId = std::nullopt,
        const std::optional<AssessmentStatus>& status = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& startDate = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& endDate = std::nullopt);
    
    // Start an assessment
    APTP::Core::Result<Assessment> startAssessment(const std::string& assessmentId);
    
    // Complete an assessment
    APTP::Core::Result<Assessment> completeAssessment(const std::string& assessmentId);
    
    // Cancel an assessment
    APTP::Core::Result<Assessment> cancelAssessment(const std::string& assessmentId);
    
    // Add a grade to an assessment
    APTP::Core::Result<Assessment> addGrade(
        const std::string& assessmentId,
        const std::string& criterionId,
        GradeScale score,
        const std::string& comment,
        const std::string& graderId);
    
    // Add feedback to an assessment
    APTP::Core::Result<Assessment> addFeedback(
        const std::string& assessmentId,
        const std::string& text,
        const std::string& providerId,
        const std::vector<MediaItem>& attachedMedia = {});
    
    // Add media to an assessment
    APTP::Core::Result<Assessment> addMedia(
        const std::string& assessmentId,
        const MediaItem& mediaItem);
    
    // Add biometric data to an assessment
    APTP::Core::Result<Assessment> addBiometricData(
        const std::string& assessmentId,
        const BiometricData& biometricData);
    
    // Add trainee signature to an assessment
    APTP::Core::Result<Assessment> addTraineeSignature(
        const std::string& assessmentId,
        const std::string& signatureData,
        const std::string& traineeId);
    
    // Add instructor signature to an assessment
    APTP::Core::Result<Assessment> addInstructorSignature(
        const std::string& assessmentId,
        const std::string& signatureData,
        const std::string& instructorId);
    
    // Get assessment summary
    APTP::Core::Result<AssessmentSummary> getAssessmentSummary(const std::string& assessmentId);
    
    // Get trainee performance trends
    APTP::Core::Result<std::vector<PerformanceTrend>> getTraineePerformanceTrends(
        const std::string& traineeId,
        const std::optional<std::string>& competencyId = std::nullopt);
    
    // Sync offline assessments
    APTP::Core::Result<std::vector<Assessment>> syncOfflineAssessments(
        const std::vector<Assessment>& offlineAssessments,
        const ProgressCallback& progressCallback = nullptr);
    
    // Export assessment to PDF
    APTP::Core::Result<std::filesystem::path> exportToPDF(
        const std::string& assessmentId,
        const std::filesystem::path& outputPath);
    
    // Export assessments to CSV
    APTP::Core::Result<std::filesystem::path> exportToCSV(
        const std::vector<std::string>& assessmentIds,
        const std::filesystem::path& outputPath);
    
    // Import assessments from CSV
    APTP::Core::Result<std::vector<Assessment>> importFromCSV(
        const std::filesystem::path& filePath,
        const ProgressCallback& progressCallback = nullptr);
    
    // Convert speech to text for feedback
    APTP::Core::Result<std::string> convertSpeechToText(
        const std::filesystem::path& audioFilePath);
    
    // Process biometric data for visualization
    APTP::Core::Result<std::unordered_map<std::string, std::vector<std::pair<std::chrono::system_clock::time_point, double>>>> 
    processBiometricData(
        const std::string& assessmentId,
        const std::vector<BiometricType>& types);

private:
    AssessmentManager();
    ~AssessmentManager();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

// Offline assessment synchronizer
class OfflineAssessmentSync {
public:
    // Check if there are pending offline assessments
    static bool hasPendingAssessments();
    
    // Get count of pending offline assessments
    static size_t getPendingAssessmentsCount();
    
    // Save assessment for offline use
    static APTP::Core::Result<void> saveForOffline(const Assessment& assessment);
    
    // Load offline assessments
    static APTP::Core::Result<std::vector<Assessment>> loadOfflineAssessments();
    
    // Clear synced offline assessments
    static APTP::Core::Result<void> clearSyncedAssessments(const std::vector<std::string>& assessmentIds);
};

} // namespace APTP::Assessment

// backend/assessment/include/GradeManager.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <optional>

#include "AssessmentTypes.h"
#include "core/include/ErrorHandling.h"

namespace APTP::Assessment {

// Grade manager class
class GradeManager {
public:
    static GradeManager& getInstance();
    
    // Initialize the grade manager
    APTP::Core::Result<void> initialize();
    
    // Calculate overall grade for an assessment
    APTP::Core::Result<double> calculateOverallGrade(const Assessment& assessment);
    
    // Determine if assessment is passing
    APTP::Core::Result<bool> isAssessmentPassing(const Assessment& assessment);
    
    // Calculate competency-based grade
    APTP::Core::Result<std::unordered_map<std::string, double>> calculateCompetencyGrades(
        const Assessment& assessment);
    
    // Calculate trend for a trainee and competency
    APTP::Core::Result<PerformanceTrend> calculatePerformanceTrend(
        const std::string& traineeId,
        const std::string& competencyId,
        size_t maxAssessments = 10);
    
    // Get historical grades for a trainee
    APTP::Core::Result<std::vector<std::pair<std::chrono::system_clock::time_point, double>>> 
    getTraineeHistoricalGrades(
        const std::string& traineeId,
        const std::optional<std::string>& competencyId = std::nullopt);
    
    // Get grading statistics for an instructor
    struct InstructorGradingStats {
        double averageGrade;
        std::unordered_map<GradeScale, size_t> gradeCounts;
        size_t totalAssessments;
        double averageGradingTime; // In minutes
    };
    
    APTP::Core::Result<InstructorGradingStats> getInstructorGradingStats(
        const std::string& instructorId);
    
    // Get grading statistics for a form
    struct FormGradingStats {
        double averageGrade;
        std::unordered_map<GradeScale, size_t> gradeCounts;
        size_t totalAssessments;
        std::unordered_map<std::string, double> criterionAverages; // Criterion ID -> average grade
    };
    
    APTP::Core::Result<FormGradingStats> getFormGradingStats(
        const std::string& formId);

private:
    GradeManager();
    ~GradeManager();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Assessment

// backend/assessment/include/BiometricProcessor.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <chrono>
#include <unordered_map>
#include <functional>

#include "AssessmentTypes.h"
#include "core/include/ErrorHandling.h"

namespace APTP::Assessment {

// Callback for biometric data processing
using BiometricDataCallback = std::function<void(const BiometricData&)>;

// Biometric processor class
class BiometricProcessor {
public:
    static BiometricProcessor& getInstance();
    
    // Initialize the biometric processor
    APTP::Core::Result<void> initialize();
    
    // Process raw biometric data
    APTP::Core::Result<BiometricData> processRawData(
        BiometricType type,
        const std::vector<double>& rawData,
        const std::chrono::system_clock::time_point& timestamp);
    
    // Register callback for biometric data
    void registerDataCallback(BiometricDataCallback callback);
    
    // Analyze biometric data for anomalies
    struct BiometricAnomaly {
        std::chrono::system_clock::time_point timestamp;
        BiometricType type;
        double value;
        double expectedValue;
        double deviation;
        std::string severity; // "Low", "Medium", "High", "Critical"
    };
    
    APTP::Core::Result<std::vector<BiometricAnomaly>> detectAnomalies(
        const std::vector<BiometricData>& data,
        double threshold = 2.0);
    
    // Correlate biometric data with assessment grades
    struct BiometricCorrelation {
        BiometricType type;
        double correlationCoefficient; // -1.0 to 1.0
        bool isSignificant;
        double pValue;
    };
    
    APTP::Core::Result<std::vector<BiometricCorrelation>> correlateWithGrades(
        const std::string& traineeId,
        const std::vector<BiometricType>& types);
    
    // Prepare biometric data for visualization
    struct VisualizationData {
        BiometricType type;
        std::vector<std::pair<std::chrono::system_clock::time_point, double>> timeSeriesData;
        std::vector<std::pair<std::chrono::system_clock::time_point, double>> normalizedData;
        std::vector<std::pair<std::chrono::system_clock::time_point, double>> smoothedData;
        std::vector<BiometricAnomaly> anomalies;
    };
    
    APTP::Core::Result<std::vector<VisualizationData>> prepareForVisualization(
        const std::vector<BiometricData>& data);

private:
    BiometricProcessor();
    ~BiometricProcessor();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Assessment

// backend/assessment/src/AssessmentManager.cpp (partial implementation)
#include "AssessmentManager.h"
#include "core/include/Logger.h"
#include "core/include/DatabaseManager.h"
#include <nlohmann/json.hpp>
#include <fstream>
#include <chrono>

namespace APTP::Assessment {

struct AssessmentManager::Impl {
    // Internal implementation details
    bool initialized = false;
    
    // Database queries (simplified for example)
    const std::string SQL_CREATE_ASSESSMENT_FORM = 
        "INSERT INTO assessment_forms (id, title, description, syllabus_id, module_id, lesson_id, criteria, metadata) "
        "VALUES ($1, $2, $3, $4, $5, $6, $7, $8) "
        "RETURNING id";
    
    const std::string SQL_GET_ASSESSMENT_FORM = 
        "SELECT id, title, description, syllabus_id, module_id, lesson_id, criteria, metadata "
        "FROM assessment_forms "
        "WHERE id = $1";
    
    const std::string SQL_UPDATE_ASSESSMENT_FORM = 
        "UPDATE assessment_forms "
        "SET title = $2, description = $3, syllabus_id = $4, module_id = $5, lesson_id = $6, criteria = $7, metadata = $8 "
        "WHERE id = $1 "
        "RETURNING id";
    
    const std::string SQL_DELETE_ASSESSMENT_FORM = 
        "DELETE FROM assessment_forms "
        "WHERE id = $1";
    
    const std::string SQL_LIST_ASSESSMENT_FORMS = 
        "SELECT id, title, description, syllabus_id, module_id, lesson_id, criteria, metadata "
        "FROM assessment_forms ";
    
    // Helper methods for database operations
    APTP::Core::Result<AssessmentForm> assessmentFormFromDbResult(const APTP::Core::DbResultSet& resultSet, size_t row) {
        // This would extract an assessment form from database results
        // For simplicity, we'll return a placeholder
        AssessmentForm form;
        form.id = "form-123";
        form.title = "Sample Assessment Form";
        return APTP::Core::Success(form);
    }
    
    APTP::Core::Result<Assessment> assessmentFromDbResult(const APTP::Core::DbResultSet& resultSet, size_t row) {
        // This would extract an assessment from database results
        // For simplicity, we'll return a placeholder
        Assessment assessment;
        assessment.id = "assessment-123";
        assessment.formId = "form-123";
        assessment.status = AssessmentStatus::Completed;
        return APTP::Core::Success(assessment);
    }
};

AssessmentManager& AssessmentManager::getInstance() {
    static AssessmentManager instance;
    return instance;
}

AssessmentManager::AssessmentManager() : impl_(std::make_unique<Impl>()) {}
AssessmentManager::~AssessmentManager() = default;

APTP::Core::Result<void> AssessmentManager::initialize() {
    if (impl_->initialized) {
        return APTP::Core::Success();
    }
    
    APTP::Core::Logger::getInstance().info("Initializing AssessmentManager");
    
    // Initialize database tables (in a real implementation)
    // Execute SQL to create necessary tables if they don't exist
    
    impl_->initialized = true;
    return APTP::Core::Success();
}

APTP::Core::Result<AssessmentForm> AssessmentManager::createAssessmentForm(
    const std::string& title,
    const std::string& description,
    const std::string& syllabusId,
    const std::string& moduleId,
    const std::string& lessonId,
    const std::vector<AssessmentCriterion>& criteria) {
    
    if (!impl_->initialized) {
        return APTP::Core::Error<AssessmentForm>(APTP::Core::ErrorCode::InvalidState);
    }
    
    APTP::Core::Logger::getInstance().info(
        "Creating assessment form: {} (syllabus={}, module={}, lesson={})",
        title, syllabusId, moduleId, lessonId);
    
    try {
        // Generate a unique ID for the form
        std::string formId = "form-" + std::to_string(std::hash<std::string>{}(
            title + syllabusId + moduleId + lessonId + std::to_string(std::time(nullptr))));
        
        // Serialize criteria to JSON
        nlohmann::json criteriaJson = nlohmann::json::array();
        for (const auto& criterion : criteria) {
            nlohmann::json criterionJson;
            criterionJson["id"] = criterion.id;
            criterionJson["competencyId"] = criterion.competencyId;
            criterionJson["description"] = criterion.description;
            criterionJson["isMandatory"] = criterion.isMandatory;
            criterionJson["minimumPassingGrade"] = static_cast<int>(criterion.minimumPassingGrade);
            criterionJson["tags"] = criterion.tags;
            criterionJson["metadata"] = criterion.metadata;
            
            criteriaJson.push_back(criterionJson);
        }
        
        // Prepare parameters for database query
        std::unordered_map<std::string, APTP::Core::DbValue> params;
        params["$1"] = formId;
        params["$2"] = title;
        params["$3"] = description;
        params["$4"] = syllabusId;
        params["$5"] = moduleId;
        params["$6"] = lessonId;
        params["$7"] = criteriaJson.dump();
        params["$8"] = nlohmann::json{}.dump(); // Empty metadata
        
        // Execute database query
        auto result = APTP::Core::PostgreSQLManager::getInstance().executeScalar(
            impl_->SQL_CREATE_ASSESSMENT_FORM, params);
        
        if (result.isError()) {
            APTP::Core::Logger::getInstance().error("Failed to create assessment form in database");
            return APTP::Core::Error<AssessmentForm>(APTP::Core::ErrorCode::AssessmentError);
        }
        
        // Create the assessment form object
        AssessmentForm form;
        form.id = formId;
        form.title = title;
        form.description = description;
        form.syllabusId = syllabusId;
        form.moduleId = moduleId;
        form.lessonId = lessonId;
        form.criteria = criteria;
        
        return APTP::Core::Success(form);
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Exception creating assessment form: {}", e.what());
        return APTP::Core::Error<AssessmentForm>(APTP::Core::ErrorCode::AssessmentError);
    }
}

APTP::Core::Result<AssessmentForm> AssessmentManager::getAssessmentForm(const std::string& formId) {
    if (!impl_->initialized) {
        return APTP::Core::Error<AssessmentForm>(APTP::Core::ErrorCode::InvalidState);
    }
    
    APTP::Core::Logger::getInstance().info("Getting assessment form: {}", formId);
    
    try {
        // Prepare parameters for database query
        std::unordered_map<std::string, APTP::Core::DbValue> params;
        params["$1"] = formId;
        
        // Execute database query
        auto result = APTP::Core::PostgreSQLManager::getInstance().executeQuery(
            impl_->SQL_GET_ASSESSMENT_FORM, params);
        
        if (result.isError()) {
            APTP::Core::Logger::getInstance().error("Failed to retrieve assessment form from database");
            return APTP::Core::Error<AssessmentForm>(APTP::Core::ErrorCode::AssessmentError);
        }
        
        const auto& resultSet = result.value();
        
        if (resultSet.rowCount() == 0) {
            APTP::Core::Logger::getInstance().warning("Assessment form not found: {}", formId);
            return APTP::Core::Error<AssessmentForm>(APTP::Core::ErrorCode::ResourceUnavailable);
        }
        
        // Extract form from database result
        return impl_->assessmentFormFromDbResult(resultSet, 0);
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Exception getting assessment form: {}", e.what());
        return APTP::Core::Error<AssessmentForm>(APTP::Core::ErrorCode::AssessmentError);
    }
}

// Additional method implementations would follow a similar pattern
// The implementation would interact with the database and handle serialization/deserialization

// OfflineAssessmentSync static methods
bool OfflineAssessmentSync::hasPendingAssessments() {
    // Check if there are offline assessments stored locally
    // In a real implementation, this would check a local storage mechanism
    
    // For this example, we'll return a placeholder
    return false;
}

size_t OfflineAssessmentSync::getPendingAssessmentsCount() {
    // Count offline assessments stored locally
    // In a real implementation, this would query a local storage mechanism
    
    // For this example, we'll return a placeholder
    return 0;
}

APTP::Core::Result<void> OfflineAssessmentSync::saveForOffline(const Assessment& assessment) {
    // Save an assessment for offline use
    // In a real implementation, this would store the assessment in a local storage mechanism
    
    APTP::Core::Logger::getInstance().info("Saving assessment for offline use: {}", assessment.id);
    
    try {
        // Serialize assessment to JSON
        nlohmann::json assessmentJson;
        // ... populate JSON with assessment data
        
        // Save to local storage
        // For example, to a local file
        std::string filename = "offline_assessment_" + assessment.id + ".json";
        std::ofstream file(filename);
        file << assessmentJson.dump(4);
        file.close();
        
        return APTP::Core::Success();
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Failed to save assessment for offline use: {}", e.what());
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::AssessmentError);
    }
}

// Additional static methods would follow a similar pattern

} // namespace APTP::Assessment

cmake_minimum_required(VERSION 3.20)
project(assessment-service VERSION 1.0.0 LANGUAGES CXX)

# Set C++20 standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Set output directories
set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)

# Find required packages
find_package(gRPC REQUIRED)
find_package(Protobuf REQUIRED)
find_package(OpenSSL REQUIRED)
find_package(nlohmann_json 3.10.0 REQUIRED)
find_package(spdlog REQUIRED)
find_package(prometheus-cpp REQUIRED)
find_package(pqxx REQUIRED)
find_package(Boost REQUIRED COMPONENTS system filesystem)

# Include directories
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_BINARY_DIR}/generated
)

# Generate protobuf and gRPC code
set(PROTO_FILES
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/assessment_service.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/core_service.proto
)

protobuf_generate_cpp(PROTO_SRCS PROTO_HDRS ${PROTO_FILES})
grpc_generate_cpp(GRPC_SRCS GRPC_HDRS ${CMAKE_CURRENT_BINARY_DIR}/generated ${PROTO_FILES})

# Source files
file(GLOB_RECURSE SOURCES 
    ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp
)

# Add executable
add_executable(${PROJECT_NAME} ${SOURCES} ${PROTO_SRCS} ${PROTO_HDRS} ${GRPC_SRCS} ${GRPC_HDRS})

# Link libraries
target_link_libraries(${PROJECT_NAME}
    PRIVATE
    gRPC::grpc++
    gRPC::grpc++_reflection
    protobuf::libprotobuf
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
    spdlog::spdlog
    prometheus-cpp::core
    prometheus-cpp::push
    pqxx::pqxx
    Boost::system
    Boost::filesystem
    pthread
)

# Copy configuration files to build directory
configure_file(
    ${CMAKE_CURRENT_SOURCE_DIR}/config/config.json
    ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/config/config.json
    COPYONLY
)

# Add tests
enable_testing()
add_subdirectory(tests)

# Installation
install(TARGETS ${PROJECT_NAME}
    RUNTIME DESTINATION bin
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)

install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/config/
    DESTINATION etc/${PROJECT_NAME}
    FILES_MATCHING PATTERN "*.json"
)

# Documentation
find_package(Doxygen)
if(DOXYGEN_FOUND)
    set(DOXYGEN_IN ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in)
    set(DOXYGEN_OUT ${CMAKE_CURRENT_BINARY_DIR}/Doxyfile)
    
    configure_file(${DOXYGEN_IN} ${DOXYGEN_OUT} @ONLY)
    
    add_custom_target(docs
        COMMAND ${DOXYGEN_EXECUTABLE} ${DOXYGEN_OUT}
        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
        COMMENT "Generating API documentation with Doxygen"
        VERBATIM
    )
endif()
#include <iostream>
#include <memory>
#include <string>
#include <csignal>
#include <thread>
#include <chrono>
#include <fstream>
#include <grpcpp/grpcpp.h>
#include <grpcpp/health_check_service_interface.h>
#include <grpcpp/ext/proto_server_reflection_plugin.h>
#include <nlohmann/json.hpp>

#include "service/assessment_service_impl.h"
#include "grading/grading_service.h"
#include "tracking/session_tracking.h"
#include "benchmarking/compliance_benchmarking.h"
#include "feedback/feedback_service.h"
#include "persistence/database_connection.h"
#include "logging/logger.h"
#include "metrics/metrics_service.h"

using namespace assessment;

// Global flag for graceful shutdown
std::atomic<bool> running{true};

// Signal handler
void signalHandler(int signal) {
    logging::Logger::getInstance().info("Received signal {}, shutting down...", signal);
    running = false;
}

// Load configuration from file
nlohmann::json loadConfig(const std::string& config_path) {
    try {
        std::ifstream config_file(config_path);
        if (!config_file.is_open()) {
            throw std::runtime_error("Failed to open config file: " + config_path);
        }
        
        nlohmann::json config;
        config_file >> config;
        return config;
    } catch (const std::exception& e) {
        std::cerr << "Error loading configuration: " << e.what() << std::endl;
        return nlohmann::json::object();
    }
}

int main(int argc, char** argv) {
    try {
        // Register signal handlers
        std::signal(SIGINT, signalHandler);
        std::signal(SIGTERM, signalHandler);
        
        // Load configuration
        std::string config_path = "config/config.json";
        if (argc > 1) {
            config_path = argv[1];
        }
        
        auto config = loadConfig(config_path);
        
        // Initialize logger
        logging::Logger::getInstance().initialize(
            "assessment-service",
            logging::LogLevel::INFO,
            config.value("logging", nlohmann::json::object()).value("file_path", "logs/assessment-service.log")
        );
        
        logging::Logger::getInstance().info("Assessment Service starting up");
        
        // Initialize metrics
        std::string metrics_host = config.value("metrics", nlohmann::json::object()).value("host", "0.0.0.0");
        int metrics_port = config.value("metrics", nlohmann::json::object()).value("port", 9107);
        
        metrics::MetricsService::getInstance().initialize(
            "assessment-service",
            true,
            metrics_host,
            metrics_port
        );
        
        // Initialize database connection
        std::string db_host = config.value("database", nlohmann::json::object()).value("host", "localhost");
        int db_port = config.value("database", nlohmann::json::object()).value("port", 5432);
        std::string db_name = config.value("database", nlohmann::json::object()).value("name", "assessment_db");
        std::string db_user = config.value("database", nlohmann::json::object()).value("user", "assessment_user");
        std::string db_password = config.value("database", nlohmann::json::object()).value("password", "assessment_password");
        
        auto db_connection = std::make_shared<persistence::DatabaseConnection>(
            db_host,
            db_port,
            db_name,
            db_user,
            db_password
        );
        
        if (!db_connection->connect()) {
            throw std::runtime_error("Failed to connect to database");
        }
        
        // Create repositories
        auto assessment_repository = std::make_shared<persistence::AssessmentRepository>(db_connection);
        auto session_repository = std::make_shared<persistence::SessionRepository>(db_connection);
        auto benchmark_repository = std::make_shared<persistence::BenchmarkRepository>(db_connection);
        auto feedback_repository = std::make_shared<persistence::FeedbackRepository>(db_connection);
        
        // Create services
        auto grading_service = std::make_shared<grading::GradingService>(assessment_repository);
        auto tracking_service = std::make_shared<tracking::SessionTrackingService>(session_repository);
        auto benchmark_service = std::make_shared<benchmarking::ComplianceBenchmarkingService>(benchmark_repository);
        auto feedback_service = std::make_shared<feedback::FeedbackService>(feedback_repository);
        
        // Initialize gRPC server
        std::string server_address = 
            config.value("server", nlohmann::json::object()).value("host", "0.0.0.0") + ":" + 
            std::to_string(config.value("server", nlohmann::json::object()).value("port", 50057));
        
        service::AssessmentServiceImpl service(
            grading_service,
            tracking_service,
            benchmark_service,
            feedback_service
        );
        
        grpc::EnableDefaultHealthCheckService(true);
        grpc::reflection::InitProtoReflectionServerBuilderPlugin();
        
        grpc::ServerBuilder builder;
        
        // Set authentication credentials if TLS is enabled
        if (config.value("security", nlohmann::json::object()).value("tls_enabled", false)) {
            std::string key_path = config.value("security", nlohmann::json::object()).value("key_path", "");
            std::string cert_path = config.value("security", nlohmann::json::object()).value("cert_path", "");
            
            std::ifstream key_file(key_path);
            std::ifstream cert_file(cert_path);
            
            if (!key_file.is_open() || !cert_file.is_open()) {
                throw std::runtime_error("Failed to open TLS key or certificate file");
            }
            
            std::stringstream key_buffer, cert_buffer;
            key_buffer << key_file.rdbuf();
            cert_buffer << cert_file.rdbuf();
            
            grpc::SslServerCredentialsOptions ssl_opts;
            ssl_opts.pem_key_cert_pairs.push_back({key_buffer.str(), cert_buffer.str()});
            
            builder.AddListeningPort(server_address, grpc::SslServerCredentials(ssl_opts));
        } else {
            builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());
        }
        
        builder.RegisterService(&service);
        
        // Set server options
        builder.SetMaxReceiveMessageSize(config.value("server", nlohmann::json::object()).value("max_message_size_mb", 100) * 1024 * 1024);
        builder.SetMaxSendMessageSize(config.value("server", nlohmann::json::object()).value("max_message_size_mb", 100) * 1024 * 1024);
        
        // Build and start server
        std::unique_ptr<grpc::Server> server(builder.BuildAndStart());
        logging::Logger::getInstance().info("Server listening on {}", server_address);
        
        // Create performance metrics
        auto& request_counter = metrics::MetricsService::getInstance().createCounter(
            "requests_total",
            "Total number of requests",
            {{"service", "assessment-service"}}
        );
        
        auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
            "request_duration_seconds",
            "Request duration in seconds",
            {{"service", "assessment-service"}}
        );
        
        auto& active_connections = metrics::MetricsService::getInstance().createGauge(
            "active_connections",
            "Number of active connections",
            {{"service", "assessment-service"}}
        );
        
        // Main loop
        while (running) {
            // Update metrics
            active_connections.Set(server->GetNumActiveConnections());
            
            // Sleep to avoid busy waiting
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
        
        // Graceful shutdown
        logging::Logger::getInstance().info("Shutting down server...");
        server->Shutdown();
        logging::Logger::getInstance().info("Server shutting down");
        
        // Shutdown metrics
        metrics::MetricsService::getInstance().shutdown();
        
        // Close database connection
        db_connection->disconnect();
        
        logging::Logger::getInstance().info("Assessment Service shut down successfully");
        return 0;
    } catch (const std::exception& e) {
        std::cerr << "Fatal error: " << e.what() << std::endl;
        
        try {
            logging::Logger::getInstance().critical("Fatal error: {}", e.what());
        } catch (...) {
            // Ignore if logging fails
        }
        
        return 1;
    }
}
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <chrono>
#include <nlohmann/json.hpp>

namespace assessment {
namespace model {

/**
 * @brief Assessment types
 */
enum class AssessmentType {
    UNKNOWN,
    PRACTICAL,
    WRITTEN,
    ORAL,
    SIMULATOR
};

/**
 * @brief Convert AssessmentType to string
 * @param type Assessment type
 * @return String representation
 */
std::string assessmentTypeToString(AssessmentType type);

/**
 * @brief Convert string to AssessmentType
 * @param str String representation
 * @return Assessment type
 */
AssessmentType assessmentTypeFromString(const std::string& str);

/**
 * @brief Assessment status
 */
enum class AssessmentStatus {
    DRAFT,
    IN_PROGRESS,
    SUBMITTED,
    GRADED,
    APPROVED
};

/**
 * @brief Convert AssessmentStatus to string
 * @param status Assessment status
 * @return String representation
 */
std::string assessmentStatusToString(AssessmentStatus status);

/**
 * @brief Convert string to AssessmentStatus
 * @param str String representation
 * @return Assessment status
 */
AssessmentStatus assessmentStatusFromString(const std::string& str);

/**
 * @brief Signature information
 */
struct SignatureInfo {
    std::string signer_id;
    std::string signer_name;
    std::string certificate_id;
    std::vector<uint8_t> signature_data;
    std::chrono::system_clock::time_point timestamp;
    bool is_valid{false};
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Signature info or nullopt if invalid
     */
    static std::optional<SignatureInfo> fromJson(const nlohmann::json& json);
};

/**
 * @brief Grade item
 */
struct GradeItem {
    std::string criteria_id;
    std::string criteria_name;
    int grade;  // 1-4 scale
    std::string comments;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Grade item or nullopt if invalid
     */
    static std::optional<GradeItem> fromJson(const nlohmann::json& json);
};

/**
 * @brief Assessment
 */
class Assessment {
public:
    /**
     * @brief Default constructor
     */
    Assessment();
    
    /**
     * @brief Constructor with ID
     * @param id Assessment ID
     */
    explicit Assessment(const std::string& id);
    
    /**
     * @brief Get assessment ID
     * @return Assessment ID
     */
    const std::string& getAssessmentId() const;
    
    /**
     * @brief Set assessment ID
     * @param id Assessment ID
     */
    void setAssessmentId(const std::string& id);
    
    /**
     * @brief Get trainee ID
     * @return Trainee ID
     */
    const std::string& getTraineeId() const;
    
    /**
     * @brief Set trainee ID
     * @param id Trainee ID
     */
    void setTraineeId(const std::string& id);
    
    /**
     * @brief Get assessor ID
     * @return Assessor ID
     */
    const std::string& getAssessorId() const;
    
    /**
     * @brief Set assessor ID
     * @param id Assessor ID
     */
    void setAssessorId(const std::string& id);
    
    /**
     * @brief Get assessment type
     * @return Assessment type
     */
    AssessmentType getAssessmentType() const;
    
    /**
     * @brief Set assessment type
     * @param type Assessment type
     */
    void setAssessmentType(AssessmentType type);
    
    /**
     * @brief Get course ID
     * @return Course ID
     */
    const std::string& getCourseId() const;
    
    /**
     * @brief Set course ID
     * @param id Course ID
     */
    void setCourseId(const std::string& id);
    
    /**
     * @brief Get syllabus ID
     * @return Syllabus ID
     */
    const std::string& getSyllabusId() const;
    
    /**
     * @brief Set syllabus ID
     * @param id Syllabus ID
     */
    void setSyllabusId(const std::string& id);
    
    /**
     * @brief Get exercise ID
     * @return Exercise ID
     */
    const std::string& getExerciseId() const;
    
    /**
     * @brief Set exercise ID
     * @param id Exercise ID
     */
    void setExerciseId(const std::string& id);
    
    /**
     * @brief Get assessment date
     * @return Assessment date
     */
    std::chrono::system_clock::time_point getDate() const;
    
    /**
     * @brief Set assessment date
     * @param date Assessment date
     */
    void setDate(const std::chrono::system_clock::time_point& date);
    
    /**
     * @brief Get duration in minutes
     * @return Duration in minutes
     */
    int getDurationMinutes() const;
    
    /**
     * @brief Set duration in minutes
     * @param minutes Duration in minutes
     */
    void setDurationMinutes(int minutes);
    
    /**
     * @brief Get location
     * @return Location
     */
    const std::string& getLocation() const;
    
    /**
     * @brief Set location
     * @param location Location
     */
    void setLocation(const std::string& location);
    
    /**
     * @brief Get grades
     * @return Grades
     */
    const std::vector<GradeItem>& getGrades() const;
    
    /**
     * @brief Set grades
     * @param grades Grades
     */
    void setGrades(const std::vector<GradeItem>& grades);
    
    /**
     * @brief Add grade
     * @param grade Grade
     */
    void addGrade(const GradeItem& grade);
    
    /**
     * @brief Get grade by criteria ID
     * @param criteria_id Criteria ID
     * @return Grade or nullopt if not found
     */
    std::optional<GradeItem> getGradeByCriteriaId(const std::string& criteria_id) const;
    
    /**
     * @brief Update grade
     * @param grade Grade
     * @return True if updated, false if not found
     */
    bool updateGrade(const GradeItem& grade);
    
    /**
     * @brief Get comments
     * @return Comments
     */
    const std::string& getComments() const;
    
    /**
     * @brief Set comments
     * @param comments Comments
     */
    void setComments(const std::string& comments);
    
    /**
     * @brief Get trainee signature
     * @return Trainee signature
     */
    const std::optional<SignatureInfo>& getTraineeSignature() const;
    
    /**
     * @brief Set trainee signature
     * @param signature Trainee signature
     */
    void setTraineeSignature(const SignatureInfo& signature);
    
    /**
     * @brief Get assessor signature
     * @return Assessor signature
     */
    const std::optional<SignatureInfo>& getAssessorSignature() const;
    
    /**
     * @brief Set assessor signature
     * @param signature Assessor signature
     */
    void setAssessorSignature(const SignatureInfo& signature);
    
    /**
     * @brief Get assessment status
     * @return Assessment status
     */
    AssessmentStatus getStatus() const;
    
    /**
     * @brief Set assessment status
     * @param status Assessment status
     */
    void setStatus(AssessmentStatus status);
    
    /**
     * @brief Get creation time
     * @return Creation time
     */
    std::chrono::system_clock::time_point getCreatedAt() const;
    
    /**
     * @brief Set creation time
     * @param time Creation time
     */
    void setCreatedAt(const std::chrono::system_clock::time_point& time);
    
    /**
     * @brief Get update time
     * @return Update time
     */
    std::chrono::system_clock::time_point getUpdatedAt() const;
    
    /**
     * @brief Set update time
     * @param time Update time
     */
    void setUpdatedAt(const std::chrono::system_clock::time_point& time);
    
    /**
     * @brief Get metadata
     * @return Metadata
     */
    const std::map<std::string, std::string>& getMetadata() const;
    
    /**
     * @brief Set metadata
     * @param metadata Metadata
     */
    void setMetadata(const std::map<std::string, std::string>& metadata);
    
    /**
     * @brief Get metadata value
     * @param key Metadata key
     * @return Metadata value or empty string if not found
     */
    std::string getMetadataValue(const std::string& key) const;
    
    /**
     * @brief Set metadata value
     * @param key Metadata key
     * @param value Metadata value
     */
    void setMetadataValue(const std::string& key, const std::string& value);
    
    /**
     * @brief Check if assessment is signed by trainee
     * @return True if signed by trainee
     */
    bool isSignedByTrainee() const;
    
    /**
     * @brief Check if assessment is signed by assessor
     * @return True if signed by assessor
     */
    bool isSignedByAssessor() const;
    
    /**
     * @brief Check if assessment is fully signed
     * @return True if fully signed
     */
    bool isFullySigned() const;
    
    /**
     * @brief Check if assessment is in draft state
     * @return True if draft
     */
    bool isDraft() const;
    
    /**
     * @brief Get overall grade (average)
     * @return Overall grade or 0 if no grades
     */
    double getOverallGrade() const;
    
    /**
     * @brief Check if assessment is passed
     * @return True if passed
     */
    bool isPassed() const;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Assessment or nullopt if invalid
     */
    static std::optional<Assessment> fromJson(const nlohmann::json& json);
    
    /**
     * @brief Generate audit log entry
     * @param action Action performed
     * @param user_id User ID
     * @param details Additional details
     * @return Audit log entry
     */
    nlohmann::json generateAuditLog(const std::string& action, const std::string& user_id, const std::string& details = "") const;
    
private:
    std::string assessment_id_;
    std::string trainee_id_;
    std::string assessor_id_;
    AssessmentType assessment_type_;
    std::string course_id_;
    std::string syllabus_id_;
    std::string exercise_id_;
    std::chrono::system_clock::time_point date_;
    int duration_minutes_;
    std::string location_;
    std::vector<GradeItem> grades_;
    std::string comments_;
    std::optional<SignatureInfo> trainee_signature_;
    std::optional<SignatureInfo> assessor_signature_;
    AssessmentStatus status_;
    std::chrono::system_clock::time_point created_at_;
    std::chrono::system_clock::time_point updated_at_;
    std::map<std::string, std::string> metadata_;
};

/**
 * @brief Session status
 */
enum class SessionStatus {
    SCHEDULED,
    IN_PROGRESS,
    COMPLETED,
    CANCELLED
};

/**
 * @brief Convert SessionStatus to string
 * @param status Session status
 * @return String representation
 */
std::string sessionStatusToString(SessionStatus status);

/**
 * @brief Convert string to SessionStatus
 * @param str String representation
 * @return Session status
 */
SessionStatus sessionStatusFromString(const std::string& str);

/**
 * @brief Session information
 */
struct SessionInfo {
    std::string session_id;
    std::string trainee_id;
    std::string instructor_id;
    std::string course_id;
    std::string syllabus_id;
    std::string exercise_id;
    std::chrono::system_clock::time_point scheduled_time;
    int scheduled_duration_minutes;
    std::string location;
    SessionStatus status;
    std::chrono::system_clock::time_point start_time;
    std::chrono::system_clock::time_point end_time;
    std::map<std::string, std::string> metadata;
    std::chrono::system_clock::time_point created_at;
    std::chrono::system_clock::time_point updated_at;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Session info or nullopt if invalid
     */
    static std::optional<SessionInfo> fromJson(const nlohmann::json& json);
};

/**
 * @brief Feedback entry
 */
struct FeedbackEntry {
    std::string feedback_id;
    std::string assessment_id;
    std::string session_id;
    std::string user_id;
    std::string feedback_text;
    int rating;  // 1-5 scale
    std::chrono::system_clock::time_point timestamp;
    bool is_anonymous;
    std::map<std::string, std::string> metadata;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Feedback entry or nullopt if invalid
     */
    static std::optional<FeedbackEntry> fromJson(const nlohmann::json& json);
};

/**
 * @brief Compliance benchmark
 */
struct ComplianceBenchmark {
    std::string benchmark_id;
    std::string regulation_id;
    std::string requirement_id;
    std::string requirement_name;
    std::string assessment_criteria;
    int min_passing_grade;
    double target_compliance_percentage;
    double current_compliance_percentage;
    int total_assessments;
    int compliant_assessments;
    std::chrono::system_clock::time_point timestamp;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Compliance benchmark or nullopt if invalid
     */
    static std::optional<ComplianceBenchmark> fromJson(const nlohmann::json& json);
};

/**
 * @brief Performance trend
 */
struct PerformanceTrend {
    std::string trend_id;
    std::string trainee_id;
    std::string course_id;
    std::string criteria_id;
    std::vector<std::pair<std::chrono::system_clock::time_point, double>> data_points;
    double trend_slope;
    std::chrono::system_clock::time_point timestamp;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Performance trend or nullopt if invalid
     */
    static std::optional<PerformanceTrend> fromJson(const nlohmann::json& json);
};

} // namespace model
} // namespace assessment
#pragma once

#include <string>
#include <vector>
#include <map>
#include <optional>
#include <chrono>
#include <nlohmann/json.hpp>

namespace assessment {
namespace model {

/**
 * @brief Assessment type
 */
enum class AssessmentType {
    UNKNOWN,
    KNOWLEDGE_TEST,
    PRACTICAL_TEST,
    SIMULATOR_SESSION,
    FLIGHT_SESSION,
    WRITTEN_EXAM,
    ORAL_EXAM
};

/**
 * @brief Convert AssessmentType to string
 */
std::string assessmentTypeToString(AssessmentType type);

/**
 * @brief Convert string to AssessmentType
 */
AssessmentType assessmentTypeFromString(const std::string& str);

/**
 * @brief Assessment status
 */
enum class AssessmentStatus {
    UNKNOWN,
    SCHEDULED,
    IN_PROGRESS,
    COMPLETED,
    GRADED,
    CANCELLED
};

/**
 * @brief Convert AssessmentStatus to string
 */
std::string assessmentStatusToString(AssessmentStatus status);

/**
 * @brief Convert string to AssessmentStatus
 */
AssessmentStatus assessmentStatusFromString(const std::string& str);

/**
 * @brief Grading scale
 */
enum class GradingScale {
    UNKNOWN,
    SCALE_1_4,          // 1-4 scale (1=unsatisfactory, 4=excellent)
    SCALE_PERCENTAGE,   // 0-100%
    SCALE_PASS_FAIL,    // Pass/Fail
    SCALE_LETTER        // A, B, C, D, F
};

/**
 * @brief Convert GradingScale to string
 */
std::string gradingScaleToString(GradingScale scale);

/**
 * @brief Convert string to GradingScale
 */
GradingScale gradingScaleFromString(const std::string& str);

/**
 * @brief Grade item
 */
struct GradeItem {
    std::string criteria_id;
    std::string criteria_name;
    double score;
    std::string comments;
    bool is_critical;
    bool satisfactory;

    /**
     * @brief Convert to JSON
     */
    nlohmann::json toJson() const;

    /**
     * @brief Create from JSON
     */
    static std::optional<GradeItem> fromJson(const nlohmann::json& json);
};

/**
 * @brief Assessment model
 */
class Assessment {
public:
    /**
     * @brief Default constructor
     */
    Assessment();

    /**
     * @brief Constructor with ID
     * @param id Assessment ID
     */
    explicit Assessment(const std::string& id);

    // Getters and setters
    const std::string& getAssessmentId() const;
    void setAssessmentId(const std::string& id);

    const std::string& getTitle() const;
    void setTitle(const std::string& title);

    const std::string& getDescription() const;
    void setDescription(const std::string& description);

    AssessmentType getType() const;
    void setType(AssessmentType type);

    AssessmentStatus getStatus() const;
    void setStatus(AssessmentStatus status);

    const std::string& getTraineeId() const;
    void setTraineeId(const std::string& id);

    const std::string& getInstructorId() const;
    void setInstructorId(const std::string& id);

    const std::string& getCourseId() const;
    void setCourseId(const std::string& id);

    const std::string& getSyllabusId() const;
    void setSyllabusId(const std::string& id);

    const std::string& getExerciseId() const;
    void setExerciseId(const std::string& id);

    std::chrono::system_clock::time_point getScheduledTime() const;
    void setScheduledTime(const std::chrono::system_clock::time_point& time);

    std::optional<std::chrono::system_clock::time_point> getActualStartTime() const;
    void setActualStartTime(const std::chrono::system_clock::time_point& time);
    void clearActualStartTime();

    std::optional<std::chrono::system_clock::time_point> getActualEndTime() const;
    void setActualEndTime(const std::chrono::system_clock::time_point& time);
    void clearActualEndTime();

    GradingScale getGradingScale() const;
    void setGradingScale(GradingScale scale);

    const std::vector<GradeItem>& getGrades() const;
    void setGrades(const std::vector<GradeItem>& grades);
    void addGrade(const GradeItem& grade);
    std::optional<GradeItem> getGradeByCriteriaId(const std::string& criteriaId) const;
    bool updateGrade(const GradeItem& grade);

    bool isPassed() const;
    void setPassed(bool passed);

    double getOverallScore() const;
    void setOverallScore(double score);

    const std::string& getComments() const;
    void setComments(const std::string& comments);
    void appendComments(const std::string& additional_comments);

    const std::vector<std::string>& getAttachments() const;
    void setAttachments(const std::vector<std::string>& attachments);
    void addAttachment(const std::string& attachment);
    bool removeAttachment(const std::string& attachment);

    const std::vector<std::string>& getTags() const;
    void setTags(const std::vector<std::string>& tags);
    void addTag(const std::string& tag);
    bool removeTag(const std::string& tag);
    bool hasTag(const std::string& tag) const;

    const std::map<std::string, std::string>& getMetadata() const;
    void setMetadata(const std::map<std::string, std::string>& metadata);
    std::string getMetadataValue(const std::string& key) const;
    void setMetadataValue(const std::string& key, const std::string& value);
    bool removeMetadataValue(const std::string& key);

    bool isDraft() const;
    void setDraft(bool is_draft);

    const std::string& getCreatedBy() const;
    void setCreatedBy(const std::string& user_id);

    std::chrono::system_clock::time_point getCreatedAt() const;
    void setCreatedAt(const std::chrono::system_clock::time_point& time);

    std::chrono::system_clock::time_point getUpdatedAt() const;
    void setUpdatedAt(const std::chrono::system_clock::time_point& time);

    /**
     * @brief Calculate overall score from grades
     * @return Calculated score
     */
    double calculateOverallScore() const;

    /**
     * @brief Determine if assessment is passed based on grades
     * @return True if passed
     */
    bool calculatePassStatus() const;

    /**
     * @brief Check if assessment is valid
     * @return True if valid
     */
    bool isValid() const;

    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;

    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Assessment or nullopt if invalid
     */
    static std::optional<Assessment> fromJson(const nlohmann::json& json);

    /**
     * @brief Generate audit log entry
     * @param action Action performed
     * @param user_id User ID
     * @param details Additional details
     * @return Audit log entry as JSON
     */
    nlohmann::json generateAuditLog(
        const std::string& action,
        const std::string& user_id,
        const std::string& details = ""
    ) const;

private:
    std::string assessment_id_;
    std::string title_;
    std::string description_;
    AssessmentType type_;
    AssessmentStatus status_;
    std::string trainee_id_;
    std::string instructor_id_;
    std::string course_id_;
    std::string syllabus_id_;
    std::string exercise_id_;
    std::chrono::system_clock::time_point scheduled_time_;
    std::optional<std::chrono::system_clock::time_point> actual_start_time_;
    std::optional<std::chrono::system_clock::time_point> actual_end_time_;
    GradingScale grading_scale_;
    std::vector<GradeItem> grades_;
    bool passed_;
    double overall_score_;
    std::string comments_;
    std::vector<std::string> attachments_;
    std::vector<std::string> tags_;
    std::map<std::string, std::string> metadata_;
    bool is_draft_;
    std::string created_by_;
    std::chrono::system_clock::time_point created_at_;
    std::chrono::system_clock::time_point updated_at_;
};

/**
 * @brief Assessment repository interface
 */
class IAssessmentRepository {
public:
    virtual ~IAssessmentRepository() = default;

    /**
     * @brief Create a new assessment
     * @param assessment Assessment to create
     * @return Created assessment ID or empty string if failed
     */
    virtual std::string createAssessment(const Assessment& assessment) = 0;

    /**
     * @brief Get an assessment by ID
     * @param assessment_id Assessment ID
     * @return Assessment or nullopt if not found
     */
    virtual std::optional<Assessment> getAssessment(const std::string& assessment_id) = 0;

    /**
     * @brief Update an assessment
     * @param assessment Assessment to update
     * @return True if updated successfully
     */
    virtual bool updateAssessment(const Assessment& assessment) = 0;

    /**
     * @brief Delete an assessment
     * @param assessment_id Assessment ID
     * @return True if deleted successfully
     */
    virtual bool deleteAssessment(const std::string& assessment_id) = 0;

    /**
     * @brief List assessments matching criteria
     * @param trainee_id Trainee ID (optional)
     * @param instructor_id Instructor ID (optional)
     * @param course_id Course ID (optional)
     * @param syllabus_id Syllabus ID (optional)
     * @param type Assessment type (optional)
     * @param status Assessment status (optional)
     * @param start_date Start date (optional)
     * @param end_date End date (optional)
     * @param tags Tags to filter by (optional)
     * @param page Page number (starting from 1)
     * @param page_size Page size
     * @param sort_by Sort field
     * @param ascending Sort direction
     * @return Pair of assessments and total count
     */
    virtual std::pair<std::vector<Assessment>, int> listAssessments(
        const std::optional<std::string>& trainee_id = std::nullopt,
        const std::optional<std::string>& instructor_id = std::nullopt,
        const std::optional<std::string>& course_id = std::nullopt,
        const std::optional<std::string>& syllabus_id = std::nullopt,
        const std::optional<AssessmentType>& type = std::nullopt,
        const std::optional<AssessmentStatus>& status = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& start_date = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& end_date = std::nullopt,
        const std::vector<std::string>& tags = {},
        int page = 1,
        int page_size = 10,
        const std::string& sort_by = "scheduled_time",
        bool ascending = false
    ) = 0;

    /**
     * @brief Log audit event
     * @param assessment_id Assessment ID
     * @param action Action performed
     * @param user_id User ID
     * @param details Additional details
     * @return True if logged successfully
     */
    virtual bool logAuditEvent(
        const std::string& assessment_id,
        const std::string& action,
        const std::string& user_id,
        const std::string& details
    ) = 0;

    /**
     * @brief Get audit logs for an assessment
     * @param assessment_id Assessment ID
     * @return Audit logs as JSON array
     */
    virtual std::vector<nlohmann::json> getAuditLogs(const std::string& assessment_id) = 0;
};

} // namespace model
} // namespace assessment
syntax = "proto3";

package assessment;

// Assessment service definition
service AssessmentService {
  // Create a new assessment
  rpc CreateAssessment (Assessment) returns (AssessmentResponse);
  
  // Get an assessment by ID
  rpc GetAssessment (AssessmentRequest) returns (Assessment);
  
  // Update an assessment
  rpc UpdateAssessment (Assessment) returns (AssessmentResponse);
  
  // Delete an assessment
  rpc DeleteAssessment (AssessmentRequest) returns (AssessmentResponse);
  
  // List assessments based on criteria
  rpc ListAssessments (ListAssessmentsRequest) returns (ListAssessmentsResponse);
  
  // Grade assessment
  rpc GradeAssessment (GradeRequest) returns (AssessmentResponse);
  
  // Get all assessments for a trainee
  rpc GetTraineeAssessments (TraineeRequest) returns (ListAssessmentsResponse);
  
  // Get assessment statistics
  rpc GetAssessmentStats (StatsRequest) returns (StatsResponse);
  
  // Start assessment session
  rpc StartAssessmentSession (SessionRequest) returns (SessionResponse);
  
  // End assessment session
  rpc EndAssessmentSession (SessionRequest) returns (SessionResponse);
  
  // Track assessment progress
  rpc TrackProgress (ProgressRequest) returns (ProgressResponse);
  
  // Add comments to assessment
  rpc AddComments (CommentsRequest) returns (AssessmentResponse);
  
  // Add attachment to assessment
  rpc AddAttachment (AttachmentRequest) returns (AttachmentResponse);
  
  // Get attachment from assessment
  rpc GetAttachment (AttachmentRequest) returns (AttachmentData);
}

// Assessment type enum
enum AssessmentType {
  UNKNOWN = 0;
  KNOWLEDGE_TEST = 1;
  PRACTICAL_TEST = 2;
  SIMULATOR_SESSION = 3;
  FLIGHT_SESSION = 4;
  WRITTEN_EXAM = 5;
  ORAL_EXAM = 6;
}

// Status enum
enum AssessmentStatus {
  STATUS_UNKNOWN = 0;
  SCHEDULED = 1;
  IN_PROGRESS = 2;
  COMPLETED = 3;
  GRADED = 4;
  CANCELLED = 5;
}

// Grading scale enum
enum GradingScale {
  SCALE_UNKNOWN = 0;
  SCALE_1_4 = 1;  // 1-4 scale (1=unsatisfactory, 4=excellent)
  SCALE_PERCENTAGE = 2;  // 0-100%
  SCALE_PASS_FAIL = 3;  // Pass/Fail
  SCALE_LETTER = 4;  // A, B, C, D, F
}

// Assessment message
message Assessment {
  string assessment_id = 1;
  string title = 2;
  string description = 3;
  AssessmentType type = 4;
  AssessmentStatus status = 5;
  string trainee_id = 6;
  string instructor_id = 7;
  string course_id = 8;
  string syllabus_id = 9;
  string exercise_id = 10;
  int64 scheduled_time = 11;  // milliseconds since epoch
  int64 actual_start_time = 12;  // milliseconds since epoch
  int64 actual_end_time = 13;  // milliseconds since epoch
  GradingScale grading_scale = 14;
  repeated GradeItem grades = 15;
  bool passed = 16;
  double overall_score = 17;
  string comments = 18;
  repeated string attachments = 19;
  repeated string tags = 20;
  map<string, string> metadata = 21;
  bool is_draft = 22;
  string created_by = 23;
  int64 created_at = 24;  // milliseconds since epoch
  int64 updated_at = 25;  // milliseconds since epoch
}

// Grade item
message GradeItem {
  string criteria_id = 1;
  string criteria_name = 2;
  double score = 3;
  string comments = 4;
  bool is_critical = 5;
  bool satisfactory = 6;
}

// Request to get assessment by ID
message AssessmentRequest {
  string assessment_id = 1;
}

// Response to assessment operations
message AssessmentResponse {
  bool success = 1;
  string assessment_id = 2;
  string error_message = 3;
  int64 timestamp = 4;  // milliseconds since epoch
}

// Request to list assessments
message ListAssessmentsRequest {
  string trainee_id = 1;
  string instructor_id = 2;
  string course_id = 3;
  string syllabus_id = 4;
  AssessmentType type = 5;
  AssessmentStatus status = 6;
  int64 start_date = 7;  // milliseconds since epoch
  int64 end_date = 8;  // milliseconds since epoch
  int32 page = 9;
  int32 page_size = 10;
  string sort_by = 11;
  bool ascending = 12;
  repeated string tags = 13;
}

// Response for list assessments
message ListAssessmentsResponse {
  bool success = 1;
  repeated Assessment assessments = 2;
  int32 total_count = 3;
  int32 page = 4;
  int32 page_size = 5;
  string error_message = 6;
}

// Request to grade assessment
message GradeRequest {
  string assessment_id = 1;
  string instructor_id = 2;
  repeated GradeItem grades = 3;
  double overall_score = 4;
  bool passed = 5;
  string comments = 6;
}

// Request to get trainee assessments
message TraineeRequest {
  string trainee_id = 1;
  string course_id = 2;
  AssessmentType type = 3;
  AssessmentStatus status = 4;
  int64 start_date = 5;  // milliseconds since epoch
  int64 end_date = 6;  // milliseconds since epoch
}

// Request to get assessment statistics
message StatsRequest {
  string trainee_id = 1;
  string course_id = 2;
  string instructor_id = 3;
  string syllabus_id = 4;
  AssessmentType type = 5;
  int64 start_date = 6;  // milliseconds since epoch
  int64 end_date = 7;  // milliseconds since epoch
}

// Response for assessment statistics
message StatsResponse {
  bool success = 1;
  int32 total_assessments = 2;
  int32 passed_assessments = 3;
  int32 failed_assessments = 4;
  double average_score = 5;
  repeated CriteriaStats criteria_stats = 6;
  string error_message = 7;
}

// Statistics for criteria
message CriteriaStats {
  string criteria_id = 1;
  string criteria_name = 2;
  double average_score = 3;
  int32 count = 4;
  map<string, double> score_distribution = 5;
}

// Request to start/end assessment session
message SessionRequest {
  string assessment_id = 1;
  string user_id = 2;
  map<string, string> session_data = 3;
}

// Response for session operations
message SessionResponse {
  bool success = 1;
  string assessment_id = 2;
  string session_id = 3;
  int64 timestamp = 4;  // milliseconds since epoch
  string error_message = 5;
}

// Request to track assessment progress
message ProgressRequest {
  string assessment_id = 1;
  string user_id = 2;
  double progress_percentage = 3;
  string current_section = 4;
  map<string, string> progress_data = 5;
}

// Response for progress tracking
message ProgressResponse {
  bool success = 1;
  string assessment_id = 2;
  double progress_percentage = 3;
  int64 estimated_completion_time = 4;  // milliseconds since epoch
  string error_message = 5;
}

// Request to add comments
message CommentsRequest {
  string assessment_id = 1;
  string user_id = 2;
  string comments = 3;
  bool append = 4;  // If true, append to existing comments, otherwise replace
}

// Request to add/get attachment
message AttachmentRequest {
  string assessment_id = 1;
  string attachment_name = 2;
  string content_type = 3;
  bytes data = 4;  // Only for AddAttachment
}

// Response for attachment operations
message AttachmentResponse {
  bool success = 1;
  string assessment_id = 2;
  string attachment_path = 3;
  string error_message = 4;
}

// Attachment data response
message AttachmentData {
  bool success = 1;
  string assessment_id = 2;
  string attachment_name = 3;
  string content_type = 4;
  bytes data = 5;
  string error_message = 6;
}
#include <drogon/drogon.h>
#include <json/json.h>
#include <openssl/sha.h>
#include <string>
#include <vector>
#include <chrono>
#include <memory>
#include <mutex>
#include "blockchain_verifier.h"
#include "regulatory_matrix.h"

namespace atp {
namespace compliance {

class AuditComplianceService : public drogon::HttpController<AuditComplianceService> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(AuditComplianceService::recordAuditEvent, "/api/audit/record", drogon::Post);
    ADD_METHOD_TO(AuditComplianceService::verifyAuditTrail, "/api/audit/verify", drogon::Post);
    ADD_METHOD_TO(AuditComplianceService::queryAuditLogs, "/api/audit/query", drogon::Post);
    ADD_METHOD_TO(AuditComplianceService::checkCompliance, "/api/compliance/check", drogon::Post);
    ADD_METHOD_TO(AuditComplianceService::trackComplianceChanges, "/api/compliance/changes", drogon::Post);
    ADD_METHOD_TO(AuditComplianceService::generateComplianceReport, "/api/compliance/report", drogon::Post);
    ADD_METHOD_TO(AuditComplianceService::detectComplianceImpact, "/api/compliance/impact", drogon::Post);
    METHOD_LIST_END

    AuditComplianceService();

    void recordAuditEvent(const drogon::HttpRequestPtr& req, 
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void verifyAuditTrail(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void queryAuditLogs(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void checkCompliance(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void trackComplianceChanges(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void generateComplianceReport(const drogon::HttpRequestPtr& req,
                                 std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void detectComplianceImpact(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback);

private:
    std::shared_ptr<BlockchainVerifier> blockchainVerifier_;
    std::shared_ptr<RegulatoryMatrix> regulatoryMatrix_;
    
    // Thread-safe audit log cache
    std::vector<Json::Value> auditLogCache_;
    std::mutex auditLogMutex_;
    
    // Maximum cache size before flushing to persistent storage
    const size_t MAX_CACHE_SIZE = 1000;
    
    // Helper methods
    std::string generateHash(const Json::Value& event);
    bool verifyHash(const std::string& hash, const Json::Value& event);
    void flushAuditLogCache();
    Json::Value enrichAuditEvent(const Json::Value& baseEvent, const drogon::HttpRequestPtr& req);
    Json::Value filterAuditLogs(const std::vector<Json::Value>& logs, const Json::Value& filters);
    Json::Value analyzeComplianceImpact(const Json::Value& changes, const std::string& regulationType);
};

AuditComplianceService::AuditComplianceService() {
    // Initialize components
    blockchainVerifier_ = std::make_shared<BlockchainVerifier>();
    regulatoryMatrix_ = std::make_shared<RegulatoryMatrix>();
    
    // Load regulatory frameworks
    regulatoryMatrix_->loadRegulatoryFrameworks();
}

void AuditComplianceService::recordAuditEvent(const drogon::HttpRequestPtr& req, 
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Enrich the event with metadata
        Json::Value enrichedEvent = enrichAuditEvent(*json, req);
        
        // Generate hash for integrity verification
        std::string eventHash = generateHash(enrichedEvent);
        enrichedEvent["hash"] = eventHash;
        
        // Add to blockchain for tamper-proof verification
        std::string blockId = blockchainVerifier_->addToChain(eventHash, enrichedEvent);
        enrichedEvent["block_id"] = blockId;
        
        // Store in cache
        {
            std::lock_guard<std::mutex> lock(auditLogMutex_);
            auditLogCache_.push_back(enrichedEvent);
            
            // Flush if cache reaches threshold
            if (auditLogCache_.size() >= MAX_CACHE_SIZE) {
                flushAuditLogCache();
            }
        }
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["event_id"] = enrichedEvent["event_id"];
        result["hash"] = eventHash;
        result["block_id"] = blockId;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AuditComplianceService::verifyAuditTrail(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string eventId = (*json)["event_id"].asString();
        
        // Retrieve event from storage
        Json::Value event = blockchainVerifier_->getEvent(eventId);
        
        if (event.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Event not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Verify hash for tampering detection
        std::string storedHash = event["hash"].asString();
        
        // Create a copy without the hash field for verification
        Json::Value eventForVerification = event;
        eventForVerification.removeMember("hash");
        eventForVerification.removeMember("block_id");
        
        std::string calculatedHash = generateHash(eventForVerification);
        bool hashValid = (calculatedHash == storedHash);
        
        // Verify blockchain integrity
        bool blockchainValid = blockchainVerifier_->verifyBlock(event["block_id"].asString());
        
        // Prepare response
        Json::Value result;
        result["event_id"] = eventId;
        result["hash_valid"] = hashValid;
        result["blockchain_valid"] = blockchainValid;
        result["overall_validity"] = (hashValid && blockchainValid);
        
        if (!hashValid || !blockchainValid) {
            result["tampering_detected"] = true;
            result["timestamp"] = drogon::utils::getFormattedDate();
        }
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AuditComplianceService::queryAuditLogs(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract query parameters
        Json::Value filters = (*json)["filters"];
        int limit = (*json)["limit"].asInt();
        int offset = (*json)["offset"].asInt();
        
        if (limit <= 0) limit = 100;  // Default limit
        if (offset < 0) offset = 0;   // Default offset
        
        // Get audit logs from storage
        std::vector<Json::Value> logs = blockchainVerifier_->getAuditLogs(limit, offset);
        
        // Apply filters if specified
        if (!filters.isNull()) {
            logs = filterAuditLogs(logs, filters);
        }
        
        // Prepare response
        Json::Value result;
        result["total"] = static_cast<int>(logs.size());
        
        Json::Value events(Json::arrayValue);
        for (const auto& log : logs) {
            events.append(log);
        }
        
        result["events"] = events;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AuditComplianceService::checkCompliance(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string entityType = (*json)["entity_type"].asString();
        std::string entityId = (*json)["entity_id"].asString();
        std::string regulationType = (*json)["regulation_type"].asString();
        
        // Get entity data for compliance checking
        Json::Value entityData = (*json)["entity_data"];
        
        // Check compliance against specified regulatory framework
        Json::Value complianceResult = regulatoryMatrix_->checkCompliance(
            entityType, entityData, regulationType
        );
        
        // Record compliance check in audit log
        Json::Value auditEvent;
        auditEvent["event_type"] = "compliance_check";
        auditEvent["entity_type"] = entityType;
        auditEvent["entity_id"] = entityId;
        auditEvent["regulation_type"] = regulationType;
        auditEvent["compliance_result"] = complianceResult["compliant"];
        
        // Asynchronously record audit event
        auto auditReq = drogon::HttpRequest::newHttpJsonRequest(auditEvent);
        recordAuditEvent(auditReq, [](const drogon::HttpResponsePtr&) {});
        
        // Prepare response
        Json::Value result;
        result["entity_id"] = entityId;
        result["regulation_type"] = regulationType;
        result["compliance_result"] = complianceResult;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AuditComplianceService::trackComplianceChanges(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string regulationType = (*json)["regulation_type"].asString();
        std::string entityType = (*json)["entity_type"].asString();
        std::string entityId = (*json)["entity_id"].asString();
        
        // Get dates for comparison
        std::string fromDate = (*json)["from_date"].asString();
        std::string toDate = (*json)["to_date"].asString();
        
        // Get compliance changes over time
        Json::Value changeHistory = regulatoryMatrix_->trackComplianceChanges(
            entityType, entityId, regulationType, fromDate, toDate
        );
        
        // Analyze trends
        bool improvingTrend = false;
        bool deterioratingTrend = false;
        
        if (changeHistory["changes"].size() > 1) {
            int positiveDelta = 0;
            int negativeDelta = 0;
            
            for (int i = 1; i < changeHistory["changes"].size(); ++i) {
                int prevCompliance = changeHistory["changes"][i-1]["compliance_percentage"].asInt();
                int currCompliance = changeHistory["changes"][i]["compliance_percentage"].asInt();
                
                if (currCompliance > prevCompliance) {
                    positiveDelta++;
                } else if (currCompliance < prevCompliance) {
                    negativeDelta++;
                }
            }
            
            improvingTrend = (positiveDelta > negativeDelta);
            deterioratingTrend = (negativeDelta > positiveDelta);
        }
        
        // Prepare response
        Json::Value result;
        result["entity_id"] = entityId;
        result["regulation_type"] = regulationType;
        result["change_history"] = changeHistory;
        result["improving_trend"] = improvingTrend;
        result["deteriorating_trend"] = deterioratingTrend;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AuditComplianceService::generateComplianceReport(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string reportType = (*json)["report_type"].asString();
        std::string regulationType = (*json)["regulation_type"].asString();
        std::string entityType = (*json)["entity_type"].asString();
        std::string entityId = (*json).get("entity_id", "").asString();
        
        // Optional date range
        std::string fromDate = (*json).get("from_date", "").asString();
        std::string toDate = (*json).get("to_date", "").asString();
        
        // Generate appropriate compliance report
        Json::Value report;
        
        if (reportType == "entity") {
            // Report for specific entity
            if (entityId.empty()) {
                throw std::runtime_error("Entity ID required for entity-level report");
            }
            
            report = regulatoryMatrix_->generateEntityReport(
                entityType, entityId, regulationType
            );
        }
        else if (reportType == "summary") {
            // Summary report across all entities of specified type
            report = regulatoryMatrix_->generateSummaryReport(
                entityType, regulationType, fromDate, toDate
            );
        }
        else if (reportType == "trend") {
            // Trend report over time
            if (fromDate.empty() || toDate.empty()) {
                throw std::runtime_error("Date range required for trend report");
            }
            
            report = regulatoryMatrix_->generateTrendReport(
                entityType, regulationType, fromDate, toDate
            );
        }
        else if (reportType == "gap") {
            // Gap analysis report
            report = regulatoryMatrix_->generateGapAnalysisReport(
                entityType, entityId, regulationType
            );
        }
        else {
            throw std::runtime_error("Unknown report type: " + reportType);
        }
        
        // Add metadata to report
        report["report_type"] = reportType;
        report["regulation_type"] = regulationType;
        report["entity_type"] = entityType;
        report["generated_at"] = drogon::utils::getFormattedDate();
        
        if (!entityId.empty()) {
            report["entity_id"] = entityId;
        }
        
        if (!fromDate.empty()) {
            report["from_date"] = fromDate;
        }
        
        if (!toDate.empty()) {
            report["to_date"] = toDate;
        }
        
        // Record report generation in audit log
        Json::Value auditEvent;
        auditEvent["event_type"] = "compliance_report_generated";
        auditEvent["report_type"] = reportType;
        auditEvent["regulation_type"] = regulationType;
        auditEvent["entity_type"] = entityType;
        
        if (!entityId.empty()) {
            auditEvent["entity_id"] = entityId;
        }
        
        // Asynchronously record audit event
        auto auditReq = drogon::HttpRequest::newHttpJsonRequest(auditEvent);
        recordAuditEvent(auditReq, [](const drogon::HttpResponsePtr&) {});
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(report);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void AuditComplianceService::detectComplianceImpact(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string entityType = (*json)["entity_type"].asString();
        std::string entityId = (*json)["entity_id"].asString();
        std::string regulationType = (*json)["regulation_type"].asString();
        
        // Get the proposed changes
        Json::Value currentState = (*json)["current_state"];
        Json::Value proposedChanges = (*json)["proposed_changes"];
        
        // Apply proposed changes to current state to create new state
        Json::Value newState = currentState;
        
        // Merge changes into new state
        for (const auto& key : proposedChanges.getMemberNames()) {
            newState[key] = proposedChanges[key];
        }
        
        // Check compliance for both states
        Json::Value currentCompliance = regulatoryMatrix_->checkCompliance(
            entityType, currentState, regulationType
        );
        
        Json::Value newCompliance = regulatoryMatrix_->checkCompliance(
            entityType, newState, regulationType
        );
        
        // Analyze impact of changes
        Json::Value impact = analyzeComplianceImpact(proposedChanges, regulationType);
        
        // Prepare response
        Json::Value result;
        result["entity_id"] = entityId;
        result["regulation_type"] = regulationType;
        result["current_compliance"] = currentCompliance;
        result["projected_compliance"] = newCompliance;
        result["impact_analysis"] = impact;
        
        // Determine overall impact
        bool hasNegativeImpact = false;
        bool hasPositiveImpact = false;
        
        for (const auto& item : impact) {
            if (item["impact_type"].asString() == "negative") {
                hasNegativeImpact = true;
            }
            else if (item["impact_type"].asString() == "positive") {
                hasPositiveImpact = true;
            }
        }
        
        if (hasNegativeImpact) {
            result["alert"] = "Proposed changes may negatively impact compliance";
            result["alert_level"] = "warning";
            
            if (newCompliance["compliant"].asBool() == false && 
                currentCompliance["compliant"].asBool() == true) {
                result["alert_level"] = "critical";
                result["alert"] = "Proposed changes will cause non-compliance";
            }
        }
        else if (hasPositiveImpact) {
            result["alert"] = "Proposed changes improve compliance";
            result["alert_level"] = "positive";
        }
        else {
            result["alert"] = "No significant compliance impact detected";
            result["alert_level"] = "info";
        }
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

// Helper methods
std::string AuditComplianceService::generateHash(const Json::Value& event) {
    // Convert JSON to string for hashing
    std::string eventStr = event.toStyledString();
    
    // Generate SHA-256 hash
    unsigned char hash[SHA256_DIGEST_LENGTH];
    SHA256(reinterpret_cast<const unsigned char*>(eventStr.c_str()), eventStr.length(), hash);
    
    // Convert hash to hexadecimal string
    std::stringstream ss;
    for (int i = 0; i < SHA256_DIGEST_LENGTH; ++i) {
        ss << std::hex << std::setw(2) << std::setfill('0') << static_cast<int>(hash[i]);
    }
    
    return ss.str();
}

bool AuditComplianceService::verifyHash(const std::string& hash, const Json::Value& event) {
    // Regenerate hash and compare
    std::string calculatedHash = generateHash(event);
    return (calculatedHash == hash);
}

void AuditComplianceService::flushAuditLogCache() {
    // In production, this would persist logs to a database
    // For this example, we're simulating persistence
    
    std::lock_guard<std::mutex> lock(auditLogMutex_);
    
    // Process each cached log
    for (const auto& log : auditLogCache_) {
        // In production, this would be a database write operation
        // Here we're just ensuring the logs are recorded in the blockchain
        blockchainVerifier_->ensurePersisted(log["event_id"].asString());
    }
    
    // Clear cache after flushing
    auditLogCache_.clear();
}

Json::Value AuditComplianceService::enrichAuditEvent(const Json::Value& baseEvent, const drogon::HttpRequestPtr& req) {
    Json::Value enrichedEvent = baseEvent;
    
    // Add timestamp if not present
    if (!enrichedEvent.isMember("timestamp")) {
        enrichedEvent["timestamp"] = drogon::utils::getFormattedDate();
    }
    
    // Add event ID if not present
    if (!enrichedEvent.isMember("event_id")) {
        // Generate a unique ID (e.g., UUID)
        std::string eventId = generateUniqueId();
        enrichedEvent["event_id"] = eventId;
    }
    
    // Add source information
    if (!enrichedEvent.isMember("source")) {
        Json::Value source;
        source["ip_address"] = req->getPeerAddr().toIp();
        
        // Get user information from request (assuming authentication is in place)
        auto userIdPtr = req->getAttributes()->find("user_id");
        if (userIdPtr) {
            source["user_id"] = *any_cast<std::string>(userIdPtr);
        }
        
        enrichedEvent["source"] = source;
    }
    
    return enrichedEvent;
}

std::string AuditComplianceService::generateUniqueId() {
    // Implementation for generating a unique ID (e.g., UUID)
    // This is a simplified version for illustration
    auto now = std::chrono::system_clock::now();
    auto now_ms = std::chrono::time_point_cast<std::chrono::milliseconds>(now);
    auto epoch = now_ms.time_since_epoch();
    uint64_t timestamp = static_cast<uint64_t>(epoch.count());
    
    // Combine timestamp with a random number
    std::random_device rd;
    std::mt19937_64 gen(rd());
    std::uniform_int_distribution<uint64_t> dist;
    uint64_t random = dist(gen);
    
    std::stringstream ss;
    ss << std::hex << timestamp << "-" << random;
    return ss.str();
}

Json::Value AuditComplianceService::filterAuditLogs(const std::vector<Json::Value>& logs, const Json::Value& filters) {
    std::vector<Json::Value> filteredLogs;
    
    // Apply filters to each log
    for (const auto& log : logs) {
        bool matchesAllFilters = true;
        
        // Check each filter condition
        for (const auto& filterKey : filters.getMemberNames()) {
            if (log.isMember(filterKey)) {
                // Simple string equality for now
                // In production, this would support more complex filtering
                if (log[filterKey].asString() != filters[filterKey].asString()) {
                    matchesAllFilters = false;
                    break;
                }
            }
            else {
                // Filter key doesn't exist in log
                matchesAllFilters = false;
                break;
            }
        }
        
        if (matchesAllFilters) {
            filteredLogs.push_back(log);
        }
    }
    
    // Convert to JSON array
    Json::Value result(Json::arrayValue);
    for (const auto& log : filteredLogs) {
        result.append(log);
    }
    
    return result;
}

Json::Value AuditComplianceService::analyzeComplianceImpact(const Json::Value& changes, const std::string& regulationType) {
    // In a real implementation, this would analyze specific regulatory impacts
    // For now, we'll use a simplified approach
    
    Json::Value impacts(Json::arrayValue);
    
    // Get regulatory requirements for the specified type
    auto requirements = regulatoryMatrix_->getRegulatoryRequirements(regulationType);
    
    // Check each change against requirements
    for (const auto& key : changes.getMemberNames()) {
        for (const auto& req : requirements) {
            // Check if this change affects the requirement
            if (req["affects_field"].asString() == key) {
                Json::Value impact;
                impact["requirement_id"] = req["id"];
                impact["requirement_description"] = req["description"];
                impact["field"] = key;
                
                // Determine impact type (simplified logic)
                if (req["allowed_values"].isArray()) {
                    bool inAllowedValues = false;
                    
                    for (const auto& allowedValue : req["allowed_values"]) {
                        if (changes[key].asString() == allowedValue.asString()) {
                            inAllowedValues = true;
                            break;
                        }
                    }
                    
                    if (inAllowedValues) {
                        impact["impact_type"] = "positive";
                        impact["description"] = "Change aligns with regulatory requirement";
                    }
                    else {
                        impact["impact_type"] = "negative";
                        impact["description"] = "Change may violate regulatory requirement";
                    }
                }
                else if (req["min_value"].isNumeric() && changes[key].isNumeric()) {
                    if (changes[key].asDouble() < req["min_value"].asDouble()) {
                        impact["impact_type"] = "negative";
                        impact["description"] = "Value below required minimum";
                    }
                    else if (req["max_value"].isNumeric() && changes[key].asDouble() > req["max_value"].asDouble()) {
                        impact["impact_type"] = "negative";
                        impact["description"] = "Value above allowed maximum";
                    }
                    else {
                        impact["impact_type"] = "positive";
                        impact["description"] = "Value within allowed range";
                    }
                }
                else {
                    impact["impact_type"] = "unknown";
                    impact["description"] = "Cannot determine impact automatically";
                }
                
                impacts.append(impact);
            }
        }
    }
    
    return impacts;
}

} // namespace compliance
} // namespace atp

// Main application entry point
int main() {
    // Configure Drogon app
    drogon::app().setLogPath("./")
                 .setLogLevel(trantor::Logger::kInfo)
                 .addListener("0.0.0.0", 8082)
                 .setThreadNum(16)
                 .run();
    
    return 0;
}

// /backend/collaboration/include/collaboration/CollaborationService.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <unordered_map>
#include <chrono>
#include <mutex>
#include <drogon/HttpController.h>
#include "core/ConfigurationManager.h"
#include "user-management/UserManager.h"
#include "database/DatabaseManager.h"
#include "collaboration/WorkspaceManager.h"
#include "collaboration/Message.h"
#include "collaboration/WebSocketHandler.h"
#include "collaboration/NotificationService.h"

namespace Collaboration {

class CollaborationService {
public:
    CollaborationService(
        std::shared_ptr<Core::ConfigurationManager> config,
        std::shared_ptr<User::UserManager> userManager,
        std::shared_ptr<Database::DatabaseManager> dbManager
    );
    ~CollaborationService();

    // Workspace management
    std::shared_ptr<Workspace> createWorkspace(const std::string& name, const std::string& ownerId);
    std::shared_ptr<Workspace> getWorkspace(const std::string& workspaceId);
    bool deleteWorkspace(const std::string& workspaceId, const std::string& userId);
    std::vector<std::shared_ptr<Workspace>> getUserWorkspaces(const std::string& userId);
    
    // Workspace sharing & access control
    bool addUserToWorkspace(const std::string& workspaceId, const std::string& userId, WorkspaceRole role);
    bool removeUserFromWorkspace(const std::string& workspaceId, const std::string& userId);
    bool updateUserRole(const std::string& workspaceId, const std::string& userId, WorkspaceRole newRole);
    std::vector<WorkspaceUser> getWorkspaceUsers(const std::string& workspaceId);
    
    // Real-time collaboration
    bool startCollaborationSession(const std::string& workspaceId, const std::string& userId);
    bool endCollaborationSession(const std::string& workspaceId, const std::string& userId);
    std::vector<std::string> getActiveUsers(const std::string& workspaceId);
    
    // Messaging
    MessageId sendMessage(const std::string& workspaceId, const std::string& senderId, 
                         const std::string& content, MessageType type = MessageType::TEXT);
    std::vector<Message> getMessages(const std::string& workspaceId, 
                                    std::chrono::system_clock::time_point since,
                                    int limit = 50);
    
    // Document collaboration
    bool lockDocument(const std::string& docId, const std::string& userId);
    bool unlockDocument(const std::string& docId, const std::string& userId);
    bool applyDocumentChange(const std::string& docId, const DocumentChange& change);
    std::vector<DocumentChange> getDocumentChanges(const std::string& docId, 
                                                 int sinceVersion = -1);
    
    // Version control
    VersionId createVersion(const std::string& docId, const std::string& userId, 
                           const std::string& comment);
    std::vector<Version> getVersionHistory(const std::string& docId);
    bool revertToVersion(const std::string& docId, VersionId versionId, 
                        const std::string& userId);
                        
    // Notifications
    void registerForNotifications(const std::string& userId, const std::string& endpoint);
    void unregisterFromNotifications(const std::string& userId, const std::string& endpoint);
    void sendNotification(const std::string& targetUserId, const Notification& notification);

private:
    std::shared_ptr<Core::ConfigurationManager> config_;
    std::shared_ptr<User::UserManager> userManager_;
    std::shared_ptr<Database::DatabaseManager> dbManager_;
    std::shared_ptr<WorkspaceManager> workspaceManager_;
    std::shared_ptr<WebSocketHandler> wsHandler_;
    std::shared_ptr<NotificationService> notificationService_;
    
    // Cache of active users per workspace
    std::unordered_map<std::string, std::unordered_set<std::string>> activeUsers_;
    std::mutex activeUsersMutex_;
    
    bool validateUserAccess(const std::string& workspaceId, const std::string& userId, 
                           WorkspaceRole requiredRole);
    void broadcastToWorkspace(const std::string& workspaceId, const std::string& event,
                             const std::string& data);
};

} // namespace Collaboration

// /backend/collaboration/include/collaboration/WorkspaceManager.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <unordered_map>
#include "collaboration/Workspace.h"
#include "database/DatabaseManager.h"

namespace Collaboration {

class WorkspaceManager {
public:
    explicit WorkspaceManager(std::shared_ptr<Database::DatabaseManager> dbManager);
    ~WorkspaceManager();
    
    // Workspace CRUD operations
    std::shared_ptr<Workspace> createWorkspace(const std::string& name, const std::string& ownerId);
    std::shared_ptr<Workspace> getWorkspace(const std::string& workspaceId);
    bool updateWorkspace(const std::shared_ptr<Workspace>& workspace);
    bool deleteWorkspace(const std::string& workspaceId);
    
    // User workspace queries
    std::vector<std::shared_ptr<Workspace>> getUserWorkspaces(const std::string& userId);
    
    // Cache management
    void refreshCache();
    void invalidateWorkspaceCache(const std::string& workspaceId);

private:
    std::shared_ptr<Database::DatabaseManager> dbManager_;
    std::unordered_map<std::string, std::shared_ptr<Workspace>> workspaceCache_;
    std::mutex cacheMutex_;
    
    std::shared_ptr<Workspace> loadWorkspaceFromDb(const std::string& workspaceId);
    bool saveWorkspaceToDb(const std::shared_ptr<Workspace>& workspace);
};

} // namespace Collaboration

// /backend/collaboration/include/collaboration/Message.h
#pragma once

#include <string>
#include <chrono>
#include <vector>
#include <optional>
#include <nlohmann/json.hpp>

namespace Collaboration {

using MessageId = std::string;

enum class MessageType {
    TEXT,
    FILE,
    SYSTEM,
    NOTIFICATION
};

struct MessageAttachment {
    std::string fileId;
    std::string fileName;
    std::string mimeType;
    size_t fileSize;
    
    nlohmann::json toJson() const;
    static MessageAttachment fromJson(const nlohmann::json& json);
};

class Message {
public:
    Message(
        const std::string& workspaceId,
        const std::string& senderId,
        const std::string& content,
        MessageType type = MessageType::TEXT
    );
    
    // Getters
    MessageId getId() const { return id_; }
    std::string getWorkspaceId() const { return workspaceId_; }
    std::string getSenderId() const { return senderId_; }
    std::string getContent() const { return content_; }
    MessageType getType() const { return type_; }
    std::chrono::system_clock::time_point getTimestamp() const { return timestamp_; }
    const std::optional<MessageAttachment>& getAttachment() const { return attachment_; }
    
    // Setters
    void setAttachment(const MessageAttachment& attachment) { attachment_ = attachment; }
    
    // Serialization
    nlohmann::json toJson() const;
    static Message fromJson(const nlohmann::json& json);

private:
    MessageId id_;
    std::string workspaceId_;
    std::string senderId_;
    std::string content_;
    MessageType type_;
    std::chrono::system_clock::time_point timestamp_;
    std::optional<MessageAttachment> attachment_;
};

} // namespace Collaboration

// /backend/collaboration/include/collaboration/WebSocketHandler.h
#pragma once

#include <string>
#include <unordered_map>
#include <unordered_set>
#include <mutex>
#include <functional>
#include <drogon/WebSocketController.h>
#include "user-management/UserManager.h"

namespace Collaboration {

class WebSocketHandler : public drogon::WebSocketController<WebSocketHandler> {
public:
    explicit WebSocketHandler(std::shared_ptr<User::UserManager> userManager);
    
    // WebSocket controller handlers
    void handleNewConnection(const drogon::HttpRequestPtr& req, 
                            const drogon::WebSocketConnectionPtr& conn) override;
    void handleNewMessage(const drogon::WebSocketConnectionPtr& conn,
                         std::string&& message,
                         const drogon::WebSocketMessageType& type) override;
    void handleConnectionClosed(const drogon::WebSocketConnectionPtr& conn) override;
    
    // Message broadcasting methods
    void broadcastToUser(const std::string& userId, const std::string& message);
    void broadcastToWorkspace(const std::string& workspaceId, const std::string& message);
    void broadcastToAll(const std::string& message);
    
    // Connection management
    void registerConnection(const std::string& userId, const std::string& workspaceId,
                          const drogon::WebSocketConnectionPtr& conn);
    void unregisterConnection(const drogon::WebSocketConnectionPtr& conn);
    
    // Event handling
    using MessageHandler = std::function<void(const std::string&, const std::string&, const std::string&)>;
    void registerMessageHandler(const std::string& eventType, MessageHandler handler);

    WS_PATH_LIST_BEGIN
    WS_PATH_ADD("/ws/collaboration", drogon::Get);
    WS_PATH_LIST_END

private:
    std::shared_ptr<User::UserManager> userManager_;
    
    // Connection mappings
    std::unordered_map<drogon::WebSocketConnectionPtr, std::string> connToUserId_;
    std::unordered_map<drogon::WebSocketConnectionPtr, std::string> connToWorkspaceId_;
    std::unordered_map<std::string, std::unordered_set<drogon::WebSocketConnectionPtr>> userIdToConns_;
    std::unordered_map<std::string, std::unordered_set<drogon::WebSocketConnectionPtr>> workspaceIdToConns_;
    
    // Event handlers
    std::unordered_map<std::string, std::vector<MessageHandler>> eventHandlers_;
    
    // Thread safety
    std::mutex mutex_;
    
    // Helper methods
    bool validateToken(const std::string& token, std::string& userId);
    void processMessage(const drogon::WebSocketConnectionPtr& conn, const std::string& message);
};

} // namespace Collaboration

// /backend/collaboration/include/collaboration/NotificationService.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <unordered_map>
#include <mutex>
#include "core/ConfigurationManager.h"
#include "database/DatabaseManager.h"

namespace Collaboration {

enum class NotificationType {
    MESSAGE,
    DOCUMENT_CHANGE,
    WORKSPACE_INVITATION,
    SYSTEM,
    ASSESSMENT_COMPLETED
};

struct Notification {
    std::string id;
    std::string targetUserId;
    std::string title;
    std::string content;
    NotificationType type;
    std::string sourceId; // workspaceId, documentId, etc.
    std::chrono::system_clock::time_point timestamp;
    bool read = false;
    
    nlohmann::json toJson() const;
    static Notification fromJson(const nlohmann::json& json);
};

class NotificationService {
public:
    NotificationService(
        std::shared_ptr<Core::ConfigurationManager> config,
        std::shared_ptr<Database::DatabaseManager> dbManager
    );
    ~NotificationService();
    
    // Notification management
    std::string createNotification(const Notification& notification);
    bool markAsRead(const std::string& notificationId, const std::string& userId);
    bool markAllAsRead(const std::string& userId);
    bool deleteNotification(const std::string& notificationId, const std::string& userId);
    
    // Query methods
    std::vector<Notification> getUserNotifications(
        const std::string& userId, 
        bool unreadOnly = false,
        int limit = 20
    );
    
    // Push notification registration
    bool registerDevice(const std::string& userId, const std::string& deviceToken,
                      const std::string& platform);
    bool unregisterDevice(const std::string& deviceToken);
    
    // Send notifications
    bool sendPushNotification(const Notification& notification);
    bool sendEmailNotification(const Notification& notification);

private:
    std::shared_ptr<Core::ConfigurationManager> config_;
    std::shared_ptr<Database::DatabaseManager> dbManager_;
    
    // In-memory cache of pending notifications
    std::unordered_map<std::string, std::vector<Notification>> pendingNotifications_;
    std::mutex notificationMutex_;
    
    // Helper methods
    bool storeNotification(const Notification& notification);
    std::vector<std::string> getUserDeviceTokens(const std::string& userId);
};

} // namespace Collaboration

// /backend/collaboration/src/CollaborationService.cpp
#include "collaboration/CollaborationService.h"
#include <spdlog/spdlog.h>
#include <uuid/uuid.h>

namespace Collaboration {

CollaborationService::CollaborationService(
    std::shared_ptr<Core::ConfigurationManager> config,
    std::shared_ptr<User::UserManager> userManager,
    std::shared_ptr<Database::DatabaseManager> dbManager
) : config_(config), userManager_(userManager), dbManager_(dbManager) {
    // Initialize workspace manager
    workspaceManager_ = std::make_shared<WorkspaceManager>(dbManager_);
    
    // Initialize WebSocket handler
    wsHandler_ = std::make_shared<WebSocketHandler>(userManager_);
    
    // Initialize notification service
    notificationService_ = std::make_shared<NotificationService>(config_, dbManager_);
    
    // Register message handlers
    wsHandler_->registerMessageHandler("document_change", 
        [this](const std::string& userId, const std::string& workspaceId, const std::string& data) {
            // Process document change event
            spdlog::debug("Received document change from user {} in workspace {}", userId, workspaceId);
            
            // Parse the document change data
            auto jsonData = nlohmann::json::parse(data);
            std::string docId = jsonData["documentId"];
            DocumentChange change = DocumentChange::fromJson(jsonData["change"]);
            
            // Apply the change
            this->applyDocumentChange(docId, change);
            
            // Broadcast to other users in the workspace
            this->broadcastToWorkspace(workspaceId, "document_updated", data);
        }
    );
    
    wsHandler_->registerMessageHandler("message", 
        [this](const std::string& userId, const std::string& workspaceId, const std::string& data) {
            // Process new message event
            spdlog::debug("Received message from user {} in workspace {}", userId, workspaceId);
            
            // Parse message data
            auto jsonData = nlohmann::json::parse(data);
            std::string content = jsonData["content"];
            MessageType type = static_cast<MessageType>(jsonData["type"].get<int>());
            
            // Save the message
            MessageId msgId = this->sendMessage(workspaceId, userId, content, type);
            
            // Add message ID to response
            nlohmann::json response = jsonData;
            response["id"] = msgId;
            response["timestamp"] = std::chrono::system_clock::now().time_since_epoch().count();
            
            // Broadcast to workspace
            this->broadcastToWorkspace(workspaceId, "new_message", response.dump());
        }
    );
    
    spdlog::info("Collaboration service initialized");
}

CollaborationService::~CollaborationService() {
    spdlog::info("Collaboration service shutting down");
}

std::shared_ptr<Workspace> CollaborationService::createWorkspace(
    const std::string& name, const std::string& ownerId
) {
    // Validate user exists
    if (!userManager_->userExists(ownerId)) {
        spdlog::error("Cannot create workspace: user {} does not exist", ownerId);
        return nullptr;
    }
    
    // Create the workspace
    auto workspace = workspaceManager_->createWorkspace(name, ownerId);
    if (workspace) {
        spdlog::info("Created workspace {} with name {} for owner {}", 
                  workspace->getId(), name, ownerId);
    }
    
    return workspace;
}

std::shared_ptr<Workspace> CollaborationService::getWorkspace(const std::string& workspaceId) {
    return workspaceManager_->getWorkspace(workspaceId);
}

bool CollaborationService::deleteWorkspace(const std::string& workspaceId, const std::string& userId) {
    // Get the workspace
    auto workspace = workspaceManager_->getWorkspace(workspaceId);
    if (!workspace) {
        spdlog::error("Cannot delete workspace {}: not found", workspaceId);
        return false;
    }
    
    // Verify user is the owner
    if (workspace->getOwnerId() != userId) {
        spdlog::error("User {} is not authorized to delete workspace {}", userId, workspaceId);
        return false;
    }
    
    // Delete the workspace
    bool success = workspaceManager_->deleteWorkspace(workspaceId);
    if (success) {
        spdlog::info("Deleted workspace {} owned by {}", workspaceId, userId);
        
        // Notify all workspace users
        for (const auto& user : workspace->getUsers()) {
            if (user.userId != userId) {  // Don't notify the deleter
                Notification notification{
                    .targetUserId = user.userId,
                    .title = "Workspace Deleted",
                    .content = "The workspace '" + workspace->getName() + "' has been deleted.",
                    .type = NotificationType::SYSTEM,
                    .sourceId = workspaceId,
                    .timestamp = std::chrono::system_clock::now()
                };
                notificationService_->createNotification(notification);
            }
        }
    }
    
    return success;
}

std::vector<std::shared_ptr<Workspace>> CollaborationService::getUserWorkspaces(
    const std::string& userId
) {
    return workspaceManager_->getUserWorkspaces(userId);
}

bool CollaborationService::addUserToWorkspace(
    const std::string& workspaceId, const std::string& userId, WorkspaceRole role
) {
    // Validate user exists
    if (!userManager_->userExists(userId)) {
        spdlog::error("Cannot add user to workspace: user {} does not exist", userId);
        return false;
    }
    
    // Get the workspace
    auto workspace = workspaceManager_->getWorkspace(workspaceId);
    if (!workspace) {
        spdlog::error("Cannot add user to workspace {}: workspace not found", workspaceId);
        return false;
    }
    
    // Add the user
    bool success = workspace->addUser(userId, role);
    if (success) {
        // Update the workspace
        workspaceManager_->updateWorkspace(workspace);
        spdlog::info("Added user {} to workspace {} with role {}", 
                  userId, workspaceId, static_cast<int>(role));
        
        // Notify the user
        auto userName = userManager_->getUserName(userId);
        Notification notification{
            .targetUserId = userId,
            .title = "Workspace Invitation",
            .content = "You have been added to workspace '" + workspace->getName() + "'.",
            .type = NotificationType::WORKSPACE_INVITATION,
            .sourceId = workspaceId,
            .timestamp = std::chrono::system_clock::now()
        };
        notificationService_->createNotification(notification);
        
        // Broadcast to workspace users
        nlohmann::json data = {
            {"userId", userId},
            {"userName", userName},
            {"role", static_cast<int>(role)}
        };
        broadcastToWorkspace(workspaceId, "user_added", data.dump());
    }
    
    return success;
}

bool CollaborationService::removeUserFromWorkspace(
    const std::string& workspaceId, const std::string& userId
) {
    // Get the workspace
    auto workspace = workspaceManager_->getWorkspace(workspaceId);
    if (!workspace) {
        spdlog::error("Cannot remove user from workspace {}: workspace not found", workspaceId);
        return false;
    }
    
    // Remove the user
    bool success = workspace->removeUser(userId);
    if (success) {
        // Update the workspace
        workspaceManager_->updateWorkspace(workspace);
        spdlog::info("Removed user {} from workspace {}", userId, workspaceId);
        
        // Notify the user
        Notification notification{
            .targetUserId = userId,
            .title = "Workspace Removal",
            .content = "You have been removed from workspace '" + workspace->getName() + "'.",
            .type = NotificationType::SYSTEM,
            .sourceId = workspaceId,
            .timestamp = std::chrono::system_clock::now()
        };
        notificationService_->createNotification(notification);
        
        // Broadcast to workspace users
        nlohmann::json data = {
            {"userId", userId}
        };
        broadcastToWorkspace(workspaceId, "user_removed", data.dump());
    }
    
    return success;
}

bool CollaborationService::updateUserRole(
    const std::string& workspaceId, const std::string& userId, WorkspaceRole newRole
) {
    // Get the workspace
    auto workspace = workspaceManager_->getWorkspace(workspaceId);
    if (!workspace) {
        spdlog::error("Cannot update user role in workspace {}: workspace not found", workspaceId);
        return false;
    }
    
    // Update the role
    bool success = workspace->updateUserRole(userId, newRole);
    if (success) {
        // Update the workspace
        workspaceManager_->updateWorkspace(workspace);
        spdlog::info("Updated role for user {} in workspace {} to {}", 
                  userId, workspaceId, static_cast<int>(newRole));
        
        // Broadcast to workspace users
        nlohmann::json data = {
            {"userId", userId},
            {"role", static_cast<int>(newRole)}
        };
        broadcastToWorkspace(workspaceId, "user_role_updated", data.dump());
    }
    
    return success;
}

std::vector<WorkspaceUser> CollaborationService::getWorkspaceUsers(const std::string& workspaceId) {
    auto workspace = workspaceManager_->getWorkspace(workspaceId);
    if (!workspace) {
        spdlog::error("Cannot get users for workspace {}: workspace not found", workspaceId);
        return {};
    }
    
    return workspace->getUsers();
}

// ... Additional method implementations would follow ...

bool CollaborationService::validateUserAccess(
    const std::string& workspaceId, const std::string& userId, WorkspaceRole requiredRole
) {
    auto workspace = workspaceManager_->getWorkspace(workspaceId);
    if (!workspace) {
        return false;
    }
    
    auto userRole = workspace->getUserRole(userId);
    if (!userRole.has_value()) {
        return false;
    }
    
    return static_cast<int>(userRole.value()) >= static_cast<int>(requiredRole);
}

void CollaborationService::broadcastToWorkspace(
    const std::string& workspaceId, const std::string& event, const std::string& data
) {
    nlohmann::json message = {
        {"event", event},
        {"data", nlohmann::json::parse(data)}
    };
    
    wsHandler_->broadcastToWorkspace(workspaceId, message.dump());
}

} // namespace Collaboration

// /backend/collaboration/src/Message.cpp
#include "collaboration/Message.h"
#include <uuid/uuid.h>

namespace Collaboration {

Message::Message(
    const std::string& workspaceId,
    const std::string& senderId,
    const std::string& content,
    MessageType type
) : workspaceId_(workspaceId),
    senderId_(senderId),
    content_(content),
    type_(type),
    timestamp_(std::chrono::system_clock::now()) {
    
    // Generate unique ID
    uuid_t uuid;
    uuid_generate(uuid);
    char uuid_str[37];
    uuid_unparse_lower(uuid, uuid_str);
    id_ = uuid_str;
}

nlohmann::json Message::toJson() const {
    nlohmann::json json = {
        {"id", id_},
        {"workspaceId", workspaceId_},
        {"senderId", senderId_},
        {"content", content_},
        {"type", static_cast<int>(type_)},
        {"timestamp", timestamp_.time_since_epoch().count()}
    };
    
    if (attachment_.has_value()) {
        json["attachment"] = attachment_->toJson();
    }
    
    return json;
}

Message Message::fromJson(const nlohmann::json& json) {
    Message message(
        json["workspaceId"].get<std::string>(),
        json["senderId"].get<std::string>(),
        json["content"].get<std::string>(),
        static_cast<MessageType>(json["type"].get<int>())
    );
    
    message.id_ = json["id"].get<std::string>();
    message.timestamp_ = std::chrono::system_clock::time_point(
        std::chrono::milliseconds(json["timestamp"].get<int64_t>())
    );
    
    if (json.contains("attachment")) {
        message.attachment_ = MessageAttachment::fromJson(json["attachment"]);
    }
    
    return message;
}

nlohmann::json MessageAttachment::toJson() const {
    return {
        {"fileId", fileId},
        {"fileName", fileName},
        {"mimeType", mimeType},
        {"fileSize", fileSize}
    };
}

MessageAttachment MessageAttachment::fromJson(const nlohmann::json& json) {
    return {
        .fileId = json["fileId"].get<std::string>(),
        .fileName = json["fileName"].get<std::string>(),
        .mimeType = json["mimeType"].get<std::string>(),
        .fileSize = json["fileSize"].get<size_t>()
    };
}

} // namespace Collaboration

// /backend/collaboration/include/collaboration/CollaborationController.h
#pragma once

#include <drogon/HttpController.h>
#include <memory>
#include "collaboration/CollaborationService.h"

namespace Collaboration {

class CollaborationController : public drogon::HttpController<CollaborationController> {
public:
    CollaborationController(std::shared_ptr<CollaborationService> service);
    
    // Workspace management
    void createWorkspace(const drogon::HttpRequestPtr& req, 
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void getWorkspace(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void deleteWorkspace(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void getUserWorkspaces(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Workspace users
    void addUserToWorkspace(const drogon::HttpRequestPtr& req,
                           std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void removeUserFromWorkspace(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void updateUserRole(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void getWorkspaceUsers(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Messaging
    void getMessages(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Document collaboration
    void getDocumentChanges(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void getVersionHistory(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void revertToVersion(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Notifications
    void getUserNotifications(const drogon::HttpRequestPtr& req,
                            std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void markNotificationAsRead(const drogon::HttpRequestPtr& req,
                              std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void markAllNotificationsAsRead(const drogon::HttpRequestPtr& req,
                                  std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    void registerDeviceForNotifications(const drogon::HttpRequestPtr& req,
                                      std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Route registration
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(CollaborationController::createWorkspace, "/api/workspaces", drogon::Post);
    ADD_METHOD_TO(CollaborationController::getWorkspace, "/api/workspaces/{id}", drogon::Get);
    ADD_METHOD_TO(CollaborationController::deleteWorkspace, "/api/workspaces/{id}", drogon::Delete);
    ADD_METHOD_TO(CollaborationController::getUserWorkspaces, "/api/users/{id}/workspaces", drogon::Get);
    
    ADD_METHOD_TO(CollaborationController::addUserToWorkspace, "/api/workspaces/{id}/users", drogon::Post);
    ADD_METHOD_TO(CollaborationController::removeUserFromWorkspace, "/api/workspaces/{id}/users/{userId}", drogon::Delete);
    ADD_METHOD_TO(CollaborationController::updateUserRole, "/api/workspaces/{id}/users/{userId}/role", drogon::Put);
    ADD_METHOD_TO(CollaborationController::getWorkspaceUsers, "/api/workspaces/{id}/users", drogon::Get);
    
    ADD_METHOD_TO(CollaborationController::getMessages, "/api/workspaces/{id}/messages", drogon::Get);
    
    ADD_METHOD_TO(CollaborationController::getDocumentChanges, "/api/documents/{id}/changes", drogon::Get);
    ADD_METHOD_TO(CollaborationController::getVersionHistory, "/api/documents/{id}/versions", drogon::Get);
    ADD_METHOD_TO(CollaborationController::revertToVersion, "/api/documents/{id}/versions/{versionId}/revert", drogon::Post);
    
    ADD_METHOD_TO(CollaborationController::getUserNotifications, "/api/users/{id}/notifications", drogon::Get);
    ADD_METHOD_TO(CollaborationController::markNotificationAsRead, "/api/notifications/{id}/read", drogon::Put);
    ADD_METHOD_TO(CollaborationController::markAllNotificationsAsRead, "/api/users/{id}/notifications/read", drogon::Put);
    ADD_METHOD_TO(CollaborationController::registerDeviceForNotifications, "/api/users/{id}/devices", drogon::Post);
    METHOD_LIST_END

private:
    std::shared_ptr<CollaborationService> service_;
    
    // Helper methods
    std::string getUserIdFromRequest(const drogon::HttpRequestPtr& req);
    bool validateRequest(const drogon::HttpRequestPtr& req, std::string& userId);
    drogon::HttpResponsePtr createErrorResponse(int statusCode, const std::string& message);
    drogon::HttpResponsePtr createJsonResponse(int statusCode, const nlohmann::json& data);
};

} // namespace Collaboration

// /backend/collaboration/python/ai_chat_assistant.py
import os
import json
import datetime
import threading
import time
from typing import Dict, List, Optional, Tuple

import numpy as np
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

class ChatAssistant:
    """AI-powered chat assistant for collaborative flight training.
    
    This assistant helps instructors and trainees with:
    - Answering technical questions about aircraft and procedures
    - Providing context-aware suggestions during document editing
    - Summarizing conversations and generating action items
    - Facilitating knowledge sharing between trainees
    """
    
    def __init__(self, model_path: str = "flight_training_gpt"):
        """Initialize the chat assistant with the specified model.
        
        Args:
            model_path: Path to the fine-tuned model
        """
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = TFAutoModelForCausalLM.from_pretrained(model_path)
        
        # Cache for workspace context
        self.workspace_contexts: Dict[str, Dict] = {}
        self.context_lock = threading.Lock()
        
        # Start context cleanup thread
        self.cleanup_thread = threading.Thread(target=self._periodic_cleanup, daemon=True)
        self.cleanup_thread.start()
    
    def process_message(self, workspace_id: str, user_id: str, 
                        message: str) -> Tuple[str, List[Dict]]:
        """Process a user message and generate a response.
        
        Args:
            workspace_id: ID of the workspace
            user_id: ID of the user sending the message
            message: Content of the message
            
        Returns:
            Tuple of (response_text, suggested_actions)
        """
        # Get or create workspace context
        context = self._get_workspace_context(workspace_id)
        
        # Add message to conversation history
        context["messages"].append({
            "user_id": user_id,
            "content": message,
            "timestamp": datetime.datetime.now().isoformat()
        })
        
        # Format conversation for the model
        prompt = self._format_conversation(context)
        
        # Generate response
        response = self._generate_response(prompt)
        
        # Extract suggested actions if any
        suggested_actions = self._extract_actions(response)
        
        # Clean response if needed
        cleaned_response = self._clean_response(response)
        
        # Add assistant's response to conversation history
        context["messages"].append({
            "user_id": "assistant",
            "content": cleaned_response,
            "timestamp": datetime.datetime.now().isoformat()
        })
        
        # Limit conversation history size
        if len(context["messages"]) > 100:
            context["messages"] = context["messages"][-100:]
        
        return cleaned_response, suggested_actions
    
    def update_workspace_context(self, workspace_id: str, 
                                documents: List[Dict], 
                                syllabus: Optional[Dict] = None):
        """Update the context for a workspace with relevant documents and syllabus.
        
        Args:
            workspace_id: ID of the workspace
            documents: List of documents in the workspace
            syllabus: Current syllabus if available
        """
        with self.context_lock:
            context = self._get_workspace_context(workspace_id)
            
            # Update document references
            context["documents"] = [{
                "id": doc["id"],
                "title": doc["title"],
                "summary": doc.get("summary", ""),
                "type": doc.get("type", "")
            } for doc in documents]
            
            # Update syllabus if provided
            if syllabus:
                context["syllabus"] = {
                    "id": syllabus["id"],
                    "title": syllabus["title"],
                    "modules": [m["title"] for m in syllabus.get("modules", [])]
                }
            
            # Update last activity timestamp
            context["last_activity"] = datetime.datetime.now().isoformat()
    
    def summarize_conversation(self, workspace_id: str, 
                              time_period: Optional[str] = "1d") -> Dict:
        """Generate a summary of recent conversation in the workspace.
        
        Args:
            workspace_id: ID of the workspace
            time_period: Time period to summarize (e.g., "1d" for 1 day)
            
        Returns:
            Dictionary with summary and extracted action items
        """
        # Get workspace context
        context = self._get_workspace_context(workspace_id)
        
        # Filter messages by time period
        cutoff = self._parse_time_period(time_period)
        recent_messages = [
            msg for msg in context["messages"] 
            if datetime.datetime.fromisoformat(msg["timestamp"]) >= cutoff
        ]
        
        if not recent_messages:
            return {
                "summary": "No recent conversations.",
                "action_items": []
            }
        
        # Format messages for summarization
        messages_text = "\n".join([
            f"{msg['user_id']}: {msg['content']}" for msg in recent_messages
        ])
        
        # Generate summary prompt
        prompt = f"""Please summarize the following conversation and extract action items:

{messages_text}

Summary:"""
        
        # Generate summary
        summary_text = self._generate_response(prompt, max_tokens=150)
        
        # Extract action items
        action_items_prompt = f"""Based on this conversation, list the specific action items:

{messages_text}

Action items:"""
        
        action_items_text = self._generate_response(action_items_prompt, max_tokens=150)
        action_items = [item.strip() for item in action_items_text.split('\n') if item.strip()]
        
        return {
            "summary": summary_text,
            "action_items": action_items
        }
    
    def _get_workspace_context(self, workspace_id: str) -> Dict:
        """Get or create context for a workspace."""
        with self.context_lock:
            if workspace_id not in self.workspace_contexts:
                self.workspace_contexts[workspace_id] = {
                    "messages": [],
                    "documents": [],
                    "syllabus": None,
                    "last_activity": datetime.datetime.now().isoformat()
                }
            return self.workspace_contexts[workspace_id]
    
    def _format_conversation(self, context: Dict) -> str:
        """Format the conversation context for the model."""
        # Add system context
        prompt = "You are an AI assistant for flight training. "
        
        # Add document context if available
        if context["documents"]:
            prompt += "Available documents:\n"
            for doc in context["documents"][:5]:  # Limit to 5 most relevant
                prompt += f"- {doc['title']} ({doc['type']})\n"
            prompt += "\n"
        
        # Add syllabus context if available
        if context["syllabus"]:
            prompt += f"Current syllabus: {context['syllabus']['title']}\n"
            if context["syllabus"].get("modules"):
                prompt += "Modules: " + ", ".join(context["syllabus"]["modules"][:5]) + "\n\n"
        
        # Add conversation history
        for msg in context["messages"][-10:]:  # Last 10 messages
            if msg["user_id"] == "assistant":
                prompt += f"Assistant: {msg['content']}\n"
            else:
                prompt += f"User: {msg['content']}\n"
        
        prompt += "Assistant:"
        return prompt
    
    def _generate_response(self, prompt: str, max_tokens: int = 250) -> str:
        """Generate a response using the model."""
        inputs = self.tokenizer(prompt, return_tensors="tf")
        
        # Generate response
        output = self.model.generate(
            inputs.input_ids,
            max_new_tokens=max_tokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            pad_token_id=self.tokenizer.eos_token_id
        )
        
        # Decode response and extract assistant's output
        full_output = self.tokenizer.decode(output[0], skip_special_tokens=True)
        response = full_output[len(prompt):].strip()
        
        return response
    
    def _extract_actions(self, response: str) -> List[Dict]:
        """Extract suggested actions from the response."""
        actions = []
        
        # Look for action patterns like [ACTION: description]
        import re
        action_matches = re.findall(r'\[ACTION: ([^\]]+)\]', response)
        
        for match in action_matches:
            actions.append({
                "type": "suggested_action",
                "description": match
            })
        
        return actions
    
    def _clean_response(self, response: str) -> str:
        """Clean the response by removing action tags and other artifacts."""
        # Remove action tags
        import re
        cleaned = re.sub(r'\[ACTION: ([^\]]+)\]', '', response)
        
        return cleaned.strip()
    
    def _parse_time_period(self, period: str) -> datetime.datetime:
        """Parse a time period string like '1d' or '4h' and return cutoff datetime."""
        now = datetime.datetime.now()
        
        if not period:
            # Default to 1 day
            return now - datetime.timedelta(days=1)
        
        unit = period[-1].lower()
        try:
            amount = int(period[:-1])
        except ValueError:
            # Default to 1 day if invalid format
            return now - datetime.timedelta(days=1)
        
        if unit == 'd':
            return now - datetime.timedelta(days=amount)
        elif unit == 'h':
            return now - datetime.timedelta(hours=amount)
        elif unit == 'w':
            return now - datetime.timedelta(weeks=amount)
        else:
            # Default to 1 day for unknown units
            return now - datetime.timedelta(days=1)
    
    def _periodic_cleanup(self):
        """Periodically clean up old workspace contexts."""
        while True:
            time.sleep(3600)  # Run every hour
            
            with self.context_lock:
                now = datetime.datetime.now()
                to_remove = []
                
                for workspace_id, context in self.workspace_contexts.items():
                    last_activity = datetime.datetime.fromisoformat(context["last_activity"])
                    # Remove contexts inactive for more than 7 days
                    if (now - last_activity).days > 7:
                        to_remove.append(workspace_id)
                
                for workspace_id in to_remove:
                    del self.workspace_contexts[workspace_id]

# Example usage:
# assistant = ChatAssistant()
# response, actions = assistant.process_message("workspace1", "user1", "What's the procedure for engine failure during takeoff?")

// /backend/integration/include/integration/IntegrationService.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <unordered_map>
#include <mutex>
#include "core/ConfigurationManager.h"
#include "database/DatabaseManager.h"
#include "integration/SimulatorConnector.h"
#include "integration/BiometricConnector.h"
#include "integration/EnterpriseConnector.h"
#include "integration/CalendarConnector.h"
#include "integration/IntegrationTypes.h"

namespace Integration {

class IntegrationService {
public:
    IntegrationService(
        std::shared_ptr<Core::ConfigurationManager> config,
        std::shared_ptr<Database::DatabaseManager> dbManager
    );
    ~IntegrationService();
    
    // Simulator integration
    bool connectToSimulator(const SimulatorConnectionParams& params);
    bool disconnectFromSimulator(const std::string& simulatorId);
    bool startTelemetryStream(const std::string& simulatorId, 
                             const TelemetryStreamParams& params,
                             TelemetryCallback callback);
    bool stopTelemetryStream(const std::string& simulatorId);
    SimulatorStatus getSimulatorStatus(const std::string& simulatorId);
    std::vector<std::string> getConnectedSimulators();
    
    // Biometric device integration
    bool connectToBiometricDevice(const BiometricDeviceParams& params);
    bool disconnectFromBiometricDevice(const std::string& deviceId);
    bool startBiometricStream(const std::string& deviceId, 
                             BiometricDataCallback callback);
    bool stopBiometricStream(const std::string& deviceId);
    BiometricDeviceStatus getBiometricDeviceStatus(const std::string& deviceId);
    std::vector<std::string> getConnectedBiometricDevices();
    
    // Enterprise system integration (HR/ERP)
    bool connectToEnterpriseSystem(const EnterpriseSystemParams& params);
    bool disconnectFromEnterpriseSystem(const std::string& systemId);
    std::vector<TraineeProfile> syncTraineeProfiles();
    std::vector<CourseRegistration> syncCourseRegistrations();
    bool pushTrainingResults(const std::vector<TrainingResult>& results);
    EnterpriseSystemStatus getEnterpriseSystemStatus(const std::string& systemId);
    std::vector<std::string> getConnectedEnterpriseSystems();
    
    // Calendar integration
    bool connectToCalendar(const CalendarConnectionParams& params);
    bool disconnectFromCalendar(const std::string& calendarId);
    std::vector<CalendarEvent> getCalendarEvents(
        const std::string& calendarId,
        const TimeRange& range
    );
    bool createCalendarEvent(const std::string& calendarId, const CalendarEvent& event);
    bool updateCalendarEvent(const std::string& calendarId, const CalendarEvent& event);
    bool deleteCalendarEvent(const std::string& calendarId, const std::string& eventId);
    CalendarStatus getCalendarStatus(const std::string& calendarId);
    std::vector<std::string> getConnectedCalendars();
    
    // Connection management
    std::vector<Connection> getAllConnections();
    Connection getConnection(const std::string& connectionId);
    bool updateConnection(const Connection& connection);
    bool deleteConnection(const std::string& connectionId);
    
    // Health checks
    bool checkAllConnections();
    ConnectionHealth getConnectionHealth(const std::string& connectionId);
    std::vector<ConnectionHealth> getAllConnectionsHealth();

private:
    std::shared_ptr<Core::ConfigurationManager> config_;
    std::shared_ptr<Database::DatabaseManager> dbManager_;
    
    // Connector instances
    std::unordered_map<std::string, std::shared_ptr<SimulatorConnector>> simulatorConnectors_;
    std::unordered_map<std::string, std::shared_ptr<BiometricConnector>> biometricConnectors_;
    std::unordered_map<std::string, std::shared_ptr<EnterpriseConnector>> enterpriseConnectors_;
    std::unordered_map<std::string, std::shared_ptr<CalendarConnector>> calendarConnectors_;
    
    // Thread safety
    std::mutex connectorsMutex_;
    
    // Helper methods
    std::string generateConnectionId(const std::string& type, const std::string& name);
    bool saveConnectionToDb(const Connection& connection);
    bool loadConnectionsFromDb();
};

} // namespace Integration

// /backend/integration/include/integration/IntegrationTypes.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <chrono>
#include <functional>
#include <unordered_map>
#include <optional>
#include <nlohmann/json.hpp>

namespace Integration {

// Common types
enum class ConnectionType {
    SIMULATOR,
    BIOMETRIC_DEVICE,
    ENTERPRISE_SYSTEM,
    CALENDAR
};

enum class ConnectionStatus {
    CONNECTED,
    DISCONNECTED,
    CONNECTING,
    ERROR
};

struct TimeRange {
    std::chrono::system_clock::time_point start;
    std::chrono::system_clock::time_point end;
};

struct Connection {
    std::string id;
    std::string name;
    ConnectionType type;
    ConnectionStatus status;
    std::string errorMessage;
    std::chrono::system_clock::time_point lastConnected;
    std::chrono::system_clock::time_point createdAt;
    nlohmann::json connectionParams;
    
    nlohmann::json toJson() const;
    static Connection fromJson(const nlohmann::json& json);
};

struct ConnectionHealth {
    std::string connectionId;
    bool isHealthy;
    int latencyMs;
    std::string statusMessage;
    std::chrono::system_clock::time_point checkedAt;
    
    nlohmann::json toJson() const;
    static ConnectionHealth fromJson(const nlohmann::json& json);
};

// Simulator types
struct SimulatorConnectionParams {
    std::string name;
    std::string host;
    int port;
    std::string username;
    std::string password;
    std::string simulatorType;  // e.g., "X-Plane", "FSX", "P3D", "MSFS"
    int updateFrequencyHz;
    
    nlohmann::json toJson() const;
    static SimulatorConnectionParams fromJson(const nlohmann::json& json);
};

struct TelemetryStreamParams {
    std::vector<std::string> parameters;  // e.g., "altitude", "airspeed", "heading"
    int samplingRateHz;
    bool includeTimestamp;
    std::string outputFormat;  // e.g., "json", "binary", "csv"
    
    nlohmann::json toJson() const;
    static TelemetryStreamParams fromJson(const nlohmann::json& json);
};

struct SimulatorTelemetry {
    double timestamp;
    std::unordered_map<std::string, double> parameters;
    
    nlohmann::json toJson() const;
    static SimulatorTelemetry fromJson(const nlohmann::json& json);
};

using TelemetryCallback = std::function<void(const SimulatorTelemetry&)>;

struct SimulatorStatus {
    std::string simulatorId;
    std::string simulatorType;
    ConnectionStatus connectionStatus;
    bool isTelemetryActive;
    int currentUpdateFrequencyHz;
    std::chrono::system_clock::time_point connectedSince;
    std::string aircraftType;
    std::string aircraftPosition;
    
    nlohmann::json toJson() const;
    static SimulatorStatus fromJson(const nlohmann::json& json);
};

// Biometric device types
struct BiometricDeviceParams {
    std::string name;
    std::string deviceType;  // e.g., "EyeTracker", "HeartRateMonitor", "GSR"
    std::string connectionMethod;  // e.g., "Bluetooth", "USB", "WiFi"
    std::string deviceId;
    std::string host;  // For network-connected devices
    int port;
    std::string apiKey;
    
    nlohmann::json toJson() const;
    static BiometricDeviceParams fromJson(const nlohmann::json& json);
};

struct BiometricData {
    double timestamp;
    std::string deviceId;
    std::string dataType;  // e.g., "heartRate", "eyePosition", "GSR"
    nlohmann::json value;
    
    nlohmann::json toJson() const;
    static BiometricData fromJson(const nlohmann::json& json);
};

using BiometricDataCallback = std::function<void(const BiometricData&)>;

struct BiometricDeviceStatus {
    std::string deviceId;
    std::string deviceType;
    ConnectionStatus connectionStatus;
    bool isStreamActive;
    std::chrono::system_clock::time_point connectedSince;
    int batteryLevel;  // Percentage, if applicable
    
    nlohmann::json toJson() const;
    static BiometricDeviceStatus fromJson(const nlohmann::json& json);
};

// Enterprise system types
struct EnterpriseSystemParams {
    std::string name;
    std::string systemType;  // e.g., "SAP", "Workday", "CustomHR"
    std::string baseUrl;
    std::string username;
    std::string password;
    std::string apiKey;
    std::string tenantId;
    int syncIntervalMinutes;
    
    nlohmann::json toJson() const;
    static EnterpriseSystemParams fromJson(const nlohmann::json& json);
};

struct TraineeProfile {
    std::string id;
    std::string externalId;  // ID in the enterprise system
    std::string firstName;
    std::string lastName;
    std::string email;
    std::string department;
    std::string position;
    std::string employeeId;
    std::chrono::system_clock::time_point hireDate;
    std::unordered_map<std::string, std::string> customAttributes;
    
    nlohmann::json toJson() const;
    static TraineeProfile fromJson(const nlohmann::json& json);
};

struct CourseRegistration {
    std::string id;
    std::string traineeId;
    std::string courseId;
    std::string courseName;
    std::chrono::system_clock::time_point registrationDate;
    std::chrono::system_clock::time_point startDate;
    std::chrono::system_clock::time_point endDate;
    std::string status;  // e.g., "Registered", "In Progress", "Completed"
    
    nlohmann::json toJson() const;
    static CourseRegistration fromJson(const nlohmann::json& json);
};

struct TrainingResult {
    std::string traineeId;
    std::string courseId;
    std::string assessmentId;
    std::string status;  // e.g., "Passed", "Failed", "In Progress"
    double score;
    std::chrono::system_clock::time_point completionDate;
    std::vector<std::string> completedCompetencies;
    std::unordered_map<std::string, double> competencyScores;
    
    nlohmann::json toJson() const;
    static TrainingResult fromJson(const nlohmann::json& json);
};

struct EnterpriseSystemStatus {
    std::string systemId;
    std::string systemType;
    ConnectionStatus connectionStatus;
    std::chrono::system_clock::time_point lastSyncTime;
    int syncIntervalMinutes;
    int recordsProcessed;
    
    nlohmann::json toJson() const;
    static EnterpriseSystemStatus fromJson(const nlohmann::json& json);
};

// Calendar types
struct CalendarConnectionParams {
    std::string name;
    std::string calendarType;  // e.g., "Google", "Outlook", "iCalendar"
    std::string authMethod;  // e.g., "OAuth", "Basic", "ApiKey"
    std::string baseUrl;
    std::string username;
    std::string password;
    std::string apiKey;
    std::string calendarId;
    
    nlohmann::json toJson() const;
    static CalendarConnectionParams fromJson(const nlohmann::json& json);
};

struct CalendarEvent {
    std::string id;
    std::string title;
    std::string description;
    std::string location;
    std::chrono::system_clock::time_point startTime;
    std::chrono::system_clock::time_point endTime;
    bool isAllDay;
    std::vector<std::string> attendees;
    std::string organizer;
    std::string status;  // e.g., "Confirmed", "Tentative", "Cancelled"
    std::unordered_map<std::string, std::string> metadata;
    
    nlohmann::json toJson() const;
    static CalendarEvent fromJson(const nlohmann::json& json);
};

struct CalendarStatus {
    std::string calendarId;
    std::string calendarType;
    ConnectionStatus connectionStatus;
    std::chrono::system_clock::time_point lastSyncTime;
    int totalEvents;
    
    nlohmann::json toJson() const;
    static CalendarStatus fromJson(const nlohmann::json& json);
};

} // namespace Integration

// /backend/integration/include/integration/SimulatorConnector.h
#pragma once

#include <string>
#include <memory>
#include <thread>
#include <atomic>
#include <mutex>
#include <queue>
#include <condition_variable>
#include "integration/IntegrationTypes.h"

namespace Integration {

class SimulatorConnector {
public:
    SimulatorConnector(const SimulatorConnectionParams& params);
    ~SimulatorConnector();
    
    // Connection management
    bool connect();
    bool disconnect();
    ConnectionStatus getStatus() const;
    std::string getErrorMessage() const;
    
    // Telemetry streaming
    bool startTelemetryStream(const TelemetryStreamParams& params, TelemetryCallback callback);
    bool stopTelemetryStream();
    bool isTelemetryActive() const;
    
    // Simulator control
    bool sendCommand(const std::string& command, const std::string& params = "");
    bool loadScenario(const std::string& scenarioPath);
    bool setAircraftPosition(double latitude, double longitude, double altitude, 
                           double heading, double speed);
    bool injectFailure(const std::string& system, double severity = 1.0);
    bool resetFailures();
    
    // Simulator status
    SimulatorStatus getStatus();
    
    // Settings
    bool setUpdateFrequency(int frequencyHz);
    int getUpdateFrequency() const;

private:
    SimulatorConnectionParams params_;
    ConnectionStatus status_;
    std::string errorMessage_;
    std::atomic<bool> isConnected_;
    std::atomic<bool> isTelemetryActive_;
    std::atomic<int> updateFrequencyHz_;
    std::chrono::system_clock::time_point connectedSince_;
    
    // Telemetry processing
    TelemetryStreamParams streamParams_;
    TelemetryCallback telemetryCallback_;
    std::thread telemetryThread_;
    std::atomic<bool> stopTelemetry_;
    
    // Data buffering
    std::queue<SimulatorTelemetry> telemetryBuffer_;
    std::mutex bufferMutex_;
    std::condition_variable bufferCV_;
    
    // Protocols
    void initializeProtocol();
    bool xplaneConnect();
    bool p3dConnect();
    bool msfsConnect();
    bool genericConnect();
    
    // Telemetry processing
    void telemetryWorker();
    void processTelemetry();
    SimulatorTelemetry parseTelemetryData(const std::string& data);
};

} // namespace Integration

// /backend/integration/include/integration/BiometricConnector.h
#pragma once

#include <string>
#include <memory>
#include <thread>
#include <atomic>
#include <mutex>
#include <queue>
#include <condition_variable>
#include "integration/IntegrationTypes.h"

namespace Integration {

class BiometricConnector {
public:
    BiometricConnector(const BiometricDeviceParams& params);
    ~BiometricConnector();
    
    // Connection management
    bool connect();
    bool disconnect();
    ConnectionStatus getStatus() const;
    std::string getErrorMessage() const;
    
    // Data streaming
    bool startDataStream(BiometricDataCallback callback);
    bool stopDataStream();
    bool isStreamActive() const;
    
    // Device control
    bool calibrate();
    bool resetDevice();
    bool setDataRate(int samplesPerSecond);
    
    // Device status
    BiometricDeviceStatus getStatus();
    int getBatteryLevel() const;
    
    // Device settings
    bool setSetting(const std::string& setting, const std::string& value);
    std::string getSetting(const std::string& setting) const;

private:
    BiometricDeviceParams params_;
    ConnectionStatus status_;
    std::string errorMessage_;
    std::atomic<bool> isConnected_;
    std::atomic<bool> isStreamActive_;
    std::chrono::system_clock::time_point connectedSince_;
    std::atomic<int> batteryLevel_;
    
    // Data processing
    BiometricDataCallback dataCallback_;
    std::thread dataThread_;
    std::atomic<bool> stopDataStream_;
    
    // Data buffering
    std::queue<BiometricData> dataBuffer_;
    std::mutex bufferMutex_;
    std::condition_variable bufferCV_;
    
    // Protocol handlers
    void initializeProtocols();
    bool eyeTrackerConnect();
    bool heartRateMonitorConnect();
    bool gsrConnect();
    bool genericConnect();
    
    // Data processing
    void dataWorker();
    void processRawData();
    BiometricData parseRawData(const std::string& data);
};

} // namespace Integration

// /backend/integration/include/integration/EnterpriseConnector.h
#pragma once

#include <string>
#include <memory>
#include <thread>
#include <atomic>
#include <mutex>
#include <vector>
#include <unordered_map>
#include <chrono>
#include "integration/IntegrationTypes.h"

namespace Integration {

class EnterpriseConnector {
public:
    EnterpriseConnector(const EnterpriseSystemParams& params);
    ~EnterpriseConnector();
    
    // Connection management
    bool connect();
    bool disconnect();
    ConnectionStatus getStatus() const;
    std::string getErrorMessage() const;
    
    // Data synchronization
    std::vector<TraineeProfile> syncTraineeProfiles();
    std::vector<CourseRegistration> syncCourseRegistrations();
    bool pushTrainingResults(const std::vector<TrainingResult>& results);
    
    // Automatic sync
    bool startAutoSync(int intervalMinutes);
    bool stopAutoSync();
    bool isAutoSyncActive() const;
    
    // Status and settings
    EnterpriseSystemStatus getStatus();
    bool setSyncInterval(int intervalMinutes);
    int getSyncInterval() const;
    std::chrono::system_clock::time_point getLastSyncTime() const;

private:
    EnterpriseSystemParams params_;
    ConnectionStatus status_;
    std::string errorMessage_;
    std::atomic<bool> isConnected_;
    std::atomic<bool> isAutoSyncActive_;
    std::atomic<int> syncIntervalMinutes_;
    std::chrono::system_clock::time_point connectedSince_;
    std::chrono::system_clock::time_point lastSyncTime_;
    std::atomic<int> recordsProcessed_;
    
    // Sync thread
    std::thread syncThread_;
    std::atomic<bool> stopSync_;
    std::mutex syncMutex_;
    
    // API clients for different ERP systems
    void initializeApiClient();
    bool sapConnect();
    bool workdayConnect();
    bool customErpConnect();
    
    // Sync workers
    void autoSyncWorker();
    std::vector<TraineeProfile> fetchTraineeProfiles();
    std::vector<CourseRegistration> fetchCourseRegistrations();
    bool sendTrainingResults(const std::vector<TrainingResult>& results);
    
    // Utility methods
    std::string buildApiUrl(const std::string& endpoint);
    std::string executeApiRequest(const std::string& url, const std::string& method, 
                                const std::string& data = "");
};

} // namespace Integration

// /backend/integration/include/integration/CalendarConnector.h
#pragma once

#include <string>
#include <memory>
#include <thread>
#include <atomic>
#include <mutex>
#include <vector>
#include <chrono>
#include "integration/IntegrationTypes.h"

namespace Integration {

class CalendarConnector {
public:
    CalendarConnector(const CalendarConnectionParams& params);
    ~CalendarConnector();
    
    // Connection management
    bool connect();
    bool disconnect();
    ConnectionStatus getStatus() const;
    std::string getErrorMessage() const;
    
    // Calendar operations
    std::vector<CalendarEvent> getEvents(const TimeRange& range);
    bool createEvent(const CalendarEvent& event);
    bool updateEvent(const CalendarEvent& event);
    bool deleteEvent(const std::string& eventId);
    
    // Automatic sync
    bool startAutoSync(int intervalMinutes);
    bool stopAutoSync();
    bool isAutoSyncActive() const;
    
    // Status and settings
    CalendarStatus getStatus();
    bool setSyncInterval(int intervalMinutes);
    int getSyncInterval() const;
    std::chrono::system_clock::time_point getLastSyncTime() const;
    int getTotalEvents() const;

private:
    CalendarConnectionParams params_;
    ConnectionStatus status_;
    std::string errorMessage_;
    std::atomic<bool> isConnected_;
    std::atomic<bool> isAutoSyncActive_;
    std::atomic<int> syncIntervalMinutes_;
    std::chrono::system_clock::time_point connectedSince_;
    std::chrono::system_clock::time_point lastSyncTime_;
    std::atomic<int> totalEvents_;
    
    // Sync thread
    std::thread syncThread_;
    std::atomic<bool> stopSync_;
    std::mutex syncMutex_;
    
    // Calendar API implementations
    void initializeApiClient();
    bool googleCalendarConnect();
    bool outlookCalendarConnect();
    bool icalendarConnect();
    
    // Sync workers
    void autoSyncWorker();
    std::vector<CalendarEvent> fetchEvents(const TimeRange& range);
    
    // API utility methods
    std::string buildApiUrl(const std::string& endpoint);
    std::string executeApiRequest(const std::string& url, const std::string& method, 
                                const std::string& data = "");
    CalendarEvent parseEventData(const std::string& data);
};

} // namespace Integration

// /backend/integration/src/IntegrationService.cpp
#include "integration/IntegrationService.h"
#include <spdlog/spdlog.h>
#include <uuid/uuid.h>

namespace Integration {

IntegrationService::IntegrationService(
    std::shared_ptr<Core::ConfigurationManager> config,
    std::shared_ptr<Database::DatabaseManager> dbManager
) : config_(config), dbManager_(dbManager) {
    // Load existing connections from database
    loadConnectionsFromDb();
    
    spdlog::info("Integration service initialized");
}

IntegrationService::~IntegrationService() {
    // Disconnect all connectors
    {
        std::lock_guard<std::mutex> lock(connectorsMutex_);
        
        for (auto& [id, connector] : simulatorConnectors_) {
            connector->disconnect();
        }
        simulatorConnectors_.clear();
        
        for (auto& [id, connector] : biometricConnectors_) {
            connector->disconnect();
        }
        biometricConnectors_.clear();
        
        for (auto& [id, connector] : enterpriseConnectors_) {
            connector->disconnect();
        }
        enterpriseConnectors_.clear();
        
        for (auto& [id, connector] : calendarConnectors_) {
            connector->disconnect();
        }
        calendarConnectors_.clear();
    }
    
    spdlog::info("Integration service shutdown");
}

bool IntegrationService::connectToSimulator(const SimulatorConnectionParams& params) {
    // Generate a connection ID
    std::string connectionId = generateConnectionId("SIM", params.name);
    
    // Create connector
    auto connector = std::make_shared<SimulatorConnector>(params);
    
    // Attempt connection
    bool connected = connector->connect();
    
    if (connected) {
        // Store connector
        std::lock_guard<std::mutex> lock(connectorsMutex_);
        simulatorConnectors_[connectionId] = connector;
        
        // Save connection to database
        Connection connection{
            .id = connectionId,
            .name = params.name,
            .type = ConnectionType::SIMULATOR,
            .status = ConnectionStatus::CONNECTED,
            .errorMessage = "",
            .lastConnected = std::chrono::system_clock::now(),
            .createdAt = std::chrono::system_clock::now(),
            .connectionParams = params.toJson()
        };
        
        saveConnectionToDb(connection);
        
        spdlog::info("Connected to simulator: {}", params.name);
    } else {
        spdlog::error("Failed to connect to simulator: {} - {}", 
                    params.name, connector->getErrorMessage());
    }
    
    return connected;
}

bool IntegrationService::disconnectFromSimulator(const std::string& simulatorId) {
    std::lock_guard<std::mutex> lock(connectorsMutex_);
    
    auto it = simulatorConnectors_.find(simulatorId);
    if (it == simulatorConnectors_.end()) {
        spdlog::error("Simulator not found: {}", simulatorId);
        return false;
    }
    
    // Disconnect
    bool success = it->second->disconnect();
    
    if (success) {
        // Update connection in database
        auto query = "UPDATE connections SET status = $1 WHERE id = $2";
        dbManager_->executeQuery(query, 
                               static_cast<int>(ConnectionStatus::DISCONNECTED), 
                               simulatorId);
        
        // Remove from map
        simulatorConnectors_.erase(it);
        
        spdlog::info("Disconnected from simulator: {}", simulatorId);
    }
    
    return success;
}

bool IntegrationService::startTelemetryStream(
    const std::string& simulatorId, 
    const TelemetryStreamParams& params,
    TelemetryCallback callback
) {
    std::lock_guard<std::mutex> lock(connectorsMutex_);
    
    auto it = simulatorConnectors_.find(simulatorId);
    if (it == simulatorConnectors_.end()) {
        spdlog::error("Simulator not found: {}", simulatorId);
        return false;
    }
    
    bool success = it->second->startTelemetryStream(params, callback);
    
    if (success) {
        spdlog::info("Started telemetry stream for simulator: {}", simulatorId);
    } else {
        spdlog::error("Failed to start telemetry stream for simulator: {}", simulatorId);
    }
    
    return success;
}

bool IntegrationService::stopTelemetryStream(const std::string& simulatorId) {
    std::lock_guard<std::mutex> lock(connectorsMutex_);
    
    auto it = simulatorConnectors_.find(simulatorId);
    if (it == simulatorConnectors_.end()) {
        spdlog::error("Simulator not found: {}", simulatorId);
        return false;
    }
    
    bool success = it->second->stopTelemetryStream();
    
    if (success) {
        spdlog::info("Stopped telemetry stream for simulator: {}", simulatorId);
    } else {
        spdlog::error("Failed to stop telemetry stream for simulator: {}", simulatorId);
    }
    
    return success;
}

SimulatorStatus IntegrationService::getSimulatorStatus(const std::string& simulatorId) {
    std::lock_guard<std::mutex> lock(connectorsMutex_);
    
    auto it = simulatorConnectors_.find(simulatorId);
    if (it == simulatorConnectors_.end()) {
        spdlog::error("Simulator not found: {}", simulatorId);
        return SimulatorStatus{
            .simulatorId = simulatorId,
            .connectionStatus = ConnectionStatus::DISCONNECTED
        };
    }
    
    return it->second->getStatus();
}

std::vector<std::string> IntegrationService::getConnectedSimulators() {
    std::lock_guard<std::mutex> lock(connectorsMutex_);
    
    std::vector<std::string> simulatorIds;
    for (const auto& [id, _] : simulatorConnectors_) {
        simulatorIds.push_back(id);
    }
    
    return simulatorIds;
}

// ... Similar implementations for other connector types ...

std::vector<Connection> IntegrationService::getAllConnections() {
    std::vector<Connection> connections;
    
    auto query = "SELECT id, name, type, status, error_message, last_connected, created_at, connection_params "
                "FROM connections";
    
    auto result = dbManager_->executeQuery(query);
    
    for (const auto& row : result) {
        Connection connection;
        connection.id = row[0].as<std::string>();
        connection.name = row[1].as<std::string>();
        connection.type = static_cast<ConnectionType>(row[2].as<int>());
        connection.status = static_cast<ConnectionStatus>(row[3].as<int>());
        connection.errorMessage = row[4].as<std::string>();
        connection.lastConnected = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(row[5].as<int64_t>())
        );
        connection.createdAt = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(row[6].as<int64_t>())
        );
        
        try {
            connection.connectionParams = nlohmann::json::parse(row[7].as<std::string>());
        } catch (const std::exception& e) {
            spdlog::error("Error parsing connection params: {}", e.what());
            connection.connectionParams = nlohmann::json({});
        }
        
        connections.push_back(connection);
    }
    
    return connections;
}

Connection IntegrationService::getConnection(const std::string& connectionId) {
    auto query = "SELECT id, name, type, status, error_message, last_connected, created_at, connection_params "
                "FROM connections WHERE id = $1";
    
    auto result = dbManager_->executeQuery(query, connectionId);
    
    if (result.empty()) {
        spdlog::error("Connection not found: {}", connectionId);
        return Connection{};
    }
    
    Connection connection;
    const auto& row = result[0];
    
    connection.id = row[0].as<std::string>();
    connection.name = row[1].as<std::string>();
    connection.type = static_cast<ConnectionType>(row[2].as<int>());
    connection.status = static_cast<ConnectionStatus>(row[3].as<int>());
    connection.errorMessage = row[4].as<std::string>();
    connection.lastConnected = std::chrono::system_clock::time_point(
        std::chrono::milliseconds(row[5].as<int64_t>())
    );
    connection.createdAt = std::chrono::system_clock::time_point(
        std::chrono::milliseconds(row[6].as<int64_t>())
    );
    
    try {
        connection.connectionParams = nlohmann::json::parse(row[7].as<std::string>());
    } catch (const std::exception& e) {
        spdlog::error("Error parsing connection params: {}", e.what());
        connection.connectionParams = nlohmann::json({});
    }
    
    return connection;
}

bool IntegrationService::updateConnection(const Connection& connection) {
    auto query = "UPDATE connections SET name = $1, status = $2, error_message = $3, "
                "last_connected = $4, connection_params = $5 WHERE id = $6";
    
    return dbManager_->executeQuery(query, 
                                  connection.name, 
                                  static_cast<int>(connection.status), 
                                  connection.errorMessage, 
                                  connection.lastConnected.time_since_epoch().count(), 
                                  connection.connectionParams.dump(), 
                                  connection.id);
}

bool IntegrationService::deleteConnection(const std::string& connectionId) {
    // First disconnect if connected
    ConnectionType type = ConnectionType::SIMULATOR;  // Default value
    
    {
        std::lock_guard<std::mutex> lock(connectorsMutex_);
        
        // Check which type of connector it is
        if (simulatorConnectors_.find(connectionId) != simulatorConnectors_.end()) {
            simulatorConnectors_[connectionId]->disconnect();
            simulatorConnectors_.erase(connectionId);
            type = ConnectionType::SIMULATOR;
        } else if (biometricConnectors_.find(connectionId) != biometricConnectors_.end()) {
            biometricConnectors_[connectionId]->disconnect();
            biometricConnectors_.erase(connectionId);
            type = ConnectionType::BIOMETRIC_DEVICE;
        } else if (enterpriseConnectors_.find(connectionId) != enterpriseConnectors_.end()) {
            enterpriseConnectors_[connectionId]->disconnect();
            enterpriseConnectors_.erase(connectionId);
            type = ConnectionType::ENTERPRISE_SYSTEM;
        } else if (calendarConnectors_.find(connectionId) != calendarConnectors_.end()) {
            calendarConnectors_[connectionId]->disconnect();
            calendarConnectors_.erase(connectionId);
            type = ConnectionType::CALENDAR;
        }
    }
    
    // Remove from database
    auto query = "DELETE FROM connections WHERE id = $1";
    bool success = dbManager_->executeQuery(query, connectionId);
    
    if (success) {
        spdlog::info("Deleted connection: {}", connectionId);
    } else {
        spdlog::error("Failed to delete connection: {}", connectionId);
    }
    
    return success;
}

bool IntegrationService::checkAllConnections() {
    std::lock_guard<std::mutex> lock(connectorsMutex_);
    
    bool allHealthy = true;
    
    // Check simulators
    for (const auto& [id, connector] : simulatorConnectors_) {
        if (connector->getStatus() != ConnectionStatus::CONNECTED) {
            allHealthy = false;
            spdlog::warn("Simulator connection unhealthy: {}", id);
        }
    }
    
    // Check biometric devices
    for (const auto& [id, connector] : biometricConnectors_) {
        if (connector->getStatus() != ConnectionStatus::CONNECTED) {
            allHealthy = false;
            spdlog::warn("Biometric device connection unhealthy: {}", id);
        }
    }
    
    // Check enterprise systems
    for (const auto& [id, connector] : enterpriseConnectors_) {
        if (connector->getStatus() != ConnectionStatus::CONNECTED) {
            allHealthy = false;
            spdlog::warn("Enterprise system connection unhealthy: {}", id);
        }
    }
    
    // Check calendars
    for (const auto& [id, connector] : calendarConnectors_) {
        if (connector->getStatus() != ConnectionStatus::CONNECTED) {
            allHealthy = false;
            spdlog::warn("Calendar connection unhealthy: {}", id);
        }
    }
    
    return allHealthy;
}

ConnectionHealth IntegrationService::getConnectionHealth(const std::string& connectionId) {
    ConnectionHealth health{
        .connectionId = connectionId,
        .isHealthy = false,
        .latencyMs = -1,
        .statusMessage = "Connection not found",
        .checkedAt = std::chrono::system_clock::now()
    };
    
    std::lock_guard<std::mutex> lock(connectorsMutex_);
    
    // Check which type of connector it is and get health
    if (simulatorConnectors_.find(connectionId) != simulatorConnectors_.end()) {
        auto status = simulatorConnectors_[connectionId]->getStatus();
        health.isHealthy = (status.connectionStatus == ConnectionStatus::CONNECTED);
        health.statusMessage = health.isHealthy ? "Connected" : "Disconnected";
        health.latencyMs = 0;  // Would need to implement actual latency measurement
    } else if (biometricConnectors_.find(connectionId) != biometricConnectors_.end()) {
        auto status = biometricConnectors_[connectionId]->getStatus();
        health.isHealthy = (status.connectionStatus == ConnectionStatus::CONNECTED);
        health.statusMessage = health.isHealthy ? "Connected" : "Disconnected";
        health.latencyMs = 0;
    } else if (enterpriseConnectors_.find(connectionId) != enterpriseConnectors_.end()) {
        auto status = enterpriseConnectors_[connectionId]->getStatus();
        health.isHealthy = (status.connectionStatus == ConnectionStatus::CONNECTED);
        health.statusMessage = health.isHealthy ? "Connected" : "Disconnected";
        health.latencyMs = 0;
    } else if (calendarConnectors_.find(connectionId) != calendarConnectors_.end()) {
        auto status = calendarConnectors_[connectionId]->getStatus();
        health.isHealthy = (status.connectionStatus == ConnectionStatus::CONNECTED);
        health.statusMessage = health.isHealthy ? "Connected" : "Disconnected";
        health.latencyMs = 0;
    }
    
    return health;
}

std::vector<ConnectionHealth> IntegrationService::getAllConnectionsHealth() {
    std::vector<ConnectionHealth> healthResults;
    
    auto connections = getAllConnections();
    for (const auto& connection : connections) {
        healthResults.push_back(getConnectionHealth(connection.id));
    }
    
    return healthResults;
}

std::string IntegrationService::generateConnectionId(const std::string& type, const std::string& name) {
    // Generate a unique ID with a prefix
    uuid_t uuid;
    uuid_generate(uuid);
    char uuid_str[37];
    uuid_unparse_lower(uuid, uuid_str);
    
    return type + "-" + uuid_str;
}

bool IntegrationService::saveConnectionToDb(const Connection& connection) {
    auto query = "INSERT INTO connections (id, name, type, status, error_message, last_connected, created_at, connection_params) "
                "VALUES ($1, $2, $3, $4, $5, $6, $7, $8) "
                "ON CONFLICT (id) DO UPDATE SET name = $2, status = $4, error_message = $5, "
                "last_connected = $6, connection_params = $8";
    
    return dbManager_->executeQuery(query, 
                                  connection.id, 
                                  connection.name, 
                                  static_cast<int>(connection.type), 
                                  static_cast<int>(connection.status), 
                                  connection.errorMessage, 
                                  connection.lastConnected.time_since_epoch().count(), 
                                  connection.createdAt.time_since_epoch().count(), 
                                  connection.connectionParams.dump());
}

bool IntegrationService::loadConnectionsFromDb() {
    auto query = "SELECT id, name, type, status, error_message, last_connected, created_at, connection_params "
                "FROM connections WHERE status = $1";
    
    auto result = dbManager_->executeQuery(query, static_cast<int>(ConnectionStatus::CONNECTED));
    
    for (const auto& row : result) {
        std::string id = row[0].as<std::string>();
        std::string name = row[1].as<std::string>();
        ConnectionType type = static_cast<ConnectionType>(row[2].as<int>());
        std::string params_json = row[7].as<std::string>();
        
        try {
            // Reconnect based on connection type
            nlohmann::json params = nlohmann::json::parse(params_json);
            
            switch (type) {
                case ConnectionType::SIMULATOR: {
                    auto simParams = SimulatorConnectionParams::fromJson(params);
                    auto connector = std::make_shared<SimulatorConnector>(simParams);
                    if (connector->connect()) {
                        std::lock_guard<std::mutex> lock(connectorsMutex_);
                        simulatorConnectors_[id] = connector;
                        spdlog::info("Reconnected to simulator: {}", name);
                    }
                    break;
                }
                case ConnectionType::BIOMETRIC_DEVICE: {
                    auto bioParams = BiometricDeviceParams::fromJson(params);
                    auto connector = std::make_shared<BiometricConnector>(bioParams);
                    if (connector->connect()) {
                        std::lock_guard<std::mutex> lock(connectorsMutex_);
                        biometricConnectors_[id] = connector;
                        spdlog::info("Reconnected to biometric device: {}", name);
                    }
                    break;
                }
                case ConnectionType::ENTERPRISE_SYSTEM: {
                    auto erpParams = EnterpriseSystemParams::fromJson(params);
                    auto connector = std::make_shared<EnterpriseConnector>(erpParams);
                    if (connector->connect()) {
                        std::lock_guard<std::mutex> lock(connectorsMutex_);
                        enterpriseConnectors_[id] = connector;
                        spdlog::info("Reconnected to enterprise system: {}", name);
                    }
                    break;
                }
                case ConnectionType::CALENDAR: {
                    auto calParams = CalendarConnectionParams::fromJson(params);
                    auto connector = std::make_shared<CalendarConnector>(calParams);
                    if (connector->connect()) {
                        std::lock_guard<std::mutex> lock(connectorsMutex_);
                        calendarConnectors_[id] = connector;
                        spdlog::info("Reconnected to calendar: {}", name);
                    }
                    break;
                }
            }
        } catch (const std::exception& e) {
            spdlog::error("Error reconnecting to {}: {}", name, e.what());
        }
    }
    
    return true;
}

} // namespace Integration

// /backend/integration/src/SimulatorConnector.cpp
#include "integration/SimulatorConnector.h"
#include <spdlog/spdlog.h>
#include <random>  // For mock implementation

namespace Integration {

SimulatorConnector::SimulatorConnector(const SimulatorConnectionParams& params)
    : params_(params),
      status_(ConnectionStatus::DISCONNECTED),
      isConnected_(false),
      isTelemetryActive_(false),
      updateFrequencyHz_(params.updateFrequencyHz),
      stopTelemetry_(false) {
    
    spdlog::debug("Created simulator connector for {}", params.name);
}

SimulatorConnector::~SimulatorConnector() {
    // Ensure telemetry is stopped
    if (isTelemetryActive_) {
        stopTelemetryStream();
    }
    
    // Ensure disconnected
    if (isConnected_) {
        disconnect();
    }
    
    spdlog::debug("Destroyed simulator connector for {}", params_.name);
}

bool SimulatorConnector::connect() {
    if (isConnected_) {
        spdlog::warn("Already connected to simulator {}", params_.name);
        return true;
    }
    
    spdlog::info("Connecting to simulator {} at {}:{}...", 
               params_.name, params_.host, params_.port);
    
    // Initialize appropriate protocol handler
    initializeProtocol();
    
    // Connect based on simulator type
    bool connected = false;
    
    if (params_.simulatorType == "X-Plane") {
        connected = xplaneConnect();
    } else if (params_.simulatorType == "P3D") {
        connected = p3dConnect();
    } else if (params_.simulatorType == "MSFS") {
        connected = msfsConnect();
    } else {
        connected = genericConnect();
    }
    
    if (connected) {
        isConnected_ = true;
        status_ = ConnectionStatus::CONNECTED;
        connectedSince_ = std::chrono::system_clock::now();
        spdlog::info("Connected to simulator {}", params_.name);
    } else {
        status_ = ConnectionStatus::ERROR;
        spdlog::error("Failed to connect to simulator {}: {}", params_.name, errorMessage_);
    }
    
    return connected;
}

bool SimulatorConnector::disconnect() {
    if (!isConnected_) {
        spdlog::warn("Not connected to simulator {}", params_.name);
        return true;
    }
    
    // Stop telemetry if active
    if (isTelemetryActive_) {
        stopTelemetryStream();
    }
    
    // Disconnect logic depends on simulator type
    // For now, just set the flags
    isConnected_ = false;
    status_ = ConnectionStatus::DISCONNECTED;
    
    spdlog::info("Disconnected from simulator {}", params_.name);
    return true;
}

ConnectionStatus SimulatorConnector::getStatus() const {
    return status_;
}

std::string SimulatorConnector::getErrorMessage() const {
    return errorMessage_;
}

bool SimulatorConnector::startTelemetryStream(
    const TelemetryStreamParams& params, 
    TelemetryCallback callback
) {
    if (!isConnected_) {
        errorMessage_ = "Not connected to simulator";
        spdlog::error("Cannot start telemetry: {}", errorMessage_);
        return false;
    }
    
    if (isTelemetryActive_) {
        spdlog::warn("Telemetry already active for simulator {}", params_.name);
        return true;
    }
    
    // Store parameters
    streamParams_ = params;
    telemetryCallback_ = callback;
    
    // Start telemetry thread
    stopTelemetry_ = false;
    telemetryThread_ = std::thread(&SimulatorConnector::telemetryWorker, this);
    
    isTelemetryActive_ = true;
    spdlog::info("Started telemetry stream for simulator {} at {} Hz", 
               params_.name, params.samplingRateHz);
    
    return true;
}

bool SimulatorConnector::stopTelemetryStream() {
    if (!isTelemetryActive_) {
        spdlog::warn("Telemetry not active for simulator {}", params_.name);
        return true;
    }
    
    // Stop telemetry thread
    stopTelemetry_ = true;
    
    // Wait for thread to finish
    if (telemetryThread_.joinable()) {
        telemetryThread_.join();
    }
    
    isTelemetryActive_ = false;
    spdlog::info("Stopped telemetry stream for simulator {}", params_.name);
    
    return true;
}

bool SimulatorConnector::isTelemetryActive() const {
    return isTelemetryActive_;
}

SimulatorStatus SimulatorConnector::getStatus() {
    SimulatorStatus status;
    status.simulatorId = params_.name;
    status.simulatorType = params_.simulatorType;
    status.connectionStatus = status_;
    status.isTelemetryActive = isTelemetryActive_;
    status.currentUpdateFrequencyHz = updateFrequencyHz_;
    status.connectedSince = connectedSince_;
    
    // These would need to be retrieved from the simulator in a real implementation
    status.aircraftType = "C172";
    status.aircraftPosition = "KSFO";
    
    return status;
}

bool SimulatorConnector::setUpdateFrequency(int frequencyHz) {
    if (frequencyHz <= 0 || frequencyHz > 1000) {
        errorMessage_ = "Invalid update frequency";
        spdlog::error("{}: {}", errorMessage_, frequencyHz);
        return false;
    }
    
    updateFrequencyHz_ = frequencyHz;
    spdlog::info("Set update frequency for simulator {} to {} Hz", params_.name, frequencyHz);
    
    return true;
}

int SimulatorConnector::getUpdateFrequency() const {
    return updateFrequencyHz_;
}

void SimulatorConnector::initializeProtocol() {
    // This would initialize the appropriate protocol handler
    spdlog::debug("Initializing protocol for simulator type: {}", params_.simulatorType);
}

bool SimulatorConnector::xplaneConnect() {
    // X-Plane specific connection logic
    // This is a mock implementation
    spdlog::debug("Connecting to X-Plane at {}:{}", params_.host, params_.port);
    
    // Simulate success (would be real connection code in production)
    return true;
}

bool SimulatorConnector::p3dConnect() {
    // P3D specific connection logic
    // This is a mock implementation
    spdlog::debug("Connecting to P3D at {}:{}", params_.host, params_.port);
    
    // Simulate success (would be real connection code in production)
    return true;
}

bool SimulatorConnector::msfsConnect() {
    // MSFS specific connection logic
    // This is a mock implementation
    spdlog::debug("Connecting to MSFS at {}:{}", params_.host, params_.port);
    
    // Simulate success (would be real connection code in production)
    return true;
}

bool SimulatorConnector::genericConnect() {
    // Generic simulator connection logic
    // This is a mock implementation
    spdlog::debug("Connecting to generic simulator at {}:{}", params_.host, params_.port);
    
    // Simulate success (would be real connection code in production)
    return true;
}

void SimulatorConnector::telemetryWorker() {
    spdlog::debug("Telemetry worker started for simulator {}", params_.name);
    
    // Calculate sleep time based on sampling rate
    auto sleepTime = std::chrono::microseconds(1000000 / streamParams_.samplingRateHz);
    
    while (!stopTelemetry_) {
        // Process telemetry data
        processTelemetry();
        
        // Sleep for the calculated time
        std::this_thread::sleep_for(sleepTime);
    }
    
    spdlog::debug("Telemetry worker stopped for simulator {}", params_.name);
}

void SimulatorConnector::processTelemetry() {
    // In a real implementation, this would fetch data from the simulator
    // For this example, we generate mock data
    
    // Generate timestamp
    double timestamp = std::chrono::duration_cast<std::chrono::milliseconds>(
        std::chrono::system_clock::now().time_since_epoch()
    ).count() / 1000.0;
    
    // Create telemetry data
    SimulatorTelemetry telemetry;
    telemetry.timestamp = timestamp;
    
    // Generate mock parameter values
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_real_distribution<> altDist(5000.0, 5100.0);  // altitude in feet
    std::uniform_real_distribution<> spdDist(120.0, 125.0);    // airspeed in knots
    std::uniform_real_distribution<> hdgDist(0.0, 360.0);      // heading in degrees
    std::uniform_real_distribution<> vspDist(-100.0, 100.0);   // vertical speed in ft/min
    
    // Set parameters based on requested parameters
    for (const auto& param : streamParams_.parameters) {
        if (param == "altitude") {
            telemetry.parameters["altitude"] = altDist(gen);
        } else if (param == "airspeed") {
            telemetry.parameters["airspeed"] = spdDist(gen);
        } else if (param == "heading") {
            telemetry.parameters["heading"] = hdgDist(gen);
        } else if (param == "vertical_speed") {
            telemetry.parameters["vertical_speed"] = vspDist(gen);
        } else {
            // Default to a random value between 0 and 100
            std::uniform_real_distribution<> defaultDist(0.0, 100.0);
            telemetry.parameters[param] = defaultDist(gen);
        }
    }
    
    // Call the callback with the telemetry data
    if (telemetryCallback_) {
        telemetryCallback_(telemetry);
    }
}

SimulatorTelemetry SimulatorConnector::parseTelemetryData(const std::string& data) {
    // Parse the raw data from the simulator
    // This is a mock implementation
    SimulatorTelemetry telemetry;
    telemetry.timestamp = std::chrono::duration_cast<std::chrono::milliseconds>(
        std::chrono::system_clock::now().time_since_epoch()
    ).count() / 1000.0;
    
    // In a real implementation, would parse the data format
    
    return telemetry;
}

} // namespace Integration

// /backend/integration/python/biometric_data_processor.py
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple
import json
import time
import threading
from collections import deque
import logging

logger = logging.getLogger(__name__)

class BiometricDataProcessor:
    """Processes and analyzes biometric data from various devices.
    
    This class provides functionality to:
    1. Process raw biometric data streams
    2. Detect patterns and anomalies
    3. Calculate derived metrics
    4. Correlate biometric data with simulator events
    """
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize the biometric data processor.
        
        Args:
            config: Configuration parameters for the processor
        """
        self.config = config
        self.buffer_size = config.get('buffer_size', 1000)
        self.sampling_rate = config.get('sampling_rate', 50)  # Hz
        
        # Data buffers for different sensor types
        self.eye_tracking_buffer = deque(maxlen=self.buffer_size)
        self.heart_rate_buffer = deque(maxlen=self.buffer_size)
        self.gsr_buffer = deque(maxlen=self.buffer_size)
        
        # Processed metrics
        self.metrics = {
            'eye_tracking': {},
            'heart_rate': {},
            'gsr': {},
            'combined': {}
        }
        
        # Processing thread
        self.processing_thread = None
        self.stop_processing = threading.Event()
        
        logger.info("Biometric data processor initialized")
    
    def start_processing(self) -> bool:
        """Start the background processing thread."""
        if self.processing_thread and self.processing_thread.is_alive():
            logger.warning("Processing thread already running")
            return False
        
        self.stop_processing.clear()
        self.processing_thread = threading.Thread(target=self._processing_loop)
        self.processing_thread.daemon = True
        self.processing_thread.start()
        
        logger.info("Biometric data processing started")
        return True
    
    def stop_processing(self) -> bool:
        """Stop the background processing thread."""
        if not (self.processing_thread and self.processing_thread.is_alive()):
            logger.warning("Processing thread not running")
            return False
        
        self.stop_processing.set()
        self.processing_thread.join(timeout=2.0)
        
        if self.processing_thread.is_alive():
            logger.error("Failed to stop processing thread")
            return False
        
        logger.info("Biometric data processing stopped")
        return True
    
    def add_eye_tracking_data(self, data: Dict[str, Any]) -> None:
        """Add eye tracking data to the buffer.
        
        Args:
            data: Eye tracking data point with timestamp and values
        """
        self.eye_tracking_buffer.append(data)
    
    def add_heart_rate_data(self, data: Dict[str, Any]) -> None:
        """Add heart rate data to the buffer.
        
        Args:
            data: Heart rate data point with timestamp and values
        """
        self.heart_rate_buffer.append(data)
    
    def add_gsr_data(self, data: Dict[str, Any]) -> None:
        """Add galvanic skin response data to the buffer.
        
        Args:
            data: GSR data point with timestamp and values
        """
        self.gsr_buffer.append(data)
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get the current computed metrics."""
        return self.metrics
    
    def get_cognitive_load_estimate(self) -> float:
        """Estimate the current cognitive load based on all biometric data.
        
        Returns:
            Estimated cognitive load on a scale of 0.0 to 1.0
        """
        # This is a simplified model - a real implementation would use more
        # sophisticated algorithms combining multiple biometric signals
        
        metrics = self.metrics['combined']
        if not metrics:
            return 0.0
        
        # Normalized pupil dilation (if available)
        pupil_factor = metrics.get('normalized_pupil_dilation', 0.5)
        
        # Heart rate variability factor (if available)
        hrv_factor = 1.0 - metrics.get('normalized_hrv', 0.5)  # Lower HRV = higher stress
        
        # GSR factor (if available)
        gsr_factor = metrics.get('normalized_gsr', 0.5)
        
        # Combine factors (equal weights for this simple example)
        available_factors = 0
        combined_score = 0.0
        
        if 'normalized_pupil_dilation' in metrics:
            combined_score += pupil_factor
            available_factors += 1
            
        if 'normalized_hrv' in metrics:
            combined_score += hrv_factor
            available_factors += 1
            
        if 'normalized_gsr' in metrics:
            combined_score += gsr_factor
            available_factors += 1
        
        if available_factors == 0:
            return 0.0
            
        return combined_score / available_factors
    
    def detect_attention_shift(self) -> Tuple[bool, Optional[Dict[str, Any]]]:
        """Detect if the trainee's attention shifted away from critical instruments.
        
        Returns:
            Tuple of (detected, details)
        """
        if not self.eye_tracking_buffer:
            return False, None
        
        # Get recent eye tracking data
        recent_data = list(self.eye_tracking_buffer)[-30:]  # Last 30 samples
        
        # Check if gaze points are within defined areas of interest
        # This is a simplified mock implementation
        aoi_violations = 0
        for sample in recent_data:
            if 'gaze_point' in sample:
                gx, gy = sample['gaze_point']
                # Check if gaze is outside defined instrument areas
                # This would use actual screen coordinates in a real implementation
                if gx < 0.2 or gx > 0.8 or gy < 0.2 or gy > 0.8:
                    aoi_violations += 1
        
        # If more than 50% of recent samples are outside AOIs, consider it an attention shift
        if aoi_violations > len(recent_data) * 0.5:
            return True, {
                'violation_count': aoi_violations,
                'total_samples': len(recent_data),
                'violation_percentage': (aoi_violations / len(recent_data)) * 100,
                'timestamp': time.time()
            }
        
        return False, None
    
    def detect_stress_reaction(self) -> Tuple[bool, Optional[Dict[str, Any]]]:
        """Detect if the trainee is experiencing high stress based on biometric data.
        
        Returns:
            Tuple of (detected, details)
        """
        metrics = self.metrics
        
        # Check heart rate (if available)
        hr_elevated = False
        hr_details = {}
        if self.heart_rate_buffer and 'heart_rate' in metrics:
            recent_hr = metrics['heart_rate'].get('mean', 0)
            baseline_hr = metrics['heart_rate'].get('baseline', 70)
            
            # If heart rate is 20% above baseline, consider it elevated
            if recent_hr > baseline_hr * 1.2:
                hr_elevated = True
                hr_details = {
                    'recent_hr': recent_hr,
                    'baseline_hr': baseline_hr,
                    'percent_increase': ((recent_hr - baseline_hr) / baseline_hr) * 100
                }
        
        # Check GSR (if available)
        gsr_elevated = False
        gsr_details = {}
        if self.gsr_buffer and 'gsr' in metrics:
            recent_gsr = metrics['gsr'].get('mean', 0)
            baseline_gsr = metrics['gsr'].get('baseline', 5)
            
            # If GSR is 30% above baseline, consider it elevated
            if recent_gsr > baseline_gsr * 1.3:
                gsr_elevated = True
                gsr_details = {
                    'recent_gsr': recent_gsr,
                    'baseline_gsr': baseline_gsr,
                    'percent_increase': ((recent_gsr - baseline_gsr) / baseline_gsr) * 100
                }
        
        # Consider it a stress reaction if either metric is elevated
        if hr_elevated or gsr_elevated:
            return True, {
                'heart_rate_elevated': hr_elevated,
                'heart_rate_details': hr_details,
                'gsr_elevated': gsr_elevated,
                'gsr_details': gsr_details,
                'timestamp': time.time()
            }
        
        return False, None
    
    def _processing_loop(self) -> None:
        """Background thread for continuous data processing."""
        logger.debug("Processing loop started")
        
        processing_interval = 1.0 / self.config.get('processing_rate', 10)  # Default 10Hz
        
        while not self.stop_processing.is_set():
            start_time = time.time()
            
            # Process eye tracking data
            if self.eye_tracking_buffer:
                self._process_eye_tracking()
            
            # Process heart rate data
            if self.heart_rate_buffer:
                self._process_heart_rate()
            
            # Process GSR data
            if self.gsr_buffer:
                self._process_gsr()
            
            # Compute combined metrics
            self._compute_combined_metrics()
            
            # Sleep to maintain target processing rate
            elapsed = time.time() - start_time
            sleep_time = max(0, processing_interval - elapsed)
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        logger.debug("Processing loop stopped")
    
    def _process_eye_tracking(self) -> None:
        """Process eye tracking data to extract metrics."""
        data = list(self.eye_tracking_buffer)
        
        # Extract pupil diameters
        pupil_diameters = []
        for sample in data:
            if 'pupil_diameter' in sample:
                if isinstance(sample['pupil_diameter'], (list, tuple)) and len(sample['pupil_diameter']) >= 2:
                    # Average left and right eye if available
                    pd_avg = sum(sample['pupil_diameter']) / len(sample['pupil_diameter'])
                    pupil_diameters.append(pd_avg)
                else:
                    # Single value
                    pupil_diameters.append(sample['pupil_diameter'])
        
        if pupil_diameters:
            # Calculate metrics
            pd_mean = np.mean(pupil_diameters)
            pd_std = np.std(pupil_diameters)
            pd_min = np.min(pupil_diameters)
            pd_max = np.max(pupil_diameters)
            
            # Normalized pupil dilation (0-1 scale)
            # This is a simplified approach - proper normalization would use baseline measurements
            pd_range = self.config.get('pupil_diameter_range', (2.0, 8.0))  # mm
            pd_norm = np.clip((pd_mean - pd_range[0]) / (pd_range[1] - pd_range[0]), 0, 1)
            
            # Update metrics
            self.metrics['eye_tracking'] = {
                'mean_pupil_diameter': pd_mean,
                'std_pupil_diameter': pd_std,
                'min_pupil_diameter': pd_min,
                'max_pupil_diameter': pd_max,
                'normalized_pupil_dilation': pd_norm,
                'samples_processed': len(pupil_diameters)
            }
    
    def _process_heart_rate(self) -> None:
        """Process heart rate data to extract metrics."""
        data = list(self.heart_rate_buffer)
        
        # Extract heart rates and timestamps
        heart_rates = []
        timestamps = []
        for sample in data:
            if 'heart_rate' in sample and 'timestamp' in sample:
                heart_rates.append(sample['heart_rate'])
                timestamps.append(sample['timestamp'])
        
        if heart_rates and len(heart_rates) > 1:
            # Calculate metrics
            hr_mean = np.mean(heart_rates)
            hr_std = np.std(heart_rates)
            hr_min = np.min(heart_rates)
            hr_max = np.max(heart_rates)
            
            # Calculate heart rate variability
            # Convert timestamps to RR intervals in ms
            rr_intervals = []
            if len(timestamps) > 1:
                for i in range(1, len(timestamps)):
                    # Convert time difference to milliseconds
                    rr = (timestamps[i] - timestamps[i-1]) * 1000
                    if 300 < rr < 2000:  # Filter physiologically plausible values
                        rr_intervals.append(rr)
            
            hrv = 0
            if rr_intervals:
                # RMSSD (Root Mean Square of Successive Differences)
                rr_diffs = np.diff(rr_intervals)
                hrv = np.sqrt(np.mean(np.square(rr_diffs)))
            
            # Normalize HRV (0-1 scale)
            # This is simplified - proper normalization would use baseline measurements
            hrv_norm = np.clip(hrv / 100.0, 0, 1)  # Arbitrary scaling
            
            # Update metrics
            self.metrics['heart_rate'] = {
                'mean': hr_mean,
                'std': hr_std,
                'min': hr_min,
                'max': hr_max,
                'baseline': self.metrics.get('heart_rate', {}).get('baseline', hr_mean),
                'hrv': hrv,
                'normalized_hrv': hrv_norm,
                'samples_processed': len(heart_rates)
            }
    
    def _process_gsr(self) -> None:
        """Process galvanic skin response data to extract metrics."""
        data = list(self.gsr_buffer)
        
        # Extract GSR values
        gsr_values = []
        for sample in data:
            if 'gsr' in sample:
                gsr_values.append(sample['gsr'])
        
        if gsr_values:
            # Calculate metrics
            gsr_mean = np.mean(gsr_values)
            gsr_std = np.std(gsr_values)
            gsr_min = np.min(gsr_values)
            gsr_max = np.max(gsr_values)
            
            # Normalize GSR (0-1 scale)
            # This is simplified - proper normalization would use baseline measurements
            gsr_range = self.config.get('gsr_range', (0.1, 20.0))  # microSiemens
            gsr_norm = np.clip((gsr_mean - gsr_range[0]) / (gsr_range[1] - gsr_range[0]), 0, 1)
            
            # Update metrics
            self.metrics['gsr'] = {
                'mean': gsr_mean,
                'std': gsr_std,
                'min': gsr_min,
                'max': gsr_max,
                'baseline': self.metrics.get('gsr', {}).get('baseline', gsr_mean),
                'normalized_gsr': gsr_norm,
                'samples_processed': len(gsr_values)
            }
    
    def _compute_combined_metrics(self) -> None:
        """Compute metrics that combine multiple biometric signals."""
        combined = {}
        
        # Copy normalized metrics from individual sources
        if 'eye_tracking' in self.metrics and 'normalized_pupil_dilation' in self.metrics['eye_tracking']:
            combined['normalized_pupil_dilation'] = self.metrics['eye_tracking']['normalized_pupil_dilation']
        
        if 'heart_rate' in self.metrics and 'normalized_hrv' in self.metrics['heart_rate']:
            combined['normalized_hrv'] = self.metrics['heart_rate']['normalized_hrv']
        
        if 'gsr' in self.metrics and 'normalized_gsr' in self.metrics['gsr']:
            combined['normalized_gsr'] = self.metrics['gsr']['normalized_gsr']
        
        # Calculate cognitive load
        if combined:
            combined['cognitive_load'] = self.get_cognitive_load_estimate()
        
        self.metrics['combined'] = combined

# Example usage:
# config = {
#     'buffer_size': 500,
#     'sampling_rate': 50,
#     'processing_rate': 10
# }
# processor = BiometricDataProcessor(config)
# processor.start_processing()
# 
# # Add mock data
# processor.add_heart_rate_data({'timestamp': time.time(), 'heart_rate': 75})
# processor.add_eye_tracking_data({'pupil_diameter': [4.2, 4.3]})
# 
# # Get metrics
# metrics = processor.get_metrics()
# cognitive_load = processor.get_cognitive_load_estimate()
# 
# processor.stop_processing()

// /backend/tests/core/ConfigurationManagerTests.cpp
#include <gtest/gtest.h>
#include "core/ConfigurationManager.h"

class ConfigurationManagerTest : public ::testing::Test {
protected:
    void SetUp() override {
        // Set up test environment
        // Create a temporary config file for testing
        std::ofstream configFile("test_config.json");
        configFile << "{ \"apiKey\": \"test-key\", \"maxConnections\": 100 }";
        configFile.close();
    }

    void TearDown() override {
        // Clean up test environment
        std::remove("test_config.json");
    }
};

TEST_F(ConfigurationManagerTest, LoadConfigFromFile) {
    ConfigurationManager config;
    bool loaded = config.loadFromFile("test_config.json");
    EXPECT_TRUE(loaded);
    EXPECT_EQ(config.getString("apiKey"), "test-key");
    EXPECT_EQ(config.getInt("maxConnections"), 100);
}

TEST_F(ConfigurationManagerTest, GetNonExistentKey) {
    ConfigurationManager config;
    config.loadFromFile("test_config.json");
    EXPECT_THROW(config.getString("nonExistentKey"), std::out_of_range);
}

// /backend/tests/document/DocumentProcessorTests.cpp
#include <gtest/gtest.h>
#include "document/DocumentProcessor.h"
#include "document/PDFProcessor.h"

class DocumentProcessorTest : public ::testing::Test {
protected:
    void SetUp() override {
        // Set up document processing test environment
        testPdfPath = "test_document.pdf";
        // Create a mock PDF file or use a fixture
    }

    void TearDown() override {
        // Clean up document processing test environment
    }

    std::string testPdfPath;
};

TEST_F(DocumentProcessorTest, ProcessPdfDocument) {
    PDFProcessor processor;
    auto result = processor.process(testPdfPath);
    EXPECT_TRUE(result.isSuccess());
    EXPECT_FALSE(result.getExtractedText().empty());
}

// /backend/tests/performance/SimulatorDataBenchmark.cpp
#include <benchmark/benchmark.h>
#include "integration/SimulatorDataProcessor.h"

// Benchmark for processing high-frequency simulator data
static void BM_SimulatorDataProcessing(benchmark::State& state) {
    // Setup simulator data processor
    SimulatorDataProcessor processor(1000); // 1000Hz frequency
    
    // Create sample telemetry data
    const size_t dataSize = state.range(0);
    std::vector<SimulatorTelemetry> telemetryData(dataSize);
    
    // Generate sample data
    for (size_t i = 0; i < dataSize; ++i) {
        telemetryData[i] = SimulatorTelemetry{
            /* timestamp */ static_cast<double>(i) / 1000.0,
            /* altitude */ 10000.0 + std::sin(static_cast<double>(i) / 100.0) * 1000.0,
            /* speed */ 250.0 + std::cos(static_cast<double>(i) / 50.0) * 50.0,
            /* heading */ static_cast<float>(i % 360),
            // Additional telemetry fields...
        };
    }
    
    // Benchmark processing loop
    for (auto _ : state) {
        processor.processBatch(telemetryData);
    }
    
    // Report processing rate (items/second)
    state.SetItemsProcessed(static_cast<int64_t>(state.iterations()) * dataSize);
}

// Register benchmark with different data sizes
BENCHMARK(BM_SimulatorDataProcessing)->Range(1000, 10000);

// /backend/tests/integration/SyllabusWorkflowTests.cpp
#include <gtest/gtest.h>
#include "document/DocumentProcessor.h"
#include "syllabus/SyllabusGenerator.h"
#include "compliance/ComplianceChecker.h"

class SyllabusWorkflowTest : public ::testing::Test {
protected:
    void SetUp() override {
        // Set up the components for the workflow
        docProcessor = std::make_unique<DocumentProcessor>();
        syllabusGenerator = std::make_unique<SyllabusGenerator>();
        complianceChecker = std::make_unique<ComplianceChecker>();
        
        // Set up test files and database connection
        testDocPath = "test_training_manual.pdf";
        // Setup database with test data
    }
    
    void TearDown() override {
        // Clean up resources
    }
    
    std::unique_ptr<DocumentProcessor> docProcessor;
    std::unique_ptr<SyllabusGenerator> syllabusGenerator;
    std::unique_ptr<ComplianceChecker> complianceChecker;
    std::string testDocPath;
};

TEST_F(SyllabusWorkflowTest, EndToEndSyllabusGeneration) {
    // Test the entire workflow from document processing to syllabus generation
    
    // 1. Process document
    auto docResult = docProcessor->process(testDocPath);
    ASSERT_TRUE(docResult.isSuccess());
    
    // 2. Extract training requirements
    auto extractedData = docProcessor->extractTrainingRequirements(docResult);
    ASSERT_FALSE(extractedData.empty());
    
    // 3. Generate syllabus
    auto syllabus = syllabusGenerator->generateFromRequirements(extractedData);
    ASSERT_TRUE(syllabus.isValid());
    ASSERT_GT(syllabus.getModules().size(), 0);
    
    // 4. Check compliance with regulations
    auto complianceResult = complianceChecker->checkCompliance(syllabus, "FAA");
    ASSERT_TRUE(complianceResult.isCompliant());
}

// /backend/tests/CMakeLists.txt
cmake_minimum_required(VERSION 3.14)
project(AdvancedPilotTrainingPlatformTests)

# Find packages
find_package(GTest REQUIRED)
find_package(benchmark REQUIRED)

# Include directories
include_directories(${CMAKE_SOURCE_DIR}/../)

# Unit tests executable
add_executable(unit_tests
    core/ConfigurationManagerTests.cpp
    document/DocumentProcessorTests.cpp
    # Add other test files
)

target_link_libraries(unit_tests
    GTest::GTest
    GTest::Main
    AdvancedPilotTrainingPlatformLib
)

# Performance benchmarks executable
add_executable(performance_benchmarks
    performance/SimulatorDataBenchmark.cpp
    # Add other benchmark files
)

target_link_libraries(performance_benchmarks
    benchmark::benchmark
    AdvancedPilotTrainingPlatformLib
)

# Integration tests executable
add_executable(integration_tests
    integration/SyllabusWorkflowTests.cpp
    # Add other integration test files
)

target_link_libraries(integration_tests
    GTest::GTest
    GTest::Main
    AdvancedPilotTrainingPlatformLib
)

# Python tests with pytest
add_custom_target(pytest
    COMMAND ${CMAKE_COMMAND} -E env PYTHONPATH=${CMAKE_SOURCE_DIR}/../python pytest -xvs ${CMAKE_SOURCE_DIR}/python
    WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}
)

# /backend/tests/python/test_document_ai.py
import pytest
import numpy as np
from document.ai.document_classifier import DocumentClassifier
from document.ai.entity_extractor import EntityExtractor

class TestDocumentAI:
    @pytest.fixture
    def document_classifier(self):
        return DocumentClassifier()
    
    @pytest.fixture
    def entity_extractor(self):
        return EntityExtractor()
    
    @pytest.fixture
    def sample_document(self):
        # Load or create sample document text
        with open("test_data/flight_manual.txt", "r") as f:
            return f.read()
    
    def test_document_classification(self, document_classifier, sample_document):
        # Test that document is correctly classified
        result = document_classifier.classify(sample_document)
        assert result.top_class == "flight_manual"
        assert result.confidence > 0.85
    
    def test_entity_extraction(self, entity_extractor, sample_document):
        # Test that entities are correctly extracted
        entities = entity_extractor.extract(sample_document)
        
        # Check for expected entities
        procedure_entities = [e for e in entities if e.type == "procedure"]
        assert len(procedure_entities) > 0
        
        # Check for specific procedure
        takeoff_procedures = [p for p in procedure_entities if "takeoff" in p.text.lower()]
        assert len(takeoff_procedures) > 0

# /backend/tests/python/test_performance_prediction.py
import pytest
import numpy as np
import pandas as pd
from analytics.performance_predictor import PerformancePredictor
from analytics.feature_engineering import FeatureEngineer

class TestPerformancePredictor:
    @pytest.fixture
    def performance_data(self):
        # Create sample performance data
        return pd.DataFrame({
            'trainee_id': np.repeat(range(1, 21), 5),  # 20 trainees, 5 sessions each
            'session_id': np.tile(range(1, 6), 20),    # 5 sessions per trainee
            'exercise_score': np.random.uniform(60, 100, 100),
            'reaction_time': np.random.uniform(0.5, 2.0, 100),
            'error_count': np.random.randint(0, 10, 100),
            'completion_time': np.random.uniform(5, 30, 100),
            'passed': np.random.choice([0, 1], 100, p=[0.2, 0.8])  # 80% pass rate
        })
    
    @pytest.fixture
    def feature_engineer(self):
        return FeatureEngineer()
    
    @pytest.fixture
    def performance_predictor(self):
        return PerformancePredictor()
    
    def test_feature_engineering(self, feature_engineer, performance_data):
        # Test feature engineering pipeline
        features = feature_engineer.transform(performance_data)
        
        # Check that we have the expected features
        assert 'avg_exercise_score' in features.columns
        assert 'trend_error_count' in features.columns
        assert features.shape[0] == len(performance_data['trainee_id'].unique())
    
    def test_performance_prediction(self, performance_predictor, feature_engineer, performance_data):
        # Split data for testing
        train_data = performance_data[performance_data['session_id'] < 4]
        test_data = performance_data[performance_data['session_id'] >= 4]
        
        # Generate features
        train_features = feature_engineer.transform(train_data)
        train_labels = train_data.groupby('trainee_id')['passed'].mean() > 0.7
        
        # Train the model
        performance_predictor.train(train_features, train_labels)
        
        # Make predictions
        test_features = feature_engineer.transform(test_data)
        predictions = performance_predictor.predict(test_features)
        
        # Check predictions shape
        assert len(predictions) == test_features.shape[0]
        
        # Evaluate accuracy (should be better than random)
        test_labels = test_data.groupby('trainee_id')['passed'].mean() > 0.7
        accuracy = (predictions == test_labels).mean()
        assert accuracy > 0.6  # Should be better than random guessing

// /backend/visualization/include/visualization/VisualizationService.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <unordered_map>
#include <mutex>
#include "core/ConfigurationManager.h"
#include "database/DatabaseManager.h"
#include "document/DocumentManager.h"
#include "syllabus/SyllabusManager.h"
#include "assessment/AssessmentManager.h"
#include "visualization/VisualizationTypes.h"
#include "visualization/ScenarioGenerator.h"

namespace Visualization {

class VisualizationService {
public:
    VisualizationService(
        std::shared_ptr<Core::ConfigurationManager> config,
        std::shared_ptr<Database::DatabaseManager> dbManager,
        std::shared_ptr<Document::DocumentManager> docManager,
        std::shared_ptr<Syllabus::SyllabusManager> syllabusManager,
        std::shared_ptr<Assessment::AssessmentManager> assessmentManager
    );
    ~VisualizationService();
    
    // 3D Knowledge Map methods
    std::shared_ptr<KnowledgeMap> createKnowledgeMap(const std::string& syllabusId);
    std::shared_ptr<KnowledgeMap> getKnowledgeMap(const std::string& mapId);
    bool updateKnowledgeMap(const std::shared_ptr<KnowledgeMap>& map);
    bool deleteKnowledgeMap(const std::string& mapId);
    std::vector<std::shared_ptr<KnowledgeMap>> getUserKnowledgeMaps(const std::string& userId);
    
    // 3D Model management
    std::shared_ptr<AircraftModel> getAircraftModel(const std::string& aircraftType);
    std::vector<std::string> getAvailableAircraftModels();
    bool addAircraftModel(const std::shared_ptr<AircraftModel>& model);
    
    // Simulation visualization
    std::shared_ptr<SimulationScene> createSimulationScene(
        const std::string& name, 
        const std::string& aircraftType,
        const SceneEnvironment& environment
    );
    std::shared_ptr<SimulationScene> getSimulationScene(const std::string& sceneId);
    bool updateSimulationScene(const std::shared_ptr<SimulationScene>& scene);
    bool deleteSimulationScene(const std::string& sceneId);
    
    // AR content generation
    std::shared_ptr<ARContent> generateARContent(
        const std::string& documentId, 
        ARContentType contentType
    );
    std::shared_ptr<ARContent> getARContent(const std::string& contentId);
    bool updateARContent(const std::shared_ptr<ARContent>& content);
    bool deleteARContent(const std::string& contentId);
    
    // Performance visualization
    std::shared_ptr<PerformanceVisualization> createPerformanceVisualization(
        const std::string& assessmentId,
        VisualizationType visualizationType
    );
    std::vector<std::shared_ptr<PerformanceVisualization>> getTraineePerformanceVisualizations(
        const std::string& traineeId
    );
    
    // Interactive Scenario Generation
    std::shared_ptr<TrainingScenario> generateScenario(
        const std::string& syllabusId,
        const std::string& moduleId,
        ScenarioDifficulty difficulty
    );
    std::shared_ptr<TrainingScenario> getScenario(const std::string& scenarioId);
    bool updateScenario(const std::shared_ptr<TrainingScenario>& scenario);
    std::vector<std::shared_ptr<TrainingScenario>> getModuleScenarios(
        const std::string& moduleId
    );
    
    // Visualization data export
    std::string exportVisualizationToGLTF(const std::string& visualizationId);
    std::string exportVisualizationToFBX(const std::string& visualizationId);
    std::string exportVisualizationToJSON(const std::string& visualizationId);

private:
    std::shared_ptr<Core::ConfigurationManager> config_;
    std::shared_ptr<Database::DatabaseManager> dbManager_;
    std::shared_ptr<Document::DocumentManager> docManager_;
    std::shared_ptr<Syllabus::SyllabusManager> syllabusManager_;
    std::shared_ptr<Assessment::AssessmentManager> assessmentManager_;
    std::shared_ptr<ScenarioGenerator> scenarioGenerator_;
    
    // Cache management
    std::unordered_map<std::string, std::shared_ptr<KnowledgeMap>> knowledgeMapCache_;
    std::unordered_map<std::string, std::shared_ptr<AircraftModel>> aircraftModelCache_;
    std::unordered_map<std::string, std::shared_ptr<SimulationScene>> simulationSceneCache_;
    std::unordered_map<std::string, std::shared_ptr<ARContent>> arContentCache_;
    std::mutex cacheMutex_;
    
    // Helper methods
    std::shared_ptr<KnowledgeNode> createNodeFromSyllabusItem(const Syllabus::SyllabusItem& item);
    std::vector<KnowledgeLink> generateLinksForNodes(const std::vector<std::shared_ptr<KnowledgeNode>>& nodes);
    void refreshCaches();
};

} // namespace Visualization

// /backend/visualization/include/visualization/VisualizationTypes.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <optional>
#include <chrono>
#include <nlohmann/json.hpp>
#include <Eigen/Dense>

namespace Visualization {

// 3D coordinate type
using Vector3 = Eigen::Vector3f;
using Vector2 = Eigen::Vector2f;
using Quaternion = Eigen::Quaternionf;

// Knowledge Map types
enum class NodeType {
    OBJECTIVE,
    COMPETENCY,
    TOPIC,
    PROCEDURE,
    REGULATION,
    AIRCRAFT_SYSTEM
};

class KnowledgeNode {
public:
    std::string id;
    std::string label;
    std::string description;
    NodeType type;
    Vector3 position;
    float size;
    std::string color;
    std::unordered_map<std::string, std::string> metadata;
    
    nlohmann::json toJson() const;
    static std::shared_ptr<KnowledgeNode> fromJson(const nlohmann::json& json);
};

struct KnowledgeLink {
    std::string id;
    std::string sourceNodeId;
    std::string targetNodeId;
    std::string label;
    float strength;
    std::string color;
    
    nlohmann::json toJson() const;
    static KnowledgeLink fromJson(const nlohmann::json& json);
};

class KnowledgeMap {
public:
    std::string id;
    std::string name;
    std::string description;
    std::string creatorId;
    std::string syllabusId;
    std::chrono::system_clock::time_point createdAt;
    std::chrono::system_clock::time_point updatedAt;
    std::vector<std::shared_ptr<KnowledgeNode>> nodes;
    std::vector<KnowledgeLink> links;
    
    nlohmann::json toJson() const;
    static std::shared_ptr<KnowledgeMap> fromJson(const nlohmann::json& json);
};

// Aircraft Model types
class AircraftModel {
public:
    std::string id;
    std::string aircraftType;
    std::string manufacturer;
    std::string modelVersion;
    std::string modelPath;
    std::string texturesPath;
    std::vector<std::string> animationNames;
    std::unordered_map<std::string, std::string> systemModels;
    
    nlohmann::json toJson() const;
    static std::shared_ptr<AircraftModel> fromJson(const nlohmann::json& json);
};

// Simulation Scene types
enum class WeatherCondition {
    CLEAR,
    SCATTERED_CLOUDS,
    BROKEN_CLOUDS,
    OVERCAST,
    RAIN,
    THUNDERSTORM,
    SNOW,
    FOG
};

enum class TimeOfDay {
    DAWN,
    MORNING,
    NOON,
    AFTERNOON,
    DUSK,
    NIGHT,
    MIDNIGHT
};

struct SceneEnvironment {
    WeatherCondition weather;
    TimeOfDay timeOfDay;
    float visibility;
    float windSpeed;
    float windDirection;
    float temperature;
    float cloudBase;
    
    nlohmann::json toJson() const;
    static SceneEnvironment fromJson(const nlohmann::json& json);
};

class SimulationScene {
public:
    std::string id;
    std::string name;
    std::string description;
    std::string creatorId;
    std::string aircraftModelId;
    SceneEnvironment environment;
    std::string airportIcao;
    std::string runwayId;
    Vector3 initialPosition;
    Quaternion initialOrientation;
    float initialAltitude;
    float initialSpeed;
    std::chrono::system_clock::time_point createdAt;
    
    nlohmann::json toJson() const;
    static std::shared_ptr<SimulationScene> fromJson(const nlohmann::json& json);
};

// AR Content types
enum class ARContentType {
    COCKPIT_OVERLAY,
    PROCEDURE_VISUALIZATION,
    SYSTEM_EXPLODED_VIEW,
    AIRPORT_DIAGRAM,
    FLIGHT_PATH_VISUALIZATION,
    EMERGENCY_PROCEDURE
};

class ARContent {
public:
    std::string id;
    std::string name;
    std::string description;
    ARContentType type;
    std::string sourceDocumentId;
    std::string modelPath;
    std::string texturesPath;
    std::unordered_map<std::string, std::string> annotations;
    std::chrono::system_clock::time_point createdAt;
    
    nlohmann::json toJson() const;
    static std::shared_ptr<ARContent> fromJson(const nlohmann::json& json);
};

// Performance Visualization types
enum class VisualizationType {
    FLIGHT_PATH_3D,
    CONTROL_INPUTS_TIMELINE,
    PARAMETER_COMPARISON,
    HEAT_MAP,
    DECISION_TREE,
    COMPETENCY_RADAR
};

struct DataPoint {
    std::chrono::system_clock::time_point timestamp;
    std::unordered_map<std::string, float> parameters;
    
    nlohmann::json toJson() const;
    static DataPoint fromJson(const nlohmann::json& json);
};

class PerformanceVisualization {
public:
    std::string id;
    std::string name;
    VisualizationType type;
    std::string assessmentId;
    std::string traineeId;
    std::string instructorId;
    std::vector<DataPoint> data;
    std::chrono::system_clock::time_point createdAt;
    
    nlohmann::json toJson() const;
    static std::shared_ptr<PerformanceVisualization> fromJson(const nlohmann::json& json);
};

// Training Scenario types
enum class ScenarioDifficulty {
    INTRODUCTORY,
    BASIC,
    INTERMEDIATE,
    ADVANCED,
    EXPERT
};

struct ScenarioEvent {
    std::string id;
    std::string name;
    std::string description;
    std::chrono::system_clock::time_point triggerTime;
    std::unordered_map<std::string, std::string> parameters;
    
    nlohmann::json toJson() const;
    static ScenarioEvent fromJson(const nlohmann::json& json);
};

class TrainingScenario {
public:
    std::string id;
    std::string name;
    std::string description;
    std::string syllabusId;
    std::string moduleId;
    ScenarioDifficulty difficulty;
    std::string aircraftModelId;
    SceneEnvironment environment;
    std::vector<ScenarioEvent> events;
    std::vector<std::string> learningObjectives;
    std::chrono::system_clock::time_point createdAt;
    
    nlohmann::json toJson() const;
    static std::shared_ptr<TrainingScenario> fromJson(const nlohmann::json& json);
};

} // namespace Visualization

// /backend/visualization/include/visualization/ScenarioGenerator.h
#pragma once

#include <string>
#include <memory>
#include <vector>
#include "visualization/VisualizationTypes.h"
#include "core/ConfigurationManager.h"
#include "database/DatabaseManager.h"
#include "syllabus/SyllabusManager.h"

namespace Visualization {

class ScenarioGenerator {
public:
    ScenarioGenerator(
        std::shared_ptr<Core::ConfigurationManager> config,
        std::shared_ptr<Database::DatabaseManager> dbManager,
        std::shared_ptr<Syllabus::SyllabusManager> syllabusManager
    );
    ~ScenarioGenerator();
    
    // Generate a training scenario based on syllabus module and difficulty
    std::shared_ptr<TrainingScenario> generateScenario(
        const std::string& syllabusId,
        const std::string& moduleId,
        ScenarioDifficulty difficulty
    );
    
    // Generate emergency scenario with specific aircraft system failures
    std::shared_ptr<TrainingScenario> generateEmergencyScenario(
        const std::string& aircraftType,
        const std::vector<std::string>& affectedSystems
    );
    
    // Generate weather-focused scenario
    std::shared_ptr<TrainingScenario> generateWeatherScenario(
        WeatherCondition condition,
        float intensity
    );
    
    // Generate a scenario focused on a specific airport and runway
    std::shared_ptr<TrainingScenario> generateAirportScenario(
        const std::string& airportIcao,
        const std::string& runwayId,
        TimeOfDay timeOfDay
    );
    
    // Save generated scenario
    bool saveScenario(const std::shared_ptr<TrainingScenario>& scenario);
    
    // Load a saved scenario
    std::shared_ptr<TrainingScenario> loadScenario(const std::string& scenarioId);
    
    // Get scenarios for a specific module
    std::vector<std::shared_ptr<TrainingScenario>> getModuleScenarios(
        const std::string& moduleId
    );

private:
    std::shared_ptr<Core::ConfigurationManager> config_;
    std::shared_ptr<Database::DatabaseManager> dbManager_;
    std::shared_ptr<Syllabus::SyllabusManager> syllabusManager_;
    
    // Helper methods
    std::vector<ScenarioEvent> generateEventsForModule(
        const std::string& moduleId,
        ScenarioDifficulty difficulty
    );
    
    SceneEnvironment generateEnvironmentForDifficulty(ScenarioDifficulty difficulty);
    
    std::vector<std::string> extractLearningObjectives(
        const std::string& syllabusId,
        const std::string& moduleId
    );
};

} // namespace Visualization

// /backend/visualization/src/VisualizationService.cpp
#include "visualization/VisualizationService.h"
#include <spdlog/spdlog.h>
#include <uuid/uuid.h>

namespace Visualization {

VisualizationService::VisualizationService(
    std::shared_ptr<Core::ConfigurationManager> config,
    std::shared_ptr<Database::DatabaseManager> dbManager,
    std::shared_ptr<Document::DocumentManager> docManager,
    std::shared_ptr<Syllabus::SyllabusManager> syllabusManager,
    std::shared_ptr<Assessment::AssessmentManager> assessmentManager
) : config_(config), 
    dbManager_(dbManager),
    docManager_(docManager),
    syllabusManager_(syllabusManager),
    assessmentManager_(assessmentManager) {
    
    // Initialize scenario generator
    scenarioGenerator_ = std::make_shared<ScenarioGenerator>(config_, dbManager_, syllabusManager_);
    
    // Load aircraft models into cache
    refreshCaches();
    
    spdlog::info("Visualization service initialized");
}

VisualizationService::~VisualizationService() {
    spdlog::info("Visualization service shutting down");
}

std::shared_ptr<KnowledgeMap> VisualizationService::createKnowledgeMap(const std::string& syllabusId) {
    // Get the syllabus
    auto syllabus = syllabusManager_->getSyllabus(syllabusId);
    if (!syllabus) {
        spdlog::error("Cannot create knowledge map: syllabus {} not found", syllabusId);
        return nullptr;
    }
    
    // Create a new knowledge map
    auto map = std::make_shared<KnowledgeMap>();
    
    // Generate a unique ID
    uuid_t uuid;
    uuid_generate(uuid);
    char uuid_str[37];
    uuid_unparse_lower(uuid, uuid_str);
    map->id = uuid_str;
    
    map->name = syllabus->getName() + " Knowledge Map";
    map->description = "3D visualization of " + syllabus->getName();
    map->creatorId = syllabus->getCreatorId();
    map->syllabusId = syllabusId;
    map->createdAt = std::chrono::system_clock::now();
    map->updatedAt = map->createdAt;
    
    // Create nodes from syllabus items
    std::vector<std::shared_ptr<KnowledgeNode>> nodes;
    
    // Process modules
    for (const auto& module : syllabus->getModules()) {
        // Create module node
        auto moduleNode = std::make_shared<KnowledgeNode>();
        moduleNode->id = module.getId();
        moduleNode->label = module.getName();
        moduleNode->description = module.getDescription();
        moduleNode->type = NodeType::TOPIC;
        moduleNode->size = 1.5f;
        moduleNode->color = "#4285F4";  // Blue
        
        // Set initial position (will be adjusted later)
        moduleNode->position = Vector3(
            static_cast<float>(rand()) / RAND_MAX * 20.0f - 10.0f,
            static_cast<float>(rand()) / RAND_MAX * 20.0f - 10.0f,
            static_cast<float>(rand()) / RAND_MAX * 20.0f - 10.0f
        );
        
        nodes.push_back(moduleNode);
        
        // Process lessons in this module
        for (const auto& lesson : module.getLessons()) {
            // Create lesson node
            auto lessonNode = std::make_shared<KnowledgeNode>();
            lessonNode->id = lesson.getId();
            lessonNode->label = lesson.getName();
            lessonNode->description = lesson.getDescription();
            lessonNode->type = NodeType::OBJECTIVE;
            lessonNode->size = 1.0f;
            lessonNode->color = "#34A853";  // Green
            
            // Set position near the module node
            lessonNode->position = moduleNode->position + Vector3(
                static_cast<float>(rand()) / RAND_MAX * 5.0f - 2.5f,
                static_cast<float>(rand()) / RAND_MAX * 5.0f - 2.5f,
                static_cast<float>(rand()) / RAND_MAX * 5.0f - 2.5f
            );
            
            nodes.push_back(lessonNode);
            
            // Process exercises in this lesson
            for (const auto& exercise : lesson.getExercises()) {
                // Create exercise node
                auto exerciseNode = std::make_shared<KnowledgeNode>();
                exerciseNode->id = exercise.getId();
                exerciseNode->label = exercise.getName();
                exerciseNode->description = exercise.getDescription();
                exerciseNode->type = NodeType::PROCEDURE;
                exerciseNode->size = 0.7f;
                exerciseNode->color = "#FBBC05";  // Yellow
                
                // Set position near the lesson node
                exerciseNode->position = lessonNode->position + Vector3(
                    static_cast<float>(rand()) / RAND_MAX * 3.0f - 1.5f,
                    static_cast<float>(rand()) / RAND_MAX * 3.0f - 1.5f,
                    static_cast<float>(rand()) / RAND_MAX * 3.0f - 1.5f
                );
                
                nodes.push_back(exerciseNode);
            }
        }
    }
    
    map->nodes = nodes;
    
    // Generate links between nodes
    map->links = generateLinksForNodes(nodes);
    
    // Save the map
    auto query = "INSERT INTO knowledge_maps (id, name, description, creator_id, syllabus_id, created_at, updated_at, data) "
                "VALUES ($1, $2, $3, $4, $5, $6, $7, $8)";
    
    nlohmann::json mapData = map->toJson();
    
    dbManager_->executeQuery(query, 
                           map->id, map->name, map->description, map->creatorId, map->syllabusId,
                           map->createdAt, map->updatedAt, mapData.dump());
    
    // Add to cache
    std::lock_guard<std::mutex> lock(cacheMutex_);
    knowledgeMapCache_[map->id] = map;
    
    spdlog::info("Created knowledge map {} for syllabus {}", map->id, syllabusId);
    
    return map;
}

std::shared_ptr<KnowledgeMap> VisualizationService::getKnowledgeMap(const std::string& mapId) {
    // Check cache first
    {
        std::lock_guard<std::mutex> lock(cacheMutex_);
        auto it = knowledgeMapCache_.find(mapId);
        if (it != knowledgeMapCache_.end()) {
            return it->second;
        }
    }
    
    // Not in cache, load from database
    auto query = "SELECT data FROM knowledge_maps WHERE id = $1";
    auto result = dbManager_->executeQuery(query, mapId);
    
    if (result.empty()) {
        spdlog::error("Knowledge map {} not found", mapId);
        return nullptr;
    }
    
    try {
        auto mapData = nlohmann::json::parse(result[0][0].as<std::string>());
        auto map = KnowledgeMap::fromJson(mapData);
        
        // Add to cache
        std::lock_guard<std::mutex> lock(cacheMutex_);
        knowledgeMapCache_[mapId] = map;
        
        return map;
    } catch (const std::exception& e) {
        spdlog::error("Error parsing knowledge map data: {}", e.what());
        return nullptr;
    }
}

bool VisualizationService::updateKnowledgeMap(const std::shared_ptr<KnowledgeMap>& map) {
    if (!map) {
        return false;
    }
    
    // Update timestamp
    map->updatedAt = std::chrono::system_clock::now();
    
    // Update in database
    auto query = "UPDATE knowledge_maps SET name = $1, description = $2, updated_at = $3, data = $4 "
                "WHERE id = $5";
    
    nlohmann::json mapData = map->toJson();
    
    bool success = dbManager_->executeQuery(query, 
                                         map->name, map->description, map->updatedAt, 
                                         mapData.dump(), map->id);
    
    if (success) {
        // Update cache
        std::lock_guard<std::mutex> lock(cacheMutex_);
        knowledgeMapCache_[map->id] = map;
        
        spdlog::info("Updated knowledge map {}", map->id);
    } else {
        spdlog::error("Failed to update knowledge map {}", map->id);
    }
    
    return success;
}

bool VisualizationService::deleteKnowledgeMap(const std::string& mapId) {
    // Delete from database
    auto query = "DELETE FROM knowledge_maps WHERE id = $1";
    bool success = dbManager_->executeQuery(query, mapId);
    
    if (success) {
        // Remove from cache
        std::lock_guard<std::mutex> lock(cacheMutex_);
        knowledgeMapCache_.erase(mapId);
        
        spdlog::info("Deleted knowledge map {}", mapId);
    } else {
        spdlog::error("Failed to delete knowledge map {}", mapId);
    }
    
    return success;
}

std::vector<std::shared_ptr<KnowledgeMap>> VisualizationService::getUserKnowledgeMaps(
    const std::string& userId
) {
    // Query database for user's knowledge maps
    auto query = "SELECT data FROM knowledge_maps WHERE creator_id = $1";
    auto result = dbManager_->executeQuery(query, userId);
    
    std::vector<std::shared_ptr<KnowledgeMap>> maps;
    
    for (const auto& row : result) {
        try {
            auto mapData = nlohmann::json::parse(row[0].as<std::string>());
            auto map = KnowledgeMap::fromJson(mapData);
            maps.push_back(map);
            
            // Update cache
            std::lock_guard<std::mutex> lock(cacheMutex_);
            knowledgeMapCache_[map->id] = map;
        } catch (const std::exception& e) {
            spdlog::error("Error parsing knowledge map data: {}", e.what());
        }
    }
    
    spdlog::info("Retrieved {} knowledge maps for user {}", maps.size(), userId);
    
    return maps;
}

std::vector<KnowledgeLink> VisualizationService::generateLinksForNodes(
    const std::vector<std::shared_ptr<KnowledgeNode>>& nodes
) {
    std::vector<KnowledgeLink> links;
    std::unordered_map<std::string, std::shared_ptr<KnowledgeNode>> nodeMap;
    
    // Create a map of node IDs to nodes for quick lookup
    for (const auto& node : nodes) {
        nodeMap[node->id] = node;
    }
    
    // Organize nodes by type
    std::unordered_map<NodeType, std::vector<std::shared_ptr<KnowledgeNode>>> nodesByType;
    for (const auto& node : nodes) {
        nodesByType[node->type].push_back(node);
    }
    
    // Helper function to generate a unique link ID
    auto generateLinkId = [](const std::string& sourceId, const std::string& targetId) {
        return sourceId + "-" + targetId;
    };
    
    // Link modules to their lessons
    for (const auto& moduleNode : nodesByType[NodeType::TOPIC]) {
        for (const auto& lessonNode : nodesByType[NodeType::OBJECTIVE]) {
            // Check if lesson position is close to module (indicating it belongs to this module)
            if ((lessonNode->position - moduleNode->position).norm() < 6.0f) {
                KnowledgeLink link;
                link.id = generateLinkId(moduleNode->id, lessonNode->id);
                link.sourceNodeId = moduleNode->id;
                link.targetNodeId = lessonNode->id;
                link.label = "Contains";
                link.strength = 1.0f;
                link.color = "#4285F4";  // Blue
                
                links.push_back(link);
            }
        }
    }
    
    // Link lessons to their exercises
    for (const auto& lessonNode : nodesByType[NodeType::OBJECTIVE]) {
        for (const auto& exerciseNode : nodesByType[NodeType::PROCEDURE]) {
            // Check if exercise position is close to lesson
            if ((exerciseNode->position - lessonNode->position).norm() < 4.0f) {
                KnowledgeLink link;
                link.id = generateLinkId(lessonNode->id, exerciseNode->id);
                link.sourceNodeId = lessonNode->id;
                link.targetNodeId = exerciseNode->id;
                link.label = "Includes";
                link.strength = 0.8f;
                link.color = "#34A853";  // Green
                
                links.push_back(link);
            }
        }
    }
    
    // Additionally, add some cross-linking between related nodes
    // This is a simplified example; in a real system, you would use more sophisticated
    // algorithms to determine related content
    
    // Link related exercises across lessons
    auto& exercises = nodesByType[NodeType::PROCEDURE];
    for (size_t i = 0; i < exercises.size(); ++i) {
        for (size_t j = i + 1; j < exercises.size(); ++j) {
            // Random chance of linking related exercises
            if (rand() % 10 == 0) {  // 10% chance
                KnowledgeLink link;
                link.id = generateLinkId(exercises[i]->id, exercises[j]->id);
                link.sourceNodeId = exercises[i]->id;
                link.targetNodeId = exercises[j]->id;
                link.label = "Related";
                link.strength = 0.3f;
                link.color = "#EA4335";  // Red
                
                links.push_back(link);
            }
        }
    }
    
    return links;
}

void VisualizationService::refreshCaches() {
    // Load aircraft models
    auto query = "SELECT data FROM aircraft_models";
    auto result = dbManager_->executeQuery(query);
    
    std::lock_guard<std::mutex> lock(cacheMutex_);
    
    for (const auto& row : result) {
        try {
            auto modelData = nlohmann::json::parse(row[0].as<std::string>());
            auto model = AircraftModel::fromJson(modelData);
            aircraftModelCache_[model->id] = model;
        } catch (const std::exception& e) {
            spdlog::error("Error parsing aircraft model data: {}", e.what());
        }
    }
    
    spdlog::info("Loaded {} aircraft models into cache", aircraftModelCache_.size());
    
    // Similarly load other caches as needed
}

std::shared_ptr<AircraftModel> VisualizationService::getAircraftModel(const std::string& aircraftType) {
    std::lock_guard<std::mutex> lock(cacheMutex_);
    
    // Find by aircraft type
    for (const auto& pair : aircraftModelCache_) {
        if (pair.second->aircraftType == aircraftType) {
            return pair.second;
        }
    }
    
    spdlog::error("Aircraft model for type {} not found", aircraftType);
    return nullptr;
}

std::vector<std::string> VisualizationService::getAvailableAircraftModels() {
    std::vector<std::string> availableModels;
    
    std::lock_guard<std::mutex> lock(cacheMutex_);
    for (const auto& pair : aircraftModelCache_) {
        availableModels.push_back(pair.second->aircraftType);
    }
    
    return availableModels;
}

// ... Additional method implementations would follow ...

} // namespace Visualization

// /backend/visualization/src/VisualizationTypes.cpp
#include "visualization/VisualizationTypes.h"
#include <spdlog/spdlog.h>

namespace Visualization {

// KnowledgeNode serialization
nlohmann::json KnowledgeNode::toJson() const {
    nlohmann::json json = {
        {"id", id},
        {"label", label},
        {"description", description},
        {"type", static_cast<int>(type)},
        {"size", size},
        {"color", color},
        {"position", {
            {"x", position.x()},
            {"y", position.y()},
            {"z", position.z()}
        }},
        {"metadata", metadata}
    };
    
    return json;
}

std::shared_ptr<KnowledgeNode> KnowledgeNode::fromJson(const nlohmann::json& json) {
    auto node = std::make_shared<KnowledgeNode>();
    
    node->id = json["id"].get<std::string>();
    node->label = json["label"].get<std::string>();
    node->description = json["description"].get<std::string>();
    node->type = static_cast<NodeType>(json["type"].get<int>());
    node->size = json["size"].get<float>();
    node->color = json["color"].get<std::string>();
    
    node->position = Vector3(
        json["position"]["x"].get<float>(),
        json["position"]["y"].get<float>(),
        json["position"]["z"].get<float>()
    );
    
    node->metadata = json["metadata"].get<std::unordered_map<std::string, std::string>>();
    
    return node;
}

// KnowledgeLink serialization
nlohmann::json KnowledgeLink::toJson() const {
    return {
        {"id", id},
        {"sourceNodeId", sourceNodeId},
        {"targetNodeId", targetNodeId},
        {"label", label},
        {"strength", strength},
        {"color", color}
    };
}

KnowledgeLink KnowledgeLink::fromJson(const nlohmann::json& json) {
    KnowledgeLink link;
    
    link.id = json["id"].get<std::string>();
    link.sourceNodeId = json["sourceNodeId"].get<std::string>();
    link.targetNodeId = json["targetNodeId"].get<std::string>();
    link.label = json["label"].get<std::string>();
    link.strength = json["strength"].get<float>();
    link.color = json["color"].get<std::string>();
    
    return link;
}

// KnowledgeMap serialization
nlohmann::json KnowledgeMap::toJson() const {
    nlohmann::json nodesJson = nlohmann::json::array();
    for (const auto& node : nodes) {
        nodesJson.push_back(node->toJson());
    }
    
    nlohmann::json linksJson = nlohmann::json::array();
    for (const auto& link : links) {
        linksJson.push_back(link.toJson());
    }
    
    return {
        {"id", id},
        {"name", name},
        {"description", description},
        {"creatorId", creatorId},
        {"syllabusId", syllabusId},
        {"createdAt", createdAt.time_since_epoch().count()},
        {"updatedAt", updatedAt.time_since_epoch().count()},
        {"nodes", nodesJson},
        {"links", linksJson}
    };
}

std::shared_ptr<KnowledgeMap> KnowledgeMap::fromJson(const nlohmann::json& json) {
    auto map = std::make_shared<KnowledgeMap>();
    
    map->id = json["id"].get<std::string>();
    map->name = json["name"].get<std::string>();
    map->description = json["description"].get<std::string>();
    map->creatorId = json["creatorId"].get<std::string>();
    map->syllabusId = json["syllabusId"].get<std::string>();
    
    map->createdAt = std::chrono::system_clock::time_point(
        std::chrono::milliseconds(json["createdAt"].get<int64_t>())
    );
    
    map->updatedAt = std::chrono::system_clock::time_point(
        std::chrono::milliseconds(json["updatedAt"].get<int64_t>())
    );
    
    for (const auto& nodeJson : json["nodes"]) {
        map->nodes.push_back(KnowledgeNode::fromJson(nodeJson));
    }
    
    for (const auto& linkJson : json["links"]) {
        map->links.push_back(KnowledgeLink::fromJson(linkJson));
    }
    
    return map;
}

// AircraftModel serialization
nlohmann::json AircraftModel::toJson() const {
    return {
        {"id", id},
        {"aircraftType", aircraftType},
        {"manufacturer", manufacturer},
        {"modelVersion", modelVersion},
        {"modelPath", modelPath},
        {"texturesPath", texturesPath},
        {"animationNames", animationNames},
        {"systemModels", systemModels}
    };
}

std::shared_ptr<AircraftModel> AircraftModel::fromJson(const nlohmann::json& json) {
    auto model = std::make_shared<AircraftModel>();
    
    model->id = json["id"].get<std::string>();
    model->aircraftType = json["aircraftType"].get<std::string>();
    model->manufacturer = json["manufacturer"].get<std::string>();
    model->modelVersion = json["modelVersion"].get<std::string>();
    model->modelPath = json["modelPath"].get<std::string>();
    model->texturesPath = json["texturesPath"].get<std::string>();
    model->animationNames = json["animationNames"].get<std::vector<std::string>>();
    model->systemModels = json["systemModels"].get<std::unordered_map<std::string, std::string>>();
    
    return model;
}

// SceneEnvironment serialization
nlohmann::json SceneEnvironment::toJson() const {
    return {
        {"weather", static_cast<int>(weather)},
        {"timeOfDay", static_cast<int>(timeOfDay)},
        {"visibility", visibility},
        {"windSpeed", windSpeed},
        {"windDirection", windDirection},
        {"temperature", temperature},
        {"cloudBase", cloudBase}
    };
}

SceneEnvironment SceneEnvironment::fromJson(const nlohmann::json& json) {
    SceneEnvironment env;
    
    env.weather = static_cast<WeatherCondition>(json["weather"].get<int>());
    env.timeOfDay = static_cast<TimeOfDay>(json["timeOfDay"].get<int>());
    env.visibility = json["visibility"].get<float>();
    env.windSpeed = json["windSpeed"].get<float>();
    env.windDirection = json["windDirection"].get<float>();
    env.temperature = json["temperature"].get<float>();
    env.cloudBase = json["cloudBase"].get<float>();
    
    return env;
}

// ... Additional serialization implementations for other types would follow ...

} // namespace Visualization

// /backend/visualization/python/knowledge_map_layout.py
import numpy as np
from typing import Dict, List, Tuple, Any
import json
import networkx as nx
from scipy.spatial import distance

class KnowledgeMapLayout:
    """Class for creating and optimizing 3D layouts for knowledge maps.
    
    This class provides methods to:
    1. Generate force-directed layouts for knowledge maps
    2. Organize nodes by clusters
    3. Create thematic layouts
    4. Export to various 3D formats
    """
    
    def __init__(self, knowledge_map_data: Dict[str, Any]):
        """Initialize with knowledge map data.
        
        Args:
            knowledge_map_data: Dictionary with nodes and links for the knowledge map
        """
        self.map_data = knowledge_map_data
        self.nodes = knowledge_map_data.get('nodes', [])
        self.links = knowledge_map_data.get('links', [])
        self.graph = self._build_graph()
        
    def _build_graph(self) -> nx.Graph:
        """Build a NetworkX graph from nodes and links."""
        G = nx.Graph()
        
        # Add nodes
        for node in self.nodes:
            node_attrs = {
                'label': node['label'],
                'type': node['type'],
                'size': node['size'],
                'color': node['color'],
                'pos': np.array([node['position']['x'], 
                                node['position']['y'], 
                                node['position']['z']])
            }
            G.add_node(node['id'], **node_attrs)
        
        # Add links
        for link in self.links:
            G.add_edge(link['sourceNodeId'], link['targetNodeId'], 
                      weight=link['strength'],
                      label=link['label'],
                      color=link['color'])
        
        return G
    
    def apply_force_directed_layout(self, iterations: int = 100, 
                                   repulsion: float = 1.0, 
                                   attraction: float = 0.1,
                                   gravity: float = 0.01) -> None:
        """Apply a 3D force-directed layout algorithm.
        
        Args:
            iterations: Number of iterations to run
            repulsion: Strength of repulsive force between nodes
            attraction: Strength of attractive force along edges
            gravity: Strength of force pulling nodes to origin
        """
        # Get positions
        pos = nx.get_node_attributes(self.graph, 'pos')
        if not pos:
            # Initialize random positions if none exist
            pos = {node: np.random.uniform(-10, 10, 3) for node in self.graph.nodes()}
            nx.set_node_attributes(self.graph, pos, 'pos')
        
        # Run force-directed algorithm
        for _ in range(iterations):
            # Calculate forces
            force = {node: np.zeros(3) for node in self.graph.nodes()}
            
            # Repulsive forces (node-node)
            nodes = list(self.graph.nodes())
            for i, node1 in enumerate(nodes):
                for node2 in nodes[i+1:]:
                    delta = pos[node1] - pos[node2]
                    dist = np.linalg.norm(delta)
                    if dist < 0.1:  # Avoid division by zero
                        dist = 0.1
                        delta = np.random.uniform(-0.1, 0.1, 3)
                    
                    # Inverse square law for repulsion
                    f_rep = repulsion * delta / (dist ** 2)
                    
                    force[node1] += f_rep
                    force[node2] -= f_rep
            
            # Attractive forces (connected nodes)
            for node1, node2 in self.graph.edges():
                delta = pos[node1] - pos[node2]
                dist = np.linalg.norm(delta)
                
                # Hooke's law for attraction (spring force)
                edge_data = self.graph.get_edge_data(node1, node2)
                weight = edge_data.get('weight', 1.0)
                f_attr = -attraction * weight * delta
                
                force[node1] += f_attr
                force[node2] -= f_attr
            
            # Gravity towards origin
            for node in self.graph.nodes():
                force[node] -= gravity * pos[node]
            
            # Update positions
            for node in self.graph.nodes():
                # Apply force with damping
                pos[node] += force[node] * 0.1
        
        # Update node positions in graph
        nx.set_node_attributes(self.graph, pos, 'pos')
        
        # Update original data
        for node in self.nodes:
            node_id = node['id']
            if node_id in pos:
                node['position']['x'] = float(pos[node_id][0])
                node['position']['y'] = float(pos[node_id][1])
                node['position']['z'] = float(pos[node_id][2])
    
    def cluster_by_type(self, spacing: float = 20.0) -> None:
        """Organize nodes in clusters by their type.
        
        Args:
            spacing: Spacing between clusters
        """
        # Group nodes by type
        nodes_by_type = {}
        for node in self.nodes:
            node_type = node['type']
            if node_type not in nodes_by_type:
                nodes_by_type[node_type] = []
            nodes_by_type[node_type].append(node)
        
        # Position clusters in a circle
        num_types = len(nodes_by_type)
        for i, (node_type, nodes) in enumerate(nodes_by_type.items()):
            # Calculate cluster center
            angle = 2 * np.pi * i / num_types
            center_x = spacing * np.cos(angle)
            center_y = spacing * np.sin(angle)
            center_z = 0
            
            # Position nodes within cluster using force-directed layout
            for j, node in enumerate(nodes):
                # Start with a spherical distribution around center
                radius = 5.0
                theta = np.pi * np.random.random()
                phi = 2 * np.pi * np.random.random()
                
                node['position']['x'] = center_x + radius * np.sin(theta) * np.cos(phi)
                node['position']['y'] = center_y + radius * np.sin(theta) * np.sin(phi)
                node['position']['z'] = center_z + radius * np.cos(theta)
            
            # Run a mini force-directed layout just for this cluster
            self._optimize_cluster_layout(nodes)
    
    def _optimize_cluster_layout(self, nodes: List[Dict[str, Any]], iterations: int = 50) -> None:
        """Optimize layout for a cluster of nodes.
        
        Args:
            nodes: List of nodes in the cluster
            iterations: Number of iterations to run
        """
        # Create a subgraph for this cluster
        node_ids = [node['id'] for node in nodes]
        subgraph = self.graph.subgraph(node_ids)
        
        # Get positions
        pos = {node['id']: np.array([node['position']['x'],
                                    node['position']['y'],
                                    node['position']['z']]) for node in nodes}
        
        # Run simplified force-directed algorithm
        for _ in range(iterations):
            # Calculate forces
            force = {node_id: np.zeros(3) for node_id in subgraph.nodes()}
            
            # Repulsive forces
            node_ids = list(subgraph.nodes())
            for i, node1 in enumerate(node_ids):
                for node2 in node_ids[i+1:]:
                    delta = pos[node1] - pos[node2]
                    dist = np.linalg.norm(delta)
                    if dist < 0.1:
                        dist = 0.1
                        delta = np.random.uniform(-0.1, 0.1, 3)
                    
                    f_rep = delta / (dist ** 2)
                    
                    force[node1] += f_rep
                    force[node2] -= f_rep
            
            # Attractive forces
            for node1, node2 in subgraph.edges():
                delta = pos[node1] - pos[node2]
                f_attr = -0.05 * delta
                
                force[node1] += f_attr
                force[node2] -= f_attr
            
            # Update positions
            for node_id in subgraph.nodes():
                pos[node_id] += force[node_id] * 0.1
        
        # Update node positions
        for node in nodes:
            node_id = node['id']
            node['position']['x'] = float(pos[node_id][0])
            node['position']['y'] = float(pos[node_id][1])
            node['position']['z'] = float(pos[node_id][2])
    
    def create_hierarchical_layout(self) -> None:
        """Organize nodes in a hierarchical 3D structure based on their relationships."""
        # Find root nodes (topics) and children
        node_map = {node['id']: node for node in self.nodes}
        
        # Create a directed graph to find the hierarchy
        digraph = nx.DiGraph()
        for link in self.links:
            source = link['sourceNodeId']
            target = link['targetNodeId']
            digraph.add_edge(source, target)
        
        # Find root nodes (nodes with no incoming edges or type == TOPIC)
        root_nodes = []
        for node in self.nodes:
            if node['type'] == 0:  # TOPIC
                root_nodes.append(node)
        
        if not root_nodes:
            # Fallback: use nodes with no incoming edges
            for node in self.nodes:
                if digraph.in_degree(node['id']) == 0:
                    root_nodes.append(node)
        
        if not root_nodes:
            # Fallback: use any node
            root_nodes = [self.nodes[0]]
        
        # Position root nodes in a circle on the top level
        num_roots = len(root_nodes)
        radius = 15.0
        for i, node in enumerate(root_nodes):
            angle = 2 * np.pi * i / num_roots
            node['position']['x'] = radius * np.cos(angle)
            node['position']['y'] = radius * np.sin(angle)
            node['position']['z'] = 20.0  # Top level
        
        # Position children recursively
        positioned = {node['id'] for node in root_nodes}
        self._position_children(digraph, node_map, root_nodes, positioned, level=1)
    
    def _position_children(self, digraph: nx.DiGraph, node_map: Dict[str, Dict],
                         parent_nodes: List[Dict], positioned: set, level: int) -> None:
        """Recursively position child nodes below their parents.
        
        Args:
            digraph: NetworkX directed graph
            node_map: Map of node IDs to node objects
            parent_nodes: List of parent nodes to process
            positioned: Set of already positioned node IDs
            level: Current hierarchy level (0 is top)
        """
        if not parent_nodes or level > 5:  # Limit depth
            return
        
        children = []
        for parent in parent_nodes:
            parent_id = parent['id']
            parent_pos = np.array([parent['position']['x'],
                                  parent['position']['y'],
                                  parent['position']['z']])
            
            # Get immediate children
            child_ids = list(digraph.successors(parent_id))
            parent_children = []
            
            for child_id in child_ids:
                if child_id not in positioned:
                    child = node_map[child_id]
                    parent_children.append(child)
                    positioned.add(child_id)
            
            # Position children in a circle below parent
            num_children = len(parent_children)
            if num_children == 0:
                continue
            
            radius = 5.0 + level * 2.0  # Increase radius with level
            for i, child in enumerate(parent_children):
                angle = 2 * np.pi * i / num_children
                
                # Position relative to parent
                child['position']['x'] = parent_pos[0] + radius * np.cos(angle)
                child['position']['y'] = parent_pos[1] + radius * np.sin(angle)
                child['position']['z'] = parent_pos[2] - 10.0  # Level below parent
            
            children.extend(parent_children)
        
        # Process next level
        self._position_children(digraph, node_map, children, positioned, level + 1)
    
    def export_to_json(self) -> Dict[str, Any]:
        """Export the knowledge map with updated positions to JSON."""
        # Update positions from graph
        pos = nx.get_node_attributes(self.graph, 'pos')
        for node in self.nodes:
            node_id = node['id']
            if node_id in pos:
                node['position']['x'] = float(pos[node_id][0])
                node['position']['y'] = float(pos[node_id][1])
                node['position']['z'] = float(pos[node_id][2])
        
        return self.map_data
    
    def export_to_gltf(self, filename: str) -> None:
        """Export the knowledge map to glTF format.
        
        This is a placeholder implementation that would need to be expanded
        with actual glTF export code in a production system.
        
        Args:
            filename: Output filename
        """
        # Get updated positions
        positions = {node['id']: np.array([node['position']['x'],
                                        node['position']['y'],
                                        node['position']['z']]) for node in self.nodes}
        
        # This is where the actual glTF export code would go
        # For a production system, you would use a library like pygltflib
        
        # For now, we'll just create a simple JSON with the data
        export_data = {
            'nodes': [{
                'id': node['id'],
                'label': node['label'],
                'position': [node['position']['x'], node['position']['y'], node['position']['z']],
                'size': node['size'],
                'color': node['color'],
                'type': node['type']
            } for node in self.nodes],
            'links': [{
                'source': link['sourceNodeId'],
                'target': link['targetNodeId'],
                'strength': link['strength'],
                'color': link['color']
            } for link in self.links]
        }
        
        with open(filename, 'w') as f:
            json.dump(export_data, f, indent=2)
        
        print(f"Exported knowledge map to {filename}")

# Example usage:
# with open('knowledge_map.json', 'r') as f:
#     map_data = json.load(f)
# 
# layout = KnowledgeMapLayout(map_data)
# layout.apply_force_directed_layout(iterations=200)
# # or layout.create_hierarchical_layout()
# 
# updated_map = layout.export_to_json()
# layout.export_to_gltf('knowledge_map.gltf')

#include <drogon/drogon.h>
#include <json/json.h>
#include <string>
#include <vector>
#include <map>
#include <memory>
#include <mutex>
#include "knowledge_repository.h"
#include "content_validator.h"
#include "recommendation_engine.h"

namespace atp {
namespace community {

class CommunityKnowledgeBackend : public drogon::HttpController<CommunityKnowledgeBackend> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(CommunityKnowledgeBackend::getBestPractices, "/api/community/best-practices", drogon::Get);
    ADD_METHOD_TO(CommunityKnowledgeBackend::submitBestPractice, "/api/community/best-practices", drogon::Post);
    ADD_METHOD_TO(CommunityKnowledgeBackend::rateBestPractice, "/api/community/best-practices/{id}/rate", drogon::Post);
    ADD_METHOD_TO(CommunityKnowledgeBackend::getScenarios, "/api/community/scenarios", drogon::Get);
    ADD_METHOD_TO(CommunityKnowledgeBackend::submitScenario, "/api/community/scenarios", drogon::Post);
    ADD_METHOD_TO(CommunityKnowledgeBackend::rateScenario, "/api/community/scenarios/{id}/rate", drogon::Post);
    ADD_METHOD_TO(CommunityKnowledgeBackend::getForumThreads, "/api/community/forum/threads", drogon::Get);
    ADD_METHOD_TO(CommunityKnowledgeBackend::createForumThread, "/api/community/forum/threads", drogon::Post);
    ADD_METHOD_TO(CommunityKnowledgeBackend::getForumPosts, "/api/community/forum/threads/{threadId}/posts", drogon::Get);
    ADD_METHOD_TO(CommunityKnowledgeBackend::createForumPost, "/api/community/forum/threads/{threadId}/posts", drogon::Post);
    ADD_METHOD_TO(CommunityKnowledgeBackend::getExpertNetwork, "/api/community/experts", drogon::Get);
    ADD_METHOD_TO(CommunityKnowledgeBackend::requestExpertAssistance, "/api/community/experts/request", drogon::Post);
    ADD_METHOD_TO(CommunityKnowledgeBackend::getExpertProfile, "/api/community/experts/{expertId}", drogon::Get);
    ADD_METHOD_TO(CommunityKnowledgeBackend::getPersonalizedRecommendations, "/api/community/recommendations/{userId}", drogon::Get);
    ADD_METHOD_TO(CommunityKnowledgeBackend::getContentStatistics, "/api/community/statistics", drogon::Get);
    ADD_METHOD_TO(CommunityKnowledgeBackend::searchContent, "/api/community/search", drogon::Get);
    METHOD_LIST_END

    CommunityKnowledgeBackend();

    void getBestPractices(const drogon::HttpRequestPtr& req, 
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void submitBestPractice(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void rateBestPractice(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id);
    
    void getScenarios(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void submitScenario(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void rateScenario(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                    const std::string& id);
    
    void getForumThreads(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void createForumThread(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getForumPosts(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& threadId);
    
    void createForumPost(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                       const std::string& threadId);
    
    void getExpertNetwork(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void requestExpertAssistance(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getExpertProfile(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& expertId);
    
    void getPersonalizedRecommendations(const drogon::HttpRequestPtr& req,
                                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                                      const std::string& userId);
    
    void getContentStatistics(const drogon::HttpRequestPtr& req,
                            std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void searchContent(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback);

private:
    std::shared_ptr<KnowledgeRepository> knowledgeRepo_;
    std::shared_ptr<ContentValidator> contentValidator_;
    std::shared_ptr<RecommendationEngine> recommendationEngine_;
    
    // Helper methods
    Json::Value formatBestPracticeForResponse(const Json::Value& bestPractice);
    Json::Value formatScenarioForResponse(const Json::Value& scenario);
    Json::Value formatForumThreadForResponse(const Json::Value& thread);
    Json::Value formatForumPostForResponse(const Json::Value& post);
    Json::Value formatExpertProfileForResponse(const Json::Value& expert);
    Json::Value generateContentStatistics();
    Json::Value sanitizeUserInput(const Json::Value& input);
    bool validateUserPermission(const std::string& userId, const std::string& action, const std::string& resourceId);
};

CommunityKnowledgeBackend::CommunityKnowledgeBackend() {
    // Initialize components
    knowledgeRepo_ = std::make_shared<KnowledgeRepository>();
    contentValidator_ = std::make_shared<ContentValidator>();
    recommendationEngine_ = std::make_shared<RecommendationEngine>();
}

void CommunityKnowledgeBackend::getBestPractices(const drogon::HttpRequestPtr& req, 
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string category = params.find("category") != params.end() ? params["category"] : "all";
        std::string sortBy = params.find("sort_by") != params.end() ? params["sort_by"] : "rating";
        int limit = params.find("limit") != params.end() ? std::stoi(params["limit"]) : 10;
        int offset = params.find("offset") != params.end() ? std::stoi(params["offset"]) : 0;
        
        // Get best practices
        std::vector<Json::Value> bestPractices = knowledgeRepo_->getBestPractices(category, sortBy, limit, offset);
        
        // Format best practices for response
        Json::Value formattedPractices(Json::arrayValue);
        
        for (const auto& practice : bestPractices) {
            formattedPractices.append(formatBestPracticeForResponse(practice));
        }
        
        // Get total count for pagination
        int totalCount = knowledgeRepo_->getBestPracticeCount(category);
        
        // Prepare response
        Json::Value result;
        result["best_practices"] = formattedPractices;
        result["total_count"] = totalCount;
        result["limit"] = limit;
        result["offset"] = offset;
        result["category"] = category;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::submitBestPractice(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Sanitize input
        Json::Value sanitizedInput = sanitizeUserInput(*json);
        
        // Validate content
        Json::Value validationResult = contentValidator_->validateBestPractice(sanitizedInput);
        
        if (!validationResult["valid"].asBool()) {
            auto resp = drogon::HttpResponse::newHttpJsonResponse(validationResult);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Extract best practice data
        std::string title = sanitizedInput["title"].asString();
        std::string content = sanitizedInput["content"].asString();
        std::string category = sanitizedInput["category"].asString();
        std::string authorId = sanitizedInput["author_id"].asString();
        
        // Check user permission
        if (!validateUserPermission(authorId, "create", "best_practice")) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "User does not have permission to create best practices";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k403Forbidden);
            callback(resp);
            return;
        }
        
        // Prepare best practice data
        Json::Value bestPractice;
        bestPractice["title"] = title;
        bestPractice["content"] = content;
        bestPractice["category"] = category;
        bestPractice["author_id"] = authorId;
        bestPractice["created_at"] = drogon::utils::getFormattedDate();
        bestPractice["rating"] = 0;
        bestPractice["rating_count"] = 0;
        bestPractice["status"] = "pending_review";  // New practices need review
        
        // Add tags if provided
        if (sanitizedInput.isMember("tags") && sanitizedInput["tags"].isArray()) {
            bestPractice["tags"] = sanitizedInput["tags"];
        }
        
        // Save best practice
        std::string practiceId = knowledgeRepo_->saveBestPractice(bestPractice);
        
        // Add ID to the saved practice
        bestPractice["id"] = practiceId;
        
        // Format for response
        Json::Value formattedPractice = formatBestPracticeForResponse(bestPractice);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["message"] = "Best practice submitted for review";
        result["best_practice"] = formattedPractice;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        resp->setStatusCode(drogon::k201Created);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::rateBestPractice(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                      const std::string& id) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract rating data
        int rating = (*json)["rating"].asInt();
        std::string userId = (*json)["user_id"].asString();
        std::string comment = (*json).get("comment", "").asString();
        
        // Validate rating range (1-5)
        if (rating < 1 || rating > 5) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Rating must be between 1 and 5";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Check if best practice exists
        Json::Value bestPractice = knowledgeRepo_->getBestPractice(id);
        
        if (bestPractice.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Best practice not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Check if user has already rated this best practice
        bool alreadyRated = knowledgeRepo_->hasUserRatedBestPractice(id, userId);
        
        if (alreadyRated) {
            // Update existing rating
            Json::Value userRating = knowledgeRepo_->getUserBestPracticeRating(id, userId);
            int oldRating = userRating["rating"].asInt();
            
            // Record updated rating
            knowledgeRepo_->updateBestPracticeRating(id, userId, rating, comment);
            
            // Update best practice aggregate rating
            int ratingCount = bestPractice["rating_count"].asInt();
            double totalRating = bestPractice["rating"].asDouble() * ratingCount;
            
            // Subtract old rating and add new rating
            totalRating = totalRating - oldRating + rating;
            
            // Calculate new average rating
            double newRating = totalRating / ratingCount;
            
            bestPractice["rating"] = newRating;
            
            // Save updated best practice
            knowledgeRepo_->updateBestPractice(id, bestPractice);
            
            // Prepare response
            Json::Value result;
            result["status"] = "success";
            result["message"] = "Rating updated successfully";
            result["best_practice_id"] = id;
            result["old_rating"] = oldRating;
            result["new_rating"] = rating;
            result["average_rating"] = newRating;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
            callback(resp);
        }
        else {
            // Create new rating
            Json::Value userRating;
            userRating["best_practice_id"] = id;
            userRating["user_id"] = userId;
            userRating["rating"] = rating;
            userRating["comment"] = comment;
            userRating["created_at"] = drogon::utils::getFormattedDate();
            
            // Save user rating
            knowledgeRepo_->saveBestPracticeRating(userRating);
            
            // Update best practice aggregate rating
            int ratingCount = bestPractice["rating_count"].asInt();
            double totalRating = bestPractice["rating"].asDouble() * ratingCount;
            
            // Add new rating and increment count
            totalRating += rating;
            ratingCount++;
            
            // Calculate new average rating
            double newRating = totalRating / ratingCount;
            
            bestPractice["rating"] = newRating;
            bestPractice["rating_count"] = ratingCount;
            
            // Save updated best practice
            knowledgeRepo_->updateBestPractice(id, bestPractice);
            
            // Prepare response
            Json::Value result;
            result["status"] = "success";
            result["message"] = "Rating submitted successfully";
            result["best_practice_id"] = id;
            result["rating"] = rating;
            result["average_rating"] = newRating;
            result["rating_count"] = ratingCount;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
            callback(resp);
        }
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::getScenarios(const drogon::HttpRequestPtr& req,
                  std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string category = params.find("category") != params.end() ? params["category"] : "all";
        std::string aircraftType = params.find("aircraft_type") != params.end() ? params["aircraft_type"] : "";
        std::string sortBy = params.find("sort_by") != params.end() ? params["sort_by"] : "rating";
        int limit = params.find("limit") != params.end() ? std::stoi(params["limit"]) : 10;
        int offset = params.find("offset") != params.end() ? std::stoi(params["offset"]) : 0;
        
        // Get scenarios
        std::vector<Json::Value> scenarios = knowledgeRepo_->getScenarios(category, aircraftType, sortBy, limit, offset);
        
        // Format scenarios for response
        Json::Value formattedScenarios(Json::arrayValue);
        
        for (const auto& scenario : scenarios) {
            formattedScenarios.append(formatScenarioForResponse(scenario));
        }
        
        // Get total count for pagination
        int totalCount = knowledgeRepo_->getScenarioCount(category, aircraftType);
        
        // Prepare response
        Json::Value result;
        result["scenarios"] = formattedScenarios;
        result["total_count"] = totalCount;
        result["limit"] = limit;
        result["offset"] = offset;
        result["category"] = category;
        
        if (!aircraftType.empty()) {
            result["aircraft_type"] = aircraftType;
        }
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::submitScenario(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Sanitize input
        Json::Value sanitizedInput = sanitizeUserInput(*json);
        
        // Validate content
        Json::Value validationResult = contentValidator_->validateScenario(sanitizedInput);
        
        if (!validationResult["valid"].asBool()) {
            auto resp = drogon::HttpResponse::newHttpJsonResponse(validationResult);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Extract scenario data
        std::string title = sanitizedInput["title"].asString();
        std::string description = sanitizedInput["description"].asString();
        std::string category = sanitizedInput["category"].asString();
        std::string aircraftType = sanitizedInput["aircraft_type"].asString();
        std::string authorId = sanitizedInput["author_id"].asString();
        
        // Check user permission
        if (!validateUserPermission(authorId, "create", "scenario")) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "User does not have permission to create scenarios";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k403Forbidden);
            callback(resp);
            return;
        }
        
        // Prepare scenario data
        Json::Value scenario;
        scenario["title"] = title;
        scenario["description"] = description;
        scenario["category"] = category;
        scenario["aircraft_type"] = aircraftType;
        scenario["author_id"] = authorId;
        scenario["created_at"] = drogon::utils::getFormattedDate();
        scenario["rating"] = 0;
        scenario["rating_count"] = 0;
        scenario["download_count"] = 0;
        scenario["status"] = "pending_review";  // New scenarios need review
        
        // Add scenario parameters if provided
        if (sanitizedInput.isMember("parameters") && sanitizedInput["parameters"].isObject()) {
            scenario["parameters"] = sanitizedInput["parameters"];
        }
        
        // Add tags if provided
        if (sanitizedInput.isMember("tags") && sanitizedInput["tags"].isArray()) {
            scenario["tags"] = sanitizedInput["tags"];
        }
        
        // Save scenario
        std::string scenarioId = knowledgeRepo_->saveScenario(scenario);
        
        // Add ID to the saved scenario
        scenario["id"] = scenarioId;
        
        // Format for response
        Json::Value formattedScenario = formatScenarioForResponse(scenario);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["message"] = "Scenario submitted for review";
        result["scenario"] = formattedScenario;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        resp->setStatusCode(drogon::k201Created);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::rateScenario(const drogon::HttpRequestPtr& req,
                  std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                  const std::string& id) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract rating data
        int rating = (*json)["rating"].asInt();
        std::string userId = (*json)["user_id"].asString();
        std::string comment = (*json).get("comment", "").asString();
        
        // Validate rating range (1-5)
        if (rating < 1 || rating > 5) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Rating must be between 1 and 5";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Check if scenario exists
        Json::Value scenario = knowledgeRepo_->getScenario(id);
        
        if (scenario.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Scenario not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Check if user has already rated this scenario
        bool alreadyRated = knowledgeRepo_->hasUserRatedScenario(id, userId);
        
        if (alreadyRated) {
            // Update existing rating
            Json::Value userRating = knowledgeRepo_->getUserScenarioRating(id, userId);
            int oldRating = userRating["rating"].asInt();
            
            // Record updated rating
            knowledgeRepo_->updateScenarioRating(id, userId, rating, comment);
            
            // Update scenario aggregate rating
            int ratingCount = scenario["rating_count"].asInt();
            double totalRating = scenario["rating"].asDouble() * ratingCount;
            
            // Subtract old rating and add new rating
            totalRating = totalRating - oldRating + rating;
            
            // Calculate new average rating
            double newRating = totalRating / ratingCount;
            
            scenario["rating"] = newRating;
            
            // Save updated scenario
            knowledgeRepo_->updateScenario(id, scenario);
            
            // Prepare response
            Json::Value result;
            result["status"] = "success";
            result["message"] = "Rating updated successfully";
            result["scenario_id"] = id;
            result["old_rating"] = oldRating;
            result["new_rating"] = rating;
            result["average_rating"] = newRating;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
            callback(resp);
        }
        else {
            // Create new rating
            Json::Value userRating;
            userRating["scenario_id"] = id;
            userRating["user_id"] = userId;
            userRating["rating"] = rating;
            userRating["comment"] = comment;
            userRating["created_at"] = drogon::utils::getFormattedDate();
            
            // Save user rating
            knowledgeRepo_->saveScenarioRating(userRating);
            
            // Update scenario aggregate rating
            int ratingCount = scenario["rating_count"].asInt();
            double totalRating = scenario["rating"].asDouble() * ratingCount;
            
            // Add new rating and increment count
            totalRating += rating;
            ratingCount++;
            
            // Calculate new average rating
            double newRating = totalRating / ratingCount;
            
            scenario["rating"] = newRating;
            scenario["rating_count"] = ratingCount;
            
            // Save updated scenario
            knowledgeRepo_->updateScenario(id, scenario);
            
            // Prepare response
            Json::Value result;
            result["status"] = "success";
            result["message"] = "Rating submitted successfully";
            result["scenario_id"] = id;
            result["rating"] = rating;
            result["average_rating"] = newRating;
            result["rating_count"] = ratingCount;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
            callback(resp);
        }
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::getForumThreads(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string category = params.find("category") != params.end() ? params["category"] : "all";
        std::string sortBy = params.find("sort_by") != params.end() ? params["sort_by"] : "recent";
        int limit = params.find("limit") != params.end() ? std::stoi(params["limit"]) : 20;
        int offset = params.find("offset") != params.end() ? std::stoi(params["offset"]) : 0;
        
        // Get forum threads
        std::vector<Json::Value> threads = knowledgeRepo_->getForumThreads(category, sortBy, limit, offset);
        
        // Format threads for response
        Json::Value formattedThreads(Json::arrayValue);
        
        for (const auto& thread : threads) {
            formattedThreads.append(formatForumThreadForResponse(thread));
        }
        
        // Get total count for pagination
        int totalCount = knowledgeRepo_->getForumThreadCount(category);
        
        // Prepare response
        Json::Value result;
        result["threads"] = formattedThreads;
        result["total_count"] = totalCount;
        result["limit"] = limit;
        result["offset"] = offset;
        result["category"] = category;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::createForumThread(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Sanitize input
        Json::Value sanitizedInput = sanitizeUserInput(*json);
        
        // Validate content
        Json::Value validationResult = contentValidator_->validateForumThread(sanitizedInput);
        
        if (!validationResult["valid"].asBool()) {
            auto resp = drogon::HttpResponse::newHttpJsonResponse(validationResult);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Extract thread data
        std::string title = sanitizedInput["title"].asString();
        std::string content = sanitizedInput["content"].asString();
        std::string category = sanitizedInput["category"].asString();
        std::string authorId = sanitizedInput["author_id"].asString();
        
        // Check user permission
        if (!validateUserPermission(authorId, "create", "forum_thread")) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "User does not have permission to create forum threads";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k403Forbidden);
            callback(resp);
            return;
        }
        
        // Prepare thread data
        Json::Value thread;
        thread["title"] = title;
        thread["content"] = content;
        thread["category"] = category;
        thread["author_id"] = authorId;
        thread["created_at"] = drogon::utils::getFormattedDate();
        thread["updated_at"] = thread["created_at"];
        thread["view_count"] = 0;
        thread["reply_count"] = 0;
        thread["is_pinned"] = false;
        thread["is_locked"] = false;
        
        // Add tags if provided
        if (sanitizedInput.isMember("tags") && sanitizedInput["tags"].isArray()) {
            thread["tags"] = sanitizedInput["tags"];
        }
        
        // Save thread
        std::string threadId = knowledgeRepo_->saveForumThread(thread);
        
        // Add ID to the saved thread
        thread["id"] = threadId;
        
        // Format for response
        Json::Value formattedThread = formatForumThreadForResponse(thread);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["message"] = "Forum thread created successfully";
        result["thread"] = formattedThread;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        resp->setStatusCode(drogon::k201Created);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::getForumPosts(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                   const std::string& threadId) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string sortBy = params.find("sort_by") != params.end() ? params["sort_by"] : "chronological";
        int limit = params.find("limit") != params.end() ? std::stoi(params["limit"]) : 50;
        int offset = params.find("offset") != params.end() ? std::stoi(params["offset"]) : 0;
        
        // Check if thread exists
        Json::Value thread = knowledgeRepo_->getForumThread(threadId);
        
        if (thread.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Forum thread not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Increment view count
        thread["view_count"] = thread["view_count"].asInt() + 1;
        knowledgeRepo_->updateForumThread(threadId, thread);
        
        // Get forum posts
        std::vector<Json::Value> posts = knowledgeRepo_->getForumPosts(threadId, sortBy, limit, offset);
        
        // Format posts for response
        Json::Value formattedPosts(Json::arrayValue);
        
        for (const auto& post : posts) {
            formattedPosts.append(formatForumPostForResponse(post));
        }
        
        // Get total count for pagination
        int totalCount = knowledgeRepo_->getForumPostCount(threadId);
        
        // Format thread for response
        Json::Value formattedThread = formatForumThreadForResponse(thread);
        
        // Prepare response
        Json::Value result;
        result["thread"] = formattedThread;
        result["posts"] = formattedPosts;
        result["total_post_count"] = totalCount;
        result["limit"] = limit;
        result["offset"] = offset;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::createForumPost(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& threadId) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Check if thread exists and is not locked
        Json::Value thread = knowledgeRepo_->getForumThread(threadId);
        
        if (thread.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Forum thread not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        if (thread["is_locked"].asBool()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Thread is locked, new posts are not allowed";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k403Forbidden);
            callback(resp);
            return;
        }
        
        // Sanitize input
        Json::Value sanitizedInput = sanitizeUserInput(*json);
        
        // Validate content
        Json::Value validationResult = contentValidator_->validateForumPost(sanitizedInput);
        
        if (!validationResult["valid"].asBool()) {
            auto resp = drogon::HttpResponse::newHttpJsonResponse(validationResult);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Extract post data
        std::string content = sanitizedInput["content"].asString();
        std::string authorId = sanitizedInput["author_id"].asString();
        
        // Check user permission
        if (!validateUserPermission(authorId, "create", "forum_post")) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "User does not have permission to create forum posts";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k403Forbidden);
            callback(resp);
            return;
        }
        
        // Prepare post data
        Json::Value post;
        post["thread_id"] = threadId;
        post["content"] = content;
        post["author_id"] = authorId;
        post["created_at"] = drogon::utils::getFormattedDate();
        post["updated_at"] = post["created_at"];
        post["is_solution"] = false;
        
        // Save post
        std::string postId = knowledgeRepo_->saveForumPost(post);
        
        // Add ID to the saved post
        post["id"] = postId;
        
        // Update thread
        thread["reply_count"] = thread["reply_count"].asInt() + 1;
        thread["updated_at"] = post["created_at"];
        knowledgeRepo_->updateForumThread(threadId, thread);
        
        // Format for response
        Json::Value formattedPost = formatForumPostForResponse(post);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["message"] = "Forum post created successfully";
        result["post"] = formattedPost;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        resp->setStatusCode(drogon::k201Created);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::getExpertNetwork(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string expertise = params.find("expertise") != params.end() ? params["expertise"] : "all";
        std::string sortBy = params.find("sort_by") != params.end() ? params["sort_by"] : "rating";
        int limit = params.find("limit") != params.end() ? std::stoi(params["limit"]) : 10;
        int offset = params.find("offset") != params.end() ? std::stoi(params["offset"]) : 0;
        
        // Get experts
        std::vector<Json::Value> experts = knowledgeRepo_->getExperts(expertise, sortBy, limit, offset);
        
        // Format experts for response
        Json::Value formattedExperts(Json::arrayValue);
        
        for (const auto& expert : experts) {
            formattedExperts.append(formatExpertProfileForResponse(expert));
        }
        
        // Get total count for pagination
        int totalCount = knowledgeRepo_->getExpertCount(expertise);
        
        // Prepare response
        Json::Value result;
        result["experts"] = formattedExperts;
        result["total_count"] = totalCount;
        result["limit"] = limit;
        result["offset"] = offset;
        result["expertise"] = expertise;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::requestExpertAssistance(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Sanitize input
        Json::Value sanitizedInput = sanitizeUserInput(*json);
        
        // Extract request data
        std::string userId = sanitizedInput["user_id"].asString();
        std::string expertId = sanitizedInput["expert_id"].asString();
        std::string topic = sanitizedInput["topic"].asString();
        std::string description = sanitizedInput["description"].asString();
        
        // Check if expert exists
        Json::Value expert = knowledgeRepo_->getExpert(expertId);
        
        if (expert.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Expert not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Create assistance request
        Json::Value request;
        request["user_id"] = userId;
        request["expert_id"] = expertId;
        request["topic"] = topic;
        request["description"] = description;
        request["created_at"] = drogon::utils::getFormattedDate();
        request["status"] = "pending";
        
        // Add optional fields
        if (sanitizedInput.isMember("priority")) {
            request["priority"] = sanitizedInput["priority"];
        } else {
            request["priority"] = "normal";
        }
        
        if (sanitizedInput.isMember("deadline")) {
            request["deadline"] = sanitizedInput["deadline"];
        }
        
        // Save request
        std::string requestId = knowledgeRepo_->saveExpertAssistanceRequest(request);
        
        // Add ID to the saved request
        request["id"] = requestId;
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["message"] = "Expert assistance request submitted successfully";
        result["request_id"] = requestId;
        result["expert"] = formatExpertProfileForResponse(expert);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        resp->setStatusCode(drogon::k201Created);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::getExpertProfile(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                      const std::string& expertId) {
    try {
        // Get expert profile
        Json::Value expert = knowledgeRepo_->getExpert(expertId);
        
        if (expert.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Expert not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Format expert profile
        Json::Value formattedProfile = formatExpertProfileForResponse(expert);
        
        // Get expert's contributions
        formattedProfile["contributions"] = knowledgeRepo_->getExpertContributions(expertId);
        
        // Get expert's availability
        formattedProfile["availability"] = knowledgeRepo_->getExpertAvailability(expertId);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(formattedProfile);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::getPersonalizedRecommendations(const drogon::HttpRequestPtr& req,
                                    std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                                    const std::string& userId) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string contentType = params.find("content_type") != params.end() ? params["content_type"] : "all";
        int limit = params.find("limit") != params.end() ? std::stoi(params["limit"]) : 10;
        
        // Get user profile/history for recommendation context
        Json::Value userProfile = knowledgeRepo_->getUserProfile(userId);
        
        if (userProfile.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "User not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Generate recommendations
        Json::Value recommendations = recommendationEngine_->generateRecommendations(userId, contentType, limit);
        
        // Prepare response
        Json::Value result;
        result["user_id"] = userId;
        result["content_type"] = contentType;
        result["recommendations"] = recommendations;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::getContentStatistics(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Generate content statistics
        Json::Value statistics = generateContentStatistics();
        
        // Prepare response
        Json::Value result;
        result["statistics"] = statistics;
        result["generated_at"] = drogon::utils::getFormattedDate();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void CommunityKnowledgeBackend::searchContent(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string query = params.find("q") != params.end() ? params["q"] : "";
        std::string contentType = params.find("content_type") != params.end() ? params["content_type"] : "all";
        std::string sortBy = params.find("sort_by") != params.end() ? params["sort_by"] : "relevance";
        int limit = params.find("limit") != params.end() ? std::stoi(params["limit"]) : 20;
        int offset = params.find("offset") != params.end() ? std::stoi(params["offset"]) : 0;
        
        if (query.empty()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Search query is required";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Search content
        Json::Value searchResults = knowledgeRepo_->searchContent(query, contentType, sortBy, limit, offset);
        
        // Prepare response
        Json::Value result;
        result["query"] = query;
        result["content_type"] = contentType;
        result["results"] = searchResults["results"];
        result["total_count"] = searchResults["total_count"];
        result["limit"] = limit;
        result["offset"] = offset;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

// Helper methods

Json::Value CommunityKnowledgeBackend::formatBestPracticeForResponse(const Json::Value& bestPractice) {
    Json::Value formatted = bestPractice;
    
    // Add author information
    if (formatted.isMember("author_id")) {
        std::string authorId = formatted["author_id"].asString();
        Json::Value authorInfo = knowledgeRepo_->getUserBasicInfo(authorId);
        
        if (!authorInfo.isNull()) {
            formatted["author"] = authorInfo;
        }
    }
    
    return formatted;
}

Json::Value CommunityKnowledgeBackend::formatScenarioForResponse(const Json::Value& scenario) {
    Json::Value formatted = scenario;
    
    // Add author information
    if (formatted.isMember("author_id")) {
        std::string authorId = formatted["author_id"].asString();
        Json::Value authorInfo = knowledgeRepo_->getUserBasicInfo(authorId);
        
        if (!authorInfo.isNull()) {
            formatted["author"] = authorInfo;
        }
    }
    
    return formatted;
}

Json::Value CommunityKnowledgeBackend::formatForumThreadForResponse(const Json::Value& thread) {
    Json::Value formatted = thread;
    
    // Add author information
    if (formatted.isMember("author_id")) {
        std::string authorId = formatted["author_id"].asString();
        Json::Value authorInfo = knowledgeRepo_->getUserBasicInfo(authorId);
        
        if (!authorInfo.isNull()) {
            formatted["author"] = authorInfo;
        }
    }
    
    return formatted;
}

Json::Value CommunityKnowledgeBackend::formatForumPostForResponse(const Json::Value& post) {
    Json::Value formatted = post;
    
    // Add author information
    if (formatted.isMember("author_id")) {
        std::string authorId = formatted["author_id"].asString();
        Json::Value authorInfo = knowledgeRepo_->getUserBasicInfo(authorId);
        
        if (!authorInfo.isNull()) {
            formatted["author"] = authorInfo;
        }
    }
    
    return formatted;
}

Json::Value CommunityKnowledgeBackend::formatExpertProfileForResponse(const Json::Value& expert) {
    Json::Value formatted = expert;
    
    // Remove sensitive information
    formatted.removeMember("password");
    formatted.removeMember("email_verified");
    
    // Add expertise areas with details
    if (formatted.isMember("expertise_areas") && formatted["expertise_areas"].isArray()) {
        Json::Value detailedExpertise(Json::arrayValue);
        
        for (const auto& area : formatted["expertise_areas"]) {
            Json::Value expertiseDetails = knowledgeRepo_->getExpertiseAreaDetails(area.asString());
            
            if (!expertiseDetails.isNull()) {
                detailedExpertise.append(expertiseDetails);
            }
        }
        
        formatted["expertise_details"] = detailedExpertise;
    }
    
    return formatted;
}

Json::Value CommunityKnowledgeBackend::generateContentStatistics() {
    Json::Value statistics;
    
    // Best practices statistics
    Json::Value bestPracticeStats;
    bestPracticeStats["total_count"] = knowledgeRepo_->getBestPracticeCount("all");
    bestPracticeStats["by_category"] = knowledgeRepo_->getBestPracticeCountByCategory();
    bestPracticeStats["average_rating"] = knowledgeRepo_->getAverageBestPracticeRating();
    bestPracticeStats["created_last_30_days"] = knowledgeRepo_->getBestPracticeCountLastDays(30);
    
    statistics["best_practices"] = bestPracticeStats;
    
    // Scenarios statistics
    Json::Value scenarioStats;
    scenarioStats["total_count"] = knowledgeRepo_->getScenarioCount("all", "");
    scenarioStats["by_category"] = knowledgeRepo_->getScenarioCountByCategory();
    scenarioStats["by_aircraft_type"] = knowledgeRepo_->getScenarioCountByAircraftType();
    scenarioStats["average_rating"] = knowledgeRepo_->getAverageScenarioRating();
    scenarioStats["created_last_30_days"] = knowledgeRepo_->getScenarioCountLastDays(30);
    
    statistics["scenarios"] = scenarioStats;
    
    // Forum statistics
    Json::Value forumStats;
    forumStats["thread_count"] = knowledgeRepo_->getForumThreadCount("all");
    forumStats["post_count"] = knowledgeRepo_->getTotalForumPostCount();
    forumStats["active_users_last_30_days"] = knowledgeRepo_->getActiveForumUsersLastDays(30);
    forumStats["by_category"] = knowledgeRepo_->getForumThreadCountByCategory();
    forumStats["threads_created_last_30_days"] = knowledgeRepo_->getForumThreadCountLastDays(30);
    
    statistics["forum"] = forumStats;
    
    // Expert network statistics
    Json::Value expertStats;
    expertStats["expert_count"] = knowledgeRepo_->getExpertCount("all");
    expertStats["by_expertise"] = knowledgeRepo_->getExpertCountByExpertise();
    expertStats["assistance_requests_last_30_days"] = knowledgeRepo_->getExpertAssistanceRequestCountLastDays(30);
    
    statistics["expert_network"] = expertStats;
    
    // Overall user engagement
    Json::Value userEngagement;
    userEngagement["total_users"] = knowledgeRepo_->getTotalUserCount();
    userEngagement["active_last_7_days"] = knowledgeRepo_->getActiveUsersLastDays(7);
    userEngagement["active_last_30_days"] = knowledgeRepo_->getActiveUsersLastDays(30);
    userEngagement["content_contributors"] = knowledgeRepo_->getContentContributorCount();
    
    statistics["user_engagement"] = userEngagement;
    
    return statistics;
}

Json::Value CommunityKnowledgeBackend::sanitizeUserInput(const Json::Value& input) {
    // In a real implementation, this would sanitize user input to prevent XSS and other attacks
    // For this example, we'll just do a very simple sanitization
    
    Json::Value sanitized;
    
    for (const auto& key : input.getMemberNames()) {
        if (input[key].isString()) {
            // Simple example: remove script tags
            std::string value = input[key].asString();
            
            // Replace <script> tags
            size_t startPos = 0;
            while ((startPos = value.find("<script", startPos)) != std::string::npos) {
                size_t endPos = value.find("</script>", startPos);
                if (endPos != std::string::npos) {
                    endPos += 9; // Length of "</script>"
                    value.replace(startPos, endPos - startPos, "");
                } else {
                    break;
                }
            }
            
            sanitized[key] = value;
        }
        else if (input[key].isObject()) {
            sanitized[key] = sanitizeUserInput(input[key]);
        }
        else if (input[key].isArray()) {
            Json::Value sanitizedArray(Json::arrayValue);
            
            for (const auto& element : input[key]) {
                if (element.isObject()) {
                    sanitizedArray.append(sanitizeUserInput(element));
                }
                else if (element.isString()) {
                    std::string value = element.asString();
                    
                    // Replace <script> tags
                    size_t startPos = 0;
                    while ((startPos = value.find("<script", startPos)) != std::string::npos) {
                        size_t endPos = value.find("</script>", startPos);
                        if (endPos != std::string::npos) {
                            endPos += 9; // Length of "</script>"
                            value.replace(startPos, endPos - startPos, "");
                        } else {
                            break;
                        }
                    }
                    
                    sanitizedArray.append(value);
                }
                else {
                    sanitizedArray.append(element);
                }
            }
            
            sanitized[key] = sanitizedArray;
        }
        else {
            sanitized[key] = input[key];
        }
    }
    
    return sanitized;
}

bool CommunityKnowledgeBackend::validateUserPermission(const std::string& userId, const std::string& action, const std::string& resourceId) {
    // In a real implementation, this would check user permissions from a database or auth service
    // For this example, we'll assume all users have permissions
    return true;
}

} // namespace community
} // namespace atp

// Main application setup
int main() {
    // Configure Drogon app
    drogon::app().setLogPath("./")
                 .setLogLevel(trantor::Logger::kInfo)
                 .addListener("0.0.0.0", 8087)
                 .setThreadNum(16)
                 .run();
    
    return 0;
}

continue and skip 
etr-service-syllabus-impl 
etr-service-compliance-repository 
etr-service-certificate-repository 
etr-service-certificate-repository-h 
etr-service-database-connection-impl 
etr-service-integration-test 
ai-analytics-service-cmakelists 
ai-analytics-service-proto 
ai-analytics-service-main 
ai-analytics-model-manager 
ai-analytics-service-model-interface 
ai-analytics-inference-engine 
etr-service-syllabus-service-impl 
ai-analytics-performance-model 
ai-analytics-cognitive-model
document-service-cmakelists
document-service-proto
document-service-repository
etr-service-record-repository-impl
assessment-service-cmakelists
assessment-service-proto
assessment-service-model
api-gateway-cmakelists
api-gateway-service
api-gateway-service-client-base
api-gateway-core-service-client
ai-analytics-inference-engine-impl
// backend/core/include/ConfigurationManager.h
#pragma once

#include <string>
#include <unordered_map>
#include <any>
#include <functional>
#include <mutex>
#include <shared_mutex>
#include <filesystem>
#include <optional>
#include <variant>
#include <vector>

namespace APTP::Core {

enum class ConfigSource {
    Environment,
    File,
    Database
};

class ConfigurationManager {
public:
    using ConfigCallback = std::function<void(const std::string&, const std::any&)>;
    
    static ConfigurationManager& getInstance();
    
    template<typename T>
    std::optional<T> get(const std::string& key) const;
    
    template<typename T>
    T getOrDefault(const std::string& key, const T& defaultValue) const;
    
    template<typename T>
    bool set(const std::string& key, const T& value, ConfigSource source);
    
    void loadFromEnvironment();
    bool loadFromFile(const std::filesystem::path& path);
    bool loadFromDatabase(const std::string& connectionString);
    
    void registerChangeCallback(const std::string& key, ConfigCallback callback);
    void unregisterChangeCallback(const std::string& key, const void* callbackOwner);
    void clearChangeCallbacks();

private:
    ConfigurationManager();
    ~ConfigurationManager();
    
    struct CallbackInfo {
        void* owner;
        ConfigCallback callback;
    };
    
    std::unordered_map<std::string, std::any> configValues_;
    std::unordered_map<std::string, std::vector<CallbackInfo>> callbacks_;
    std::unordered_map<std::string, ConfigSource> configSources_;
    
    mutable std::shared_mutex mutex_;
    
    void notifyChangeCallbacks(const std::string& key, const std::any& value);
};

// Implementation of template methods
template<typename T>
std::optional<T> ConfigurationManager::get(const std::string& key) const {
    std::shared_lock<std::shared_mutex> lock(mutex_);
    auto it = configValues_.find(key);
    if (it != configValues_.end()) {
        try {
            return std::any_cast<T>(it->second);
        } catch (const std::bad_any_cast&) {
            return std::nullopt;
        }
    }
    return std::nullopt;
}

template<typename T>
T ConfigurationManager::getOrDefault(const std::string& key, const T& defaultValue) const {
    auto value = get<T>(key);
    return value.has_value() ? *value : defaultValue;
}

template<typename T>
bool ConfigurationManager::set(const std::string& key, const T& value, ConfigSource source) {
    std::unique_lock<std::shared_mutex> lock(mutex_);
    configValues_[key] = value;
    configSources_[key] = source;
    lock.unlock();
    notifyChangeCallbacks(key, value);
    return true;
}

} // namespace APTP::Core

// backend/core/include/Logger.h
#pragma once

#include <string>
#include <sstream>
#include <memory>
#include <unordered_map>
#include <source_location>
#include <chrono>

namespace APTP::Core {

enum class LogLevel {
    Trace,
    Debug,
    Info,
    Warning,
    Error,
    Critical
};

class LogContext {
public:
    LogContext() = default;
    LogContext(const LogContext&) = default;
    LogContext& operator=(const LogContext&) = default;
    
    template<typename T>
    LogContext& add(const std::string& key, const T& value) {
        std::stringstream ss;
        ss << value;
        context_[key] = ss.str();
        return *this;
    }
    
    const std::unordered_map<std::string, std::string>& getContext() const {
        return context_;
    }
    
private:
    std::unordered_map<std::string, std::string> context_;
};

class Logger {
public:
    static Logger& getInstance();
    
    void setLogLevel(LogLevel level);
    LogLevel getLogLevel() const;
    
    template<typename... Args>
    void log(LogLevel level, 
             const std::source_location& location,
             const LogContext& context,
             const std::string& format,
             const Args&... args);
    
    template<typename... Args>
    void trace(const std::string& format, const Args&... args,
              const std::source_location& location = std::source_location::current());
    
    template<typename... Args>
    void debug(const std::string& format, const Args&... args,
              const std::source_location& location = std::source_location::current());
    
    template<typename... Args>
    void info(const std::string& format, const Args&... args,
             const std::source_location& location = std::source_location::current());
    
    template<typename... Args>
    void warning(const std::string& format, const Args&... args,
                const std::source_location& location = std::source_location::current());
    
    template<typename... Args>
    void error(const std::string& format, const Args&... args,
              const std::source_location& location = std::source_location::current());
    
    template<typename... Args>
    void critical(const std::string& format, const Args&... args,
                 const std::source_location& location = std::source_location::current());

private:
    Logger();
    ~Logger();
    
    struct LoggerImpl;
    std::unique_ptr<LoggerImpl> impl_;
};

// Convenient global functions
template<typename... Args>
void trace(const std::string& format, const Args&... args,
          const std::source_location& location = std::source_location::current()) {
    Logger::getInstance().trace(format, args..., location);
}

template<typename... Args>
void debug(const std::string& format, const Args&... args,
          const std::source_location& location = std::source_location::current()) {
    Logger::getInstance().debug(format, args..., location);
}

template<typename... Args>
void info(const std::string& format, const Args&... args,
         const std::source_location& location = std::source_location::current()) {
    Logger::getInstance().info(format, args..., location);
}

template<typename... Args>
void warning(const std::string& format, const Args&... args,
            const std::source_location& location = std::source_location::current()) {
    Logger::getInstance().warning(format, args..., location);
}

template<typename... Args>
void error(const std::string& format, const Args&... args,
          const std::source_location& location = std::source_location::current()) {
    Logger::getInstance().error(format, args..., location);
}

template<typename... Args>
void critical(const std::string& format, const Args&... args,
             const std::source_location& location = std::source_location::current()) {
    Logger::getInstance().critical(format, args..., location);
}

// Helper class for RAII-style logging
class ScopedLogger {
public:
    template<typename... Args>
    ScopedLogger(const std::string& componentName, const std::string& operationName, const Args&... args,
                const std::source_location& location = std::source_location::current())
        : componentName_(componentName), operationName_(operationName), location_(location) {
        LogContext context;
        (context.add(std::to_string(sizeof...(Args) - Args), args), ...);
        Logger::getInstance().debug("Starting operation {} in component {}", operationName_, componentName_, location_);
        startTime_ = std::chrono::high_resolution_clock::now();
    }
    
    ~ScopedLogger() {
        auto endTime = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(endTime - startTime_).count();
        Logger::getInstance().debug("Completed operation {} in component {} (took {}ms)", 
                                   operationName_, componentName_, duration, location_);
    }
    
private:
    std::string componentName_;
    std::string operationName_;
    std::source_location location_;
    std::chrono::time_point<std::chrono::high_resolution_clock> startTime_;
};

} // namespace APTP::Core

// backend/core/include/ErrorHandling.h
#pragma once

#include <string>
#include <exception>
#include <functional>
#include <optional>
#include <variant>
#include <source_location>

namespace APTP::Core {

// Generic error code definition
enum class ErrorCode {
    // System errors
    Success = 0,
    Unknown = 1,
    InvalidArgument = 2,
    OutOfRange = 3,
    ResourceUnavailable = 4,
    Timeout = 5,
    NotImplemented = 6,
    InvalidState = 7,
    
    // Application-specific errors
    DocumentProcessingError = 1000,
    SyllabusGenerationError = 2000,
    AssessmentError = 3000,
    UserManagementError = 4000,
    SchedulerError = 5000,
    AnalyticsError = 6000,
    ComplianceError = 7000,
    CollaborationError = 8000,
    VisualizationError = 9000,
    IntegrationError = 10000,
    SecurityError = 11000
};

// Base exception class for the application
class APTPException : public std::exception {
public:
    APTPException(ErrorCode code, 
                 const std::string& message, 
                 const std::source_location& location = std::source_location::current());
    
    ErrorCode getErrorCode() const;
    const std::string& getFullMessage() const;
    const char* what() const noexcept override;
    const std::source_location& getLocation() const;
    
private:
    ErrorCode errorCode_;
    std::string message_;
    std::string fullMessage_;
    std::source_location location_;
};

// Result class for handling operations that can fail
template<typename T, typename E = ErrorCode>
class Result {
public:
    Result(T value) : value_(std::move(value)), error_{} {}
    Result(E error) : value_{}, error_(std::move(error)) {}
    
    bool isSuccess() const { return value_.has_value(); }
    bool isError() const { return error_.has_value(); }
    
    const T& value() const { 
        if (!value_) throw APTPException(ErrorCode::InvalidState, "Attempted to access value of failed Result");
        return *value_; 
    }
    
    T& value() { 
        if (!value_) throw APTPException(ErrorCode::InvalidState, "Attempted to access value of failed Result");
        return *value_; 
    }
    
    const E& error() const { 
        if (!error_) throw APTPException(ErrorCode::InvalidState, "Attempted to access error of successful Result");
        return *error_; 
    }
    
    // Map success value using a function
    template<typename U, typename Func>
    Result<U, E> map(Func&& func) const {
        if (isSuccess()) {
            return Result<U, E>(func(value()));
        } else {
            return Result<U, E>(error());
        }
    }
    
    // Flat map (monadic bind) success value using a function that returns a Result
    template<typename U, typename Func>
    Result<U, E> flatMap(Func&& func) const {
        if (isSuccess()) {
            return func(value());
        } else {
            return Result<U, E>(error());
        }
    }
    
    // Handle both success and error cases
    template<typename SuccessFunc, typename ErrorFunc>
    auto match(SuccessFunc&& successFunc, ErrorFunc&& errorFunc) const {
        if (isSuccess()) {
            return successFunc(value());
        } else {
            return errorFunc(error());
        }
    }
    
private:
    std::optional<T> value_;
    std::optional<E> error_;
};

// Void result class for operations that don't return a value
template<typename E>
class Result<void, E> {
public:
    Result() : success_(true), error_{} {}
    Result(E error) : success_(false), error_(std::move(error)) {}
    
    bool isSuccess() const { return success_; }
    bool isError() const { return !success_; }
    
    const E& error() const { 
        if (success_) throw APTPException(ErrorCode::InvalidState, "Attempted to access error of successful Result");
        return *error_; 
    }
    
    // Flat map void result to a result with a value
    template<typename U, typename Func>
    Result<U, E> flatMap(Func&& func) const {
        if (isSuccess()) {
            return func();
        } else {
            return Result<U, E>(error());
        }
    }
    
    // Handle both success and error cases
    template<typename SuccessFunc, typename ErrorFunc>
    auto match(SuccessFunc&& successFunc, ErrorFunc&& errorFunc) const {
        if (isSuccess()) {
            return successFunc();
        } else {
            return errorFunc(error());
        }
    }
    
private:
    bool success_;
    std::optional<E> error_;
};

// Helper to create success result
template<typename T>
Result<T> Success(T value) {
    return Result<T>(std::move(value));
}

// Helper to create void success result
inline Result<void> Success() {
    return Result<void>();
}

// Helper to create error result
template<typename T, typename E>
Result<T, E> Error(E error) {
    return Result<T, E>(std::move(error));
}

// Helper for void error result
template<typename E>
Result<void, E> Error(E error) {
    return Result<void, E>(std::move(error));
}

// Exception handler utility
class ExceptionHandler {
public:
    template<typename Func, typename... Args>
    static auto tryExecute(Func&& func, Args&&... args) -> Result<decltype(func(args...))> {
        try {
            if constexpr (std::is_void_v<decltype(func(args...))>) {
                func(std::forward<Args>(args)...);
                return Success();
            } else {
                return Success(func(std::forward<Args>(args)...));
            }
        } catch (const APTPException& e) {
            return Error<decltype(func(args...))>(e.getErrorCode());
        } catch (const std::exception& e) {
            return Error<decltype(func(args...))>(ErrorCode::Unknown);
        } catch (...) {
            return Error<decltype(func(args...))>(ErrorCode::Unknown);
        }
    }
};

} // namespace APTP::Core

// backend/core/src/ConfigurationManager.cpp
#include "ConfigurationManager.h"
#include "Logger.h"
#include <fstream>
#include <json.hpp> // Using nlohmann/json

namespace APTP::Core {

ConfigurationManager& ConfigurationManager::getInstance() {
    static ConfigurationManager instance;
    return instance;
}

ConfigurationManager::ConfigurationManager() {
    // Constructor implementation
}

ConfigurationManager::~ConfigurationManager() {
    // Destructor implementation
}

void ConfigurationManager::loadFromEnvironment() {
    // Implementation to load from environment variables
    // This is a simplified example
    
    // List of environment variables to check
    const std::vector<std::string> envVars = {
        "APTP_DB_HOST", "APTP_DB_PORT", "APTP_DB_USER", "APTP_DB_PASSWORD", "APTP_DB_NAME",
        "APTP_LOG_LEVEL", "APTP_API_PORT", "APTP_API_HOST", "APTP_REDIS_URL",
        "APTP_SECURITY_KEY", "APTP_JWT_SECRET", "APTP_ENABLE_SSL"
    };
    
    for (const auto& var : envVars) {
        if (const char* env = std::getenv(var.c_str())) {
            set<std::string>(var, std::string(env), ConfigSource::Environment);
            info("Loaded environment variable: {}", var);
        }
    }
}

bool ConfigurationManager::loadFromFile(const std::filesystem::path& path) {
    try {
        // Check if file exists
        if (!std::filesystem::exists(path)) {
            error("Configuration file not found: {}", path.string());
            return false;
        }
        
        // Read JSON file
        std::ifstream file(path);
        nlohmann::json jsonConfig;
        file >> jsonConfig;
        
        // Process JSON and add to configuration
        for (auto it = jsonConfig.begin(); it != jsonConfig.end(); ++it) {
            const auto& key = it.key();
            const auto& value = it.value();
            
            if (value.is_string()) {
                set<std::string>(key, value.get<std::string>(), ConfigSource::File);
            } else if (value.is_number_integer()) {
                set<int>(key, value.get<int>(), ConfigSource::File);
            } else if (value.is_number_float()) {
                set<double>(key, value.get<double>(), ConfigSource::File);
            } else if (value.is_boolean()) {
                set<bool>(key, value.get<bool>(), ConfigSource::File);
            } else if (value.is_array() || value.is_object()) {
                // Store complex types as JSON strings
                set<std::string>(key, value.dump(), ConfigSource::File);
            }
        }
        
        info("Loaded configuration from file: {}", path.string());
        return true;
    } catch (const std::exception& e) {
        error("Failed to load configuration from file: {} ({})", path.string(), e.what());
        return false;
    }
}

bool ConfigurationManager::loadFromDatabase(const std::string& connectionString) {
    // This would be implemented to load configuration from a database
    // For this example, we'll provide a stub implementation
    
    info("Loading configuration from database with connection: {}", connectionString);
    // In a real implementation, you would connect to the database and load configuration values
    
    // Mock implementation for example purposes
    set<std::string>("db_loaded", "true", ConfigSource::Database);
    set<int>("db_config_version", 1, ConfigSource::Database);
    
    return true;
}

void ConfigurationManager::registerChangeCallback(const std::string& key, ConfigCallback callback) {
    std::unique_lock<std::shared_mutex> lock(mutex_);
    CallbackInfo info{nullptr, callback};
    callbacks_[key].push_back(info);
}

void ConfigurationManager::unregisterChangeCallback(const std::string& key, const void* callbackOwner) {
    std::unique_lock<std::shared_mutex> lock(mutex_);
    auto it = callbacks_.find(key);
    if (it != callbacks_.end()) {
        auto& callbacksList = it->second;
        callbacksList.erase(
            std::remove_if(callbacksList.begin(), callbacksList.end(),
                [callbackOwner](const CallbackInfo& info) { return info.owner == callbackOwner; }),
            callbacksList.end()
        );
    }
}

void ConfigurationManager::clearChangeCallbacks() {
    std::unique_lock<std::shared_mutex> lock(mutex_);
    callbacks_.clear();
}

void ConfigurationManager::notifyChangeCallbacks(const std::string& key, const std::any& value) {
    // Make a copy of the callbacks to avoid holding the lock during callback execution
    std::vector<ConfigCallback> callbacksToNotify;
    {
        std::shared_lock<std::shared_mutex> lock(mutex_);
        auto it = callbacks_.find(key);
        if (it != callbacks_.end()) {
            for (const auto& callbackInfo : it->second) {
                callbacksToNotify.push_back(callbackInfo.callback);
            }
        }
    }
    
    // Execute callbacks
    for (const auto& callback : callbacksToNotify) {
        try {
            callback(key, value);
        } catch (const std::exception& e) {
            error("Exception in configuration change callback for key {}: {}", key, e.what());
        }
    }
}

// backend/core/src/Logger.cpp implementation would go here
// backend/core/src/ErrorHandling.cpp implementation would go here

} // namespace APTP::Core

#pragma once

#include <string>
#include <memory>
#include <functional>
#include <nlohmann/json.hpp>
#include "auth/jwt_auth_service.h"

namespace core_platform {
namespace api {

/**
 * @brief HTTP method types
 */
enum class HttpMethod {
    GET,
    POST,
    PUT,
    DELETE,
    OPTIONS
};

/**
 * @brief HTTP request structure
 */
struct HttpRequest {
    HttpMethod method;
    std::string path;
    std::unordered_map<std::string, std::string> headers;
    std::unordered_map<std::string, std::string> query_params;
    std::string body;
    std::unordered_map<std::string, std::string> path_params;
};

/**
 * @brief HTTP response structure
 */
struct HttpResponse {
    int status_code = 200;
    std::unordered_map<std::string, std::string> headers;
    std::string body;
    
    static HttpResponse ok(const nlohmann::json& data) {
        HttpResponse response;
        response.status_code = 200;
        response.headers["Content-Type"] = "application/json";
        response.body = data.dump();
        return response;
    }
    
    static HttpResponse created(const nlohmann::json& data) {
        HttpResponse response;
        response.status_code = 201;
        response.headers["Content-Type"] = "application/json";
        response.body = data.dump();
        return response;
    }
    
    static HttpResponse noContent() {
        HttpResponse response;
        response.status_code = 204;
        return response;
    }
    
    static HttpResponse badRequest(const std::string& message) {
        HttpResponse response;
        response.status_code = 400;
        response.headers["Content-Type"] = "application/json";
        response.body = nlohmann::json({{"error", message}}).dump();
        return response;
    }
    
    static HttpResponse unauthorized(const std::string& message) {
        HttpResponse response;
        response.status_code = 401;
        response.headers["Content-Type"] = "application/json";
        response.body = nlohmann::json({{"error", message}}).dump();
        return response;
    }
    
    static HttpResponse forbidden(const std::string& message) {
        HttpResponse response;
        response.status_code = 403;
        response.headers["Content-Type"] = "application/json";
        response.body = nlohmann::json({{"error", message}}).dump();
        return response;
    }
    
    static HttpResponse notFound(const std::string& message) {
        HttpResponse response;
        response.status_code = 404;
        response.headers["Content-Type"] = "application/json";
        response.body = nlohmann::json({{"error", message}}).dump();
        return response;
    }
    
    static HttpResponse internalError(const std::string& message) {
        HttpResponse response;
        response.status_code = 500;
        response.headers["Content-Type"] = "application/json";
        response.body = nlohmann::json({{"error", message}}).dump();
        return response;
    }
};

/**
 * @brief Route handler function type
 */
using RouteHandler = std::function<HttpResponse(const HttpRequest&)>;

/**
 * @brief API route structure
 */
struct Route {
    HttpMethod method;
    std::string path;
    RouteHandler handler;
    bool requires_auth;
    auth::PermissionLevel required_permission;
};

/**
 * @brief API router
 */
class Router {
public:
    /**
     * @brief Constructor
     * @param auth_service Authentication service
     * @param authz_service Authorization service
     */
    Router(
        std::shared_ptr<auth::IAuthService> auth_service,
        std::shared_ptr<auth::AuthorizationService> authz_service
    );
    
    /**
     * @brief Add a route
     * @param method HTTP method
     * @param path Route path
     * @param handler Route handler
     * @param requires_auth Whether authentication is required
     * @param required_permission Required permission level
     */
    void addRoute(
        HttpMethod method,
        const std::string& path,
        RouteHandler handler,
        bool requires_auth = true,
        auth::PermissionLevel required_permission = auth::PermissionLevel::READ
    );
    
    /**
     * @brief Handle an HTTP request
     * @param request HTTP request
     * @return HTTP response
     */
    HttpResponse handleRequest(const HttpRequest& request);
    
private:
    /**
     * @brief Get route for request
     * @param method HTTP method
     * @param path Request path
     * @return Route and path parameters
     */
    std::pair<Route*, std::unordered_map<std::string, std::string>> getRoute(
        HttpMethod method, 
        const std::string& path
    );
    
    /**
     * @brief Check if route pattern matches path
     * @param pattern Route pattern
     * @param path Request path
     * @return Path parameters if match, empty if no match
     */
    std::optional<std::unordered_map<std::string, std::string>> matchRoute(
        const std::string& pattern, 
        const std::string& path
    );
    
    std::vector<Route> routes_;
    std::shared_ptr<auth::IAuthService> auth_service_;
    std::shared_ptr<auth::AuthorizationService> authz_service_;
};

/**
 * @brief API server
 */
class ApiServer {
public:
    /**
     * @brief Constructor
     * @param host Host to bind to
     * @param port Port to bind to
     * @param auth_service Authentication service
     * @param authz_service Authorization service
     */
    ApiServer(
        const std::string& host,
        int port,
        std::shared_ptr<auth::IAuthService> auth_service,
        std::shared_ptr<auth::AuthorizationService> authz_service
    );
    
    /**
     * @brief Start the API server
     * @return True if started successfully
     */
    bool start();
    
    /**
     * @brief Stop the API server
     */
    void stop();
    
    /**
     * @brief Get the router
     * @return Router reference
     */
    Router& getRouter();
    
private:
    std::string host_;
    int port_;
    Router router_;
    std::atomic<bool> running_;
    std::thread server_thread_;
};

// Authentication API implementations

/**
 * @brief Login handler
 * @param auth_service Authentication service
 * @return Route handler
 */
RouteHandler createLoginHandler(std::shared_ptr<auth::IAuthService> auth_service);

/**
 * @brief Token refresh handler
 * @param auth_service Authentication service
 * @return Route handler
 */
RouteHandler createRefreshHandler(std::shared_ptr<auth::IAuthService> auth_service);

/**
 * @brief Current user info handler
 * @param auth_service Authentication service
 * @return Route handler
 */
RouteHandler createCurrentUserHandler(std::shared_ptr<auth::IAuthService> auth_service);

// Setup API routes
void setupAuthenticationApi(
    Router& router,
    std::shared_ptr<auth::IAuthService> auth_service
);

} // namespace api
} // namespace core_platform
#include "api/api_server.h"
#include "logging/logger.h"
#include "metrics/metrics_service.h"

#include <algorithm>
#include <regex>
#include <sstream>
#include <thread>
#include <chrono>

// This would be replaced with actual HTTP server like Crow or RESTinio
// For simplicity, we're mocking the HTTP server implementation

namespace core_platform {
namespace api {

// Convert string to HTTP method
HttpMethod methodFromString(const std::string& method) {
    if (method == "GET") return HttpMethod::GET;
    if (method == "POST") return HttpMethod::POST;
    if (method == "PUT") return HttpMethod::PUT;
    if (method == "DELETE") return HttpMethod::DELETE;
    if (method == "OPTIONS") return HttpMethod::OPTIONS;
    
    throw std::invalid_argument("Invalid HTTP method: " + method);
}

// Convert HTTP method to string
std::string methodToString(HttpMethod method) {
    switch (method) {
        case HttpMethod::GET: return "GET";
        case HttpMethod::POST: return "POST";
        case HttpMethod::PUT: return "PUT";
        case HttpMethod::DELETE: return "DELETE";
        case HttpMethod::OPTIONS: return "OPTIONS";
        default: return "UNKNOWN";
    }
}

// Router implementation
Router::Router(
    std::shared_ptr<auth::IAuthService> auth_service,
    std::shared_ptr<auth::AuthorizationService> authz_service
) :
    auth_service_(std::move(auth_service)),
    authz_service_(std::move(authz_service)) {
}

void Router::addRoute(
    HttpMethod method,
    const std::string& path,
    RouteHandler handler,
    bool requires_auth,
    auth::PermissionLevel required_permission
) {
    Route route;
    route.method = method;
    route.path = path;
    route.handler = std::move(handler);
    route.requires_auth = requires_auth;
    route.required_permission = required_permission;
    
    routes_.push_back(std::move(route));
    
    logging::Logger::getInstance().debug("Added route: {} {}", 
        methodToString(method), path);
}

HttpResponse Router::handleRequest(const HttpRequest& request) {
    // Find matching route
    auto [route, path_params] = getRoute(request.method, request.path);
    
    if (!route) {
        return HttpResponse::notFound("Route not found: " + request.path);
    }
    
    // Check authentication if required
    if (route->requires_auth) {
        auto it = request.headers.find("Authorization");
        if (it == request.headers.end()) {
            return HttpResponse::unauthorized("Authorization header missing");
        }
        
        std::string auth_header = it->second;
        if (auth_header.substr(0, 7) != "Bearer ") {
            return HttpResponse::unauthorized("Invalid authorization format, expected Bearer token");
        }
        
        std::string token = auth_header.substr(7);
        
        // Validate token
        if (!auth_service_->validateToken(token)) {
            return HttpResponse::unauthorized("Invalid or expired token");
        }
        
        // Check authorization
        if (route->required_permission != auth::PermissionLevel::NONE) {
            if (!authz_service_->hasPermission(token, request.path, route->required_permission)) {
                return HttpResponse::forbidden("Insufficient permissions");
            }
        }
    }
    
    // Create a copy of the request with path parameters
    HttpRequest req_with_params = request;
    req_with_params.path_params = path_params;
    
    // Metrics for request handling
    auto& request_counter = metrics::MetricsService::getInstance().createCounter(
        "http_requests_total",
        "Total number of HTTP requests",
        {
            {"method", methodToString(request.method)},
            {"path", route->path}
        }
    );
    
    auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
        "http_request_duration_seconds",
        "HTTP request duration in seconds",
        {
            {"method", methodToString(request.method)},
            {"path", route->path}
        }
    );
    
    // Increment request counter
    request_counter.Increment();
    
    // Time the request
    auto start_time = std::chrono::steady_clock::now();
    
    try {
        // Handle the request
        HttpResponse response = route->handler(req_with_params);
        
        // Record request duration
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        // Track response status codes
        auto& status_counter = metrics::MetricsService::getInstance().createCounter(
            "http_response_status",
            "HTTP response status codes",
            {
                {"method", methodToString(request.method)},
                {"path", route->path},
                {"status", std::to_string(response.status_code)}
            }
        );
        status_counter.Increment();
        
        return response;
    }
    catch (const std::exception& e) {
        // Record request duration for errors
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        // Log error
        logging::Logger::getInstance().error("Error handling request: {}", e.what());
        
        // Track error responses
        auto& error_counter = metrics::MetricsService::getInstance().createCounter(
            "http_response_status",
            "HTTP response status codes",
            {
                {"method", methodToString(request.method)},
                {"path", route->path},
                {"status", "500"}
            }
        );
        error_counter.Increment();
        
        return HttpResponse::internalError(e.what());
    }
}

std::pair<Route*, std::unordered_map<std::string, std::string>> Router::getRoute(
    HttpMethod method, 
    const std::string& path
) {
    for (auto& route : routes_) {
        if (route.method == method) {
            auto path_params = matchRoute(route.path, path);
            if (path_params) {
                return {&route, *path_params};
            }
        }
    }
    
    return {nullptr, {}};
}

std::optional<std::unordered_map<std::string, std::string>> Router::matchRoute(
    const std::string& pattern, 
    const std::string& path
) {
    // Simple path matching with parameters
    std::vector<std::string> pattern_parts;
    std::vector<std::string> path_parts;
    
    std::istringstream pattern_stream(pattern);
    std::istringstream path_stream(path);
    
    std::string part;
    while (std::getline(pattern_stream, part, '/')) {
        if (!part.empty()) {
            pattern_parts.push_back(part);
        }
    }
    
    while (std::getline(path_stream, part, '/')) {
        if (!part.empty()) {
            path_parts.push_back(part);
        }
    }
    
    if (pattern_parts.size() != path_parts.size()) {
        return std::nullopt;
    }
    
    std::unordered_map<std::string, std::string> params;
    
    for (size_t i = 0; i < pattern_parts.size(); ++i) {
        const auto& pattern_part = pattern_parts[i];
        const auto& path_part = path_parts[i];
        
        if (pattern_part[0] == ':') {
            // This is a parameter
            std::string param_name = pattern_part.substr(1);
            params[param_name] = path_part;
        }
        else if (pattern_part != path_part) {
            // Static part doesn't match
            return std::nullopt;
        }
    }
    
    return params;
}

// ApiServer implementation
ApiServer::ApiServer(
    const std::string& host,
    int port,
    std::shared_ptr<auth::IAuthService> auth_service,
    std::shared_ptr<auth::AuthorizationService> authz_service
) :
    host_(host),
    port_(port),
    router_(auth_service, authz_service),
    running_(false) {
}

bool ApiServer::start() {
    if (running_) {
        logging::Logger::getInstance().warn("API server already running");
        return true;
    }
    
    running_ = true;
    
    // In a real implementation, this would start an HTTP server
    // For this example, we're just logging that it started
    logging::Logger::getInstance().info("API server started on {}:{}", host_, port_);
    
    return true;
}

void ApiServer::stop() {
    if (!running_) {
        return;
    }
    
    running_ = false;
    
    // In a real implementation, this would stop the HTTP server
    logging::Logger::getInstance().info("API server stopped");
}

Router& ApiServer::getRouter() {
    return router_;
}

// Authentication API handlers
RouteHandler createLoginHandler(std::shared_ptr<auth::IAuthService> auth_service) {
    return [auth_service](const HttpRequest& request) -> HttpResponse {
        try {
            // Parse request body
            nlohmann::json request_data = nlohmann::json::parse(request.body);
            
            // Validate required fields
            if (!request_data.contains("username") || !request_data.contains("password")) {
                return HttpResponse::badRequest("Missing required fields: username and password");
            }
            
            // Create credentials
            auth::Credentials credentials;
            credentials.username = request_data["username"];
            credentials.password = request_data["password"];
            
            // Check for certificate
            if (request_data.contains("certificate")) {
                credentials.certificate = request_data["certificate"];
            }
            
            // Authenticate
            auth::AuthResult result = auth_service->authenticate(credentials);
            
            if (!result.success) {
                return HttpResponse::unauthorized(result.error_message);
            }
            
            // Generate tokens
            // In a real system, user roles would come from a database
            std::vector<std::string> roles;
            if (result.user_id == "admin") {
                roles = {"admin", "instructor", "trainee"};
            }
            else if (result.user_id == "instructor") {
                roles = {"instructor", "trainee"};
            }
            else {
                roles = {"trainee"};
            }
            
            auth::TokenData token_data = auth_service->generateTokens(result.user_id, roles);
            
            // Create response
            nlohmann::json response = {
                {"token", token_data.token},
                {"refresh_token", token_data.refresh_token},
                {"expires_in", std::chrono::duration_cast<std::chrono::seconds>(
                    token_data.expiry - std::chrono::system_clock::now()).count()},
                {"user_id", token_data.user_id},
                {"roles", token_data.roles}
            };
            
            return HttpResponse::ok(response);
        }
        catch (const nlohmann::json::exception& e) {
            return HttpResponse::badRequest("Invalid JSON: " + std::string(e.what()));
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Login error: {}", e.what());
            return HttpResponse::internalError(e.what());
        }
    };
}

RouteHandler createRefreshHandler(std::shared_ptr<auth::IAuthService> auth_service) {
    return [auth_service](const HttpRequest& request) -> HttpResponse {
        try {
            // Parse request body
            nlohmann::json request_data = nlohmann::json::parse(request.body);
            
            // Validate required fields
            if (!request_data.contains("refresh_token")) {
                return HttpResponse::badRequest("Missing required field: refresh_token");
            }
            
            std::string refresh_token = request_data["refresh_token"];
            
            // Refresh token
            std::optional<auth::TokenData> token_data = auth_service->refreshToken(refresh_token);
            
            if (!token_data) {
                return HttpResponse::unauthorized("Invalid or expired refresh token");
            }
            
            // Create response
            nlohmann::json response = {
                {"token", token_data->token},
                {"refresh_token", token_data->refresh_token},
                {"expires_in", std::chrono::duration_cast<std::chrono::seconds>(
                    token_data->expiry - std::chrono::system_clock::now()).count()},
                {"user_id", token_data->user_id},
                {"roles", token_data->roles}
            };
            
            return HttpResponse::ok(response);
        }
        catch (const nlohmann::json::exception& e) {
            return HttpResponse::badRequest("Invalid JSON: " + std::string(e.what()));
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Token refresh error: {}", e.what());
            return HttpResponse::internalError(e.what());
        }
    };
}

RouteHandler createCurrentUserHandler(std::shared_ptr<auth::IAuthService> auth_service) {
    return [auth_service](const HttpRequest& request) -> HttpResponse {
        try {
            // Get token from Authorization header
            auto it = request.headers.find("Authorization");
            if (it == request.headers.end()) {
                return HttpResponse::unauthorized("Authorization header missing");
            }
            
            std::string auth_header = it->second;
            if (auth_header.substr(0, 7) != "Bearer ") {
                return HttpResponse::unauthorized("Invalid authorization format, expected Bearer token");
            }
            
            std::string token = auth_header.substr(7);
            
            // Validate token
            if (!auth_service->validateToken(token)) {
                return HttpResponse::unauthorized("Invalid or expired token");
            }
            
            // Parse token to get user data
            auto decoded = jwt::decode(token);
            
            // Get user ID
            std::string user_id = decoded.get_subject();
            
            // Get roles
            std::vector<std::string> roles;
            if (decoded.has_payload_claim("roles")) {
                std::string roles_json = decoded.get_payload_claim("roles").as_string();
                roles = nlohmann::json::parse(roles_json);
            }
            
            // Create response
            nlohmann::json response = {
                {"user_id", user_id},
                {"roles", roles}
            };
            
            return HttpResponse::ok(response);
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Current user info error: {}", e.what());
            return HttpResponse::internalError(e.what());
        }
    };
}

void setupAuthenticationApi(
    Router& router,
    std::shared_ptr<auth::IAuthService> auth_service
) {
    // Login endpoint - POST /auth/login
    router.addRoute(
        HttpMethod::POST,
        "/auth/login",
        createLoginHandler(auth_service),
        false,  // No authentication required for login
        auth::PermissionLevel::NONE
    );
    
    // Token refresh endpoint - POST /auth/refresh
    router.addRoute(
        HttpMethod::POST,
        "/auth/refresh",
        createRefreshHandler(auth_service),
        false,  // No authentication required for refresh
        auth::PermissionLevel::NONE
    );
    
    // Current user info endpoint - GET /auth/me
    router.addRoute(
        HttpMethod::GET,
        "/auth/me",
        createCurrentUserHandler(auth_service),
        true,  // Authentication required
        auth::PermissionLevel::NONE
    );
    
    logging::Logger::getInstance().info("Authentication API routes set up");
}

} // namespace api
} // namespace core_platform
#pragma once

#include <string>
#include <vector>
#include <unordered_map>
#include <optional>
#include <memory>
#include <chrono>
#include <functional>

#include <jwt-cpp/jwt.h>
#include <nlohmann/json.hpp>
#include <openssl/x509.h>

namespace core_platform {
namespace auth {

/**
 * @brief Role-based permission levels
 */
enum class PermissionLevel {
    NONE = 0,
    READ = 1,
    WRITE = 2,
    ADMIN = 3
};

/**
 * @brief Authentication result structure
 */
struct AuthResult {
    bool success;
    std::string user_id;
    std::string error_message;
};

/**
 * @brief User credentials structure
 */
struct Credentials {
    std::string username;
    std::string password;
    std::optional<std::string> certificate;
};

/**
 * @brief Token data structure
 */
struct TokenData {
    std::string token;
    std::string refresh_token;
    std::chrono::system_clock::time_point expiry;
    std::string user_id;
    std::vector<std::string> roles;
};

/**
 * @brief Authentication service interface
 */
class IAuthService {
public:
    virtual ~IAuthService() = default;
    
    /**
     * @brief Authenticate a user with credentials
     * @param credentials User credentials
     * @return Authentication result
     */
    virtual AuthResult authenticate(const Credentials& credentials) = 0;
    
    /**
     * @brief Generate JWT tokens for an authenticated user
     * @param user_id User identifier
     * @param roles User roles
     * @return Token data
     */
    virtual TokenData generateTokens(const std::string& user_id, const std::vector<std::string>& roles) = 0;
    
    /**
     * @brief Validate a JWT token
     * @param token JWT token string
     * @return True if token is valid
     */
    virtual bool validateToken(const std::string& token) = 0;
    
    /**
     * @brief Refresh an existing token
     * @param refresh_token Refresh token
     * @return New token data or nullopt if refresh fails
     */
    virtual std::optional<TokenData> refreshToken(const std::string& refresh_token) = 0;
    
    /**
     * @brief Revoke a user's tokens
     * @param user_id User identifier
     */
    virtual void revokeUserTokens(const std::string& user_id) = 0;
};

/**
 * @brief JWT-based authentication service implementation
 */
class JwtAuthService : public IAuthService {
public:
    /**
     * @brief Constructor
     * @param secret JWT secret key
     * @param token_expiry Token expiry time in seconds
     * @param refresh_expiry Refresh token expiry time in seconds
     * @param cert_path Path to X.509 certificate file for cert-based auth
     */
    JwtAuthService(
        const std::string& secret,
        int token_expiry = 3600,
        int refresh_expiry = 86400,
        const std::string& cert_path = ""
    );
    
    ~JwtAuthService() override;
    
    // IAuthService implementation
    AuthResult authenticate(const Credentials& credentials) override;
    TokenData generateTokens(const std::string& user_id, const std::vector<std::string>& roles) override;
    bool validateToken(const std::string& token) override;
    std::optional<TokenData> refreshToken(const std::string& refresh_token) override;
    void revokeUserTokens(const std::string& user_id) override;

private:
    /**
     * @brief Validate X.509 certificate
     * @param cert_str Certificate in PEM format
     * @return Validation result
     */
    bool validateCertificate(const std::string& cert_str);
    
    /**
     * @brief Extract user ID from certificate
     * @param cert_str Certificate in PEM format
     * @return User ID or empty string if not found
     */
    std::string extractCertUserID(const std::string& cert_str);

    std::string secret_;
    int token_expiry_seconds_;
    int refresh_expiry_seconds_;
    std::string cert_path_;
    std::unordered_map<std::string, std::vector<std::string>> revoked_tokens_;
    
    // User credential validation (in a real system, this would connect to a database)
    // This is a simplified mock for demonstration
    std::unordered_map<std::string, std::string> user_credentials_;
    std::unordered_map<std::string, std::vector<std::string>> user_roles_;
};

/**
 * @brief Authorization service for role-based access control
 */
class AuthorizationService {
public:
    /**
     * @brief Constructor
     * @param auth_service Authentication service reference
     */
    explicit AuthorizationService(std::shared_ptr<IAuthService> auth_service);
    
    /**
     * @brief Check if a token has permission for a resource
     * @param token JWT token
     * @param resource_path Resource path
     * @param required_level Required permission level
     * @return True if authorized
     */
    bool hasPermission(
        const std::string& token,
        const std::string& resource_path,
        PermissionLevel required_level
    );
    
    /**
     * @brief Add a permission mapping for a role
     * @param role Role name
     * @param resource_path Resource path
     * @param level Permission level
     */
    void addRolePermission(
        const std::string& role,
        const std::string& resource_path,
        PermissionLevel level
    );

private:
    std::shared_ptr<IAuthService> auth_service_;
    
    // Role-based permissions mapping
    std::unordered_map<
        std::string, // role
        std::unordered_map<
            std::string, // resource_path
            PermissionLevel
        >
    > role_permissions_;
    
    // Role hierarchy (parent -> children)
    std::unordered_map<
        std::string,
        std::vector<std::string>
    > role_hierarchy_;
};

} // namespace auth
} // namespace core_platform
#include "auth/jwt_auth_service.h"
#include "logging/logger.h"

#include <fstream>
#include <iomanip>
#include <sstream>
#include <chrono>
#include <algorithm>
#include <openssl/pem.h>
#include <openssl/err.h>

namespace core_platform {
namespace auth {

JwtAuthService::JwtAuthService(
    const std::string& secret,
    int token_expiry,
    int refresh_expiry,
    const std::string& cert_path
) : 
    secret_(secret),
    token_expiry_seconds_(token_expiry),
    refresh_expiry_seconds_(refresh_expiry),
    cert_path_(cert_path)
{
    // Initialize OpenSSL
    OpenSSL_add_all_algorithms();
    ERR_load_crypto_strings();
    
    // Mock user data - in a real system, this would come from a database
    user_credentials_["admin"] = "admin_password";
    user_credentials_["instructor"] = "instructor_password";
    user_credentials_["trainee"] = "trainee_password";
    
    user_roles_["admin"] = {"admin", "instructor", "trainee"};
    user_roles_["instructor"] = {"instructor", "trainee"};
    user_roles_["trainee"] = {"trainee"};
    
    logging::Logger::getInstance().info("JwtAuthService initialized");
}

JwtAuthService::~JwtAuthService() {
    // Clean up OpenSSL
    EVP_cleanup();
    ERR_free_strings();
}

AuthResult JwtAuthService::authenticate(const Credentials& credentials) {
    AuthResult result;
    result.success = false;
    
    // Check for certificate-based authentication
    if (credentials.certificate.has_value() && !credentials.certificate.value().empty()) {
        const std::string& cert_str = credentials.certificate.value();
        if (validateCertificate(cert_str)) {
            std::string user_id = extractCertUserID(cert_str);
            if (!user_id.empty()) {
                result.success = true;
                result.user_id = user_id;
                logging::Logger::getInstance().info("User {} authenticated with certificate", user_id);
                return result;
            }
        }
        result.error_message = "Invalid certificate";
        logging::Logger::getInstance().warn("Certificate authentication failed");
        return result;
    }
    
    // Fall back to username/password authentication
    auto it = user_credentials_.find(credentials.username);
    if (it != user_credentials_.end() && it->second == credentials.password) {
        result.success = true;
        result.user_id = credentials.username;
        logging::Logger::getInstance().info("User {} authenticated with password", credentials.username);
    } else {
        result.error_message = "Invalid username or password";
        logging::Logger::getInstance().warn("Password authentication failed for user {}", credentials.username);
    }
    
    return result;
}

TokenData JwtAuthService::generateTokens(const std::string& user_id, const std::vector<std::string>& roles) {
    auto now = std::chrono::system_clock::now();
    auto token_exp = now + std::chrono::seconds(token_expiry_seconds_);
    auto refresh_exp = now + std::chrono::seconds(refresh_expiry_seconds_);
    
    // Create token payload
    auto token = jwt::create()
        .set_issuer("core-platform-service")
        .set_subject(user_id)
        .set_issued_at(now)
        .set_expires_at(token_exp);
    
    // Add roles to token
    nlohmann::json roles_json = roles;
    token.set_payload_claim("roles", jwt::claim(roles_json.dump()));
    
    // Sign the token
    std::string token_str = token.sign(jwt::algorithm::hs256{secret_});
    
    // Create refresh token
    auto refresh_token = jwt::create()
        .set_issuer("core-platform-service")
        .set_subject(user_id)
        .set_issued_at(now)
        .set_expires_at(refresh_exp)
        .set_payload_claim("type", jwt::claim(std::string("refresh")))
        .sign(jwt::algorithm::hs256{secret_});
    
    TokenData token_data;
    token_data.token = token_str;
    token_data.refresh_token = refresh_token;
    token_data.expiry = token_exp;
    token_data.user_id = user_id;
    token_data.roles = roles;
    
    logging::Logger::getInstance().info("Generated tokens for user {}", user_id);
    
    return token_data;
}

bool JwtAuthService::validateToken(const std::string& token) {
    try {
        // Check if token has been revoked
        auto decoded = jwt::decode(token);
        std::string user_id = decoded.get_subject();
        
        auto it = revoked_tokens_.find(user_id);
        if (it != revoked_tokens_.end()) {
            for (const auto& revoked_token : it->second) {
                if (revoked_token == token) {
                    logging::Logger::getInstance().warn("Token has been revoked for user {}", user_id);
                    return false;
                }
            }
        }
        
        // Verify token signature and expiration
        auto verifier = jwt::verify()
            .allow_algorithm(jwt::algorithm::hs256{secret_})
            .with_issuer("core-platform-service");
        
        verifier.verify(decoded);
        logging::Logger::getInstance().debug("Token validated for user {}", user_id);
        return true;
    } 
    catch (const jwt::token_verification_exception& e) {
        logging::Logger::getInstance().warn("Token validation failed: {}", e.what());
        return false;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Token validation error: {}", e.what());
        return false;
    }
}

std::optional<TokenData> JwtAuthService::refreshToken(const std::string& refresh_token) {
    try {
        auto decoded = jwt::decode(refresh_token);
        
        // Verify token
        auto verifier = jwt::verify()
            .allow_algorithm(jwt::algorithm::hs256{secret_})
            .with_issuer("core-platform-service");
        
        verifier.verify(decoded);
        
        // Check if it's a refresh token
        if (!decoded.has_payload_claim("type") || 
            decoded.get_payload_claim("type").as_string() != "refresh") {
            logging::Logger::getInstance().warn("Not a refresh token");
            return std::nullopt;
        }
        
        // Get user data
        std::string user_id = decoded.get_subject();
        
        // Check if user exists and get roles
        auto roles_it = user_roles_.find(user_id);
        if (roles_it == user_roles_.end()) {
            logging::Logger::getInstance().warn("User {} not found for token refresh", user_id);
            return std::nullopt;
        }
        
        // Generate new tokens
        auto token_data = generateTokens(user_id, roles_it->second);
        logging::Logger::getInstance().info("Refreshed tokens for user {}", user_id);
        
        return token_data;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Token refresh error: {}", e.what());
        return std::nullopt;
    }
}

void JwtAuthService::revokeUserTokens(const std::string& user_id) {
    // In a real implementation, all tokens for this user would be added to a
    // blacklist or revocation list, possibly in a database or redis cache
    
    // Here we're just clearing any existing revoked tokens and creating a new entry
    revoked_tokens_[user_id] = std::vector<std::string>();
    logging::Logger::getInstance().info("Revoked all tokens for user {}", user_id);
}

bool JwtAuthService::validateCertificate(const std::string& cert_str) {
    BIO* bio = BIO_new(BIO_s_mem());
    BIO_puts(bio, cert_str.c_str());
    
    X509* cert = PEM_read_bio_X509(bio, nullptr, nullptr, nullptr);
    BIO_free(bio);
    
    if (!cert) {
        logging::Logger::getInstance().error("Failed to parse X.509 certificate");
        return false;
    }
    
    // Check certificate validity period
    auto now = std::chrono::system_clock::now();
    auto now_time_t = std::chrono::system_clock::to_time_t(now);
    
    if (X509_cmp_time(X509_get_notBefore(cert), &now_time_t) >= 0 ||
        X509_cmp_time(X509_get_notAfter(cert), &now_time_t) <= 0) {
        X509_free(cert);
        logging::Logger::getInstance().warn("Certificate is not valid at current time");
        return false;
    }
    
    // In a real implementation, you would also:
    // 1. Verify certificate against a trusted CA
    // 2. Check certificate revocation status using CRL or OCSP
    // 3. Verify certificate extensions and usage
    
    X509_free(cert);
    return true;
}

std::string JwtAuthService::extractCertUserID(const std::string& cert_str) {
    BIO* bio = BIO_new(BIO_s_mem());
    BIO_puts(bio, cert_str.c_str());
    
    X509* cert = PEM_read_bio_X509(bio, nullptr, nullptr, nullptr);
    BIO_free(bio);
    
    if (!cert) {
        return "";
    }
    
    // Get subject name
    X509_NAME* subject_name = X509_get_subject_name(cert);
    if (!subject_name) {
        X509_free(cert);
        return "";
    }
    
    // Extract Common Name (CN) which often contains the user ID
    int index = X509_NAME_get_index_by_NID(subject_name, NID_commonName, -1);
    if (index < 0) {
        X509_free(cert);
        return "";
    }
    
    X509_NAME_ENTRY* entry = X509_NAME_get_entry(subject_name, index);
    if (!entry) {
        X509_free(cert);
        return "";
    }
    
    ASN1_STRING* data = X509_NAME_ENTRY_get_data(entry);
    unsigned char* utf8 = nullptr;
    int len = ASN1_STRING_to_UTF8(&utf8, data);
    
    std::string user_id;
    if (len > 0) {
        user_id = std::string(reinterpret_cast<char*>(utf8), len);
        OPENSSL_free(utf8);
    }
    
    X509_free(cert);
    return user_id;
}

// AuthorizationService implementation

AuthorizationService::AuthorizationService(std::shared_ptr<IAuthService> auth_service)
    : auth_service_(std::move(auth_service)) {
    
    // Setup role hierarchy
    role_hierarchy_["admin"] = {"instructor", "trainee"};
    role_hierarchy_["instructor"] = {"trainee"};
    
    // Setup default permissions
    addRolePermission("admin", "/api/admin", PermissionLevel::ADMIN);
    addRolePermission("admin", "/api/users", PermissionLevel::ADMIN);
    addRolePermission("instructor", "/api/courses", PermissionLevel::ADMIN);
    addRolePermission("instructor", "/api/assessments", PermissionLevel::ADMIN);
    addRolePermission("trainee", "/api/courses", PermissionLevel::READ);
    addRolePermission("trainee", "/api/assessments", PermissionLevel::READ);
    
    logging::Logger::getInstance().info("AuthorizationService initialized");
}

bool AuthorizationService::hasPermission(
    const std::string& token,
    const std::string& resource_path,
    PermissionLevel required_level
) {
    // Validate token first
    if (!auth_service_->validateToken(token)) {
        return false;
    }
    
    try {
        // Extract roles from token
        auto decoded = jwt::decode(token);
        if (!decoded.has_payload_claim("roles")) {
            logging::Logger::getInstance().warn("Token has no roles claim");
            return false;
        }
        
        std::string roles_json = decoded.get_payload_claim("roles").as_string();
        auto roles = nlohmann::json::parse(roles_json).get<std::vector<std::string>>();
        
        // Check each role for permission
        for (const auto& role : roles) {
            // Check direct permission
            auto role_it = role_permissions_.find(role);
            if (role_it != role_permissions_.end()) {
                auto perm_it = role_it->second.find(resource_path);
                if (perm_it != role_it->second.end() && 
                    static_cast<int>(perm_it->second) >= static_cast<int>(required_level)) {
                    return true;
                }
            }
            
            // Check hierarchical permissions
            std::function<bool(const std::string&)> check_hierarchy;
            check_hierarchy = [&](const std::string& parent_role) -> bool {
                auto hier_it = role_hierarchy_.find(parent_role);
                if (hier_it == role_hierarchy_.end()) {
                    return false;
                }
                
                for (const auto& child_role : hier_it->second) {
                    if (child_role == role) {
                        auto parent_perm_it = role_permissions_.find(parent_role);
                        if (parent_perm_it != role_permissions_.end()) {
                            auto res_perm_it = parent_perm_it->second.find(resource_path);
                            if (res_perm_it != parent_perm_it->second.end() && 
                                static_cast<int>(res_perm_it->second) >= static_cast<int>(required_level)) {
                                return true;
                            }
                        }
                    }
                    
                    if (check_hierarchy(child_role)) {
                        return true;
                    }
                }
                
                return false;
            };
            
            for (const auto& [parent_role, _] : role_hierarchy_) {
                if (check_hierarchy(parent_role)) {
                    return true;
                }
            }
        }
        
        logging::Logger::getInstance().warn("User does not have required permissions for {}", resource_path);
        return false;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Permission check error: {}", e.what());
        return false;
    }
}

void AuthorizationService::addRolePermission(
    const std::string& role,
    const std::string& resource_path,
    PermissionLevel level
) {
    role_permissions_[role][resource_path] = level;
    logging::Logger::getInstance().debug("Added permission {} for role {} on resource {}", 
        static_cast<int>(level), role, resource_path);
}

} // namespace auth
} // namespace core_platform
#include <gtest/gtest.h>
#include <gmock/gmock.h>

#include "auth/jwt_auth_service.h"

using namespace core_platform::auth;
using namespace testing;

class AuthServiceTest : public Test {
protected:
    void SetUp() override {
        // Create auth service with test secret
        auth_service = std::make_unique<JwtAuthService>(
            "test_secret_key", 
            60,     // Short token expiry for testing
            300     // Short refresh expiry for testing
        );
    }
    
    std::unique_ptr<JwtAuthService> auth_service;
};

TEST_F(AuthServiceTest, AuthenticateValidCredentials) {
    // Create test credentials
    Credentials credentials;
    credentials.username = "admin";
    credentials.password = "admin_password";
    
    // Authenticate
    AuthResult result = auth_service->authenticate(credentials);
    
    // Verify result
    EXPECT_TRUE(result.success);
    EXPECT_EQ(result.user_id, "admin");
    EXPECT_TRUE(result.error_message.empty());
}

TEST_F(AuthServiceTest, AuthenticateInvalidCredentials) {
    // Create test credentials with wrong password
    Credentials credentials;
    credentials.username = "admin";
    credentials.password = "wrong_password";
    
    // Authenticate
    AuthResult result = auth_service->authenticate(credentials);
    
    // Verify result
    EXPECT_FALSE(result.success);
    EXPECT_TRUE(result.user_id.empty());
    EXPECT_FALSE(result.error_message.empty());
}

TEST_F(AuthServiceTest, GenerateAndValidateToken) {
    // Generate token for test user
    std::string user_id = "test_user";
    std::vector<std::string> roles = {"admin", "instructor"};
    
    TokenData token_data = auth_service->generateTokens(user_id, roles);
    
    // Verify token data
    EXPECT_FALSE(token_data.token.empty());
    EXPECT_FALSE(token_data.refresh_token.empty());
    EXPECT_GT(std::chrono::system_clock::to_time_t(token_data.expiry),
              std::chrono::system_clock::to_time_t(std::chrono::system_clock::now()));
    EXPECT_EQ(token_data.user_id, user_id);
    EXPECT_EQ(token_data.roles, roles);
    
    // Validate token
    bool valid = auth_service->validateToken(token_data.token);
    EXPECT_TRUE(valid);
    
    // Validate with wrong token
    valid = auth_service->validateToken("wrong_token");
    EXPECT_FALSE(valid);
}

TEST_F(AuthServiceTest, RefreshToken) {
    // Generate token for test user
    std::string user_id = "test_user";
    std::vector<std::string> roles = {"admin", "instructor"};
    
    TokenData token_data = auth_service->generateTokens(user_id, roles);
    
    // Refresh token
    auto refreshed = auth_service->refreshToken(token_data.refresh_token);
    
    // Verify refreshed token
    EXPECT_TRUE(refreshed.has_value());
    EXPECT_FALSE(refreshed->token.empty());
    EXPECT_FALSE(refreshed->refresh_token.empty());
    EXPECT_GT(std::chrono::system_clock::to_time_t(refreshed->expiry),
              std::chrono::system_clock::to_time_t(std::chrono::system_clock::now()));
    EXPECT_EQ(refreshed->user_id, user_id);
    EXPECT_EQ(refreshed->roles, roles);
    
    // Refresh with wrong token
    auto invalid_refresh = auth_service->refreshToken("wrong_token");
    EXPECT_FALSE(invalid_refresh.has_value());
}

TEST_F(AuthServiceTest, RevokeToken) {
    // Generate token for test user
    std::string user_id = "test_user";
    std::vector<std::string> roles = {"admin", "instructor"};
    
    TokenData token_data = auth_service->generateTokens(user_id, roles);
    
    // Validate token
    bool valid = auth_service->validateToken(token_data.token);
    EXPECT_TRUE(valid);
    
    // Revoke token
    auth_service->revokeUserTokens(user_id);
    
    // Validate token again
    valid = auth_service->validateToken(token_data.token);
    EXPECT_FALSE(valid);
}

TEST_F(AuthServiceTest, TokenExpiry) {
    // Create auth service with very short expiry
    auto short_expiry_auth = std::make_unique<JwtAuthService>(
        "test_secret_key", 
        1,   // 1 second expiry
        10   // 10 second refresh expiry
    );
    
    // Generate token
    std::string user_id = "test_user";
    std::vector<std::string> roles = {"admin"};
    
    TokenData token_data = short_expiry_auth->generateTokens(user_id, roles);
    
    // Validate token immediately
    bool valid = short_expiry_auth->validateToken(token_data.token);
    EXPECT_TRUE(valid);
    
    // Wait for token to expire
    std::this_thread::sleep_for(std::chrono::seconds(2));
    
    // Validate token again
    valid = short_expiry_auth->validateToken(token_data.token);
    EXPECT_FALSE(valid);
}

// Authorization service tests

class AuthorizationServiceTest : public Test {
protected:
    void SetUp() override {
        // Create auth service
        auth_service = std::make_shared<JwtAuthService>(
            "test_secret_key", 
            60,    // Token expiry
            300    // Refresh expiry
        );
        
        // Create authorization service
        authz_service = std::make_unique<AuthorizationService>(auth_service);
        
        // Add test permissions
        authz_service->addRolePermission("admin", "/api/admin", PermissionLevel::ADMIN);
        authz_service->addRolePermission("instructor", "/api/courses", PermissionLevel::ADMIN);
        authz_service->addRolePermission("trainee", "/api/courses", PermissionLevel::READ);
    }
    
    std::shared_ptr<JwtAuthService> auth_service;
    std::unique_ptr<AuthorizationService> authz_service;
};

TEST_F(AuthorizationServiceTest, CheckPermission) {
    // Generate tokens for different roles
    auto admin_token = auth_service->generateTokens("admin", {"admin"});
    auto instructor_token = auth_service->generateTokens("instructor", {"instructor"});
    auto trainee_token = auth_service->generateTokens("trainee", {"trainee"});
    
    // Admin should have ADMIN permission on /api/admin
    EXPECT_TRUE(authz_service->hasPermission(
        admin_token.token, "/api/admin", PermissionLevel::ADMIN));
    
    // Instructor should NOT have permission on /api/admin
    EXPECT_FALSE(authz_service->hasPermission(
        instructor_token.token, "/api/admin", PermissionLevel::READ));
    
    // Instructor should have ADMIN permission on /api/courses
    EXPECT_TRUE(authz_service->hasPermission(
        instructor_token.token, "/api/courses", PermissionLevel::ADMIN));
    
    // Trainee should have READ permission on /api/courses
    EXPECT_TRUE(authz_service->hasPermission(
        trainee_token.token, "/api/courses", PermissionLevel::READ));
    
    // Trainee should NOT have WRITE permission on /api/courses
    EXPECT_FALSE(authz_service->hasPermission(
        trainee_token.token, "/api/courses", PermissionLevel::WRITE));
}

TEST_F(AuthorizationServiceTest, RoleHierarchy) {
    // Generate token for admin (who should inherit instructor and trainee permissions)
    auto admin_token = auth_service->generateTokens("admin_user", {"admin"});
    
    // Admin should have ADMIN permission on /api/courses (instructor permission)
    EXPECT_TRUE(authz_service->hasPermission(
        admin_token.token, "/api/courses", PermissionLevel::ADMIN));
}

int main(int argc, char** argv) {
    // Initialize Google Test
    ::testing::InitGoogleTest(&argc, argv);
    
    // Run all tests
    return RUN_ALL_TESTS();
}
cmake_minimum_required(VERSION 3.20)
project(core-platform-service VERSION 1.0.0 LANGUAGES CXX)

# Set C++20 standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Set output directories
set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)

# Find required packages
find_package(gRPC REQUIRED)
find_package(Protobuf REQUIRED)
find_package(OpenSSL REQUIRED)
find_package(nlohmann_json 3.10.0 REQUIRED)
find_package(spdlog REQUIRED)
find_package(prometheus-cpp REQUIRED)
find_package(jwt-cpp REQUIRED)

# Include directories
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_BINARY_DIR}/generated
)

# Generate protobuf and gRPC code
set(PROTO_FILES
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/auth.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/service.proto
)

protobuf_generate_cpp(PROTO_SRCS PROTO_HDRS ${PROTO_FILES})
grpc_generate_cpp(GRPC_SRCS GRPC_HDRS ${CMAKE_CURRENT_BINARY_DIR}/generated ${PROTO_FILES})

# Source files
file(GLOB_RECURSE SOURCES 
    ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp
)

# Add executable
add_executable(${PROJECT_NAME} ${SOURCES} ${PROTO_SRCS} ${PROTO_HDRS} ${GRPC_SRCS} ${GRPC_HDRS})

# Link libraries
target_link_libraries(${PROJECT_NAME}
    PRIVATE
    gRPC::grpc++
    gRPC::grpc++_reflection
    protobuf::libprotobuf
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
    spdlog::spdlog
    prometheus-cpp::core
    prometheus-cpp::push
    jwt-cpp::jwt-cpp
)

# Copy configuration files to build directory
configure_file(
    ${CMAKE_CURRENT_SOURCE_DIR}/config/config.json
    ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/config/config.json
    COPYONLY
)

# Add tests
enable_testing()
add_subdirectory(tests)

# Installation
install(TARGETS ${PROJECT_NAME}
    RUNTIME DESTINATION bin
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)

install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/config/
    DESTINATION etc/${PROJECT_NAME}
    FILES_MATCHING PATTERN "*.json"
)

# Documentation
find_package(Doxygen)
if(DOXYGEN_FOUND)
    set(DOXYGEN_IN ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in)
    set(DOXYGEN_OUT ${CMAKE_CURRENT_BINARY_DIR}/Doxyfile)
    
    configure_file(${DOXYGEN_IN} ${DOXYGEN_OUT} @ONLY)
    
    add_custom_target(docs
        COMMAND ${DOXYGEN_EXECUTABLE} ${DOXYGEN_OUT}
        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
        COMMENT "Generating API documentation with Doxygen"
        VERBATIM
    )
endif()
#pragma once

#include <string>
#include <memory>
#include <functional>
#include <unordered_map>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <future>
#include <queue>
#include <chrono>

#include <grpcpp/grpcpp.h>
#include <nlohmann/json.hpp>

namespace core_platform {
namespace communication {

/**
 * @brief Service discovery interface
 */
class IServiceDiscovery {
public:
    virtual ~IServiceDiscovery() = default;
    
    /**
     * @brief Register a service
     * @param service_name Service name
     * @param endpoint Service endpoint (host:port)
     * @return True if registration was successful
     */
    virtual bool registerService(const std::string& service_name, const std::string& endpoint) = 0;
    
    /**
     * @brief Unregister a service
     * @param service_name Service name
     * @param endpoint Service endpoint (host:port)
     * @return True if unregistration was successful
     */
    virtual bool unregisterService(const std::string& service_name, const std::string& endpoint) = 0;
    
    /**
     * @brief Discover a service
     * @param service_name Service name
     * @return Service endpoint or empty string if not found
     */
    virtual std::string discoverService(const std::string& service_name) = 0;
    
    /**
     * @brief Get all instances of a service
     * @param service_name Service name
     * @return Vector of service endpoints
     */
    virtual std::vector<std::string> getAllServiceInstances(const std::string& service_name) = 0;
};

/**
 * @brief Simple in-memory service discovery implementation
 */
class LocalServiceDiscovery : public IServiceDiscovery {
public:
    /**
     * @brief Get the singleton instance
     * @return LocalServiceDiscovery singleton
     */
    static LocalServiceDiscovery& getInstance();
    
    bool registerService(const std::string& service_name, const std::string& endpoint) override;
    bool unregisterService(const std::string& service_name, const std::string& endpoint) override;
    std::string discoverService(const std::string& service_name) override;
    std::vector<std::string> getAllServiceInstances(const std::string& service_name) override;

private:
    LocalServiceDiscovery() = default;
    ~LocalServiceDiscovery() = default;
    
    LocalServiceDiscovery(const LocalServiceDiscovery&) = delete;
    LocalServiceDiscovery& operator=(const LocalServiceDiscovery&) = delete;
    
    std::unordered_map<std::string, std::vector<std::string>> services_;
    std::mutex mutex_;
};

/**
 * @brief Message structure for inter-service communication
 */
struct Message {
    std::string id;
    std::string sender;
    std::string target;
    std::string type;
    nlohmann::json payload;
    std::chrono::system_clock::time_point timestamp;
    
    Message() : timestamp(std::chrono::system_clock::now()) {}
};

/**
 * @brief Message handler callback type
 */
using MessageHandler = std::function<void(const Message&)>;

/**
 * @brief Inter-service communication interface
 */
class IMessagingService {
public:
    virtual ~IMessagingService() = default;
    
    /**
     * @brief Start the messaging service
     * @return True if started successfully
     */
    virtual bool start() = 0;
    
    /**
     * @brief Stop the messaging service
     */
    virtual void stop() = 0;
    
    /**
     * @brief Send a message to a service
     * @param message Message to send
     * @return True if the message was sent successfully
     */
    virtual bool sendMessage(const Message& message) = 0;
    
    /**
     * @brief Send a message and wait for a response
     * @param message Message to send
     * @param timeout_ms Timeout in milliseconds
     * @return Response message or nullopt if timed out
     */
    virtual std::optional<Message> sendMessageWithResponse(
        const Message& message, 
        int timeout_ms = 5000
    ) = 0;
    
    /**
     * @brief Register a message handler
     * @param message_type Message type to handle
     * @param handler Handler function
     */
    virtual void registerHandler(const std::string& message_type, MessageHandler handler) = 0;
    
    /**
     * @brief Unregister a message handler
     * @param message_type Message type to unregister
     */
    virtual void unregisterHandler(const std::string& message_type) = 0;
};

/**
 * @brief gRPC-based messaging service implementation
 */
class GrpcMessagingService : public IMessagingService {
public:
    /**
     * @brief Constructor
     * @param service_name This service's name
     * @param host Host to bind to
     * @param port Port to bind to
     * @param discovery Service discovery implementation
     */
    GrpcMessagingService(
        const std::string& service_name,
        const std::string& host,
        int port,
        std::shared_ptr<IServiceDiscovery> discovery
    );
    
    ~GrpcMessagingService() override;
    
    bool start() override;
    void stop() override;
    bool sendMessage(const Message& message) override;
    std::optional<Message> sendMessageWithResponse(const Message& message, int timeout_ms = 5000) override;
    void registerHandler(const std::string& message_type, MessageHandler handler) override;
    void unregisterHandler(const std::string& message_type) override;

private:
    /**
     * @brief Handle an incoming message
     * @param message Received message
     * @return Response message
     */
    Message handleIncomingMessage(const Message& message);
    
    /**
     * @brief Run the server in a separate thread
     */
    void runServer();
    
    /**
     * @brief Get or create a client channel to a service
     * @param service_name Target service name
     * @return gRPC channel
     */
    std::shared_ptr<grpc::Channel> getChannel(const std::string& service_name);
    
    std::string service_name_;
    std::string host_;
    int port_;
    std::shared_ptr<IServiceDiscovery> discovery_;
    std::unique_ptr<grpc::Server> server_;
    std::thread server_thread_;
    std::atomic<bool> running_;
    
    std::unordered_map<std::string, MessageHandler> handlers_;
    std::mutex handlers_mutex_;
    
    std::unordered_map<std::string, std::shared_ptr<grpc::Channel>> channels_;
    std::mutex channels_mutex_;
    
    // For request-response pattern
    std::unordered_map<std::string, std::promise<Message>> pending_responses_;
    std::mutex pending_mutex_;
};

} // namespace communication
} // namespace core_platform
#include "communication/grpc_messaging_service.h"
#include "logging/logger.h"

#include <grpcpp/server_builder.h>
#include <grpcpp/create_channel.h>
#include <grpcpp/security/credentials.h>
#include <chrono>
#include <random>
#include <uuid.h>

namespace core_platform {
namespace communication {

// Local service discovery implementation
LocalServiceDiscovery& LocalServiceDiscovery::getInstance() {
    static LocalServiceDiscovery instance;
    return instance;
}

bool LocalServiceDiscovery::registerService(const std::string& service_name, const std::string& endpoint) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Check if endpoint already exists
    auto it = services_.find(service_name);
    if (it != services_.end()) {
        for (const auto& existing_endpoint : it->second) {
            if (existing_endpoint == endpoint) {
                logging::Logger::getInstance().debug("Service {} endpoint {} already registered", 
                    service_name, endpoint);
                return true;
            }
        }
    }
    
    // Add endpoint
    services_[service_name].push_back(endpoint);
    logging::Logger::getInstance().info("Registered service {} at {}", service_name, endpoint);
    return true;
}

bool LocalServiceDiscovery::unregisterService(const std::string& service_name, const std::string& endpoint) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    auto it = services_.find(service_name);
    if (it != services_.end()) {
        auto& endpoints = it->second;
        auto endpoint_it = std::find(endpoints.begin(), endpoints.end(), endpoint);
        
        if (endpoint_it != endpoints.end()) {
            endpoints.erase(endpoint_it);
            logging::Logger::getInstance().info("Unregistered service {} at {}", service_name, endpoint);
            
            // Remove service if no endpoints left
            if (endpoints.empty()) {
                services_.erase(it);
            }
            
            return true;
        }
    }
    
    logging::Logger::getInstance().warn("Service {} at {} not found for unregistration", 
        service_name, endpoint);
    return false;
}

std::string LocalServiceDiscovery::discoverService(const std::string& service_name) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    auto it = services_.find(service_name);
    if (it != services_.end() && !it->second.empty()) {
        // Simple load balancing - pick a random endpoint
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_int_distribution<size_t> dist(0, it->second.size() - 1);
        
        const std::string& endpoint = it->second[dist(gen)];
        logging::Logger::getInstance().debug("Discovered service {} at {}", service_name, endpoint);
        return endpoint;
    }
    
    logging::Logger::getInstance().warn("Service {} not found for discovery", service_name);
    return "";
}

std::vector<std::string> LocalServiceDiscovery::getAllServiceInstances(const std::string& service_name) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    auto it = services_.find(service_name);
    if (it != services_.end()) {
        return it->second;
    }
    
    return {};
}

// gRPC service implementation
class MessagingServiceImpl final : public MessagingService::Service {
public:
    explicit MessagingServiceImpl(GrpcMessagingService* service) : service_(service) {}
    
    grpc::Status SendMessage(
        grpc::ServerContext* context,
        const MessageRequest* request,
        MessageResponse* response
    ) override {
        logging::Logger::getInstance().debug("Received message from {}", request->sender());
        
        try {
            // Convert protobuf message to internal format
            Message message;
            message.id = request->id();
            message.sender = request->sender();
            message.target = request->target();
            message.type = request->type();
            message.payload = nlohmann::json::parse(request->payload());
            message.timestamp = std::chrono::system_clock::from_time_t(request->timestamp());
            
            // Handle message
            Message response_msg = service_->handleIncomingMessage(message);
            
            // Convert response to protobuf
            response->set_id(response_msg.id);
            response->set_sender(response_msg.sender);
            response->set_target(response_msg.target);
            response->set_type(response_msg.type);
            response->set_payload(response_msg.payload.dump());
            response->set_timestamp(
                std::chrono::system_clock::to_time_t(response_msg.timestamp)
            );
            response->set_success(true);
            
            return grpc::Status::OK;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error handling message: {}", e.what());
            
            response->set_id(request->id());
            response->set_sender(service_->getServiceName());
            response->set_target(request->sender());
            response->set_type("error");
            response->set_success(false);
            response->set_error_message(e.what());
            
            return grpc::Status(grpc::StatusCode::INTERNAL, e.what());
        }
    }
    
    grpc::Status StreamMessages(
        grpc::ServerContext* context,
        grpc::ServerReaderWriter<MessageResponse, MessageRequest>* stream
    ) override {
        logging::Logger::getInstance().debug("Started message stream");
        
        MessageRequest request;
        while (stream->Read(&request)) {
            try {
                // Convert protobuf message to internal format
                Message message;
                message.id = request.id();
                message.sender = request.sender();
                message.target = request.target();
                message.type = request.type();
                message.payload = nlohmann::json::parse(request.payload());
                message.timestamp = std::chrono::system_clock::from_time_t(request.timestamp());
                
                // Handle message
                Message response_msg = service_->handleIncomingMessage(message);
                
                // Convert response to protobuf
                MessageResponse response;
                response.set_id(response_msg.id);
                response.set_sender(response_msg.sender);
                response.set_target(response_msg.target);
                response.set_type(response_msg.type);
                response.set_payload(response_msg.payload.dump());
                response.set_timestamp(
                    std::chrono::system_clock::to_time_t(response_msg.timestamp)
                );
                response.set_success(true);
                
                stream->Write(response);
            }
            catch (const std::exception& e) {
                logging::Logger::getInstance().error("Error handling streamed message: {}", e.what());
                
                MessageResponse response;
                response.set_id(request.id());
                response.set_sender(service_->getServiceName());
                response.set_target(request.sender());
                response.set_type("error");
                response.set_success(false);
                response.set_error_message(e.what());
                
                stream->Write(response);
            }
        }
        
        logging::Logger::getInstance().debug("Ended message stream");
        return grpc::Status::OK;
    }
    
private:
    GrpcMessagingService* service_;
};

// GrpcMessagingService implementation
GrpcMessagingService::GrpcMessagingService(
    const std::string& service_name,
    const std::string& host,
    int port,
    std::shared_ptr<IServiceDiscovery> discovery
) :
    service_name_(service_name),
    host_(host),
    port_(port),
    discovery_(std::move(discovery)),
    running_(false) {
    
    logging::Logger::getInstance().debug("Created GrpcMessagingService for {} at {}:{}", 
        service_name_, host_, port_);
}

GrpcMessagingService::~GrpcMessagingService() {
    stop();
}

bool GrpcMessagingService::start() {
    if (running_) {
        logging::Logger::getInstance().warn("GrpcMessagingService already running");
        return true;
    }
    
    try {
        // Start server in a new thread
        running_ = true;
        server_thread_ = std::thread(&GrpcMessagingService::runServer, this);
        
        // Register with service discovery
        std::string endpoint = host_ + ":" + std::to_string(port_);
        if (!discovery_->registerService(service_name_, endpoint)) {
            logging::Logger::getInstance().error("Failed to register service with discovery");
            stop();
            return false;
        }
        
        logging::Logger::getInstance().info("GrpcMessagingService started");
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Failed to start GrpcMessagingService: {}", e.what());
        running_ = false;
        return false;
    }
}

void GrpcMessagingService::stop() {
    if (!running_) {
        return;
    }
    
    logging::Logger::getInstance().info("Stopping GrpcMessagingService");
    
    // Unregister from service discovery
    std::string endpoint = host_ + ":" + std::to_string(port_);
    discovery_->unregisterService(service_name_, endpoint);
    
    // Stop gRPC server
    running_ = false;
    
    if (server_) {
        server_->Shutdown();
    }
    
    if (server_thread_.joinable()) {
        server_thread_.join();
    }
    
    // Clear all channels
    std::lock_guard<std::mutex> lock(channels_mutex_);
    channels_.clear();
    
    logging::Logger::getInstance().info("GrpcMessagingService stopped");
}

bool GrpcMessagingService::sendMessage(const Message& message) {
    if (!running_) {
        logging::Logger::getInstance().error("Cannot send message, service not running");
        return false;
    }
    
    try {
        // Get target service endpoint
        std::string target_endpoint = discovery_->discoverService(message.target);
        if (target_endpoint.empty()) {
            logging::Logger::getInstance().error("Target service {} not found", message.target);
            return false;
        }
        
        // Get or create channel
        auto channel = getChannel(message.target);
        
        // Create stub
        auto stub = MessagingService::NewStub(channel);
        
        // Create request
        MessageRequest request;
        request.set_id(message.id);
        request.set_sender(service_name_);
        request.set_target(message.target);
        request.set_type(message.type);
        request.set_payload(message.payload.dump());
        request.set_timestamp(
            std::chrono::system_clock::to_time_t(message.timestamp)
        );
        
        // Send message
        MessageResponse response;
        grpc::ClientContext context;
        
        // Set timeout
        context.set_deadline(
            std::chrono::system_clock::now() + std::chrono::seconds(5)
        );
        
        grpc::Status status = stub->SendMessage(&context, request, &response);
        
        if (!status.ok()) {
            logging::Logger::getInstance().error("Failed to send message to {}: {} ({})", 
                message.target, status.error_message(), status.error_code());
            return false;
        }
        
        logging::Logger::getInstance().debug("Message sent to {}: {}", message.target, message.id);
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error sending message: {}", e.what());
        return false;
    }
}

std::optional<Message> GrpcMessagingService::sendMessageWithResponse(
    const Message& message, 
    int timeout_ms
) {
    if (!running_) {
        logging::Logger::getInstance().error("Cannot send message, service not running");
        return std::nullopt;
    }
    
    try {
        // Generate a unique ID for this request if not set
        std::string message_id = message.id;
        if (message_id.empty()) {
            uuids::uuid uuid = uuids::uuid_system_generator{}();
            message_id = uuids::to_string(uuid);
        }
        
        // Create a promise for the response
        std::promise<Message> response_promise;
        auto response_future = response_promise.get_future();
        
        {
            std::lock_guard<std::mutex> lock(pending_mutex_);
            pending_responses_[message_id] = std::move(response_promise);
        }
        
        // Create message with response handler
        Message request_msg = message;
        request_msg.id = message_id;
        
        // Send the message
        if (!sendMessage(request_msg)) {
            // Remove pending response on failure
            std::lock_guard<std::mutex> lock(pending_mutex_);
            pending_responses_.erase(message_id);
            return std::nullopt;
        }
        
        // Wait for response with timeout
        auto status = response_future.wait_for(std::chrono::milliseconds(timeout_ms));
        
        if (status != std::future_status::ready) {
            // Timeout occurred
            std::lock_guard<std::mutex> lock(pending_mutex_);
            pending_responses_.erase(message_id);
            logging::Logger::getInstance().warn("Timeout waiting for response to message {}", message_id);
            return std::nullopt;
        }
        
        // Get response
        Message response = response_future.get();
        
        logging::Logger::getInstance().debug("Received response to message {}", message_id);
        return response;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error in sendMessageWithResponse: {}", e.what());
        return std::nullopt;
    }
}

void GrpcMessagingService::registerHandler(const std::string& message_type, MessageHandler handler) {
    std::lock_guard<std::mutex> lock(handlers_mutex_);
    handlers_[message_type] = std::move(handler);
    logging::Logger::getInstance().debug("Registered handler for message type: {}", message_type);
}

void GrpcMessagingService::unregisterHandler(const std::string& message_type) {
    std::lock_guard<std::mutex> lock(handlers_mutex_);
    handlers_.erase(message_type);
    logging::Logger::getInstance().debug("Unregistered handler for message type: {}", message_type);
}

Message GrpcMessagingService::handleIncomingMessage(const Message& message) {
    logging::Logger::getInstance().debug("Handling message {} of type {}", message.id, message.type);
    
    // Check if this is a response to a pending request
    if (message.type == "response") {
        std::lock_guard<std::mutex> lock(pending_mutex_);
        
        auto it = pending_responses_.find(message.id);
        if (it != pending_responses_.end()) {
            // Set the response value
            it->second.set_value(message);
            pending_responses_.erase(it);
            
            // Create acknowledgment response
            Message ack;
            ack.id = message.id;
            ack.sender = service_name_;
            ack.target = message.sender;
            ack.type = "ack";
            ack.payload = {{"status", "acknowledged"}};
            ack.timestamp = std::chrono::system_clock::now();
            
            return ack;
        }
    }
    
    // Find handler for message type
    MessageHandler handler;
    {
        std::lock_guard<std::mutex> lock(handlers_mutex_);
        auto it = handlers_.find(message.type);
        if (it != handlers_.end()) {
            handler = it->second;
        }
    }
    
    // Process message with handler
    if (handler) {
        try {
            handler(message);
            
            // Create success response
            Message response;
            response.id = message.id;
            response.sender = service_name_;
            response.target = message.sender;
            response.type = "response";
            response.payload = {{"status", "success"}};
            response.timestamp = std::chrono::system_clock::now();
            
            return response;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error in message handler: {}", e.what());
            
            // Create error response
            Message response;
            response.id = message.id;
            response.sender = service_name_;
            response.target = message.sender;
            response.type = "error";
            response.payload = {
                {"status", "error"},
                {"error", e.what()}
            };
            response.timestamp = std::chrono::system_clock::now();
            
            return response;
        }
    }
    else {
        logging::Logger::getInstance().warn("No handler for message type: {}", message.type);
        
        // Create error response for unknown message type
        Message response;
        response.id = message.id;
        response.sender = service_name_;
        response.target = message.sender;
        response.type = "error";
        response.payload = {
            {"status", "error"},
            {"error", "No handler for message type: " + message.type}
        };
        response.timestamp = std::chrono::system_clock::now();
        
        return response;
    }
}

void GrpcMessagingService::runServer() {
    std::string server_address = host_ + ":" + std::to_string(port_);
    
    MessagingServiceImpl service(this);
    
    grpc::ServerBuilder builder;
    builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());
    builder.RegisterService(&service);
    
    server_ = builder.BuildAndStart();
    logging::Logger::getInstance().info("Server listening on {}", server_address);
    
    server_->Wait();
    
    logging::Logger::getInstance().info("Server shutdown");
}

std::shared_ptr<grpc::Channel> GrpcMessagingService::getChannel(const std::string& service_name) {
    std::lock_guard<std::mutex> lock(channels_mutex_);
    
    auto it = channels_.find(service_name);
    if (it != channels_.end()) {
        return it->second;
    }
    
    // Get endpoint from service discovery
    std::string endpoint = discovery_->discoverService(service_name);
    if (endpoint.empty()) {
        throw std::runtime_error("Service not found: " + service_name);
    }
    
    // Create new channel
    auto channel = grpc::CreateChannel(endpoint, grpc::InsecureChannelCredentials());
    channels_[service_name] = channel;
    
    return channel;
}

std::string GrpcMessagingService::getServiceName() const {
    return service_name_;
}

} // namespace communication
} // namespace core_platform
{
    "server": {
        "host": "0.0.0.0",
        "port": 50051
    },
    "auth": {
        "jwt_secret": "default_secret_key_change_in_production",
        "token_expiry_seconds": 3600,
        "refresh_expiry_seconds": 86400,
        "certificate_path": ""
    },
    "metrics": {
        "host": "0.0.0.0",
        "port": 9100,
        "push_gateway": false,
        "push_address": "localhost",
        "push_port": 9091,
        "push_interval_seconds": 15
    },
    "logging": {
        "level": "info",
        "console": true,
        "file": true,
        "file_path": "logs/core-platform-service.log",
        "max_file_size": 10485760,
        "max_files": 5
    },
    "services": {
        "data_acquisition_service": {
            "host": "data-acquisition-service",
            "port": 50052
        },
        "etr_service": {
            "host": "etr-service",
            "port": 50053
        },
        "ai_analytics_service": {
            "host": "ai-analytics-service",
            "port": 50054
        },
        "document_service": {
            "host": "document-service",
            "port": 50055
        },
        "syllabus_generator_service": {
            "host": "syllabus-generator-service",
            "port": 50056
        },
        "assessment_service": {
            "host": "assessment-service",
            "port": 50057
        }
    },
    "security": {
        "tls_enabled": false,
        "cert_file": "",
        "key_file": "",
        "ca_file": "",
        "rate_limit": {
            "enabled": true,
            "requests_per_minute": 60
        },
        "cors": {
            "enabled": true,
            "allowed_origins": ["*"],
            "allowed_methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
            "allowed_headers": ["Content-Type", "Authorization"],
            "exposed_headers": [],
            "allow_credentials": false,
            "max_age": 86400
        }
    },
    "performance": {
        "thread_pool_size": 4,
        "max_concurrent_requests": 100,
        "timeout_ms": 5000,
        "keep_alive_ms": 30000
    }
}
#pragma once

#include <string>
#include <unordered_map>
#include <any>
#include <mutex>
#include <optional>
#include <memory>
#include <vector>
#include <nlohmann/json.hpp>

namespace core_platform {
namespace config {

/**
 * @brief Configuration service interface
 */
class IConfigService {
public:
    virtual ~IConfigService() = default;
    
    /**
     * @brief Get a configuration value
     * @tparam T Value type
     * @param key Configuration key
     * @return Configuration value or nullopt if not found
     */
    template<typename T>
    std::optional<T> get(const std::string& key) const {
        return getValueAs<T>(key);
    }
    
    /**
     * @brief Set a configuration value
     * @tparam T Value type
     * @param key Configuration key
     * @param value Configuration value
     */
    template<typename T>
    void set(const std::string& key, const T& value) {
        setValue(key, value);
    }
    
    /**
     * @brief Check if a configuration key exists
     * @param key Configuration key
     * @return True if key exists
     */
    virtual bool has(const std::string& key) const = 0;
    
    /**
     * @brief Reload configuration from sources
     * @return True if reload was successful
     */
    virtual bool reload() = 0;
    
protected:
    /**
     * @brief Get a configuration value as a specific type
     * @tparam T Value type
     * @param key Configuration key
     * @return Configuration value or nullopt if not found or wrong type
     */
    template<typename T>
    virtual std::optional<T> getValueAs(const std::string& key) const = 0;
    
    /**
     * @brief Set a configuration value
     * @tparam T Value type
     * @param key Configuration key
     * @param value Configuration value
     */
    template<typename T>
    virtual void setValue(const std::string& key, const T& value) = 0;
};

/**
 * @brief Configuration source interface
 */
class IConfigSource {
public:
    virtual ~IConfigSource() = default;
    
    /**
     * @brief Load configuration from source
     * @return Configuration data as JSON
     */
    virtual nlohmann::json load() = 0;
    
    /**
     * @brief Save configuration to source
     * @param config Configuration data as JSON
     * @return True if save was successful
     */
    virtual bool save(const nlohmann::json& config) = 0;
    
    /**
     * @brief Get the priority of this source
     * Higher priority sources override lower priority ones
     * @return Priority value
     */
    virtual int getPriority() const = 0;
};

/**
 * @brief File-based configuration source
 */
class FileConfigSource : public IConfigSource {
public:
    /**
     * @brief Constructor
     * @param file_path Path to configuration file
     * @param priority Source priority
     */
    FileConfigSource(const std::string& file_path, int priority = 0);
    
    /**
     * @brief Load configuration from file
     * @return Configuration data as JSON
     */
    nlohmann::json load() override;
    
    /**
     * @brief Save configuration to file
     * @param config Configuration data as JSON
     * @return True if save was successful
     */
    bool save(const nlohmann::json& config) override;
    
    /**
     * @brief Get the priority of this source
     * @return Priority value
     */
    int getPriority() const override;
    
private:
    std::string file_path_;
    int priority_;
};

/**
 * @brief Environment variable configuration source
 */
class EnvConfigSource : public IConfigSource {
public:
    /**
     * @brief Constructor
     * @param prefix Prefix for environment variables
     * @param priority Source priority
     */
    EnvConfigSource(const std::string& prefix = "APP_", int priority = 100);
    
    /**
     * @brief Load configuration from environment variables
     * @return Configuration data as JSON
     */
    nlohmann::json load() override;
    
    /**
     * @brief Save configuration to environment variables
     * Environment variables cannot be saved, so this always returns false
     * @param config Configuration data as JSON
     * @return Always false
     */
    bool save(const nlohmann::json& config) override;
    
    /**
     * @brief Get the priority of this source
     * @return Priority value
     */
    int getPriority() const override;
    
private:
    std::string prefix_;
    int priority_;
};

/**
 * @brief Configuration service implementation
 */
class ConfigService : public IConfigService {
public:
    /**
     * @brief Get the singleton instance
     * @return ConfigService singleton
     */
    static ConfigService& getInstance();
    
    /**
     * @brief Add a configuration source
     * @param source Configuration source
     */
    void addSource(std::shared_ptr<IConfigSource> source);
    
    /**
     * @brief Check if a configuration key exists
     * @param key Configuration key
     * @return True if key exists
     */
    bool has(const std::string& key) const override;
    
    /**
     * @brief Reload configuration from all sources
     * @return True if reload was successful
     */
    bool reload() override;
    
protected:
    /**
     * @brief Get a configuration value as a specific type
     * @tparam T Value type
     * @param key Configuration key
     * @return Configuration value or nullopt if not found or wrong type
     */
    template<typename T>
    std::optional<T> getValueAs(const std::string& key) const override;
    
    /**
     * @brief Set a configuration value
     * @tparam T Value type
     * @param key Configuration key
     * @param value Configuration value
     */
    template<typename T>
    void setValue(const std::string& key, const T& value) override;
    
private:
    ConfigService();
    ~ConfigService() = default;
    
    ConfigService(const ConfigService&) = delete;
    ConfigService& operator=(const ConfigService&) = delete;
    
    /**
     * @brief Parse a configuration key path
     * @param key Configuration key in dot notation
     * @return Vector of key segments
     */
    std::vector<std::string> parseKey(const std::string& key) const;
    
    /**
     * @brief Get JSON element at path
     * @param json JSON object
     * @param path Key path segments
     * @return JSON element or null if not found
     */
    nlohmann::json getJsonAtPath(const nlohmann::json& json, const std::vector<std::string>& path) const;
    
    /**
     * @brief Set JSON element at path
     * @param json JSON object to modify
     * @param path Key path segments
     * @param value Value to set
     */
    void setJsonAtPath(nlohmann::json& json, const std::vector<std::string>& path, const nlohmann::json& value);
    
    std::vector<std::shared_ptr<IConfigSource>> sources_;
    nlohmann::json config_;
    mutable std::mutex mutex_;
};

// Template specializations for common types
template<>
std::optional<std::string> ConfigService::getValueAs(const std::string& key) const;

template<>
std::optional<int> ConfigService::getValueAs(const std::string& key) const;

template<>
std::optional<double> ConfigService::getValueAs(const std::string& key) const;

template<>
std::optional<bool> ConfigService::getValueAs(const std::string& key) const;

template<>
std::optional<std::vector<std::string>> ConfigService::getValueAs(const std::string& key) const;

template<>
void ConfigService::setValue(const std::string& key, const std::string& value);

template<>
void ConfigService::setValue(const std::string& key, const int& value);

template<>
void ConfigService::setValue(const std::string& key, const double& value);

template<>
void ConfigService::setValue(const std::string& key, const bool& value);

template<>
void ConfigService::setValue(const std::string& key, const std::vector<std::string>& value);

} // namespace config
} // namespace core_platform
#include "config/config_service.h"
#include "logging/logger.h"

#include <fstream>
#include <iostream>
#include <sstream>
#include <algorithm>
#include <stdexcept>
#include <cstdlib>

namespace core_platform {
namespace config {

// FileConfigSource implementation

FileConfigSource::FileConfigSource(const std::string& file_path, int priority)
    : file_path_(file_path), priority_(priority) {
}

nlohmann::json FileConfigSource::load() {
    try {
        std::ifstream file(file_path_);
        if (!file.is_open()) {
            logging::Logger::getInstance().warn("Could not open config file: {}", file_path_);
            return nlohmann::json::object();
        }
        
        nlohmann::json config;
        file >> config;
        
        logging::Logger::getInstance().info("Loaded configuration from file: {}", file_path_);
        return config;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error loading configuration from file {}: {}", 
            file_path_, e.what());
        return nlohmann::json::object();
    }
}

bool FileConfigSource::save(const nlohmann::json& config) {
    try {
        std::ofstream file(file_path_);
        if (!file.is_open()) {
            logging::Logger::getInstance().error("Could not open config file for writing: {}", file_path_);
            return false;
        }
        
        file << std::setw(4) << config;
        
        logging::Logger::getInstance().info("Saved configuration to file: {}", file_path_);
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error saving configuration to file {}: {}", 
            file_path_, e.what());
        return false;
    }
}

int FileConfigSource::getPriority() const {
    return priority_;
}

// EnvConfigSource implementation

EnvConfigSource::EnvConfigSource(const std::string& prefix, int priority)
    : prefix_(prefix), priority_(priority) {
}

nlohmann::json EnvConfigSource::load() {
    nlohmann::json config = nlohmann::json::object();
    
    // Platform-specific code to get environment variables
    #ifdef _WIN32
        char* env = nullptr;
        size_t len = 0;
        if (_dupenv_s(&env, &len, "PATH") == 0 && env != nullptr) {
            free(env);
        }
        
        // Windows env var enumeration
        LPWCH envStrings = GetEnvironmentStringsW();
        if (envStrings != nullptr) {
            LPWCH current = envStrings;
            while (*current) {
                DWORD size = WideCharToMultiByte(CP_UTF8, 0, current, -1, NULL, 0, NULL, NULL);
                if (size > 0) {
                    std::vector<char> buffer(size);
                    WideCharToMultiByte(CP_UTF8, 0, current, -1, buffer.data(), size, NULL, NULL);
                    std::string envVar(buffer.data());
                    
                    size_t pos = envVar.find('=');
                    if (pos != std::string::npos) {
                        std::string key = envVar.substr(0, pos);
                        std::string value = envVar.substr(pos + 1);
                        
                        if (key.find(prefix_) == 0) {
                            std::string configKey = key.substr(prefix_.length());
                            std::replace(configKey.begin(), configKey.end(), '_', '.');
                            std::transform(configKey.begin(), configKey.end(), configKey.begin(), ::tolower);
                            
                            // Parse and convert the value to appropriate JSON type
                            try {
                                if (value == "true" || value == "false") {
                                    config[configKey] = (value == "true");
                                } else if (std::all_of(value.begin(), value.end(), [](char c) {
                                    return std::isdigit(c) || c == '-' || c == '+';
                                })) {
                                    config[configKey] = std::stoi(value);
                                } else if (std::all_of(value.begin(), value.end(), [](char c) {
                                    return std::isdigit(c) || c == '.' || c == '-' || c == '+' || c == 'e' || c == 'E';
                                })) {
                                    config[configKey] = std::stod(value);
                                } else {
                                    config[configKey] = value;
                                }
                            } catch (const std::exception&) {
                                config[configKey] = value;
                            }
                        }
                    }
                }
                
                current += wcslen(current) + 1;
            }
            FreeEnvironmentStringsW(envStrings);
        }
    #else
        // POSIX env var enumeration
        for (char** env = environ; *env != nullptr; ++env) {
            std::string envVar(*env);
            size_t pos = envVar.find('=');
            if (pos != std::string::npos) {
                std::string key = envVar.substr(0, pos);
                std::string value = envVar.substr(pos + 1);
                
                if (key.find(prefix_) == 0) {
                    std::string configKey = key.substr(prefix_.length());
                    std::replace(configKey.begin(), configKey.end(), '_', '.');
                    std::transform(configKey.begin(), configKey.end(), configKey.begin(), ::tolower);
                    
                    // Parse and convert the value to appropriate JSON type
                    try {
                        if (value == "true" || value == "false") {
                            config[configKey] = (value == "true");
                        } else if (std::all_of(value.begin(), value.end(), [](char c) {
                            return std::isdigit(c) || c == '-' || c == '+';
                        })) {
                            config[configKey] = std::stoi(value);
                        } else if (std::all_of(value.begin(), value.end(), [](char c) {
                            return std::isdigit(c) || c == '.' || c == '-' || c == '+' || c == 'e' || c == 'E';
                        })) {
                            config[configKey] = std::stod(value);
                        } else {
                            config[configKey] = value;
                        }
                    } catch (const std::exception&) {
                        config[configKey] = value;
                    }
                }
            }
        }
    #endif
    
    logging::Logger::getInstance().info("Loaded configuration from environment variables with prefix: {}", prefix_);
    return config;
}

bool EnvConfigSource::save(const nlohmann::json& config) {
    // Environment variables cannot be saved programmatically in a cross-platform way
    logging::Logger::getInstance().warn("Saving to environment variables is not supported");
    return false;
}

int EnvConfigSource::getPriority() const {
    return priority_;
}

// ConfigService implementation

ConfigService& ConfigService::getInstance() {
    static ConfigService instance;
    return instance;
}

ConfigService::ConfigService() : config_(nlohmann::json::object()) {
    logging::Logger::getInstance().info("ConfigService initialized");
}

void ConfigService::addSource(std::shared_ptr<IConfigSource> source) {
    std::lock_guard<std::mutex> lock(mutex_);
    sources_.push_back(source);
    
    // Sort sources by priority (descending)
    std::sort(sources_.begin(), sources_.end(), 
        [](const std::shared_ptr<IConfigSource>& a, const std::shared_ptr<IConfigSource>& b) {
            return a->getPriority() > b->getPriority();
        });
    
    // Load configuration from this source and merge with existing
    nlohmann::json source_config = source->load();
    
    // Merge with existing configuration
    // Higher priority sources override lower priority ones
    for (auto& [key, value] : source_config.items()) {
        config_[key] = value;
    }
    
    logging::Logger::getInstance().debug("Added configuration source with priority {}", source->getPriority());
}

bool ConfigService::has(const std::string& key) const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return false;
    }
    
    nlohmann::json value = getJsonAtPath(config_, path);
    return !value.is_null();
}

bool ConfigService::reload() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Clear existing configuration
    config_ = nlohmann::json::object();
    
    // Load from all sources in order of priority
    for (const auto& source : sources_) {
        nlohmann::json source_config = source->load();
        
        // Merge with existing configuration
        for (auto& [key, value] : source_config.items()) {
            config_[key] = value;
        }
    }
    
    logging::Logger::getInstance().info("Configuration reloaded from all sources");
    return true;
}

std::vector<std::string> ConfigService::parseKey(const std::string& key) const {
    std::vector<std::string> result;
    std::stringstream ss(key);
    std::string segment;
    
    while (std::getline(ss, segment, '.')) {
        if (!segment.empty()) {
            result.push_back(segment);
        }
    }
    
    return result;
}

nlohmann::json ConfigService::getJsonAtPath(
    const nlohmann::json& json, 
    const std::vector<std::string>& path
) const {
    nlohmann::json current = json;
    
    for (const auto& segment : path) {
        if (!current.is_object() || !current.contains(segment)) {
            return nullptr;
        }
        
        current = current[segment];
    }
    
    return current;
}

void ConfigService::setJsonAtPath(
    nlohmann::json& json, 
    const std::vector<std::string>& path, 
    const nlohmann::json& value
) {
    if (path.empty()) {
        return;
    }
    
    nlohmann::json* current = &json;
    
    for (size_t i = 0; i < path.size() - 1; ++i) {
        const auto& segment = path[i];
        
        if (!current->is_object()) {
            *current = nlohmann::json::object();
        }
        
        if (!current->contains(segment)) {
            (*current)[segment] = nlohmann::json::object();
        }
        
        current = &(*current)[segment];
    }
    
    (*current)[path.back()] = value;
}

// Template specializations

template<>
std::optional<std::string> ConfigService::getValueAs(const std::string& key) const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return std::nullopt;
    }
    
    nlohmann::json value = getJsonAtPath(config_, path);
    if (value.is_null()) {
        return std::nullopt;
    }
    
    try {
        return value.get<std::string>();
    } catch (const std::exception& e) {
        logging::Logger::getInstance().warn("Failed to convert config value for key {} to string: {}", 
            key, e.what());
        return std::nullopt;
    }
}

template<>
std::optional<int> ConfigService::getValueAs(const std::string& key) const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return std::nullopt;
    }
    
    nlohmann::json value = getJsonAtPath(config_, path);
    if (value.is_null()) {
        return std::nullopt;
    }
    
    try {
        return value.get<int>();
    } catch (const std::exception& e) {
        logging::Logger::getInstance().warn("Failed to convert config value for key {} to int: {}", 
            key, e.what());
        return std::nullopt;
    }
}

template<>
std::optional<double> ConfigService::getValueAs(const std::string& key) const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return std::nullopt;
    }
    
    nlohmann::json value = getJsonAtPath(config_, path);
    if (value.is_null()) {
        return std::nullopt;
    }
    
    try {
        return value.get<double>();
    } catch (const std::exception& e) {
        logging::Logger::getInstance().warn("Failed to convert config value for key {} to double: {}", 
            key, e.what());
        return std::nullopt;
    }
}

template<>
std::optional<bool> ConfigService::getValueAs(const std::string& key) const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return std::nullopt;
    }
    
    nlohmann::json value = getJsonAtPath(config_, path);
    if (value.is_null()) {
        return std::nullopt;
    }
    
    try {
        return value.get<bool>();
    } catch (const std::exception& e) {
        logging::Logger::getInstance().warn("Failed to convert config value for key {} to bool: {}", 
            key, e.what());
        return std::nullopt;
    }
}

template<>
std::optional<std::vector<std::string>> ConfigService::getValueAs(const std::string& key) const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return std::nullopt;
    }
    
    nlohmann::json value = getJsonAtPath(config_, path);
    if (value.is_null() || !value.is_array()) {
        return std::nullopt;
    }
    
    try {
        return value.get<std::vector<std::string>>();
    } catch (const std::exception& e) {
        logging::Logger::getInstance().warn("Failed to convert config value for key {} to string array: {}", 
            key, e.what());
        return std::nullopt;
    }
}

template<>
void ConfigService::setValue(const std::string& key, const std::string& value) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return;
    }
    
    setJsonAtPath(config_, path, value);
    
    // Save to all writable sources
    for (const auto& source : sources_) {
        source->save(config_);
    }
    
    logging::Logger::getInstance().debug("Set config value for key {}: {}", key, value);
}

template<>
void ConfigService::setValue(const std::string& key, const int& value) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return;
    }
    
    setJsonAtPath(config_, path, value);
    
    // Save to all writable sources
    for (const auto& source : sources_) {
        source->save(config_);
    }
    
    logging::Logger::getInstance().debug("Set config value for key {}: {}", key, value);
}

template<>
void ConfigService::setValue(const std::string& key, const double& value) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return;
    }
    
    setJsonAtPath(config_, path, value);
    
    // Save to all writable sources
    for (const auto& source : sources_) {
        source->save(config_);
    }
    
    logging::Logger::getInstance().debug("Set config value for key {}: {}", key, value);
}

template<>
void ConfigService::setValue(const std::string& key, const bool& value) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return;
    }
    
    setJsonAtPath(config_, path, value);
    
    // Save to all writable sources
    for (const auto& source : sources_) {
        source->save(config_);
    }
    
    logging::Logger::getInstance().debug("Set config value for key {}: {}", key, value);
}

template<>
void ConfigService::setValue(const std::string& key, const std::vector<std::string>& value) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    std::vector<std::string> path = parseKey(key);
    if (path.empty()) {
        return;
    }
    
    setJsonAtPath(config_, path, value);
    
    // Save to all writable sources
    for (const auto& source : sources_) {
        source->save(config_);
    }
    
    logging::Logger::getInstance().debug("Set config value for key {}: array with {} elements", 
        key, value.size());
}

} // namespace config
} // namespace core_platform
version: '3.8'

services:
  core-platform-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: core-platform-service
    ports:
      - "50051:50051"  # gRPC port
      - "9100:9100"    # Metrics port
    environment:
      - CPS_SERVER_HOST=0.0.0.0
      - CPS_SERVER_PORT=50051
      - CPS_METRICS_HOST=0.0.0.0
      - CPS_METRICS_PORT=9100
      - CPS_AUTH_JWT_SECRET=${JWT_SECRET:-default_secret_key_change_in_production}
      - CPS_AUTH_TOKEN_EXPIRY_SECONDS=3600
      - CPS_AUTH_REFRESH_EXPIRY_SECONDS=86400
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
    networks:
      - platform-network
    depends_on:
      - prometheus
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --web.console.templates=/etc/prometheus/consoles
      - --web.enable-lifecycle
    networks:
      - platform-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    networks:
      - platform-network
    depends_on:
      - prometheus
    restart: unless-stopped

networks:
  platform-network:
    driver: bridge

volumes:
  prometheus-data:
  grafana-data:
# Stage 1: Build environment
FROM ubuntu:22.04 AS builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    libssl-dev \
    pkg-config \
    curl \
    unzip \
    && rm -rf /var/lib/apt/lists/*

# Install vcpkg for dependency management
WORKDIR /opt
RUN git clone https://github.com/Microsoft/vcpkg.git && \
    ./vcpkg/bootstrap-vcpkg.sh -disableMetrics && \
    ./vcpkg/vcpkg integrate install

# Install dependencies with vcpkg
RUN ./vcpkg/vcpkg install \
    grpc \
    protobuf \
    openssl \
    nlohmann-json \
    spdlog \
    prometheus-cpp \
    jwt-cpp \
    stduuid

# Copy source code
WORKDIR /app
COPY . .

# Create build directory
RUN mkdir -p build

# Configure and build
WORKDIR /app/build
RUN cmake .. \
    -DCMAKE_TOOLCHAIN_FILE=/opt/vcpkg/scripts/buildsystems/vcpkg.cmake \
    -DCMAKE_BUILD_TYPE=Release && \
    cmake --build . --config Release -j$(nproc)

# Stage 2: Runtime environment
FROM ubuntu:22.04

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    libssl3 \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Create app directories
RUN mkdir -p /app/bin /app/config /app/logs

# Copy build artifacts
COPY --from=builder /app/build/bin/core-platform-service /app/bin/
COPY --from=builder /app/config/*.json /app/config/

# Set working directory
WORKDIR /app

# Set environment variables
ENV CPS_SERVER_HOST=0.0.0.0
ENV CPS_SERVER_PORT=50051
ENV CPS_METRICS_HOST=0.0.0.0
ENV CPS_METRICS_PORT=9100

# Create non-root user
RUN useradd -m -s /bin/bash appuser && \
    chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Expose ports
EXPOSE 50051
EXPOSE 9100

# Define health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:9100/metrics || exit 1

# Start the service
CMD ["/app/bin/core-platform-service"]
#pragma once

#include <string>
#include <memory>
#include <mutex>
#include <spdlog/spdlog.h>
#include <spdlog/sinks/rotating_file_sink.h>
#include <spdlog/sinks/stdout_color_sinks.h>

namespace core_platform {
namespace logging {

/**
 * @brief Log level enumeration
 */
enum class LogLevel {
    TRACE = spdlog::level::trace,
    DEBUG = spdlog::level::debug,
    INFO = spdlog::level::info,
    WARN = spdlog::level::warn,
    ERROR = spdlog::level::err,
    CRITICAL = spdlog::level::critical,
    OFF = spdlog::level::off
};

/**
 * @brief Convert string to log level
 * @param level Level string (case-insensitive)
 * @return LogLevel value
 */
LogLevel logLevelFromString(const std::string& level);

/**
 * @brief Convert log level to string
 * @param level LogLevel value
 * @return Level string
 */
std::string logLevelToString(LogLevel level);

/**
 * @brief Logging service
 */
class Logger {
public:
    /**
     * @brief Get the singleton logger instance
     * @return Logger instance
     */
    static Logger& getInstance();
    
    /**
     * @brief Initialize the logger
     * @param service_name Service name for log identification
     * @param log_level Default log level
     * @param log_path Path to log file (empty for console only)
     * @param max_file_size Maximum log file size in bytes
     * @param max_files Maximum number of log files for rotation
     */
    void initialize(
        const std::string& service_name,
        LogLevel log_level = LogLevel::INFO,
        const std::string& log_path = "",
        size_t max_file_size = 10 * 1024 * 1024,
        size_t max_files = 5
    );
    
    /**
     * @brief Set the log level
     * @param level New log level
     */
    void setLevel(LogLevel level);
    
    /**
     * @brief Get the current log level
     * @return Current log level
     */
    LogLevel getLevel() const;
    
    /**
     * @brief Log a trace message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void trace(const std::string& fmt, const Args&... args) {
        logger_->trace(fmt, args...);
    }
    
    /**
     * @brief Log a debug message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void debug(const std::string& fmt, const Args&... args) {
        logger_->debug(fmt, args...);
    }
    
    /**
     * @brief Log an info message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void info(const std::string& fmt, const Args&... args) {
        logger_->info(fmt, args...);
    }
    
    /**
     * @brief Log a warning message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void warn(const std::string& fmt, const Args&... args) {
        logger_->warn(fmt, args...);
    }
    
    /**
     * @brief Log an error message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void error(const std::string& fmt, const Args&... args) {
        logger_->error(fmt, args...);
    }
    
    /**
     * @brief Log a critical message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void critical(const std::string& fmt, const Args&... args) {
        logger_->critical(fmt, args...);
    }
    
    /**
     * @brief Flush the logger
     */
    void flush();
    
private:
    Logger();
    ~Logger() = default;
    
    Logger(const Logger&) = delete;
    Logger& operator=(const Logger&) = delete;
    
    std::shared_ptr<spdlog::logger> logger_;
    std::mutex mutex_;
    bool initialized_;
};

} // namespace logging
} // namespace core_platform
#include "logging/logger.h"
#include <algorithm>
#include <cctype>
#include <iostream>
#include <filesystem>
#include <spdlog/async.h>
#include <spdlog/sinks/daily_file_sink.h>
#include <spdlog/sinks/syslog_sink.h>

namespace core_platform {
namespace logging {

LogLevel logLevelFromString(const std::string& level) {
    std::string level_lower = level;
    std::transform(level_lower.begin(), level_lower.end(), level_lower.begin(),
                   [](unsigned char c) { return std::tolower(c); });
    
    if (level_lower == "trace") return LogLevel::TRACE;
    if (level_lower == "debug") return LogLevel::DEBUG;
    if (level_lower == "info") return LogLevel::INFO;
    if (level_lower == "warn" || level_lower == "warning") return LogLevel::WARN;
    if (level_lower == "error" || level_lower == "err") return LogLevel::ERROR;
    if (level_lower == "critical" || level_lower == "fatal") return LogLevel::CRITICAL;
    if (level_lower == "off") return LogLevel::OFF;
    
    // Default to INFO if not recognized
    return LogLevel::INFO;
}

std::string logLevelToString(LogLevel level) {
    switch (level) {
        case LogLevel::TRACE: return "trace";
        case LogLevel::DEBUG: return "debug";
        case LogLevel::INFO: return "info";
        case LogLevel::WARN: return "warn";
        case LogLevel::ERROR: return "error";
        case LogLevel::CRITICAL: return "critical";
        case LogLevel::OFF: return "off";
        default: return "unknown";
    }
}

Logger::Logger() : initialized_(false) {
    // Create a default console logger until properly initialized
    logger_ = spdlog::stdout_color_mt("core_platform");
    logger_->set_level(spdlog::level::info);
}

Logger& Logger::getInstance() {
    static Logger instance;
    return instance;
}

void Logger::initialize(
    const std::string& service_name,
    LogLevel log_level,
    const std::string& log_path,
    size_t max_file_size,
    size_t max_files
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (initialized_) {
        logger_->warn("Logger already initialized, skipping re-initialization");
        return;
    }
    
    try {
        // Register the async logger with a thread pool of 8 threads and a queue size of 8192
        spdlog::init_thread_pool(8192, 8);
        
        std::vector<spdlog::sink_ptr> sinks;
        
        // Always add console output sink
        auto console_sink = std::make_shared<spdlog::sinks::stdout_color_sink_mt>();
        console_sink->set_level(static_cast<spdlog::level::level_enum>(log_level));
        sinks.push_back(console_sink);
        
        // Add file sink if path provided
        if (!log_path.empty()) {
            std::filesystem::path log_dir = std::filesystem::path(log_path).parent_path();
            
            // Create log directory if it doesn't exist
            if (!log_dir.empty() && !std::filesystem::exists(log_dir)) {
                std::filesystem::create_directories(log_dir);
            }
            
            auto file_sink = std::make_shared<spdlog::sinks::rotating_file_sink_mt>(
                log_path, max_file_size, max_files);
            file_sink->set_level(static_cast<spdlog::level::level_enum>(log_level));
            sinks.push_back(file_sink);
        }
        
        // Create an async logger with multiple sinks
        logger_ = std::make_shared<spdlog::async_logger>(
            service_name, sinks.begin(), sinks.end(),
            spdlog::thread_pool(), spdlog::async_overflow_policy::block);
        
        // Set log pattern with timestamp, service name, and thread ID
        logger_->set_pattern("%Y-%m-%d %H:%M:%S.%e [%n] [%t] [%l] %v");
        
        // Set log level
        logger_->set_level(static_cast<spdlog::level::level_enum>(log_level));
        
        // Register the logger in the registry
        spdlog::register_logger(logger_);
        
        // Set as default logger
        spdlog::set_default_logger(logger_);
        
        initialized_ = true;
        
        logger_->info("Logger initialized for service: {}", service_name);
    }
    catch (const std::exception& ex) {
        std::cerr << "Logger initialization failed: " << ex.what() << std::endl;
        
        // Fallback to console logger
        logger_ = spdlog::stdout_color_mt(service_name);
        logger_->set_level(static_cast<spdlog::level::level_enum>(log_level));
        logger_->error("Failed to initialize logger with file sink: {}", ex.what());
    }
}

void Logger::setLevel(LogLevel level) {
    std::lock_guard<std::mutex> lock(mutex_);
    logger_->set_level(static_cast<spdlog::level::level_enum>(level));
    logger_->info("Log level set to: {}", logLevelToString(level));
}

LogLevel Logger::getLevel() const {
    return static_cast<LogLevel>(logger_->level());
}

void Logger::flush() {
    logger_->flush();
}

} // namespace logging
} // namespace core_platform
#include <iostream>
#include <csignal>
#include <thread>
#include <chrono>

#include "auth/jwt_auth_service.h"
#include "config/config_service.h"
#include "communication/grpc_messaging_service.h"
#include "logging/logger.h"
#include "metrics/metrics_service.h"

using namespace core_platform;

// Global flag for graceful shutdown
std::atomic<bool> running{true};

// Signal handler
void signalHandler(int signal) {
    logging::Logger::getInstance().info("Received signal {}, shutting down...", signal);
    running = false;
}

int main(int argc, char** argv) {
    try {
        // Register signal handlers
        std::signal(SIGINT, signalHandler);
        std::signal(SIGTERM, signalHandler);
        
        // Initialize logger
        logging::Logger::getInstance().initialize(
            "core-platform-service",
            logging::LogLevel::INFO,
            "logs/core-platform-service.log"
        );
        
        logging::Logger::getInstance().info("Core Platform Service starting up");
        
        // Initialize configuration
        auto& config_service = config::ConfigService::getInstance();
        
        // Add configuration sources
        auto file_config = std::make_shared<config::FileConfigSource>("config/config.json");
        auto env_config = std::make_shared<config::EnvConfigSource>("CPS_");
        
        config_service.addSource(file_config);
        config_service.addSource(env_config);
        
        // Get configuration values
        std::string host = config_service.get<std::string>("server.host").value_or("0.0.0.0");
        int port = config_service.get<int>("server.port").value_or(50051);
        std::string jwt_secret = config_service.get<std::string>("auth.jwt_secret").value_or("default_secret_key_change_in_production");
        int token_expiry = config_service.get<int>("auth.token_expiry_seconds").value_or(3600);
        int refresh_expiry = config_service.get<int>("auth.refresh_expiry_seconds").value_or(86400);
        std::string metrics_host = config_service.get<std::string>("metrics.host").value_or("0.0.0.0");
        int metrics_port = config_service.get<int>("metrics.port").value_or(9100);
        
        // Initialize metrics
        metrics::MetricsService::getInstance().initialize(
            "core-platform-service",
            true,
            metrics_host,
            metrics_port
        );
        
        // Create authentication service
        auto auth_service = std::make_shared<auth::JwtAuthService>(
            jwt_secret,
            token_expiry,
            refresh_expiry
        );
        
        // Create authorization service
        auto authz_service = std::make_shared<auth::AuthorizationService>(auth_service);
        
        // Initialize service discovery
        auto service_discovery = std::make_shared<communication::LocalServiceDiscovery>();
        
        // Register this service
        service_discovery->registerService(
            "core-platform-service",
            host + ":" + std::to_string(port)
        );
        
        // Initialize messaging service
        auto messaging_service = std::make_shared<communication::GrpcMessagingService>(
            "core-platform-service",
            host,
            port,
            service_discovery
        );
        
        // Start messaging service
        if (!messaging_service->start()) {
            logging::Logger::getInstance().critical("Failed to start messaging service");
            return 1;
        }
        
        logging::Logger::getInstance().info("Core Platform Service started on {}:{}", host, port);
        
        // Create performance metrics
        auto& request_counter = metrics::MetricsService::getInstance().createCounter(
            "requests_total",
            "Total number of requests",
            {{"service", "core-platform-service"}}
        );
        
        auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
            "request_duration_seconds",
            "Request duration in seconds",
            {{"service", "core-platform-service"}}
        );
        
        auto& active_connections = metrics::MetricsService::getInstance().createGauge(
            "active_connections",
            "Number of active connections",
            {{"service", "core-platform-service"}}
        );
        
        // Main loop
        while (running) {
            // Update metrics
            active_connections.Set(42); // Example value, should be replaced with actual logic
            
            // Sleep to avoid busy waiting
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
        
        // Graceful shutdown
        logging::Logger::getInstance().info("Shutting down Core Platform Service");
        
        // Stop messaging service
        messaging_service->stop();
        
        // Unregister service
        service_discovery->unregisterService(
            "core-platform-service",
            host + ":" + std::to_string(port)
        );
        
        // Shutdown metrics
        metrics::MetricsService::getInstance().shutdown();
        
        logging::Logger::getInstance().info("Core Platform Service shut down successfully");
        return 0;
    }
    catch (const std::exception& e) {
        // Use std::cerr in case logging is not available
        std::cerr << "Fatal error: " << e.what() << std::endl;
        
        try {
            logging::Logger::getInstance().critical("Fatal error: {}", e.what());
        } catch (...) {
            // Ignore if logging fails
        }
        
        return 1;
    }
}
#pragma once

#include <string>
#include <memory>
#include <unordered_map>
#include <mutex>
#include <vector>
#include <prometheus/counter.h>
#include <prometheus/gauge.h>
#include <prometheus/histogram.h>
#include <prometheus/summary.h>
#include <prometheus/registry.h>
#include <prometheus/exposer.h>
#include <prometheus/push_gateway.h>

namespace core_platform {
namespace metrics {

/**
 * @brief Metric type enumeration
 */
enum class MetricType {
    COUNTER,
    GAUGE,
    HISTOGRAM,
    SUMMARY
};

/**
 * @brief Labels type for metric dimensions
 */
using Labels = std::map<std::string, std::string>;

/**
 * @brief Metrics service for collecting and exposing metrics
 */
class MetricsService {
public:
    /**
     * @brief Get the singleton instance
     * @return MetricsService singleton
     */
    static MetricsService& getInstance();
    
    /**
     * @brief Initialize the metrics service
     * @param service_name Service name for metrics namespace
     * @param expose_http Enable HTTP exposition on given address:port
     * @param http_address Address to expose metrics on
     * @param http_port Port to expose metrics on
     * @param push_gateway Enable push gateway publishing
     * @param push_address Push gateway address
     * @param push_port Push gateway port
     * @param push_interval_sec Push interval in seconds
     */
    void initialize(
        const std::string& service_name,
        bool expose_http = true,
        const std::string& http_address = "0.0.0.0",
        int http_port = 9100,
        bool push_gateway = false,
        const std::string& push_address = "localhost",
        int push_port = 9091,
        int push_interval_sec = 15
    );
    
    /**
     * @brief Create or get a counter
     * @param name Counter name
     * @param help Counter help text
     * @param labels Counter labels
     * @return Counter reference
     */
    prometheus::Counter& createCounter(
        const std::string& name,
        const std::string& help,
        const Labels& labels = {}
    );
    
    /**
     * @brief Create or get a gauge
     * @param name Gauge name
     * @param help Gauge help text
     * @param labels Gauge labels
     * @return Gauge reference
     */
    prometheus::Gauge& createGauge(
        const std::string& name,
        const std::string& help,
        const Labels& labels = {}
    );
    
    /**
     * @brief Create or get a histogram
     * @param name Histogram name
     * @param help Histogram help text
     * @param labels Histogram labels
     * @param buckets Histogram buckets
     * @return Histogram reference
     */
    prometheus::Histogram& createHistogram(
        const std::string& name,
        const std::string& help,
        const Labels& labels = {},
        const std::vector<double>& buckets = prometheus::Histogram::ExponentialBuckets(0.005, 2, 10)
    );
    
    /**
     * @brief Create or get a summary
     * @param name Summary name
     * @param help Summary help text
     * @param labels Summary labels
     * @param quantiles Summary quantiles
     * @return Summary reference
     */
    prometheus::Summary& createSummary(
        const std::string& name,
        const std::string& help,
        const Labels& labels = {},
        const std::map<double, prometheus::detail::quantile_t>& quantiles = {
            {0.5, prometheus::detail::quantile_t{0.05}},
            {0.9, prometheus::detail::quantile_t{0.01}},
            {0.99, prometheus::detail::quantile_t{0.001}}
        }
    );
    
    /**
     * @brief Push metrics to push gateway
     * Called automatically by timer if push gateway is enabled
     */
    void pushMetrics();
    
    /**
     * @brief Start HTTP exposition server
     * Called automatically by initialize if expose_http is true
     */
    void startHttpServer();
    
    /**
     * @brief Stop HTTP exposition server and push timer
     */
    void shutdown();

private:
    MetricsService();
    ~MetricsService();
    
    MetricsService(const MetricsService&) = delete;
    MetricsService& operator=(const MetricsService&) = delete;
    
    std::shared_ptr<prometheus::Registry> registry_;
    std::string service_name_;
    
    // HTTP exposition
    bool expose_http_;
    std::string http_address_;
    int http_port_;
    std::unique_ptr<prometheus::Exposer> exposer_;
    
    // Push gateway
    bool push_gateway_;
    std::string push_address_;
    int push_port_;
    int push_interval_sec_;
    std::unique_ptr<prometheus::PushGateway> push_gateway_client_;
    
    // Push timer
    std::thread push_thread_;
    std::atomic<bool> running_;
    
    // Families cache
    std::unordered_map<std::string, prometheus::Family<prometheus::Counter>*> counter_families_;
    std::unordered_map<std::string, prometheus::Family<prometheus::Gauge>*> gauge_families_;
    std::unordered_map<std::string, prometheus::Family<prometheus::Histogram>*> histogram_families_;
    std::unordered_map<std::string, prometheus::Family<prometheus::Summary>*> summary_families_;
    
    std::mutex mutex_;
};

/**
 * @brief Utility class for timing operations and recording metrics
 */
class ScopedTimer {
public:
    /**
     * @brief Constructor
     * @param histogram Histogram to record duration
     */
    explicit ScopedTimer(prometheus::Histogram& histogram);
    
    /**
     * @brief Destructor - records elapsed time
     */
    ~ScopedTimer();
    
private:
    prometheus::Histogram& histogram_;
    std::chrono::steady_clock::time_point start_time_;
};

} // namespace metrics
} // namespace core_platform
#include "metrics/metrics_service.h"
#include "logging/logger.h"

#include <thread>
#include <chrono>

namespace core_platform {
namespace metrics {

MetricsService::MetricsService()
    : registry_(std::make_shared<prometheus::Registry>()),
      expose_http_(false),
      http_port_(9100),
      push_gateway_(false),
      push_port_(9091),
      push_interval_sec_(15),
      running_(false) {
}

MetricsService::~MetricsService() {
    shutdown();
}

MetricsService& MetricsService::getInstance() {
    static MetricsService instance;
    return instance;
}

void MetricsService::initialize(
    const std::string& service_name,
    bool expose_http,
    const std::string& http_address,
    int http_port,
    bool push_gateway,
    const std::string& push_address,
    int push_port,
    int push_interval_sec
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    service_name_ = service_name;
    expose_http_ = expose_http;
    http_address_ = http_address;
    http_port_ = http_port;
    push_gateway_ = push_gateway;
    push_address_ = push_address;
    push_port_ = push_port;
    push_interval_sec_ = push_interval_sec;
    
    // Start HTTP exposition server if enabled
    if (expose_http_) {
        startHttpServer();
    }
    
    // Setup push gateway client if enabled
    if (push_gateway_) {
        std::string push_gateway_url = push_address_ + ":" + std::to_string(push_port_);
        push_gateway_client_ = std::make_unique<prometheus::PushGateway>(push_gateway_url);
        
        // Start push thread
        running_ = true;
        push_thread_ = std::thread([this]() {
            while (running_) {
                try {
                    pushMetrics();
                } 
                catch (const std::exception& e) {
                    logging::Logger::getInstance().error("Error pushing metrics: {}", e.what());
                }
                
                // Sleep for push interval
                for (int i = 0; i < push_interval_sec_ && running_; ++i) {
                    std::this_thread::sleep_for(std::chrono::seconds(1));
                }
            }
        });
    }
    
    logging::Logger::getInstance().info("MetricsService initialized for service: {}", service_name_);
}

prometheus::Counter& MetricsService::createCounter(
    const std::string& name,
    const std::string& help,
    const Labels& labels
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Check if family exists
    auto family_it = counter_families_.find(name);
    if (family_it == counter_families_.end()) {
        // Create new family
        auto& family = prometheus::BuildCounter()
            .Name(name)
            .Help(help)
            .Register(*registry_);
        
        counter_families_[name] = &family;
        family_it = counter_families_.find(name);
        
        logging::Logger::getInstance().debug("Created counter family: {}", name);
    }
    
    // Create or get counter with labels
    return family_it->second->Add(labels);
}

prometheus::Gauge& MetricsService::createGauge(
    const std::string& name,
    const std::string& help,
    const Labels& labels
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Check if family exists
    auto family_it = gauge_families_.find(name);
    if (family_it == gauge_families_.end()) {
        // Create new family
        auto& family = prometheus::BuildGauge()
            .Name(name)
            .Help(help)
            .Register(*registry_);
        
        gauge_families_[name] = &family;
        family_it = gauge_families_.find(name);
        
        logging::Logger::getInstance().debug("Created gauge family: {}", name);
    }
    
    // Create or get gauge with labels
    return family_it->second->Add(labels);
}

prometheus::Histogram& MetricsService::createHistogram(
    const std::string& name,
    const std::string& help,
    const Labels& labels,
    const std::vector<double>& buckets
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Check if family exists
    auto family_it = histogram_families_.find(name);
    if (family_it == histogram_families_.end()) {
        // Create new family
        auto& family = prometheus::BuildHistogram()
            .Name(name)
            .Help(help)
            .Buckets(buckets)
            .Register(*registry_);
        
        histogram_families_[name] = &family;
        family_it = histogram_families_.find(name);
        
        logging::Logger::getInstance().debug("Created histogram family: {}", name);
    }
    
    // Create or get histogram with labels
    return family_it->second->Add(labels);
}

prometheus::Summary& MetricsService::createSummary(
    const std::string& name,
    const std::string& help,
    const Labels& labels,
    const std::map<double, prometheus::detail::quantile_t>& quantiles
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Check if family exists
    auto family_it = summary_families_.find(name);
    if (family_it == summary_families_.end()) {
        // Create new family
        auto& family = prometheus::BuildSummary()
            .Name(name)
            .Help(help)
            .Quantiles(quantiles)
            .Register(*registry_);
        
        summary_families_[name] = &family;
        family_it = summary_families_.find(name);
        
        logging::Logger::getInstance().debug("Created summary family: {}", name);
    }
    
    // Create or get summary with labels
    return family_it->second->Add(labels);
}

void MetricsService::pushMetrics() {
    if (!push_gateway_ || !push_gateway_client_) {
        return;
    }
    
    try {
        push_gateway_client_->Push(registry_, service_name_, Labels{{"instance", service_name_}});
        logging::Logger::getInstance().debug("Pushed metrics to push gateway");
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Failed to push metrics: {}", e.what());
    }
}

void MetricsService::startHttpServer() {
    if (!expose_http_) {
        return;
    }
    
    try {
        std::string endpoint = http_address_ + ":" + std::to_string(http_port_);
        exposer_ = std::make_unique<prometheus::Exposer>(endpoint);
        exposer_->RegisterCollectable(registry_);
        
        logging::Logger::getInstance().info("Started metrics HTTP server on {}", endpoint);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Failed to start metrics HTTP server: {}", e.what());
        expose_http_ = false;
    }
}

void MetricsService::shutdown() {
    // Stop push thread
    if (push_thread_.joinable()) {
        running_ = false;
        push_thread_.join();
    }
    
    // Clean up resources
    exposer_.reset();
    push_gateway_client_.reset();
    
    logging::Logger::getInstance().info("MetricsService shut down");
}

// ScopedTimer implementation

ScopedTimer::ScopedTimer(prometheus::Histogram& histogram)
    : histogram_(histogram), start_time_(std::chrono::steady_clock::now()) {
}

ScopedTimer::~ScopedTimer() {
    auto end_time = std::chrono::steady_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::seconds>(end_time - start_time_).count();
    histogram_.Observe(duration);
}

} // namespace metrics
} // namespace core_platform
syntax = "proto3";

package core_platform;

// Service interface for inter-service communication
service MessagingService {
  // Send a message to a service
  rpc SendMessage (MessageRequest) returns (MessageResponse);
  
  // Stream messages (for future use)
  rpc StreamMessages (stream MessageRequest) returns (stream MessageResponse);
}

// Message request structure
message MessageRequest {
  string id = 1;
  string sender = 2;
  string target = 3;
  string type = 4;
  string payload = 5;  // JSON-encoded payload
  int64 timestamp = 6;
}

// Message response structure
message MessageResponse {
  string id = 1;
  string sender = 2;
  string target = 3;
  string type = 4;
  string payload = 5;  // JSON-encoded payload
  int64 timestamp = 6;
  bool success = 7;
  string error_message = 8;
}

// Authentication service
service AuthService {
  // Authenticate a user
  rpc Authenticate (AuthRequest) returns (AuthResponse);
  
  // Validate a token
  rpc ValidateToken (TokenValidationRequest) returns (TokenValidationResponse);
  
  // Refresh a token
  rpc RefreshToken (TokenRefreshRequest) returns (AuthResponse);
}

// Authentication request
message AuthRequest {
  string username = 1;
  string password = 2;
  string certificate = 3;  // Optional certificate in PEM format
}

// Authentication response
message AuthResponse {
  bool success = 1;
  string token = 2;
  string refresh_token = 3;
  int64 expiry = 4;
  string user_id = 5;
  repeated string roles = 6;
  string error_message = 7;
}

// Token validation request
message TokenValidationRequest {
  string token = 1;
}

// Token validation response
message TokenValidationResponse {
  bool valid = 1;
  string user_id = 2;
  repeated string roles = 3;
  string error_message = 4;
}

// Token refresh request
message TokenRefreshRequest {
  string refresh_token = 1;
}

// Health check service
service HealthService {
  // Check the health of a service
  rpc Check (HealthCheckRequest) returns (HealthCheckResponse);
}

// Health check request
message HealthCheckRequest {
  string service = 1;
}

// Health check response with service status
message HealthCheckResponse {
  enum Status {
    UNKNOWN = 0;
    SERVING = 1;
    NOT_SERVING = 2;
    SERVICE_UNKNOWN = 3;
  }
  Status status = 1;
}

// Configuration service
service ConfigService {
  // Get a configuration value
  rpc GetConfig (ConfigRequest) returns (ConfigResponse);
  
  // Set a configuration value
  rpc SetConfig (ConfigUpdateRequest) returns (ConfigResponse);
}

// Configuration request
message ConfigRequest {
  string key = 1;
}

// Configuration response
message ConfigResponse {
  bool success = 1;
  string value = 2;  // JSON-encoded value
  string error_message = 3;
}

// Configuration update request
message ConfigUpdateRequest {
  string key = 1;
  string value = 2;  // JSON-encoded value
}

// Metrics service
service MetricsService {
  // Report metrics
  rpc ReportMetrics (MetricsReport) returns (MetricsResponse);
  
  // Stream metrics (for continuous reporting)
  rpc StreamMetrics (stream MetricsReport) returns (MetricsResponse);
}

// Metrics report
message MetricsReport {
  string service = 1;
  string instance = 2;
  repeated Metric metrics = 3;
  int64 timestamp = 4;
}

// Individual metric
message Metric {
  string name = 1;
  double value = 2;
  enum Type {
    COUNTER = 0;
    GAUGE = 1;
    HISTOGRAM = 2;
    SUMMARY = 3;
  }
  Type type = 3;
  map<string, string> labels = 4;
}

// Metrics response
message MetricsResponse {
  bool success = 1;
  string error_message = 2;
}
cmake_minimum_required(VERSION 3.20)

# Find GTest
find_package(GTest REQUIRED)
include_directories(${GTEST_INCLUDE_DIRS})

# Auth service tests
add_executable(auth_service_test auth_service_test.cpp)
target_link_libraries(auth_service_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    GTest::gmock
    core_platform_lib
    pthread
)

# Config service tests
add_executable(config_service_test config_service_test.cpp)
target_link_libraries(config_service_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    GTest::gmock
    core_platform_lib
    pthread
)

# Messaging service tests
add_executable(messaging_service_test messaging_service_test.cpp)
target_link_libraries(messaging_service_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    GTest::gmock
    core_platform_lib
    pthread
)

# API tests
add_executable(api_test api_test.cpp)
target_link_libraries(api_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    GTest::gmock
    core_platform_lib
    pthread
)

# Register tests
include(GoogleTest)
gtest_discover_tests(auth_service_test)
gtest_discover_tests(config_service_test)
gtest_discover_tests(messaging_service_test)
gtest_discover_tests(api_test)

# Add test for main
add_test(NAME main_test COMMAND ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/core-platform-service --test-mode)
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <optional>
#include <functional>
#include <unordered_map>
#include <chrono>
#include <nlohmann/json.hpp>

namespace data_acquisition {
namespace connectors {

/**
 * @brief Device types
 */
enum class DeviceType {
    UNKNOWN,
    EYE_TRACKER,
    HEART_RATE_MONITOR,
    EEG,
    SIMULATOR,
    CAMERA
};

/**
 * @brief Data types
 */
enum class DataType {
    UNKNOWN,
    GAZE,
    PUPIL,
    HEART_RATE,
    EEG_SIGNAL,
    SIMULATOR_POSITION,
    SIMULATOR_CONTROL,
    SIMULATOR_INSTRUMENT,
    VIDEO_FRAME
};

/**
 * @brief Convert DeviceType to string
 * @param type Device type
 * @return String representation
 */
std::string deviceTypeToString(DeviceType type);

/**
 * @brief Convert string to DeviceType
 * @param str String representation
 * @return Device type
 */
DeviceType deviceTypeFromString(const std::string& str);

/**
 * @brief Convert DataType to string
 * @param type Data type
 * @return String representation
 */
std::string dataTypeToString(DataType type);

/**
 * @brief Convert string to DataType
 * @param str String representation
 * @return Data type
 */
DataType dataTypeFromString(const std::string& str);

/**
 * @brief Device capabilities
 */
struct DeviceCapabilities {
    std::vector<DataType> supported_data_types;
    std::unordered_map<std::string, std::string> parameters;
    int max_sample_rate_hz;
    bool supports_streaming;
    bool supports_recording;
};

/**
 * @brief Device information
 */
struct DeviceInfo {
    std::string device_id;
    DeviceType device_type;
    std::string model;
    std::string serial_number;
    std::string firmware_version;
    DeviceCapabilities capabilities;
    bool is_connected;
    std::string connection_info;
};

/**
 * @brief Device configuration
 */
struct DeviceConfig {
    std::string device_id;
    std::vector<DataType> data_types;
    int sample_rate_hz;
    std::unordered_map<std::string, std::string> parameters;
};

/**
 * @brief Base class for device data
 */
struct DeviceData {
    std::string device_id;
    DataType data_type;
    std::chrono::microseconds timestamp;
    
    virtual ~DeviceData() = default;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    virtual nlohmann::json toJson() const = 0;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Device data or nullopt if invalid
     */
    static std::optional<std::unique_ptr<DeviceData>> fromJson(const nlohmann::json& json);
};

/**
 * @brief Gaze data (eye tracking)
 */
struct GazeData : public DeviceData {
    double x;  // X position in normalized coordinates (0-1)
    double y;  // Y position in normalized coordinates (0-1)
    double z;  // Distance from screen in mm
    double confidence;  // Confidence level (0-1)
    
    nlohmann::json toJson() const override;
};

/**
 * @brief Pupil data (eye tracking)
 */
struct PupilData : public DeviceData {
    double left_diameter;  // Left pupil diameter in mm
    double right_diameter;  // Right pupil diameter in mm
    double left_confidence;  // Confidence level (0-1)
    double right_confidence;  // Confidence level (0-1)
    
    nlohmann::json toJson() const override;
};

/**
 * @brief Heart rate data
 */
struct HeartRateData : public DeviceData {
    double bpm;  // Beats per minute
    double confidence;  // Confidence level (0-1)
    
    nlohmann::json toJson() const override;
};

/**
 * @brief EEG data
 */
struct EegData : public DeviceData {
    std::vector<double> channels;  // Raw EEG channel values
    std::vector<std::string> channel_names;  // Channel names
    double sampling_rate;  // Sampling rate in Hz
    
    nlohmann::json toJson() const override;
};

/**
 * @brief Simulator position data
 */
struct SimulatorPositionData : public DeviceData {
    double latitude;
    double longitude;
    double altitude;
    double heading;
    double pitch;
    double roll;
    double ground_speed;
    
    nlohmann::json toJson() const override;
};

/**
 * @brief Simulator control data
 */
struct SimulatorControlData : public DeviceData {
    double aileron;  // -1 to 1
    double elevator;  // -1 to 1
    double rudder;  // -1 to 1
    double throttle;  // 0 to 1
    std::vector<double> engine_controls;  // Multiple engine controls
    
    nlohmann::json toJson() const override;
};

/**
 * @brief Simulator instrument data
 */
struct SimulatorInstrumentData : public DeviceData {
    std::unordered_map<std::string, double> instrument_values;  // Name-value pairs for instruments
    
    nlohmann::json toJson() const override;
};

/**
 * @brief Video frame data
 */
struct VideoFrameData : public DeviceData {
    std::vector<uint8_t> frame_data;  // Compressed image data
    std::string format;  // Format (e.g., "jpeg", "h264")
    int width;
    int height;
    
    nlohmann::json toJson() const override;
};

/**
 * @brief Data callback type
 */
using DataCallback = std::function<void(std::unique_ptr<DeviceData>)>;

/**
 * @brief Status callback type
 */
using StatusCallback = std::function<void(const std::string& device_id, const std::string& status, const std::string& message)>;

/**
 * @brief Device connector interface
 */
class IDeviceConnector {
public:
    virtual ~IDeviceConnector() = default;
    
    /**
     * @brief Get device type
     * @return Device type
     */
    virtual DeviceType getDeviceType() const = 0;
    
    /**
     * @brief Get connector name
     * @return Connector name
     */
    virtual std::string getName() const = 0;
    
    /**
     * @brief Initialize the connector
     * @param config Configuration parameters
     * @return True if initialized successfully
     */
    virtual bool initialize(const std::unordered_map<std::string, std::string>& config) = 0;
    
    /**
     * @brief Shutdown the connector
     */
    virtual void shutdown() = 0;
    
    /**
     * @brief Discover available devices
     * @return List of discovered devices
     */
    virtual std::vector<DeviceInfo> discoverDevices() = 0;
    
    /**
     * @brief Connect to a device
     * @param device_id Device ID
     * @param config Device configuration
     * @return True if connected successfully
     */
    virtual bool connectDevice(const std::string& device_id, const DeviceConfig& config) = 0;
    
    /**
     * @brief Disconnect from a device
     * @param device_id Device ID
     * @return True if disconnected successfully
     */
    virtual bool disconnectDevice(const std::string& device_id) = 0;
    
    /**
     * @brief Start data streaming
     * @param device_id Device ID
     * @param callback Data callback
     * @return True if streaming started successfully
     */
    virtual bool startStreaming(const std::string& device_id, DataCallback callback) = 0;
    
    /**
     * @brief Stop data streaming
     * @param device_id Device ID
     * @return True if streaming stopped successfully
     */
    virtual bool stopStreaming(const std::string& device_id) = 0;
    
    /**
     * @brief Start data recording
     * @param device_id Device ID
     * @param session_id Session ID
     * @param output_dir Output directory
     * @return True if recording started successfully
     */
    virtual bool startRecording(const std::string& device_id, const std::string& session_id, const std::string& output_dir) = 0;
    
    /**
     * @brief Stop data recording
     * @param device_id Device ID
     * @param session_id Session ID
     * @return Path to recorded data or empty string if failed
     */
    virtual std::string stopRecording(const std::string& device_id, const std::string& session_id) = 0;
    
    /**
     * @brief Get device status
     * @param device_id Device ID
     * @return Status message
     */
    virtual std::string getDeviceStatus(const std::string& device_id) = 0;
    
    /**
     * @brief Set status callback
     * @param callback Status callback
     */
    virtual void setStatusCallback(StatusCallback callback) = 0;
    
    /**
     * @brief Get device capabilities
     * @param device_id Device ID
     * @return Device capabilities
     */
    virtual DeviceCapabilities getDeviceCapabilities(const std::string& device_id) = 0;
    
    /**
     * @brief Configure device
     * @param device_id Device ID
     * @param config Configuration parameters
     * @return True if configured successfully
     */
    virtual bool configureDevice(const std::string& device_id, const std::unordered_map<std::string, std::string>& config) = 0;
    
    /**
     * @brief Get device information
     * @param device_id Device ID
     * @return Device information
     */
    virtual DeviceInfo getDeviceInfo(const std::string& device_id) = 0;
};

/**
 * @brief Factory for creating device connectors
 */
class DeviceConnectorFactory {
public:
    /**
     * @brief Get the singleton instance
     * @return Factory instance
     */
    static DeviceConnectorFactory& getInstance();
    
    /**
     * @brief Register a connector type
     * @tparam T Connector type
     * @param type Device type
     * @param name Connector name
     */
    template<typename T>
    void registerConnector(DeviceType type, const std::string& name) {
        creators_[std::make_pair(type, name)] = []() { return std::make_unique<T>(); };
    }
    
    /**
     * @brief Create a connector
     * @param type Device type
     * @param name Connector name
     * @return Connector instance or nullptr if not found
     */
    std::unique_ptr<IDeviceConnector> createConnector(DeviceType type, const std::string& name) const;
    
    /**
     * @brief Get all registered connector types
     * @return List of (device type, connector name) pairs
     */
    std::vector<std::pair<DeviceType, std::string>> getRegisteredConnectors() const;
    
private:
    DeviceConnectorFactory() = default;
    ~DeviceConnectorFactory() = default;
    
    DeviceConnectorFactory(const DeviceConnectorFactory&) = delete;
    DeviceConnectorFactory& operator=(const DeviceConnectorFactory&) = delete;
    
    using CreatorFunc = std::function<std::unique_ptr<IDeviceConnector>()>;
    std::unordered_map<std::pair<DeviceType, std::string>, CreatorFunc, 
                      decltype([](const std::pair<DeviceType, std::string>& p) {
                          return std::hash<int>{}(static_cast<int>(p.first)) ^ 
                                 std::hash<std::string>{}(p.second);
                      })> creators_;
};

} // namespace connectors
} // namespace data_acquisition
# Stage 1: Build environment
FROM ubuntu:22.04 AS builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    libssl-dev \
    pkg-config \
    curl \
    unzip \
    libeigen3-dev \
    libboost-all-dev \
    && rm -rf /var/lib/apt/lists/*

# Install vcpkg for dependency management
WORKDIR /opt
RUN git clone https://github.com/Microsoft/vcpkg.git && \
    ./vcpkg/bootstrap-vcpkg.sh -disableMetrics && \
    ./vcpkg/vcpkg integrate install

# Install dependencies with vcpkg
RUN ./vcpkg/vcpkg install \
    grpc \
    protobuf \
    openssl \
    nlohmann-json \
    spdlog \
    prometheus-cpp \
    eigen3 \
    boost-system \
    boost-filesystem

# Copy source code
WORKDIR /app
COPY . .

# Create build directory
RUN mkdir -p build

# Configure and build
WORKDIR /app/build
RUN cmake .. \
    -DCMAKE_TOOLCHAIN_FILE=/opt/vcpkg/scripts/buildsystems/vcpkg.cmake \
    -DCMAKE_BUILD_TYPE=Release && \
    cmake --build . --config Release -j$(nproc)

# Stage 2: Runtime environment
FROM ubuntu:22.04

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    libssl3 \
    ca-certificates \
    libeigen3-dev \
    libboost-system1.74.0 \
    libboost-filesystem1.74.0 \
    && rm -rf /var/lib/apt/lists/*

# Create app directories
RUN mkdir -p /app/bin /app/config /app/data

# Copy build artifacts
COPY --from=builder /app/build/bin/data-acquisition-service /app/bin/
COPY --from=builder /app/config/*.json /app/config/

# Set working directory
WORKDIR /app

# Set environment variables
ENV DAS_SERVER_HOST=0.0.0.0
ENV DAS_SERVER_PORT=50052
ENV DAS_DATA_DIR=/app/data

# Create non-root user
RUN useradd -m -s /bin/bash appuser && \
    chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Expose ports
EXPOSE 50052

# Define health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD nc -z localhost 50052 || exit 1

# Start the service
CMD ["/app/bin/data-acquisition-service"]
#pragma once

#include "connectors/device_connector.h"
#include <Eigen/Dense>
#include <deque>
#include <mutex>

namespace data_acquisition {
namespace fusion {

/**
 * @brief Data fusion algorithm types
 */
enum class FusionAlgorithm {
    KALMAN_FILTER,
    EXTENDED_KALMAN_FILTER,
    UNSCENTED_KALMAN_FILTER,
    PARTICLE_FILTER,
    MOVING_AVERAGE
};

/**
 * @brief Convert FusionAlgorithm to string
 * @param algorithm Fusion algorithm
 * @return String representation
 */
std::string fusionAlgorithmToString(FusionAlgorithm algorithm);

/**
 * @brief Convert string to FusionAlgorithm
 * @param str String representation
 * @return Fusion algorithm
 */
FusionAlgorithm fusionAlgorithmFromString(const std::string& str);

/**
 * @brief Data fusion configuration
 */
struct FusionConfig {
    FusionAlgorithm algorithm;
    std::vector<std::string> input_device_ids;
    std::vector<connectors::DataType> input_data_types;
    double sample_rate_hz;
    int buffer_size;
    std::unordered_map<std::string, double> weights;
    std::unordered_map<std::string, std::string> parameters;
};

/**
 * @brief Fused data output
 */
struct FusedData {
    std::string fusion_id;
    std::chrono::microseconds timestamp;
    std::vector<std::string> source_devices;
    std::vector<connectors::DataType> source_data_types;
    std::unordered_map<std::string, double> fused_values;
    double confidence;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Fused data or nullopt if invalid
     */
    static std::optional<FusedData> fromJson(const nlohmann::json& json);
};

/**
 * @brief Data fusion result callback
 */
using FusionCallback = std::function<void(const FusedData&)>;

/**
 * @brief Base class for data fusion algorithms
 */
class IFusionAlgorithm {
public:
    virtual ~IFusionAlgorithm() = default;
    
    /**
     * @brief Initialize the algorithm
     * @param config Fusion configuration
     * @return True if initialized successfully
     */
    virtual bool initialize(const FusionConfig& config) = 0;
    
    /**
     * @brief Process a new data point
     * @param data Input data
     * @return True if processed successfully
     */
    virtual bool processData(const std::unique_ptr<connectors::DeviceData>& data) = 0;
    
    /**
     * @brief Get the latest fused data
     * @return Fused data
     */
    virtual FusedData getFusedData() const = 0;
    
    /**
     * @brief Reset the algorithm state
     */
    virtual void reset() = 0;
    
    /**
     * @brief Get the algorithm type
     * @return Algorithm type
     */
    virtual FusionAlgorithm getAlgorithmType() const = 0;
};

/**
 * @brief Kalman filter implementation for data fusion
 */
class KalmanFilterFusion : public IFusionAlgorithm {
public:
    KalmanFilterFusion();
    ~KalmanFilterFusion() override;
    
    bool initialize(const FusionConfig& config) override;
    bool processData(const std::unique_ptr<connectors::DeviceData>& data) override;
    FusedData getFusedData() const override;
    void reset() override;
    FusionAlgorithm getAlgorithmType() const override;
    
private:
    /**
     * @brief Initialize state and covariance matrices
     */
    void initializeMatrices();
    
    /**
     * @brief Predict step of the Kalman filter
     */
    void predict();
    
    /**
     * @brief Update step of the Kalman filter
     * @param data Input data
     */
    void update(const std::unique_ptr<connectors::DeviceData>& data);
    
    /**
     * @brief Convert device data to measurement vector
     * @param data Input data
     * @return Measurement vector
     */
    Eigen::VectorXd dataToMeasurement(const std::unique_ptr<connectors::DeviceData>& data);
    
    /**
     * @brief Get measurement matrix for data type
     * @param data_type Data type
     * @return Measurement matrix
     */
    Eigen::MatrixXd getMeasurementMatrix(connectors::DataType data_type);
    
    /**
     * @brief Get process noise for data type
     * @param data_type Data type
     * @return Process noise covariance
     */
    Eigen::MatrixXd getProcessNoise(connectors::DataType data_type);
    
    /**
     * @brief Get measurement noise for data type
     * @param data_type Data type
     * @return Measurement noise covariance
     */
    Eigen::MatrixXd getMeasurementNoise(connectors::DataType data_type);
    
    FusionConfig config_;
    bool initialized_;
    
    // Kalman filter state
    Eigen::VectorXd state_;
    Eigen::MatrixXd covariance_;
    Eigen::MatrixXd transition_matrix_;
    Eigen::MatrixXd process_noise_;
    
    // Output state
    FusedData fused_data_;
    mutable std::mutex mutex_;
    
    // State history for confidence calculation
    std::deque<Eigen::VectorXd> state_history_;
    
    // Mapping from data types to state indices
    std::unordered_map<connectors::DataType, int, std::hash<int>> data_type_indices_;
    
    // Last update timestamp for each data type
    std::unordered_map<connectors::DataType, std::chrono::microseconds, std::hash<int>> last_update_times_;
};

/**
 * @brief Data fusion manager
 */
class DataFusionManager {
public:
    /**
     * @brief Get the singleton instance
     * @return Manager instance
     */
    static DataFusionManager& getInstance();
    
    /**
     * @brief Initialize the manager
     * @return True if initialized successfully
     */
    bool initialize();
    
    /**
     * @brief Shutdown the manager
     */
    void shutdown();
    
    /**
     * @brief Create a new fusion pipeline
     * @param config Fusion configuration
     * @return Fusion ID or empty string if creation failed
     */
    std::string createFusion(const FusionConfig& config);
    
    /**
     * @brief Remove a fusion pipeline
     * @param fusion_id Fusion ID
     * @return True if removed successfully
     */
    bool removeFusion(const std::string& fusion_id);
    
    /**
     * @brief Get fusion configuration
     * @param fusion_id Fusion ID
     * @return Fusion configuration or nullopt if not found
     */
    std::optional<FusionConfig> getFusionConfig(const std::string& fusion_id) const;
    
    /**
     * @brief Set fusion callback
     * @param fusion_id Fusion ID
     * @param callback Fusion callback
     * @return True if set successfully
     */
    bool setFusionCallback(const std::string& fusion_id, FusionCallback callback);
    
    /**
     * @brief Process data for fusion
     * @param data Input data
     */
    void processData(const std::unique_ptr<connectors::DeviceData>& data);
    
    /**
     * @brief Get all fusion pipelines
     * @return List of fusion IDs
     */
    std::vector<std::string> getFusionIds() const;
    
    /**
     * @brief Get the latest fused data
     * @param fusion_id Fusion ID
     * @return Fused data or nullopt if not found
     */
    std::optional<FusedData> getLatestFusedData(const std::string& fusion_id) const;
    
private:
    DataFusionManager();
    ~DataFusionManager();
    
    DataFusionManager(const DataFusionManager&) = delete;
    DataFusionManager& operator=(const DataFusionManager&) = delete;
    
    /**
     * @brief Create a fusion algorithm
     * @param algorithm Algorithm type
     * @return Algorithm instance
     */
    std::unique_ptr<IFusionAlgorithm> createAlgorithm(FusionAlgorithm algorithm);
    
    /**
     * @brief Information about a fusion pipeline
     */
    struct FusionInfo {
        FusionConfig config;
        std::unique_ptr<IFusionAlgorithm> algorithm;
        FusionCallback callback;
        FusedData latest_data;
    };
    
    bool initialized_;
    std::unordered_map<std::string, std::unique_ptr<FusionInfo>> fusions_;
    mutable std::mutex mutex_;
};

} // namespace fusion
} // namespace data_acquisition
#include <iostream>
#include <csignal>
#include <thread>
#include <chrono>
#include <grpcpp/server.h>
#include <grpcpp/server_builder.h>
#include <grpcpp/security/server_credentials.h>
#include <nlohmann/json.hpp>

#include "connectors/device_connector.h"
#include "connectors/tobii_connector.h"
#include "fusion/data_fusion.h"
#include "persistence/data_persistence.h"
#include "services/data_acquisition_service.h"

// Include generated protobuf headers
#include "data_acquisition.grpc.pb.h"

using namespace data_acquisition;

// Global flag for graceful shutdown
std::atomic<bool> running{true};

// Signal handler
void signalHandler(int signal) {
    std::cout << "Received signal " << signal << ", shutting down..." << std::endl;
    running = false;
}

class DataAcquisitionServiceImpl final : public data_acquisition::DataAcquisitionService::Service {
public:
    DataAcquisitionServiceImpl() {
        // Register device connectors
        auto& factory = connectors::DeviceConnectorFactory::getInstance();
        factory.registerConnector<connectors::TobiiEyeTrackerConnector>(
            connectors::DeviceType::EYE_TRACKER, "Tobii");
            
        // More connectors would be registered here
    }
    
    grpc::Status StreamData(
        grpc::ServerContext* context,
        const StreamDataRequest* request,
        grpc::ServerWriter<DataPoint>* writer
    ) override {
        std::cout << "Received StreamData request for session " << request->session_id() << std::endl;
        
        // Implement the streaming logic here
        // For each device in the request, start streaming data
        
        // Example implementation with a simple loop
        while (!context->IsCancelled() && running) {
            // Create a sample data point
            DataPoint data_point;
            data_point.set_device_id("sample_device");
            data_point.set_data_type(DataType::GAZE);
            data_point.set_timestamp(
                std::chrono::duration_cast<std::chrono::microseconds>(
                    std::chrono::system_clock::now().time_since_epoch()
                ).count()
            );
            
            // Set gaze data
            auto* gaze = new GazeData();
            gaze->set_x(0.5 + (rand() % 100 - 50) / 1000.0);
            gaze->set_y(0.5 + (rand() % 100 - 50) / 1000.0);
            gaze->set_z(600.0 + (rand() % 100 - 50));
            gaze->set_confidence(0.95);
            data_point.set_allocated_gaze(gaze);
            
            // Write data point
            writer->Write(data_point);
            
            // Sleep for a short time
            std::this_thread::sleep_for(std::chrono::milliseconds(16));  // ~60Hz
        }
        
        return grpc::Status::OK;
    }
    
    grpc::Status GetHistoricalData(
        grpc::ServerContext* context,
        const HistoricalDataRequest* request,
        DataSeries* response
    ) override {
        std::cout << "Received GetHistoricalData request for session " << request->session_id() << std::endl;
        
        // Set response session ID
        response->set_session_id(request->session_id());
        
        // Query historical data from persistence
        persistence::SessionDataQuery query;
        query.session_id = request->session_id();
        
        if (!request->device_types().empty()) {
            // Convert protobuf device types to our internal types
            // For simplicity, we'll use the first one
            auto device_type = request->device_types(0);
            // In a real implementation, we would map these properly
        }
        
        if (!request->data_types().empty()) {
            // Convert protobuf data types to our internal types
            // For simplicity, we'll use the first one
            auto data_type = request->data_types(0);
            // In a real implementation, we would map these properly
        }
        
        query.start_time = std::chrono::system_clock::time_point(
            std::chrono::microseconds(request->start_time())
        );
        
        query.end_time = std::chrono::system_clock::time_point(
            std::chrono::microseconds(request->end_time())
        );
        
        query.limit = request->max_points() > 0 ? 
            std::optional<int>(request->max_points()) : std::nullopt;
        
        // Query data from persistence manager
        auto& persistence_manager = persistence::DataPersistenceManager::getInstance();
        auto result = persistence_manager.querySessionData(query);
        
        // Convert internal data to protobuf data points
        for (const auto& device_data : result.device_data) {
            DataPoint* data_point = response->add_data_points();
            
            // Set common fields
            data_point->set_device_id(device_data->device_id);
            data_point->set_data_type(static_cast<data_acquisition::DataType>(
                static_cast<int>(device_data->data_type)
            ));
            data_point->set_timestamp(
                std::chrono::duration_cast<std::chrono::microseconds>(
                    device_data->timestamp.time_since_epoch()
                ).count()
            );
            
            // Set specific data fields based on type
            switch (device_data->data_type) {
                case connectors::DataType::GAZE: {
                    const auto* gaze_data = dynamic_cast<const connectors::GazeData*>(device_data.get());
                    if (gaze_data) {
                        auto* gaze = new data_acquisition::GazeData();
                        gaze->set_x(gaze_data->x);
                        gaze->set_y(gaze_data->y);
                        gaze->set_z(gaze_data->z);
                        gaze->set_confidence(gaze_data->confidence);
                        data_point->set_allocated_gaze(gaze);
                    }
                    break;
                }
                case connectors::DataType::PUPIL: {
                    const auto* pupil_data = dynamic_cast<const connectors::PupilData*>(device_data.get());
                    if (pupil_data) {
                        auto* pupil = new data_acquisition::PupilData();
                        pupil->set_left_diameter(pupil_data->left_diameter);
                        pupil->set_right_diameter(pupil_data->right_diameter);
                        pupil->set_left_confidence(pupil_data->left_confidence);
                        pupil->set_right_confidence(pupil_data->right_confidence);
                        data_point->set_allocated_pupil(pupil);
                    }
                    break;
                }
                // More data types would be handled here
                default:
                    // Unsupported data type
                    break;
            }
        }
        
        return grpc::Status::OK;
    }
    
    grpc::Status StartRecording(
        grpc::ServerContext* context,
        const RecordingRequest* request,
        RecordingResponse* response
    ) override {
        std::cout << "Received StartRecording request for session " << request->session_id() << std::endl;
        
        // Create session metadata
        persistence::SessionMetadata metadata;
        metadata.session_id = request->session_id();
        metadata.user_id = request->user_id();
        metadata.exercise_id = request->exercise_id();
        metadata.start_time = std::chrono::system_clock::now();
        
        // Add device IDs
        for (const auto& device : request->devices()) {
            metadata.device_ids.push_back(device.device_id());
        }
        
        // Add additional metadata
        for (const auto& [key, value] : request->metadata()) {
            metadata.additional_metadata[key] = value;
        }
        
        // Start recording
        auto& persistence_manager = persistence::DataPersistenceManager::getInstance();
        bool success = persistence_manager.createSession(metadata);
        
        // Set response
        response->set_success(success);
        response->set_session_id(request->session_id());
        
        if (!success) {
            response->set_error_message("Failed to create session");
        }
        
        return grpc::Status::OK;
    }
    
    grpc::Status StopRecording(
        grpc::ServerContext* context,
        const StopRecordingRequest* request,
        RecordingResponse* response
    ) override {
        std::cout << "Received StopRecording request for session " << request->session_id() << std::endl;
        
        // Stop recording
        auto& persistence_manager = persistence::DataPersistenceManager::getInstance();
        bool success = persistence_manager.closeSession(request->session_id());
        
        // Set response
        response->set_success(success);
        response->set_session_id(request->session_id());
        
        if (!success) {
            response->set_error_message("Failed to close session");
        }
        
        return grpc::Status::OK;
    }
    
    grpc::Status GetAvailableDevices(
        grpc::ServerContext* context,
        const DeviceRequest* request,
        DeviceList* response
    ) override {
        std::cout << "Received GetAvailableDevices request" << std::endl;
        
        // Get registered connectors
        auto& factory = connectors::DeviceConnectorFactory::getInstance();
        auto registered_connectors = factory.getRegisteredConnectors();
        
        // For each connector, discover devices
        for (const auto& [device_type, connector_name] : registered_connectors) {
            // Check if this device type is requested
            bool type_requested = request->device_types().empty();
            for (const auto& requested_type : request->device_types()) {
                if (static_cast<connectors::DeviceType>(requested_type) == device_type) {
                    type_requested = true;
                    break;
                }
            }
            
            if (!type_requested) {
                continue;
            }
            
            // Create connector
            auto connector = factory.createConnector(device_type, connector_name);
            if (!connector) {
                continue;
            }
            
            // Initialize connector
            std::unordered_map<std::string, std::string> config;
            if (!connector->initialize(config)) {
                continue;
            }
            
            // Discover devices
            auto devices = connector->discoverDevices();
            
            // Add devices to response
            for (const auto& device_info : devices) {
                auto* device = response->add_devices();
                device->set_device_id(device_info.device_id);
                device->set_device_type(static_cast<data_acquisition::DeviceType>(
                    static_cast<int>(device_info.device_type)
                ));
                device->set_model(device_info.model);
                device->set_serial_number(device_info.serial_number);
                device->set_firmware_version(device_info.firmware_version);
                
                for (const auto& data_type : device_info.capabilities.supported_data_types) {
                    device->add_supported_data_types(static_cast<data_acquisition::DataType>(
                        static_cast<int>(data_type)
                    ));
                }
                
                for (const auto& [key, value] : device_info.capabilities.parameters) {
                    (*device->mutable_capabilities())[key] = value;
                }
                
                device->set_is_connected(device_info.is_connected);
                device->set_connection_info(device_info.connection_info);
            }
            
            // Shutdown connector
            connector->shutdown();
        }
        
        return grpc::Status::OK;
    }
    
    grpc::Status ConfigureDevice(
        grpc::ServerContext* context,
        const DeviceConfig* request,
        DeviceConfigResponse* response
    ) override {
        std::cout << "Received ConfigureDevice request for device " << request->device_id() << std::endl;
        
        // Find connector for device type
        auto& factory = connectors::DeviceConnectorFactory::getInstance();
        auto device_type = static_cast<connectors::DeviceType>(request->device_type());
        
        // In a real implementation, we would need to track which connector is associated with
        // which device ID. For simplicity, we'll just try to find any connector for the device type.
        auto registered_connectors = factory.getRegisteredConnectors();
        
        for (const auto& [registered_type, connector_name] : registered_connectors) {
            if (registered_type == device_type) {
                // Create and initialize connector
                auto connector = factory.createConnector(device_type, connector_name);
                if (!connector || !connector->initialize({})) {
                    continue;
                }
                
                // Convert request parameters
                std::unordered_map<std::string, std::string> config;
                for (const auto& [key, value] : request->parameters()) {
                    config[key] = value;
                }
                
                // Configure device
                bool success = connector->configureDevice(request->device_id(), config);
                
                // Set response
                response->set_success(success);
                response->set_device_id(request->device_id());
                
                if (!success) {
                    response->set_error_message("Failed to configure device");
                }
                
                // Shutdown connector
                connector->shutdown();
                
                return grpc::Status::OK;
            }
        }
        
        // No suitable connector found
        response->set_success(false);
        response->set_device_id(request->device_id());
        response->set_error_message("No suitable connector found for device type");
        
        return grpc::Status::OK;
    }
};

int main(int argc, char** argv) {
    // Register signal handlers
    std::signal(SIGINT, signalHandler);
    std::signal(SIGTERM, signalHandler);
    
    std::cout << "Starting Data Acquisition Service..." << std::endl;
    
    // Parse configuration
    // In a real implementation, we would load this from a config file
    nlohmann::json config = {
        {"server", {
            {"host", "0.0.0.0"},
            {"port", 50052}
        }},
        {"persistence", {
            {"type", "file"},
            {"format", "json"},
            {"path", "data"},
            {"compression", false},
            {"flush_interval_ms", 1000}
        }}
    };
    
    std::string server_address = 
        config["server"]["host"].get<std::string>() + ":" + 
        std::to_string(config["server"]["port"].get<int>());
    
    // Initialize persistence
    persistence::StorageOptions storage_options;
    storage_options.format = persistence::StorageFormat::JSON;
    storage_options.compress = config["persistence"]["compression"].get<bool>();
    storage_options.include_metadata = true;
    storage_options.flush_interval_ms = config["persistence"]["flush_interval_ms"].get<int>();
    
    auto& persistence_manager = persistence::DataPersistenceManager::getInstance();
    if (!persistence_manager.initialize(
            config["persistence"]["type"].get<std::string>(),
            storage_options
        )) {
        std::cerr << "Failed to initialize persistence manager" << std::endl;
        return 1;
    }
    
    // Initialize fusion
    auto& fusion_manager = fusion::DataFusionManager::getInstance();
    if (!fusion_manager.initialize()) {
        std::cerr << "Failed to initialize fusion manager" << std::endl;
        return 1;
    }
    
    // Create and start gRPC server
    DataAcquisitionServiceImpl service;
    
    grpc::ServerBuilder builder;
    builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());
    builder.RegisterService(&service);
    
    std::unique_ptr<grpc::Server> server(builder.BuildAndStart());
    std::cout << "Server listening on " << server_address << std::endl;
    
    // Keep running until signal
    while (running) {
        std::this_thread::sleep_for(std::chrono::seconds(1));
    }
    
    // Shutdown
    std::cout << "Shutting down server..." << std::endl;
    server->Shutdown();
    server->Wait();
    
    // Shutdown managers
    fusion_manager.shutdown();
    persistence_manager.shutdown();
    
    std::cout << "Server shutdown complete" << std::endl;
    return 0;
}
#pragma once

#include "connectors/device_connector.h"
#include "fusion/data_fusion.h"
#include <string>
#include <vector>
#include <memory>
#include <optional>
#include <chrono>
#include <mutex>
#include <thread>
#include <atomic>
#include <queue>
#include <condition_variable>
#include <filesystem>

namespace data_acquisition {
namespace persistence {

/**
 * @brief Storage format enum
 */
enum class StorageFormat {
    CSV,
    JSON,
    BINARY,
    PARQUET,
    SQL
};

/**
 * @brief Convert StorageFormat to string
 * @param format Storage format
 * @return String representation
 */
std::string storageFormatToString(StorageFormat format);

/**
 * @brief Convert string to StorageFormat
 * @param str String representation
 * @return Storage format
 */
StorageFormat storageFormatFromString(const std::string& str);

/**
 * @brief Storage options
 */
struct StorageOptions {
    StorageFormat format;
    bool compress;
    bool include_metadata;
    int flush_interval_ms;
    std::string encryption_key;
    std::unordered_map<std::string, std::string> additional_options;
};

/**
 * @brief Session metadata
 */
struct SessionMetadata {
    std::string session_id;
    std::string user_id;
    std::string exercise_id;
    std::chrono::system_clock::time_point start_time;
    std::chrono::system_clock::time_point end_time;
    std::vector<std::string> device_ids;
    std::unordered_map<std::string, std::string> additional_metadata;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Session metadata or nullopt if invalid
     */
    static std::optional<SessionMetadata> fromJson(const nlohmann::json& json);
};

/**
 * @brief Session data query
 */
struct SessionDataQuery {
    std::string session_id;
    std::optional<std::string> device_id;
    std::optional<connectors::DataType> data_type;
    std::optional<std::chrono::system_clock::time_point> start_time;
    std::optional<std::chrono::system_clock::time_point> end_time;
    std::optional<int> limit;
    std::optional<int> offset;
    std::optional<std::string> filter_expression;
    std::optional<std::string> sort_expression;
};

/**
 * @brief Session data result
 */
struct SessionDataResult {
    std::string session_id;
    std::vector<std::unique_ptr<connectors::DeviceData>> device_data;
    std::vector<fusion::FusedData> fusion_data;
    bool has_more;
    int total_count;
};

/**
 * @brief Data storage interface
 */
class IDataStorage {
public:
    virtual ~IDataStorage() = default;
    
    /**
     * @brief Initialize the storage
     * @param options Storage options
     * @return True if initialized successfully
     */
    virtual bool initialize(const StorageOptions& options) = 0;
    
    /**
     * @brief Shutdown the storage
     */
    virtual void shutdown() = 0;
    
    /**
     * @brief Create a new session
     * @param metadata Session metadata
     * @return True if created successfully
     */
    virtual bool createSession(const SessionMetadata& metadata) = 0;
    
    /**
     * @brief Close a session
     * @param session_id Session ID
     * @param end_time Session end time
     * @return True if closed successfully
     */
    virtual bool closeSession(const std::string& session_id, const std::chrono::system_clock::time_point& end_time) = 0;
    
    /**
     * @brief Store device data
     * @param session_id Session ID
     * @param data Device data
     * @return True if stored successfully
     */
    virtual bool storeDeviceData(const std::string& session_id, const connectors::DeviceData& data) = 0;
    
    /**
     * @brief Store fusion data
     * @param session_id Session ID
     * @param data Fusion data
     * @return True if stored successfully
     */
    virtual bool storeFusionData(const std::string& session_id, const fusion::FusedData& data) = 0;
    
    /**
     * @brief Get session metadata
     * @param session_id Session ID
     * @return Session metadata or nullopt if not found
     */
    virtual std::optional<SessionMetadata> getSessionMetadata(const std::string& session_id) = 0;
    
    /**
     * @brief Update session metadata
     * @param metadata Session metadata
     * @return True if updated successfully
     */
    virtual bool updateSessionMetadata(const SessionMetadata& metadata) = 0;
    
    /**
     * @brief Query session data
     * @param query Session data query
     * @return Session data result
     */
    virtual SessionDataResult querySessionData(const SessionDataQuery& query) = 0;
    
    /**
     * @brief List all sessions
     * @param user_id Optional user ID filter
     * @param exercise_id Optional exercise ID filter
     * @param limit Optional limit
     * @param offset Optional offset
     * @return List of session metadata
     */
    virtual std::vector<SessionMetadata> listSessions(
        const std::optional<std::string>& user_id = std::nullopt,
        const std::optional<std::string>& exercise_id = std::nullopt,
        const std::optional<int>& limit = std::nullopt,
        const std::optional<int>& offset = std::nullopt
    ) = 0;
    
    /**
     * @brief Delete a session
     * @param session_id Session ID
     * @return True if deleted successfully
     */
    virtual bool deleteSession(const std::string& session_id) = 0;
    
    /**
     * @brief Export session data
     * @param session_id Session ID
     * @param format Export format
     * @param output_path Output path
     * @return True if exported successfully
     */
    virtual bool exportSession(
        const std::string& session_id, 
        StorageFormat format, 
        const std::string& output_path
    ) = 0;
    
    /**
     * @brief Import session data
     * @param input_path Input path
     * @param format Import format
     * @return Imported session ID or empty string if import failed
     */
    virtual std::string importSession(
        const std::string& input_path, 
        StorageFormat format
    ) = 0;
    
    /**
     * @brief Get storage statistics
     * @return Statistics as JSON
     */
    virtual nlohmann::json getStatistics() = 0;
};

/**
 * @brief File-based data storage implementation
 */
class FileDataStorage : public IDataStorage {
public:
    FileDataStorage();
    ~FileDataStorage() override;
    
    bool initialize(const StorageOptions& options) override;
    void shutdown() override;
    bool createSession(const SessionMetadata& metadata) override;
    bool closeSession(const std::string& session_id, const std::chrono::system_clock::time_point& end_time) override;
    bool storeDeviceData(const std::string& session_id, const connectors::DeviceData& data) override;
    bool storeFusionData(const std::string& session_id, const fusion::FusedData& data) override;
    std::optional<SessionMetadata> getSessionMetadata(const std::string& session_id) override;
    bool updateSessionMetadata(const SessionMetadata& metadata) override;
    SessionDataResult querySessionData(const SessionDataQuery& query) override;
    std::vector<SessionMetadata> listSessions(
        const std::optional<std::string>& user_id,
        const std::optional<std::string>& exercise_id,
        const std::optional<int>& limit,
        const std::optional<int>& offset
    ) override;
    bool deleteSession(const std::string& session_id) override;
    bool exportSession(
        const std::string& session_id, 
        StorageFormat format, 
        const std::string& output_path
    ) override;
    std::string importSession(
        const std::string& input_path, 
        StorageFormat format
    ) override;
    nlohmann::json getStatistics() override;
    
private:
    /**
     * @brief Session data files
     */
    struct SessionFiles {
        std::filesystem::path metadata_path;
        std::filesystem::path device_data_path;
        std::filesystem::path fusion_data_path;
        std::unique_ptr<std::ofstream> device_data_file;
        std::unique_ptr<std::ofstream> fusion_data_file;
        std::chrono::system_clock::time_point last_flush_time;
    };
    
    /**
     * @brief Get session files
     * @param session_id Session ID
     * @param create_if_missing Create if missing
     * @return Session files or nullptr if not found
     */
    SessionFiles* getSessionFiles(const std::string& session_id, bool create_if_missing = false);
    
    /**
     * @brief Flush session files
     * @param session_id Session ID
     * @param force Force flush even if interval not reached
     * @return True if flushed successfully
     */
    bool flushSessionFiles(const std::string& session_id, bool force = false);
    
    /**
     * @brief Parse device data from JSON
     * @param json JSON representation
     * @return Device data or nullptr if invalid
     */
    std::unique_ptr<connectors::DeviceData> parseDeviceData(const nlohmann::json& json);
    
    /**
     * @brief Write data batch to disk
     */
    void writeBatchToDisk();
    
    /**
     * @brief Worker thread function
     */
    void workerThread();
    
    StorageOptions options_;
    std::filesystem::path base_path_;
    std::unordered_map<std::string, std::unique_ptr<SessionFiles>> session_files_;
    mutable std::mutex sessions_mutex_;
    
    // Worker thread for async writes
    std::thread worker_thread_;
    std::atomic<bool> running_;
    std::queue<std::function<void()>> work_queue_;
    std::mutex queue_mutex_;
    std::condition_variable queue_condition_;
};

/**
 * @brief Database-based data storage implementation
 */
class DatabaseDataStorage : public IDataStorage {
public:
    DatabaseDataStorage();
    ~DatabaseDataStorage() override;
    
    bool initialize(const StorageOptions& options) override;
    void shutdown() override;
    bool createSession(const SessionMetadata& metadata) override;
    bool closeSession(const std::string& session_id, const std::chrono::system_clock::time_point& end_time) override;
    bool storeDeviceData(const std::string& session_id, const connectors::DeviceData& data) override;
    bool storeFusionData(const std::string& session_id, const fusion::FusedData& data) override;
    std::optional<SessionMetadata> getSessionMetadata(const std::string& session_id) override;
    bool updateSessionMetadata(const SessionMetadata& metadata) override;
    SessionDataResult querySessionData(const SessionDataQuery& query) override;
    std::vector<SessionMetadata> listSessions(
        const std::optional<std::string>& user_id,
        const std::optional<std::string>& exercise_id,
        const std::optional<int>& limit,
        const std::optional<int>& offset
    ) override;
    bool deleteSession(const std::string& session_id) override;
    bool exportSession(
        const std::string& session_id, 
        StorageFormat format, 
        const std::string& output_path
    ) override;
    std::string importSession(
        const std::string& input_path, 
        StorageFormat format
    ) override;
    nlohmann::json getStatistics() override;
    
private:
    // Database connection details would go here
    // This would be implemented with a proper SQL library (e.g., SQLite, PostgreSQL)
    // For now, this is just a placeholder
};

/**
 * @brief Data persistence manager
 */
class DataPersistenceManager {
public:
    /**
     * @brief Get the singleton instance
     * @return Manager instance
     */
    static DataPersistenceManager& getInstance();
    
    /**
     * @brief Initialize the manager
     * @param storage_type Storage type ("file" or "database")
     * @param options Storage options
     * @return True if initialized successfully
     */
    bool initialize(const std::string& storage_type, const StorageOptions& options);
    
    /**
     * @brief Shutdown the manager
     */
    void shutdown();
    
    /**
     * @brief Get the storage instance
     * @return Storage instance
     */
    IDataStorage* getStorage();
    
    /**
     * @brief Create a new session
     * @param metadata Session metadata
     * @return True if created successfully
     */
    bool createSession(const SessionMetadata& metadata);
    
    /**
     * @brief Close a session
     * @param session_id Session ID
     * @return True if closed successfully
     */
    bool closeSession(const std::string& session_id);
    
    /**
     * @brief Store device data
     * @param session_id Session ID
     * @param data Device data
     * @return True if stored successfully
     */
    bool storeDeviceData(const std::string& session_id, const connectors::DeviceData& data);
    
    /**
     * @brief Store fusion data
     * @param session_id Session ID
     * @param data Fusion data
     * @return True if stored successfully
     */
    bool storeFusionData(const std::string& session_id, const fusion::FusedData& data);
    
    /**
     * @brief Query session data
     * @param query Session data query
     * @return Session data result
     */
    SessionDataResult querySessionData(const SessionDataQuery& query);
    
private:
    DataPersistenceManager();
    ~DataPersistenceManager();
    
    DataPersistenceManager(const DataPersistenceManager&) = delete;
    DataPersistenceManager& operator=(const DataPersistenceManager&) = delete;
    
    std::unique_ptr<IDataStorage> storage_;
    std::atomic<bool> initialized_{false};
    mutable std::mutex mutex_;
};

} // namespace persistence
} // namespace data_acquisition
cmake_minimum_required(VERSION 3.20)
project(data-acquisition-service VERSION 1.0.0 LANGUAGES CXX)

# Set C++20 standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Set output directories
set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)

# Find required packages
find_package(gRPC REQUIRED)
find_package(Protobuf REQUIRED)
find_package(OpenSSL REQUIRED)
find_package(nlohmann_json 3.10.0 REQUIRED)
find_package(spdlog REQUIRED)
find_package(prometheus-cpp REQUIRED)
find_package(Boost REQUIRED COMPONENTS system filesystem)
find_package(Eigen3 REQUIRED)

# Include directories
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_BINARY_DIR}/generated
    ${EIGEN3_INCLUDE_DIR}
)

# Generate protobuf and gRPC code
set(PROTO_FILES
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/data_acquisition.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/core_service.proto
)

protobuf_generate_cpp(PROTO_SRCS PROTO_HDRS ${PROTO_FILES})
grpc_generate_cpp(GRPC_SRCS GRPC_HDRS ${CMAKE_CURRENT_BINARY_DIR}/generated ${PROTO_FILES})

# Source files
file(GLOB_RECURSE SOURCES 
    ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp
)

# Add executable
add_executable(${PROJECT_NAME} ${SOURCES} ${PROTO_SRCS} ${PROTO_HDRS} ${GRPC_SRCS} ${GRPC_HDRS})

# Link libraries
target_link_libraries(${PROJECT_NAME}
    PRIVATE
    gRPC::grpc++
    gRPC::grpc++_reflection
    protobuf::libprotobuf
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
    spdlog::spdlog
    prometheus-cpp::core
    prometheus-cpp::push
    Boost::system
    Boost::filesystem
    Eigen3::Eigen
)

# Copy configuration files to build directory
configure_file(
    ${CMAKE_CURRENT_SOURCE_DIR}/config/config.json
    ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/config/config.json
    COPYONLY
)

# Add tests
enable_testing()
add_subdirectory(tests)

# Installation
install(TARGETS ${PROJECT_NAME}
    RUNTIME DESTINATION bin
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)

install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/config/
    DESTINATION etc/${PROJECT_NAME}
    FILES_MATCHING PATTERN "*.json"
)

# Documentation
find_package(Doxygen)
if(DOXYGEN_FOUND)
    set(DOXYGEN_IN ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in)
    set(DOXYGEN_OUT ${CMAKE_CURRENT_BINARY_DIR}/Doxyfile)
    
    configure_file(${DOXYGEN_IN} ${DOXYGEN_OUT} @ONLY)
    
    add_custom_target(docs
        COMMAND ${DOXYGEN_EXECUTABLE} ${DOXYGEN_OUT}
        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
        COMMENT "Generating API documentation with Doxygen"
        VERBATIM
    )
endif()
syntax = "proto3";

package data_acquisition;

// Service definition for data acquisition
service DataAcquisitionService {
  // Stream real-time data
  rpc StreamData (StreamDataRequest) returns (stream DataPoint);
  
  // Get historical data
  rpc GetHistoricalData (HistoricalDataRequest) returns (DataSeries);
  
  // Start recording data
  rpc StartRecording (RecordingRequest) returns (RecordingResponse);
  
  // Stop recording data
  rpc StopRecording (StopRecordingRequest) returns (RecordingResponse);
  
  // Get available devices
  rpc GetAvailableDevices (DeviceRequest) returns (DeviceList);
  
  // Configure device
  rpc ConfigureDevice (DeviceConfig) returns (DeviceConfigResponse);
}

// Device types
enum DeviceType {
  UNKNOWN_DEVICE = 0;
  EYE_TRACKER = 1;
  HEART_RATE_MONITOR = 2;
  EEG = 3;
  SIMULATOR = 4;
  CAMERA = 5;
}

// Data types
enum DataType {
  UNKNOWN_DATA = 0;
  GAZE = 1;
  PUPIL = 2;
  HEART_RATE = 3;
  EEG_SIGNAL = 4;
  SIMULATOR_POSITION = 5;
  SIMULATOR_CONTROL = 6;
  SIMULATOR_INSTRUMENT = 7;
  VIDEO_FRAME = 8;
}

// Request to stream data
message StreamDataRequest {
  string session_id = 1;
  repeated DeviceConfig devices = 2;
  int32 sample_rate_hz = 3;
  bool apply_filtering = 4;
}

// Device configuration
message DeviceConfig {
  string device_id = 1;
  DeviceType device_type = 2;
  repeated DataType data_types = 3;
  map<string, string> parameters = 4;
}

// Single data point
message DataPoint {
  string device_id = 1;
  DataType data_type = 2;
  int64 timestamp = 3;  // Microseconds since epoch
  oneof value {
    GazeData gaze = 4;
    PupilData pupil = 5;
    HeartRateData heart_rate = 6;
    EegData eeg = 7;
    SimulatorPositionData sim_position = 8;
    SimulatorControlData sim_control = 9;
    SimulatorInstrumentData sim_instrument = 10;
    VideoFrameData video_frame = 11;
  }
}

// Gaze data (eye tracking)
message GazeData {
  double x = 1;  // X position in normalized coordinates (0-1)
  double y = 2;  // Y position in normalized coordinates (0-1)
  double z = 3;  // Distance from screen in mm
  double confidence = 4;  // Confidence level (0-1)
}

// Pupil data (eye tracking)
message PupilData {
  double left_diameter = 1;  // Left pupil diameter in mm
  double right_diameter = 2;  // Right pupil diameter in mm
  double left_confidence = 3;  // Confidence level (0-1)
  double right_confidence = 4;  // Confidence level (0-1)
}

// Heart rate data
message HeartRateData {
  double bpm = 1;  // Beats per minute
  double confidence = 2;  // Confidence level (0-1)
}

// EEG data
message EegData {
  repeated double channels = 1;  // Raw EEG channel values
  repeated string channel_names = 2;  // Channel names
  double sampling_rate = 3;  // Sampling rate in Hz
}

// Simulator position data
message SimulatorPositionData {
  double latitude = 1;
  double longitude = 2;
  double altitude = 3;
  double heading = 4;
  double pitch = 5;
  double roll = 6;
  double ground_speed = 7;
}

// Simulator control data
message SimulatorControlData {
  double aileron = 1;  // -1 to 1
  double elevator = 2;  // -1 to 1
  double rudder = 3;  // -1 to 1
  double throttle = 4;  // 0 to 1
  repeated double engine_controls = 5;  // Multiple engine controls
}

// Simulator instrument data
message SimulatorInstrumentData {
  map<string, double> instrument_values = 1;  // Name-value pairs for instruments
}

// Video frame data
message VideoFrameData {
  bytes frame_data = 1;  // Compressed image data
  string format = 2;  // Format (e.g., "jpeg", "h264")
  int32 width = 3;
  int32 height = 4;
}

// Historical data request
message HistoricalDataRequest {
  string session_id = 1;
  repeated DeviceType device_types = 2;
  repeated DataType data_types = 3;
  int64 start_time = 4;  // Start time in microseconds since epoch
  int64 end_time = 5;  // End time in microseconds since epoch
  int32 max_points = 6;  // Maximum number of points to return (0 for all)
}

// Data series with multiple points
message DataSeries {
  string session_id = 1;
  repeated DataPoint data_points = 2;
}

// Recording request
message RecordingRequest {
  string session_id = 1;
  string user_id = 2;
  string exercise_id = 3;
  repeated DeviceConfig devices = 4;
  map<string, string> metadata = 5;
}

// Stop recording request
message StopRecordingRequest {
  string session_id = 1;
}

// Recording response
message RecordingResponse {
  bool success = 1;
  string session_id = 2;
  string error_message = 3;
  string recording_path = 4;
}

// Device request
message DeviceRequest {
  repeated DeviceType device_types = 1;
}

// Device list
message DeviceList {
  repeated Device devices = 1;
}

// Device information
message Device {
  string device_id = 1;
  DeviceType device_type = 2;
  string model = 3;
  string serial_number = 4;
  string firmware_version = 5;
  repeated DataType supported_data_types = 6;
  map<string, string> capabilities = 7;
  bool is_connected = 8;
  string connection_info = 9;
}

// Device configuration response
message DeviceConfigResponse {
  bool success = 1;
  string device_id = 2;
  string error_message = 3;
}
#pragma once

#include "connectors/device_connector.h"
#include <mutex>
#include <thread>
#include <atomic>
#include <queue>
#include <condition_variable>
#include <fstream>
#include <filesystem>

namespace data_acquisition {
namespace connectors {

/**
 * @brief Implementation of the Tobii eye tracker connector
 */
class TobiiEyeTrackerConnector : public IDeviceConnector {
public:
    TobiiEyeTrackerConnector();
    ~TobiiEyeTrackerConnector() override;
    
    // IDeviceConnector implementation
    DeviceType getDeviceType() const override;
    std::string getName() const override;
    bool initialize(const std::unordered_map<std::string, std::string>& config) override;
    void shutdown() override;
    std::vector<DeviceInfo> discoverDevices() override;
    bool connectDevice(const std::string& device_id, const DeviceConfig& config) override;
    bool disconnectDevice(const std::string& device_id) override;
    bool startStreaming(const std::string& device_id, DataCallback callback) override;
    bool stopStreaming(const std::string& device_id) override;
    bool startRecording(const std::string& device_id, const std::string& session_id, const std::string& output_dir) override;
    std::string stopRecording(const std::string& device_id, const std::string& session_id) override;
    std::string getDeviceStatus(const std::string& device_id) override;
    void setStatusCallback(StatusCallback callback) override;
    DeviceCapabilities getDeviceCapabilities(const std::string& device_id) override;
    bool configureDevice(const std::string& device_id, const std::unordered_map<std::string, std::string>& config) override;
    DeviceInfo getDeviceInfo(const std::string& device_id) override;
    
private:
    /**
     * @brief Information about a connected device
     */
    struct ConnectedDevice {
        DeviceInfo info;
        DeviceConfig config;
        std::atomic<bool> is_streaming{false};
        std::atomic<bool> is_recording{false};
        std::string session_id;
        std::string output_dir;
        std::unique_ptr<std::ofstream> recording_file;
        DataCallback data_callback;
        std::thread streaming_thread;
    };
    
    /**
     * @brief Initialize the Tobii API
     * @return True if initialized successfully
     */
    bool initializeApi();
    
    /**
     * @brief Shutdown the Tobii API
     */
    void shutdownApi();
    
    /**
     * @brief Get a connected device
     * @param device_id Device ID
     * @return Connected device or nullptr if not found
     */
    ConnectedDevice* getConnectedDevice(const std::string& device_id);
    
    /**
     * @brief Stream data from a device
     * @param device_id Device ID
     */
    void streamData(const std::string& device_id);
    
    /**
     * @brief Generate sample gaze data (for simulation)
     * @param device_id Device ID
     * @return Gaze data
     */
    std::unique_ptr<GazeData> generateGazeData(const std::string& device_id);
    
    /**
     * @brief Generate sample pupil data (for simulation)
     * @param device_id Device ID
     * @return Pupil data
     */
    std::unique_ptr<PupilData> generatePupilData(const std::string& device_id);
    
    /**
     * @brief Write data to recording file
     * @param device Device
     * @param data Data to write
     */
    void writeToRecording(ConnectedDevice& device, const DeviceData& data);
    
    /**
     * @brief Report device status
     * @param device_id Device ID
     * @param status Status message
     * @param message Additional information
     */
    void reportStatus(const std::string& device_id, const std::string& status, const std::string& message);
    
    std::atomic<bool> initialized_{false};
    std::unordered_map<std::string, std::unique_ptr<ConnectedDevice>> connected_devices_;
    mutable std::mutex devices_mutex_;
    StatusCallback status_callback_;
    std::atomic<bool> api_initialized_{false};
    
    // Simulation parameters
    double simulation_noise_level_{0.01};
    std::atomic<bool> simulate_{true};  // Use simulated data if true
    
    // Device discovery cache
    std::vector<DeviceInfo> discovered_devices_;
    std::chrono::steady_clock::time_point last_discovery_time_;
    static constexpr auto discovery_cache_duration = std::chrono::seconds(10);
};

} // namespace connectors
} // namespace data_acquisition
// backend/core/include/DatabaseManager.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <future>
#include <optional>
#include <functional>
#include <tuple>
#include <unordered_map>
#include <variant>
#include <chrono>
#include <mutex>
#include <shared_mutex>

#include "core/include/ErrorHandling.h"

namespace APTP::Core {

// Database value types
using DbValue = std::variant<
    std::nullptr_t,
    int64_t,
    double,
    std::string,
    bool,
    std::vector<uint8_t>,
    std::chrono::system_clock::time_point
>;

// Database row type
using DbRow = std::vector<DbValue>;

// Database result set
struct DbResultSet {
    std::vector<std::string> columnNames;
    std::vector<DbRow> rows;
    
    size_t rowCount() const { return rows.size(); }
    size_t columnCount() const { return columnNames.size(); }
    
    template<typename T>
    std::optional<T> getValue(size_t row, size_t column) const {
        if (row >= rows.size() || column >= columnNames.size()) {
            return std::nullopt;
        }
        
        try {
            return std::get<T>(rows[row][column]);
        } catch (const std::bad_variant_access&) {
            return std::nullopt;
        }
    }
    
    template<typename T>
    std::optional<T> getValue(size_t row, const std::string& columnName) const {
        auto it = std::find(columnNames.begin(), columnNames.end(), columnName);
        if (it == columnNames.end()) {
            return std::nullopt;
        }
        
        size_t column = std::distance(columnNames.begin(), it);
        return getValue<T>(row, column);
    }
};

// Database connection parameters
struct DbConnectionParams {
    std::string host;
    uint16_t port;
    std::string dbName;
    std::string username;
    std::string password;
    std::string connectionString;
    std::chrono::seconds connectionTimeout = std::chrono::seconds(30);
    std::chrono::seconds commandTimeout = std::chrono::seconds(30);
    bool useSsl = false;
    std::string sslMode = "require";
    std::string sslCertPath;
    std::string sslKeyPath;
    std::string sslRootCertPath;
    
    // Helper method to build connection string
    std::string buildConnectionString() const {
        if (!connectionString.empty()) {
            return connectionString;
        }
        
        std::string connStr = "host=" + host + 
                             " port=" + std::to_string(port) + 
                             " dbname=" + dbName + 
                             " user=" + username + 
                             " password=" + password;
        
        if (useSsl) {
            connStr += " sslmode=" + sslMode;
            
            if (!sslCertPath.empty()) {
                connStr += " sslcert=" + sslCertPath;
            }
            
            if (!sslKeyPath.empty()) {
                connStr += " sslkey=" + sslKeyPath;
            }
            
            if (!sslRootCertPath.empty()) {
                connStr += " sslrootcert=" + sslRootCertPath;
            }
        }
        
        return connStr;
    }
};

// Transaction isolation level
enum class TransactionIsolationLevel {
    ReadUncommitted,
    ReadCommitted,
    RepeatableRead,
    Serializable
};

// Forward declarations
class DbConnection;
class DbTransaction;
class DbCommand;
class DbParameter;

// Database connection interface
class DbConnection {
public:
    virtual ~DbConnection() = default;
    
    // Open the connection
    virtual APTP::Core::Result<void> open() = 0;
    
    // Close the connection
    virtual APTP::Core::Result<void> close() = 0;
    
    // Check if connection is open
    virtual bool isOpen() const = 0;
    
    // Begin a transaction
    virtual APTP::Core::Result<std::unique_ptr<DbTransaction>> beginTransaction(
        TransactionIsolationLevel isolationLevel = TransactionIsolationLevel::ReadCommitted) = 0;
    
    // Create a command
    virtual std::unique_ptr<DbCommand> createCommand(const std::string& commandText) = 0;
    
    // Execute a command directly
    virtual APTP::Core::Result<DbResultSet> executeQuery(const std::string& commandText) = 0;
    virtual APTP::Core::Result<int64_t> executeNonQuery(const std::string& commandText) = 0;
    virtual APTP::Core::Result<DbValue> executeScalar(const std::string& commandText) = 0;
    
    // Execute a command asynchronously
    virtual std::future<APTP::Core::Result<DbResultSet>> executeQueryAsync(const std::string& commandText) = 0;
    virtual std::future<APTP::Core::Result<int64_t>> executeNonQueryAsync(const std::string& commandText) = 0;
    virtual std::future<APTP::Core::Result<DbValue>> executeScalarAsync(const std::string& commandText) = 0;
    
    // Get last error
    virtual std::string getLastError() const = 0;
};

// Database transaction interface
class DbTransaction {
public:
    virtual ~DbTransaction() = default;
    
    // Commit the transaction
    virtual APTP::Core::Result<void> commit() = 0;
    
    // Rollback the transaction
    virtual APTP::Core::Result<void> rollback() = 0;
    
    // Check if transaction is active
    virtual bool isActive() const = 0;
};

// Database command interface
class DbCommand {
public:
    virtual ~DbCommand() = default;
    
    // Set command text
    virtual void setCommandText(const std::string& commandText) = 0;
    
    // Set command timeout
    virtual void setCommandTimeout(std::chrono::seconds timeout) = 0;
    
    // Add a parameter
    virtual void addParameter(const std::string& name, const DbValue& value) = 0;
    
    // Clear parameters
    virtual void clearParameters() = 0;
    
    // Execute the command
    virtual APTP::Core::Result<DbResultSet> executeQuery() = 0;
    virtual APTP::Core::Result<int64_t> executeNonQuery() = 0;
    virtual APTP::Core::Result<DbValue> executeScalar() = 0;
    
    // Execute the command asynchronously
    virtual std::future<APTP::Core::Result<DbResultSet>> executeQueryAsync() = 0;
    virtual std::future<APTP::Core::Result<int64_t>> executeNonQueryAsync() = 0;
    virtual std::future<APTP::Core::Result<DbValue>> executeScalarAsync() = 0;
};

// Database migration interface
class DbMigration {
public:
    virtual ~DbMigration() = default;
    
    // Get migration version
    virtual std::string getVersion() const = 0;
    
    // Get migration description
    virtual std::string getDescription() const = 0;
    
    // Get up migration SQL
    virtual std::string getUpMigration() const = 0;
    
    // Get down migration SQL
    virtual std::string getDownMigration() const = 0;
};

// Database connection pool
class DbConnectionPool {
public:
    static DbConnectionPool& getInstance();
    
    // Initialize the connection pool
    APTP::Core::Result<void> initialize(const DbConnectionParams& params, size_t minPoolSize = 5, size_t maxPoolSize = 20);
    
    // Get a connection from the pool
    APTP::Core::Result<std::shared_ptr<DbConnection>> getConnection();
    
    // Return a connection to the pool
    void returnConnection(std::shared_ptr<DbConnection> connection);
    
    // Get pool statistics
    size_t getAvailableConnectionsCount() const;
    size_t getActiveConnectionsCount() const;
    size_t getTotalConnectionsCount() const;

private:
    DbConnectionPool();
    ~DbConnectionPool();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

// Database manager for PostgreSQL
class PostgreSQLManager {
public:
    static PostgreSQLManager& getInstance();
    
    // Initialize the database manager
    APTP::Core::Result<void> initialize(const DbConnectionParams& params);
    
    // Run migrations
    APTP::Core::Result<void> runMigrations(const std::string& migrationsPath);
    APTP::Core::Result<void> runMigrationUp(const DbMigration& migration);
    APTP::Core::Result<void> runMigrationDown(const DbMigration& migration);
    
    // Execute a query
    APTP::Core::Result<DbResultSet> executeQuery(const std::string& sql);
    APTP::Core::Result<int64_t> executeNonQuery(const std::string& sql);
    APTP::Core::Result<DbValue> executeScalar(const std::string& sql);
    
    // Execute a parameterized query
    APTP::Core::Result<DbResultSet> executeQuery(
        const std::string& sql, 
        const std::unordered_map<std::string, DbValue>& parameters);
    
    APTP::Core::Result<int64_t> executeNonQuery(
        const std::string& sql, 
        const std::unordered_map<std::string, DbValue>& parameters);
    
    APTP::Core::Result<DbValue> executeScalar(
        const std::string& sql, 
        const std::unordered_map<std::string, DbValue>& parameters);
    
    // Execute in a transaction
    template<typename Func>
    APTP::Core::Result<std::invoke_result_t<Func, std::shared_ptr<DbConnection>&, std::unique_ptr<DbTransaction>&>> 
    executeInTransaction(Func&& func, TransactionIsolationLevel isolationLevel = TransactionIsolationLevel::ReadCommitted) {
        auto connResult = DbConnectionPool::getInstance().getConnection();
        if (connResult.isError()) {
            return APTP::Core::Error<std::invoke_result_t<Func, std::shared_ptr<DbConnection>&, std::unique_ptr<DbTransaction>&>>(
                APTP::Core::ErrorCode::ResourceUnavailable);
        }
        
        auto conn = connResult.value();
        auto txResult = conn->beginTransaction(isolationLevel);
        if (txResult.isError()) {
            DbConnectionPool::getInstance().returnConnection(conn);
            return APTP::Core::Error<std::invoke_result_t<Func, std::shared_ptr<DbConnection>&, std::unique_ptr<DbTransaction>&>>(
                APTP::Core::ErrorCode::ResourceUnavailable);
        }
        
        auto tx = std::move(txResult.value());
        
        try {
            auto result = func(conn, tx);
            auto commitResult = tx->commit();
            
            if (commitResult.isError()) {
                tx->rollback();
                DbConnectionPool::getInstance().returnConnection(conn);
                return APTP::Core::Error<std::invoke_result_t<Func, std::shared_ptr<DbConnection>&, std::unique_ptr<DbTransaction>&>>(
                    APTP::Core::ErrorCode::ResourceUnavailable);
            }
            
            DbConnectionPool::getInstance().returnConnection(conn);
            return APTP::Core::Success(result);
        } catch (const std::exception& e) {
            tx->rollback();
            DbConnectionPool::getInstance().returnConnection(conn);
            return APTP::Core::Error<std::invoke_result_t<Func, std::shared_ptr<DbConnection>&, std::unique_ptr<DbTransaction>&>>(
                APTP::Core::ErrorCode::ResourceUnavailable);
        }
    }
    
    // Get database schema information
    APTP::Core::Result<std::vector<std::string>> getTables();
    APTP::Core::Result<std::vector<std::string>> getViews();
    APTP::Core::Result<std::vector<std::tuple<std::string, std::string, std::string>>> getColumns(const std::string& table);

private:
    PostgreSQLManager();
    ~PostgreSQLManager();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

// TimescaleDB manager for time-series data
class TimescaleDBManager {
public:
    static TimescaleDBManager& getInstance();
    
    // Initialize the TimescaleDB manager
    APTP::Core::Result<void> initialize(const DbConnectionParams& params);
    
    // Create a hypertable
    APTP::Core::Result<void> createHypertable(
        const std::string& tableName, 
        const std::string& timeColumn,
        const std::string& partitioningColumn = "",
        int64_t chunkTimeInterval = 86400000000); // Default 1 day in microseconds
    
    // Insert time-series data
    template<typename T>
    APTP::Core::Result<int64_t> insertTimeSeriesData(
        const std::string& tableName,
        const std::string& timeColumn,
        const std::chrono::system_clock::time_point& timestamp,
        const std::unordered_map<std::string, T>& values) {
        
        // Construct the SQL query
        std::string columns = timeColumn;
        std::string placeholders = "$1";
        
        int paramIndex = 2;
        for (const auto& [column, _] : values) {
            columns += ", " + column;
            placeholders += ", $" + std::to_string(paramIndex++);
        }
        
        std::string sql = "INSERT INTO " + tableName + " (" + columns + ") VALUES (" + placeholders + ")";
        
        // Prepare parameters
        std::unordered_map<std::string, DbValue> parameters;
        
        // Convert timestamp to database value
        parameters["$1"] = timestamp;
        
        // Add other values
        paramIndex = 2;
        for (const auto& [column, value] : values) {
            parameters["$" + std::to_string(paramIndex++)] = value;
        }
        
        // Execute the query
        return PostgreSQLManager::getInstance().executeNonQuery(sql, parameters);
    }
    
    // Query time-series data with time range
    APTP::Core::Result<DbResultSet> queryTimeSeriesData(
        const std::string& tableName,
        const std::string& timeColumn,
        const std::chrono::system_clock::time_point& startTime,
        const std::chrono::system_clock::time_point& endTime,
        const std::vector<std::string>& selectColumns = {},
        const std::string& orderBy = "",
        size_t limit = 0);
    
    // Aggregate time-series data with time buckets
    APTP::Core::Result<DbResultSet> aggregateTimeSeriesData(
        const std::string& tableName,
        const std::string& timeColumn,
        const std::string& bucketSize, // e.g., '1 hour', '5 minutes'
        const std::chrono::system_clock::time_point& startTime,
        const std::chrono::system_clock::time_point& endTime,
        const std::vector<std::pair<std::string, std::string>>& aggregations, // (column, function)
        const std::vector<std::string>& groupByColumns = {});
    
    // Create a continuous aggregate
    APTP::Core::Result<void> createContinuousAggregate(
        const std::string& viewName,
        const std::string& query,
        const std::string& refreshInterval = "1 hour");

private:
    TimescaleDBManager();
    ~TimescaleDBManager();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Core

// backend/core/src/DatabaseManager.cpp (partial implementation)
#include "DatabaseManager.h"
#include "Logger.h"
#include <memory>
#include <queue>
#include <pqxx/pqxx>

namespace APTP::Core {

// Implementation of DbConnectionPool
struct DbConnectionPool::Impl {
    DbConnectionParams connectionParams;
    size_t minPoolSize;
    size_t maxPoolSize;
    
    std::queue<std::shared_ptr<DbConnection>> availableConnections;
    std::unordered_map<DbConnection*, std::shared_ptr<DbConnection>> activeConnections;
    
    mutable std::shared_mutex mutex;
    
    bool initialized = false;
    
    // Helper to create a new connection
    APTP::Core::Result<std::shared_ptr<DbConnection>> createConnection() {
        try {
            // This would create a PostgreSQL connection
            // For this example, we'll use a simplified implementation
            
            // The actual implementation would use pqxx to create a connection
            
            return APTP::Core::Success(std::shared_ptr<DbConnection>(nullptr));
        } catch (const std::exception& e) {
            APTP::Core::Logger::getInstance().error("Failed to create database connection: {}", e.what());
            return APTP::Core::Error<std::shared_ptr<DbConnection>>(APTP::Core::ErrorCode::ResourceUnavailable);
        }
    }
};

DbConnectionPool& DbConnectionPool::getInstance() {
    static DbConnectionPool instance;
    return instance;
}

DbConnectionPool::DbConnectionPool() : impl_(std::make_unique<Impl>()) {}
DbConnectionPool::~DbConnectionPool() = default;

APTP::Core::Result<void> DbConnectionPool::initialize(const DbConnectionParams& params, size_t minPoolSize, size_t maxPoolSize) {
    std::unique_lock<std::shared_mutex> lock(impl_->mutex);
    
    if (impl_->initialized) {
        return APTP::Core::Success();
    }
    
    impl_->connectionParams = params;
    impl_->minPoolSize = minPoolSize;
    impl_->maxPoolSize = maxPoolSize;
    
    // Create initial connections
    for (size_t i = 0; i < minPoolSize; ++i) {
        auto connResult = impl_->createConnection();
        if (connResult.isSuccess()) {
            impl_->availableConnections.push(connResult.value());
        } else {
            APTP::Core::Logger::getInstance().warning("Failed to create initial connection {}/{}", i + 1, minPoolSize);
        }
    }
    
    impl_->initialized = true;
    
    APTP::Core::Logger::getInstance().info(
        "Initialized database connection pool (min={}, max={})", 
        minPoolSize, maxPoolSize);
    
    return APTP::Core::Success();
}

APTP::Core::Result<std::shared_ptr<DbConnection>> DbConnectionPool::getConnection() {
    std::unique_lock<std::shared_mutex> lock(impl_->mutex);
    
    if (!impl_->initialized) {
        return APTP::Core::Error<std::shared_ptr<DbConnection>>(APTP::Core::ErrorCode::InvalidState);
    }
    
    // Check if there's an available connection
    if (!impl_->availableConnections.empty()) {
        auto conn = impl_->availableConnections.front();
        impl_->availableConnections.pop();
        impl_->activeConnections[conn.get()] = conn;
        return APTP::Core::Success(conn);
    }
    
    // Check if we can create a new connection
    if (impl_->activeConnections.size() < impl_->maxPoolSize) {
        auto connResult = impl_->createConnection();
        if (connResult.isSuccess()) {
            auto conn = connResult.value();
            impl_->activeConnections[conn.get()] = conn;
            return APTP::Core::Success(conn);
        } else {
            return connResult;
        }
    }
    
    // Pool is exhausted
    return APTP::Core::Error<std::shared_ptr<DbConnection>>(APTP::Core::ErrorCode::ResourceUnavailable);
}

void DbConnectionPool::returnConnection(std::shared_ptr<DbConnection> connection) {
    if (!connection) {
        return;
    }
    
    std::unique_lock<std::shared_mutex> lock(impl_->mutex);
    
    auto it = impl_->activeConnections.find(connection.get());
    if (it != impl_->activeConnections.end()) {
        impl_->activeConnections.erase(it);
        
        // Make sure connection is healthy before returning it to the pool
        if (connection->isOpen()) {
            impl_->availableConnections.push(connection);
        } else {
            // Try to reopen the connection
            auto openResult = connection->open();
            if (openResult.isSuccess()) {
                impl_->availableConnections.push(connection);
            } else {
                // Connection is unusable, discard it
                APTP::Core::Logger::getInstance().warning("Discarded unhealthy database connection");
            }
        }
    }
}

size_t DbConnectionPool::getAvailableConnectionsCount() const {
    std::shared_lock<std::shared_mutex> lock(impl_->mutex);
    return impl_->availableConnections.size();
}

size_t DbConnectionPool::getActiveConnectionsCount() const {
    std::shared_lock<std::shared_mutex> lock(impl_->mutex);
    return impl_->activeConnections.size();
}

size_t DbConnectionPool::getTotalConnectionsCount() const {
    std::shared_lock<std::shared_mutex> lock(impl_->mutex);
    return impl_->availableConnections.size() + impl_->activeConnections.size();
}

// Implementation of PostgreSQLManager
struct PostgreSQLManager::Impl {
    DbConnectionParams connectionParams;
    bool initialized = false;
    
    std::unordered_map<std::string, std::string> preparedStatements;
    mutable std::shared_mutex mutex;
    
    // Helper to execute a query with connection from pool
    template<typename Func>
    auto executeWithConnection(Func&& func) -> decltype(func(std::declval<std::shared_ptr<DbConnection>&>())) {
        auto connResult = DbConnectionPool::getInstance().getConnection();
        if (connResult.isError()) {
            using ResultType = decltype(func(std::declval<std::shared_ptr<DbConnection>&>()));
            return APTP::Core::Error<typename ResultType::value_type>(APTP::Core::ErrorCode::ResourceUnavailable);
        }
        
        auto conn = connResult.value();
        auto result = func(conn);
        
        DbConnectionPool::getInstance().returnConnection(conn);
        return result;
    }
};

PostgreSQLManager& PostgreSQLManager::getInstance() {
    static PostgreSQLManager instance;
    return instance;
}

PostgreSQLManager::PostgreSQLManager() : impl_(std::make_unique<Impl>()) {}
PostgreSQLManager::~PostgreSQLManager() = default;

APTP::Core::Result<void> PostgreSQLManager::initialize(const DbConnectionParams& params) {
    std::unique_lock<std::shared_mutex> lock(impl_->mutex);
    
    if (impl_->initialized) {
        return APTP::Core::Success();
    }
    
    impl_->connectionParams = params;
    
    // Initialize the connection pool
    auto poolInitResult = DbConnectionPool::getInstance().initialize(params);
    if (poolInitResult.isError()) {
        return poolInitResult;
    }
    
    impl_->initialized = true;
    
    APTP::Core::Logger::getInstance().info(
        "Initialized PostgreSQL manager (host={}, db={})", 
        params.host, params.dbName);
    
    return APTP::Core::Success();
}

APTP::Core::Result<void> PostgreSQLManager::runMigrations(const std::string& migrationsPath) {
    // This would scan the migrations path and run all migrations in order
    // For this example, we'll provide a stub implementation
    
    APTP::Core::Logger::getInstance().info("Running migrations from {}", migrationsPath);
    
    // In a real implementation, this would:
    // 1. Create a migrations table if it doesn't exist
    // 2. Scan the migrations directory for SQL files
    // 3. Parse migration versions from filenames
    // 4. Check which migrations have already been applied
    // 5. Apply new migrations in version order
    
    return APTP::Core::Success();
}

APTP::Core::Result<DbResultSet> PostgreSQLManager::executeQuery(const std::string& sql) {
    return impl_->executeWithConnection([&](std::shared_ptr<DbConnection>& conn) {
        return conn->executeQuery(sql);
    });
}

APTP::Core::Result<int64_t> PostgreSQLManager::executeNonQuery(const std::string& sql) {
    return impl_->executeWithConnection([&](std::shared_ptr<DbConnection>& conn) {
        return conn->executeNonQuery(sql);
    });
}

APTP::Core::Result<DbValue> PostgreSQLManager::executeScalar(const std::string& sql) {
    return impl_->executeWithConnection([&](std::shared_ptr<DbConnection>& conn) {
        return conn->executeScalar(sql);
    });
}

APTP::Core::Result<DbResultSet> PostgreSQLManager::executeQuery(
    const std::string& sql, 
    const std::unordered_map<std::string, DbValue>& parameters) {
    
    return impl_->executeWithConnection([&](std::shared_ptr<DbConnection>& conn) {
        auto cmd = conn->createCommand(sql);
        
        for (const auto& [name, value] : parameters) {
            cmd->addParameter(name, value);
        }
        
        return cmd->executeQuery();
    });
}

APTP::Core::Result<int64_t> PostgreSQLManager::executeNonQuery(
    const std::string& sql, 
    const std::unordered_map<std::string, DbValue>& parameters) {
    
    return impl_->executeWithConnection([&](std::shared_ptr<DbConnection>& conn) {
        auto cmd = conn->createCommand(sql);
        
        for (const auto& [name, value] : parameters) {
            cmd->addParameter(name, value);
        }
        
        return cmd->executeNonQuery();
    });
}

APTP::Core::Result<DbValue> PostgreSQLManager::executeScalar(
    const std::string& sql, 
    const std::unordered_map<std::string, DbValue>& parameters) {
    
    return impl_->executeWithConnection([&](std::shared_ptr<DbConnection>& conn) {
        auto cmd = conn->createCommand(sql);
        
        for (const auto& [name, value] : parameters) {
            cmd->addParameter(name, value);
        }
        
        return cmd->executeScalar();
    });
}

APTP::Core::Result<std::vector<std::string>> PostgreSQLManager::getTables() {
    const std::string sql = 
        "SELECT table_name FROM information_schema.tables "
        "WHERE table_schema = 'public' AND table_type = 'BASE TABLE' "
        "ORDER BY table_name";
    
    auto result = executeQuery(sql);
    if (result.isError()) {
        return APTP::Core::Error<std::vector<std::string>>(APTP::Core::ErrorCode::ResourceUnavailable);
    }
    
    std::vector<std::string> tables;
    const auto& resultSet = result.value();
    
    for (size_t i = 0; i < resultSet.rowCount(); ++i) {
        auto tableName = resultSet.getValue<std::string>(i, 0);
        if (tableName.has_value()) {
            tables.push_back(*tableName);
        }
    }
    
    return APTP::Core::Success(tables);
}

APTP::Core::Result<std::vector<std::string>> PostgreSQLManager::getViews() {
    const std::string sql = 
        "SELECT table_name FROM information_schema.views "
        "WHERE table_schema = 'public' "
        "ORDER BY table_name";
    
    auto result = executeQuery(sql);
    if (result.isError()) {
        return APTP::Core::Error<std::vector<std::string>>(APTP::Core::ErrorCode::ResourceUnavailable);
    }
    
    std::vector<std::string> views;
    const auto& resultSet = result.value();
    
    for (size_t i = 0; i < resultSet.rowCount(); ++i) {
        auto viewName = resultSet.getValue<std::string>(i, 0);
        if (viewName.has_value()) {
            views.push_back(*viewName);
        }
    }
    
    return APTP::Core::Success(views);
}

APTP::Core::Result<std::vector<std::tuple<std::string, std::string, std::string>>> 
PostgreSQLManager::getColumns(const std::string& table) {
    const std::string sql = 
        "SELECT column_name, data_type, is_nullable "
        "FROM information_schema.columns "
        "WHERE table_schema = 'public' AND table_name = $1 "
        "ORDER BY ordinal_position";
    
    std::unordered_map<std::string, DbValue> parameters;
    parameters["$1"] = table;
    
    auto result = executeQuery(sql, parameters);
    if (result.isError()) {
        return APTP::Core::Error<std::vector<std::tuple<std::string, std::string, std::string>>>(
            APTP::Core::ErrorCode::ResourceUnavailable);
    }
    
    std::vector<std::tuple<std::string, std::string, std::string>> columns;
    const auto& resultSet = result.value();
    
    for (size_t i = 0; i < resultSet.rowCount(); ++i) {
        auto columnName = resultSet.getValue<std::string>(i, "column_name");
        auto dataType = resultSet.getValue<std::string>(i, "data_type");
        auto isNullable = resultSet.getValue<std::string>(i, "is_nullable");
        
        if (columnName.has_value() && dataType.has_value() && isNullable.has_value()) {
            columns.emplace_back(*columnName, *dataType, *isNullable);
        }
    }
    
    return APTP::Core::Success(columns);
}

// Implementation of TimescaleDBManager would follow a similar pattern
// This would provide specialized methods for time-series data management

} // namespace APTP::Core

-- TimescaleDB Schema for Advanced Pilot Training Platform
-- This schema implements efficient time-series data storage with automated
-- partitioning, continuous aggregation, and data retention policies.

-- Extensions & Setup
CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;
CREATE EXTENSION IF NOT EXISTS postgis CASCADE;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Create role-based permissions
CREATE ROLE app_readonly;
CREATE ROLE app_readwrite;
CREATE ROLE app_admin;

GRANT app_readonly TO app_readwrite;
GRANT app_readwrite TO app_admin;

-- Main Tables

-- Users and Authentication
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(255) NOT NULL,
    role VARCHAR(50) NOT NULL,
    organization_id UUID NOT NULL,
    mfa_enabled BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    last_login TIMESTAMPTZ,
    is_active BOOLEAN DEFAULT TRUE
);

CREATE TABLE organizations (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    name VARCHAR(255) NOT NULL,
    industry VARCHAR(100),
    subscription_tier VARCHAR(50) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    settings JSONB DEFAULT '{}'::JSONB,
    max_users INTEGER DEFAULT 10
);

CREATE TABLE auth_sessions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    token_hash VARCHAR(255) NOT NULL,
    device_info JSONB,
    ip_address VARCHAR(45),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    expires_at TIMESTAMPTZ NOT NULL,
    revoked BOOLEAN DEFAULT FALSE,
    CONSTRAINT unique_active_token UNIQUE (user_id, token_hash, revoked)
);

-- Syllabus and Training Content
CREATE TABLE syllabi (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    version VARCHAR(50) NOT NULL,
    status VARCHAR(50) DEFAULT 'draft', -- draft, active, archived
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_by UUID REFERENCES users(id),
    metadata JSONB DEFAULT '{}'::JSONB,
    parent_syllabus_id UUID REFERENCES syllabi(id)
);

CREATE TABLE modules (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    syllabus_id UUID NOT NULL REFERENCES syllabi(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    sequence_number INTEGER NOT NULL,
    estimated_duration INTEGER, -- in minutes
    prerequisites JSONB DEFAULT '[]'::JSONB,
    learning_objectives JSONB DEFAULT '[]'::JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE TABLE lessons (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    module_id UUID NOT NULL REFERENCES modules(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    sequence_number INTEGER NOT NULL,
    estimated_duration INTEGER, -- in minutes
    content_type VARCHAR(50) NOT NULL, -- theory, practical, simulation, assessment
    content JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE TABLE exercises (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    lesson_id UUID NOT NULL REFERENCES lessons(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    sequence_number INTEGER NOT NULL,
    difficulty_level INTEGER, -- 1-5
    equipment_required JSONB DEFAULT '[]'::JSONB,
    instructions TEXT,
    evaluation_criteria JSONB DEFAULT '[]'::JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Documents and Resources
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    file_path VARCHAR(1024),
    file_size BIGINT,
    file_type VARCHAR(100),
    status VARCHAR(50) DEFAULT 'active', -- active, archived, processing
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_by UUID REFERENCES users(id),
    version VARCHAR(50),
    parent_document_id UUID REFERENCES documents(id),
    extracted_text TEXT,
    metadata JSONB DEFAULT '{}'::JSONB,
    tags TEXT[]
);

CREATE TABLE document_syllabus_mapping (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    syllabus_id UUID NOT NULL REFERENCES syllabi(id) ON DELETE CASCADE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (document_id, syllabus_id)
);

-- Trainees and Training Records
CREATE TABLE trainees (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    status VARCHAR(50) DEFAULT 'active', -- active, on-leave, graduated, withdrawn
    enrollment_date TIMESTAMPTZ NOT NULL,
    expected_completion_date TIMESTAMPTZ,
    actual_completion_date TIMESTAMPTZ,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    profile_data JSONB DEFAULT '{}'::JSONB
);

CREATE TABLE trainee_syllabus_assignments (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    trainee_id UUID NOT NULL REFERENCES trainees(id) ON DELETE CASCADE,
    syllabus_id UUID NOT NULL REFERENCES syllabi(id) ON DELETE CASCADE,
    assigned_date TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    expected_completion_date TIMESTAMPTZ,
    status VARCHAR(50) DEFAULT 'assigned', -- assigned, in-progress, completed, failed
    instructor_id UUID REFERENCES users(id),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (trainee_id, syllabus_id)
);

CREATE TABLE trainee_progress (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    trainee_id UUID NOT NULL REFERENCES trainees(id) ON DELETE CASCADE,
    syllabus_id UUID NOT NULL REFERENCES syllabi(id) ON DELETE CASCADE,
    module_id UUID REFERENCES modules(id) ON DELETE CASCADE,
    lesson_id UUID REFERENCES lessons(id) ON DELETE CASCADE,
    exercise_id UUID REFERENCES exercises(id) ON DELETE CASCADE,
    status VARCHAR(50) NOT NULL, -- not-started, in-progress, completed, failed
    start_time TIMESTAMPTZ,
    completion_time TIMESTAMPTZ,
    time_spent INTEGER, -- in seconds
    attempts INTEGER DEFAULT 0,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (trainee_id, syllabus_id, module_id, lesson_id, exercise_id)
);

-- Assessments and Evaluations
CREATE TABLE assessment_templates (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    assessment_type VARCHAR(50) NOT NULL, -- practical, written, simulation
    competency_areas JSONB NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_by UUID REFERENCES users(id),
    version VARCHAR(50),
    status VARCHAR(50) DEFAULT 'active' -- draft, active, archived
);

CREATE TABLE assessments (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    template_id UUID REFERENCES assessment_templates(id),
    trainee_id UUID NOT NULL REFERENCES trainees(id) ON DELETE CASCADE,
    assessor_id UUID REFERENCES users(id),
    syllabus_id UUID REFERENCES syllabi(id),
    module_id UUID REFERENCES modules(id),
    lesson_id UUID REFERENCES lessons(id),
    status VARCHAR(50) DEFAULT 'scheduled', -- scheduled, in-progress, completed, cancelled
    scheduled_time TIMESTAMPTZ,
    start_time TIMESTAMPTZ,
    end_time TIMESTAMPTZ,
    location VARCHAR(255),
    notes TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE TABLE assessment_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    assessment_id UUID NOT NULL REFERENCES assessments(id) ON DELETE CASCADE,
    competency_area VARCHAR(255) NOT NULL,
    score INTEGER NOT NULL, -- 1-4 scale
    comments TEXT,
    evidence JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (assessment_id, competency_area)
);

-- Scheduling
CREATE TABLE resources (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    name VARCHAR(255) NOT NULL,
    type VARCHAR(100) NOT NULL, -- instructor, simulator, aircraft, classroom
    description TEXT,
    capacity INTEGER,
    status VARCHAR(50) DEFAULT 'available', -- available, maintenance, reserved, inactive
    location JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    metadata JSONB DEFAULT '{}'::JSONB
);

CREATE TABLE schedule_entries (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    resource_id UUID REFERENCES resources(id),
    trainee_id UUID REFERENCES trainees(id),
    instructor_id UUID REFERENCES users(id),
    syllabus_id UUID REFERENCES syllabi(id),
    module_id UUID REFERENCES modules(id),
    lesson_id UUID REFERENCES lessons(id),
    assessment_id UUID REFERENCES assessments(id),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    start_time TIMESTAMPTZ NOT NULL,
    end_time TIMESTAMPTZ NOT NULL,
    status VARCHAR(50) DEFAULT 'scheduled', -- scheduled, in-progress, completed, cancelled
    recurrence_rule TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_by UUID REFERENCES users(id),
    location VARCHAR(255),
    metadata JSONB DEFAULT '{}'::JSONB
);

-- Collaboration and Communication
CREATE TABLE messages (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    sender_id UUID NOT NULL REFERENCES users(id),
    receiver_id UUID REFERENCES users(id),
    group_id UUID, -- For group messages
    content TEXT NOT NULL,
    sent_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    read_at TIMESTAMPTZ,
    attachment_path VARCHAR(1024),
    message_type VARCHAR(50) DEFAULT 'direct', -- direct, group, system
    parent_message_id UUID REFERENCES messages(id)
);

CREATE TABLE notifications (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    message TEXT NOT NULL,
    notification_type VARCHAR(50) NOT NULL,
    related_resource_type VARCHAR(100),
    related_resource_id UUID,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    read_at TIMESTAMPTZ,
    action_url VARCHAR(1024)
);

-- Audit and Security
CREATE TABLE audit_logs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID REFERENCES users(id),
    action VARCHAR(100) NOT NULL,
    entity_type VARCHAR(100) NOT NULL,
    entity_id UUID,
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    ip_address VARCHAR(45),
    user_agent TEXT,
    details JSONB,
    status VARCHAR(50) -- success, failure, error
);

CREATE TABLE encrypted_data (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    entity_type VARCHAR(100) NOT NULL,
    entity_id UUID NOT NULL,
    field_name VARCHAR(100) NOT NULL,
    encrypted_value BYTEA NOT NULL,
    encryption_method VARCHAR(50) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (entity_type, entity_id, field_name)
);

-- TimescaleDB Hypertables for Time-Series Data

-- Flight telemetry data
CREATE TABLE flight_telemetry (
    time TIMESTAMPTZ NOT NULL,
    flight_id UUID NOT NULL,
    trainee_id UUID NOT NULL,
    aircraft_id VARCHAR(100) NOT NULL,
    latitude DOUBLE PRECISION,
    longitude DOUBLE PRECISION,
    altitude DOUBLE PRECISION,
    heading DOUBLE PRECISION,
    airspeed DOUBLE PRECISION,
    vertical_speed DOUBLE PRECISION,
    roll DOUBLE PRECISION,
    pitch DOUBLE PRECISION,
    yaw DOUBLE PRECISION,
    g_force DOUBLE PRECISION,
    engine_parameters JSONB,
    system_statuses JSONB,
    weather_conditions JSONB,
    control_inputs JSONB
);

-- Convert to hypertable
SELECT create_hypertable('flight_telemetry', 'time',
                         chunk_time_interval => INTERVAL '1 hour');

-- Simulator session data
CREATE TABLE simulator_telemetry (
    time TIMESTAMPTZ NOT NULL,
    session_id UUID NOT NULL,
    trainee_id UUID NOT NULL,
    simulator_id VARCHAR(100) NOT NULL,
    scenario_id VARCHAR(100),
    latitude DOUBLE PRECISION,
    longitude DOUBLE PRECISION,
    altitude DOUBLE PRECISION,
    heading DOUBLE PRECISION,
    airspeed DOUBLE PRECISION,
    vertical_speed DOUBLE PRECISION,
    roll DOUBLE PRECISION,
    pitch DOUBLE PRECISION,
    yaw DOUBLE PRECISION,
    g_force DOUBLE PRECISION,
    engine_parameters JSONB,
    system_statuses JSONB,
    weather_conditions JSONB,
    control_inputs JSONB,
    system_alerts JSONB,
    instructor_annotations JSONB
);

-- Convert to hypertable
SELECT create_hypertable('simulator_telemetry', 'time',
                         chunk_time_interval => INTERVAL '1 hour');

-- Biometric data from trainees
CREATE TABLE biometric_data (
    time TIMESTAMPTZ NOT NULL,
    trainee_id UUID NOT NULL,
    session_id UUID NOT NULL,
    heart_rate INTEGER,
    blood_pressure JSONB,
    eye_tracking JSONB,
    stress_level DOUBLE PRECISION,
    attention_score DOUBLE PRECISION,
    fatigue_indicators JSONB,
    reaction_time DOUBLE PRECISION
);

-- Convert to hypertable
SELECT create_hypertable('biometric_data', 'time',
                         chunk_time_interval => INTERVAL '1 hour');

-- System performance metrics
CREATE TABLE system_metrics (
    time TIMESTAMPTZ NOT NULL,
    server_id VARCHAR(100) NOT NULL,
    cpu_usage DOUBLE PRECISION,
    memory_usage DOUBLE PRECISION,
    disk_usage DOUBLE PRECISION,
    network_traffic DOUBLE PRECISION,
    active_users INTEGER,
    response_time DOUBLE PRECISION,
    error_count INTEGER,
    service_status JSONB
);

-- Convert to hypertable
SELECT create_hypertable('system_metrics', 'time',
                         chunk_time_interval => INTERVAL '1 hour');

-- Continuous Aggregates for Analytics
-- Create hourly aggregates for flight telemetry
CREATE MATERIALIZED VIEW flight_telemetry_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS bucket,
    flight_id,
    trainee_id,
    aircraft_id,
    AVG(altitude) AS avg_altitude,
    AVG(airspeed) AS avg_airspeed,
    AVG(g_force) AS avg_g_force,
    MIN(altitude) AS min_altitude,
    MAX(altitude) AS max_altitude,
    MIN(airspeed) AS min_airspeed,
    MAX(airspeed) AS max_airspeed,
    MIN(g_force) AS min_g_force,
    MAX(g_force) AS max_g_force
FROM flight_telemetry
GROUP BY bucket, flight_id, trainee_id, aircraft_id;

-- Add refresh policy (refresh every 1 hour)
SELECT add_continuous_aggregate_policy('flight_telemetry_hourly',
    start_offset => INTERVAL '3 days',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour');

-- Create daily aggregates for simulator sessions
CREATE MATERIALIZED VIEW simulator_telemetry_daily
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', time) AS bucket,
    trainee_id,
    simulator_id,
    scenario_id,
    COUNT(DISTINCT session_id) AS session_count,
    AVG(airspeed) AS avg_airspeed,
    AVG(altitude) AS avg_altitude,
    MIN(airspeed) AS min_airspeed,
    MAX(airspeed) AS max_airspeed
FROM simulator_telemetry
GROUP BY bucket, trainee_id, simulator_id, scenario_id;

-- Add refresh policy (refresh every day)
SELECT add_continuous_aggregate_policy('simulator_telemetry_daily',
    start_offset => INTERVAL '30 days',
    end_offset => INTERVAL '1 day',
    schedule_interval => INTERVAL '1 day');

-- Create hourly aggregates for biometric data
CREATE MATERIALIZED VIEW biometric_data_hourly
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 hour', time) AS bucket,
    trainee_id,
    session_id,
    AVG(heart_rate) AS avg_heart_rate,
    AVG(stress_level) AS avg_stress_level,
    AVG(attention_score) AS avg_attention_score,
    AVG(reaction_time) AS avg_reaction_time,
    MIN(heart_rate) AS min_heart_rate,
    MAX(heart_rate) AS max_heart_rate
FROM biometric_data
GROUP BY bucket, trainee_id, session_id;

-- Add refresh policy (refresh every hour)
SELECT add_continuous_aggregate_policy('biometric_data_hourly',
    start_offset => INTERVAL '7 days',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour');

-- Create daily system performance aggregates
CREATE MATERIALIZED VIEW system_metrics_daily
WITH (timescaledb.continuous) AS
SELECT
    time_bucket('1 day', time) AS bucket,
    server_id,
    AVG(cpu_usage) AS avg_cpu_usage,
    MAX(cpu_usage) AS max_cpu_usage,
    AVG(memory_usage) AS avg_memory_usage,
    MAX(memory_usage) AS max_memory_usage,
    AVG(response_time) AS avg_response_time,
    MAX(response_time) AS max_response_time,
    SUM(error_count) AS total_errors,
    MAX(active_users) AS peak_users
FROM system_metrics
GROUP BY bucket, server_id;

-- Add refresh policy (refresh every day)
SELECT add_continuous_aggregate_policy('system_metrics_daily',
    start_offset => INTERVAL '30 days',
    end_offset => INTERVAL '1 day',
    schedule_interval => INTERVAL '1 day');

-- Retention Policies
-- Keep detailed flight telemetry for 30 days, then drop
SELECT add_retention_policy('flight_telemetry', INTERVAL '30 days');

-- Keep detailed simulator telemetry for 60 days, then drop
SELECT add_retention_policy('simulator_telemetry', INTERVAL '60 days');

-- Keep detailed biometric data for 90 days, then drop
SELECT add_retention_policy('biometric_data', INTERVAL '90 days');

-- Keep detailed system metrics for 14 days, then drop
SELECT add_retention_policy('system_metrics', INTERVAL '14 days');

-- Note: Continuous aggregates will still retain the aggregated historical data
-- even after the detailed data is dropped by the retention policy

-- Compression Policies
-- Enable compression for flight telemetry after 3 days
ALTER TABLE flight_telemetry SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'flight_id, trainee_id, aircraft_id'
);

SELECT add_compression_policy('flight_telemetry', INTERVAL '3 days');

-- Enable compression for simulator telemetry after 7 days
ALTER TABLE simulator_telemetry SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'session_id, trainee_id, simulator_id'
);

SELECT add_compression_policy('simulator_telemetry', INTERVAL '7 days');

-- Enable compression for biometric data after 7 days
ALTER TABLE biometric_data SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'trainee_id, session_id'
);

SELECT add_compression_policy('biometric_data', INTERVAL '7 days');

-- Enable compression for system metrics after 1 day
ALTER TABLE system_metrics SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'server_id'
);

SELECT add_compression_policy('system_metrics', INTERVAL '1 day');

-- Create indexes for performance
-- Flight telemetry indexes
CREATE INDEX idx_flight_telemetry_trainee_time 
ON flight_telemetry (trainee_id, time DESC);

CREATE INDEX idx_flight_telemetry_flight_time 
ON flight_telemetry (flight_id, time DESC);

-- Simulator telemetry indexes
CREATE INDEX idx_simulator_telemetry_trainee_time 
ON simulator_telemetry (trainee_id, time DESC);

CREATE INDEX idx_simulator_telemetry_session_time 
ON simulator_telemetry (session_id, time DESC);

-- Biometric data indexes
CREATE INDEX idx_biometric_data_trainee_time 
ON biometric_data (trainee_id, time DESC);

CREATE INDEX idx_biometric_data_session_time 
ON biometric_data (session_id, time DESC);

-- System metrics indexes
CREATE INDEX idx_system_metrics_server_time 
ON system_metrics (server_id, time DESC);

-- Grant appropriate permissions
GRANT SELECT ON ALL TABLES IN SCHEMA public TO app_readonly;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO app_readwrite;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO app_admin;
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO app_readwrite;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO app_admin;

-- TimescaleDB Schema for Advanced Pilot Training Platform
-- This schema implements efficient time-series data storage with automated
-- partitioning, continuous aggregation, and data retention policies.

-- Extensions & Setup
CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;
CREATE EXTENSION IF NOT EXISTS postgis CASCADE;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Create role-based permissions
CREATE ROLE app_readonly;
CREATE ROLE app_readwrite;
CREATE ROLE app_admin;

GRANT app_readonly TO app_readwrite;
GRANT app_readwrite TO app_admin;

-- Main Tables

-- Users and Authentication
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(255) NOT NULL,
    role VARCHAR(50) NOT NULL,
    organization_id UUID NOT NULL,
    mfa_enabled BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    last_login TIMESTAMPTZ,
    is_active BOOLEAN DEFAULT TRUE
);

CREATE TABLE organizations (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    name VARCHAR(255) NOT NULL,
    industry VARCHAR(100),
    subscription_tier VARCHAR(50) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    settings JSONB DEFAULT '{}'::JSONB,
    max_users INTEGER DEFAULT 10
);

CREATE TABLE auth_sessions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    token_hash VARCHAR(255) NOT NULL,
    device_info JSONB,
    ip_address VARCHAR(45),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    expires_at TIMESTAMPTZ NOT NULL,
    revoked BOOLEAN DEFAULT FALSE,
    CONSTRAINT unique_active_token UNIQUE (user_id, token_hash, revoked)
);

-- Syllabus and Training Content
CREATE TABLE syllabi (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    version VARCHAR(50) NOT NULL,
    status VARCHAR(50) DEFAULT 'draft', -- draft, active, archived
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_by UUID REFERENCES users(id),
    metadata JSONB DEFAULT '{}'::JSONB,
    parent_syllabus_id UUID REFERENCES syllabi(id)
);

CREATE TABLE modules (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    syllabus_id UUID NOT NULL REFERENCES syllabi(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    sequence_number INTEGER NOT NULL,
    estimated_duration INTEGER, -- in minutes
    prerequisites JSONB DEFAULT '[]'::JSONB,
    learning_objectives JSONB DEFAULT '[]'::JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE TABLE lessons (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    module_id UUID NOT NULL REFERENCES modules(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    sequence_number INTEGER NOT NULL,
    estimated_duration INTEGER, -- in minutes
    content_type VARCHAR(50) NOT NULL, -- theory, practical, simulation, assessment
    content JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE TABLE exercises (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    lesson_id UUID NOT NULL REFERENCES lessons(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    sequence_number INTEGER NOT NULL,
    difficulty_level INTEGER, -- 1-5
    equipment_required JSONB DEFAULT '[]'::JSONB,
    instructions TEXT,
    evaluation_criteria JSONB DEFAULT '[]'::JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Documents and Resources
CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    file_path VARCHAR(1024),
    file_size BIGINT,
    file_type VARCHAR(100),
    status VARCHAR(50) DEFAULT 'active', -- active, archived, processing
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_by UUID REFERENCES users(id),
    version VARCHAR(50),
    parent_document_id UUID REFERENCES documents(id),
    extracted_text TEXT,
    metadata JSONB DEFAULT '{}'::JSONB,
    tags TEXT[]
);

CREATE TABLE document_syllabus_mapping (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    syllabus_id UUID NOT NULL REFERENCES syllabi(id) ON DELETE CASCADE,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (document_id, syllabus_id)
);

-- Trainees and Training Records
CREATE TABLE trainees (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    status VARCHAR(50) DEFAULT 'active', -- active, on-leave, graduated, withdrawn
    enrollment_date TIMESTAMPTZ NOT NULL,
    expected_completion_date TIMESTAMPTZ,
    actual_completion_date TIMESTAMPTZ,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    profile_data JSONB DEFAULT '{}'::JSONB
);

CREATE TABLE trainee_syllabus_assignments (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    trainee_id UUID NOT NULL REFERENCES trainees(id) ON DELETE CASCADE,
    syllabus_id UUID NOT NULL REFERENCES syllabi(id) ON DELETE CASCADE,
    assigned_date TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    expected_completion_date TIMESTAMPTZ,
    status VARCHAR(50) DEFAULT 'assigned', -- assigned, in-progress, completed, failed
    instructor_id UUID REFERENCES users(id),
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (trainee_id, syllabus_id)
);

CREATE TABLE trainee_progress (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    trainee_id UUID NOT NULL REFERENCES trainees(id) ON DELETE CASCADE,
    syllabus_id UUID NOT NULL REFERENCES syllabi(id) ON DELETE CASCADE,
    module_id UUID REFERENCES modules(id) ON DELETE CASCADE,
    lesson_id UUID REFERENCES lessons(id) ON DELETE CASCADE,
    exercise_id UUID REFERENCES exercises(id) ON DELETE CASCADE,
    status VARCHAR(50) NOT NULL, -- not-started, in-progress, completed, failed
    start_time TIMESTAMPTZ,
    completion_time TIMESTAMPTZ,
    time_spent INTEGER, -- in seconds
    attempts INTEGER DEFAULT 0,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (trainee_id, syllabus_id, module_id, lesson_id, exercise_id)
);

-- Assessments and Evaluations
CREATE TABLE assessment_templates (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    assessment_type VARCHAR(50) NOT NULL, -- practical, written, simulation
    competency_areas JSONB NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_by UUID REFERENCES users(id),
    version VARCHAR(50),
    status VARCHAR(50) DEFAULT 'active' -- draft, active, archived
);

CREATE TABLE assessments (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    template_id UUID REFERENCES assessment_templates(id),
    trainee_id UUID NOT NULL REFERENCES trainees(id) ON DELETE CASCADE,
    assessor_id UUID REFERENCES users(id),
    syllabus_id UUID REFERENCES syllabi(id),
    module_id UUID REFERENCES modules(id),
    lesson_id UUID REFERENCES lessons(id),
    status VARCHAR(50) DEFAULT 'scheduled', -- scheduled, in-progress, completed, cancelled
    scheduled_time TIMESTAMPTZ,
    start_time TIMESTAMPTZ,
    end_time TIMESTAMPTZ,
    location VARCHAR(255),
    notes TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE TABLE assessment_results (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    assessment_id UUID NOT NULL REFERENCES assessments(id) ON DELETE CASCADE,
    competency_area VARCHAR(255) NOT NULL,
    score INTEGER NOT NULL, -- 1-4 scale
    comments TEXT,
    evidence JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (assessment_id, competency_area)
);

-- Scheduling
CREATE TABLE resources (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    name VARCHAR(255) NOT NULL,
    type VARCHAR(100) NOT NULL, -- instructor, simulator, aircraft, classroom
    description TEXT,
    capacity INTEGER,
    status VARCHAR(50) DEFAULT 'available', -- available, maintenance, reserved, inactive
    location JSONB,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    metadata JSONB DEFAULT '{}'::JSONB
);

CREATE TABLE schedule_entries (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    organization_id UUID NOT NULL REFERENCES organizations(id),
    resource_id UUID REFERENCES resources(id),
    trainee_id UUID REFERENCES trainees(id),
    instructor_id UUID REFERENCES users(id),
    syllabus_id UUID REFERENCES syllabi(id),
    module_id UUID REFERENCES modules(id),
    lesson_id UUID REFERENCES lessons(id),
    assessment_id UUID REFERENCES assessments(id),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    start_time TIMESTAMPTZ NOT NULL,
    end_time TIMESTAMPTZ NOT NULL,
    status VARCHAR(50) DEFAULT 'scheduled', -- scheduled, in-progress, completed, cancelled
    recurrence_rule TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    created_by UUID REFERENCES users(id),
    location VARCHAR(255),
    metadata JSONB DEFAULT '{}'::JSONB
);

-- Collaboration and Communication
CREATE TABLE messages (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    sender_id UUID NOT NULL REFERENCES users(id),
    receiver_id UUID REFERENCES users(id),
    group_id UUID, -- For group messages
    content TEXT NOT NULL,
    sent_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    read_at TIMESTAMPTZ,
    attachment_path VARCHAR(1024),
    message_type VARCHAR(50) DEFAULT 'direct', -- direct, group, system
    parent_message_id UUID REFERENCES messages(id)
);

CREATE TABLE notifications (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    message TEXT NOT NULL,
    notification_type VARCHAR(50) NOT NULL,
    related_resource_type VARCHAR(100),
    related_resource_id UUID,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    read_at TIMESTAMPTZ,
    action_url VARCHAR(1024)
);

-- Audit and Security
CREATE TABLE audit_logs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID REFERENCES users(id),
    action VARCHAR(100) NOT NULL,
    entity_type VARCHAR(100) NOT NULL,
    entity_id UUID,
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    ip_address VARCHAR(45),
    user_agent TEXT,
    details JSONB,
    status VARCHAR(50) -- success, failure, error
);

CREATE TABLE encrypted_data (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    entity_type VARCHAR(100) NOT NULL,
    entity_id UUID NOT NULL,
    field_name VARCHAR(100) NOT NULL,
    encrypted_value BYTEA NOT NULL,
    encryption_method VARCHAR(50) NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (entity_type, entity_id, field_name)
);

-- TimescaleDB Hypertables for Time-Series Data

-- Flight telemetry data
CREATE TABLE flight_telemetry (
    time TIMESTAMPTZ NOT NULL,
    flight_id UUID NOT NULL,
    trainee_id UUID NOT NULL,
    aircraft_id VARCHAR(100) NOT NULL,
    latitude DOUBLE PRECISION,
    longitude DOUBLE PRECISION,
    altitude DOUBLE PRECISION,
    heading DOUBLE PRECISION,
    airspeed DOUBLE PRECISION,
    vertical_speed DOUBLE PRECISION,
    roll DOUBLE PRECISION,
    pitch DOUBLE PRECISION,
    yaw DOUBLE PRECISION,
    g_force DOUBLE PRECISION,
    engine_parameters JSONB,
    system_statuses JSONB,
    weather_conditions JSONB,
    control_inputs JSONB
);

-- Convert to hypertable
SELECT create_hypertable('flight_telemetry', 'time',
                         chunk_time_interval => INTERVAL '1 hour');

-- Simulator session data
CREATE TABLE simulator_telemetry (
    time TIMESTAMPTZ NOT NULL,
    session_id UUID NOT NULL,
    trainee_id UUID NOT NULL,
    simulator_id VARCHAR(100) NOT NULL,
    scenario_id VARCHAR(100),
    
#include <drogon/drogon.h>
#include <json/json.h>
#include <string>
#include <vector>
#include <map>
#include <chrono>
#include <memory>
#include <mutex>
#include "session_repository.h"
#include "analytics_processor.h"
#include "metrics_calculator.h"

namespace atp {
namespace debriefing {

class DebriefingSessionService : public drogon::HttpController<DebriefingSessionService> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(DebriefingSessionService::createSession, "/api/debrief/sessions", drogon::Post);
    ADD_METHOD_TO(DebriefingSessionService::getSession, "/api/debrief/sessions/{id}", drogon::Get);
    ADD_METHOD_TO(DebriefingSessionService::addEvent, "/api/debrief/sessions/{id}/events", drogon::Post);
    ADD_METHOD_TO(DebriefingSessionService::getSessionEvents, "/api/debrief/sessions/{id}/events", drogon::Get);
    ADD_METHOD_TO(DebriefingSessionService::addAnnotation, "/api/debrief/sessions/{id}/annotations", drogon::Post);
    ADD_METHOD_TO(DebriefingSessionService::getAnnotations, "/api/debrief/sessions/{id}/annotations", drogon::Get);
    ADD_METHOD_TO(DebriefingSessionService::generateReport, "/api/debrief/sessions/{id}/report", drogon::Get);
    ADD_METHOD_TO(DebriefingSessionService::flagCriticalEvent, "/api/debrief/sessions/{id}/flag-event", drogon::Post);
    ADD_METHOD_TO(DebriefingSessionService::getSessionMetrics, "/api/debrief/sessions/{id}/metrics", drogon::Get);
    ADD_METHOD_TO(DebriefingSessionService::compareWithReference, "/api/debrief/sessions/{id}/compare", drogon::Post);
    METHOD_LIST_END

    DebriefingSessionService();

    void createSession(const drogon::HttpRequestPtr& req, 
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getSession(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                   const std::string& id);
    
    void addEvent(const drogon::HttpRequestPtr& req,
                 std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                 const std::string& id);
    
    void getSessionEvents(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                         const std::string& id);
    
    void addAnnotation(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                      const std::string& id);
    
    void getAnnotations(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                       const std::string& id);
    
    void generateReport(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                       const std::string& id);
    
    void flagCriticalEvent(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                          const std::string& id);
    
    void getSessionMetrics(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                          const std::string& id);
    
    void compareWithReference(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                             const std::string& id);

private:
    std::shared_ptr<SessionRepository> sessionRepo_;
    std::shared_ptr<AnalyticsProcessor> analyticsProcessor_;
    std::shared_ptr<MetricsCalculator> metricsCalculator_;
    
    // Helper methods
    bool validateSession(const std::string& sessionId);
    Json::Value analyzeEventSequence(const std::vector<Json::Value>& events);
    Json::Value detectAnomalies(const std::vector<Json::Value>& events);
    Json::Value generateLearningPoints(const std::string& sessionId);
    Json::Value extractProcedureCompliance(const std::vector<Json::Value>& events, const std::string& procedureType);
};

DebriefingSessionService::DebriefingSessionService() {
    // Initialize components
    sessionRepo_ = std::make_shared<SessionRepository>();
    analyticsProcessor_ = std::make_shared<AnalyticsProcessor>();
    metricsCalculator_ = std::make_shared<MetricsCalculator>();
}

void DebriefingSessionService::createSession(const drogon::HttpRequestPtr& req, 
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract session metadata
        std::string traineeId = (*json)["trainee_id"].asString();
        std::string instructorId = (*json)["instructor_id"].asString();
        std::string trainingType = (*json)["training_type"].asString();
        std::string aircraftType = (*json)["aircraft_type"].asString();
        
        // Create session
        Json::Value sessionData = *json;
        sessionData["created_at"] = drogon::utils::getFormattedDate();
        sessionData["status"] = "active";
        
        // Store session and get ID
        std::string sessionId = sessionRepo_->createSession(sessionData);
        
        // Prepare response
        Json::Value result;
        result["session_id"] = sessionId;
        result["status"] = "active";
        result["created_at"] = sessionData["created_at"];
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void DebriefingSessionService::getSession(const drogon::HttpRequestPtr& req,
                 std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                 const std::string& id) {
    try {
        // Get session data
        Json::Value session = sessionRepo_->getSession(id);
        
        if (session.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Return session data
        auto resp = drogon::HttpResponse::newHttpJsonResponse(session);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void DebriefingSessionService::addEvent(const drogon::HttpRequestPtr& req,
               std::function<void(const drogon::HttpResponsePtr&)>&& callback,
               const std::string& id) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Validate session exists
        if (!validateSession(id)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Extract event data
        Json::Value eventData = *json;
        eventData["timestamp"] = eventData.get("timestamp", drogon::utils::getFormattedDate()).asString();
        
        // Add session ID
        eventData["session_id"] = id;
        
        // Generate event ID if not provided
        if (!eventData.isMember("event_id")) {
            eventData["event_id"] = generateEventId();
        }
        
        // Store event
        std::string eventId = sessionRepo_->addEvent(id, eventData);
        
        // Process event for real-time analytics
        Json::Value analyticsResult = analyticsProcessor_->processEvent(eventData);
        
        // Check if this is a critical event
        bool isCritical = analyticsProcessor_->isCriticalEvent(eventData);
        
        // Prepare response
        Json::Value result;
        result["event_id"] = eventId;
        result["session_id"] = id;
        result["timestamp"] = eventData["timestamp"];
        
        if (isCritical) {
            result["critical"] = true;
            result["critical_reason"] = analyticsResult["critical_reason"];
        }
        
        if (analyticsResult.isMember("insights")) {
            result["insights"] = analyticsResult["insights"];
        }
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void DebriefingSessionService::getSessionEvents(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                       const std::string& id) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string startTime = params.find("start_time") != params.end() ? params["start_time"] : "";
        std::string endTime = params.find("end_time") != params.end() ? params["end_time"] : "";
        std::string eventType = params.find("event_type") != params.end() ? params["event_type"] : "";
        
        // Validate session exists
        if (!validateSession(id)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Get events
        std::vector<Json::Value> events = sessionRepo_->getSessionEvents(id, startTime, endTime, eventType);
        
        // Convert to JSON array
        Json::Value eventsArray(Json::arrayValue);
        for (const auto& event : events) {
            eventsArray.append(event);
        }
        
        // Prepare response
        Json::Value result;
        result["session_id"] = id;
        result["events"] = eventsArray;
        result["count"] = static_cast<int>(events.size());
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void DebriefingSessionService::addAnnotation(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                    const std::string& id) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Validate session exists
        if (!validateSession(id)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Extract annotation data
        Json::Value annotationData = *json;
        annotationData["timestamp"] = annotationData.get("timestamp", drogon::utils::getFormattedDate()).asString();
        
        // Add session ID
        annotationData["session_id"] = id;
        
        // Generate annotation ID if not provided
        if (!annotationData.isMember("annotation_id")) {
            annotationData["annotation_id"] = generateAnnotationId();
        }
        
        // Store annotation
        std::string annotationId = sessionRepo_->addAnnotation(id, annotationData);
        
        // Prepare response
        Json::Value result;
        result["annotation_id"] = annotationId;
        result["session_id"] = id;
        result["timestamp"] = annotationData["timestamp"];
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void DebriefingSessionService::getAnnotations(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& id) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string timePosition = params.find("time_position") != params.end() ? params["time_position"] : "";
        std::string annotationType = params.find("type") != params.end() ? params["type"] : "";
        
        // Validate session exists
        if (!validateSession(id)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Get annotations
        std::vector<Json::Value> annotations = sessionRepo_->getAnnotations(id, timePosition, annotationType);
        
        // Convert to JSON array
        Json::Value annotationsArray(Json::arrayValue);
        for (const auto& annotation : annotations) {
            annotationsArray.append(annotation);
        }
        
        // Prepare response
        Json::Value result;
        result["session_id"] = id;
        result["annotations"] = annotationsArray;
        result["count"] = static_cast<int>(annotations.size());
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void DebriefingSessionService::generateReport(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& id) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string format = params.find("format") != params.end() ? params["format"] : "json";
        bool includeEvents = params.find("include_events") != params.end() && params["include_events"] == "true";
        bool includeAnnotations = params.find("include_annotations") != params.end() && params["include_annotations"] == "true";
        bool includeMetrics = params.find("include_metrics") != params.end() && params["include_metrics"] == "true";
        bool includeLearningPoints = params.find("include_learning_points") != params.end() && params["include_learning_points"] == "true";
        
        // Validate session exists
        if (!validateSession(id)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Get session data
        Json::Value session = sessionRepo_->getSession(id);
        
        // Prepare report
        Json::Value report;
        report["session_id"] = id;
        report["trainee_id"] = session["trainee_id"];
        report["instructor_id"] = session["instructor_id"];
        report["training_type"] = session["training_type"];
        report["aircraft_type"] = session["aircraft_type"];
        report["date"] = session["created_at"];
        report["generated_at"] = drogon::utils::getFormattedDate();
        
        // Include events if requested
        if (includeEvents) {
            std::vector<Json::Value> events = sessionRepo_->getSessionEvents(id, "", "", "");
            
            Json::Value eventsArray(Json::arrayValue);
            for (const auto& event : events) {
                eventsArray.append(event);
            }
            
            report["events"] = eventsArray;
        }
        
        // Include annotations if requested
        if (includeAnnotations) {
            std::vector<Json::Value> annotations = sessionRepo_->getAnnotations(id, "", "");
            
            Json::Value annotationsArray(Json::arrayValue);
            for (const auto& annotation : annotations) {
                annotationsArray.append(annotation);
            }
            
            report["annotations"] = annotationsArray;
        }
        
        // Include metrics if requested
        if (includeMetrics) {
            std::vector<Json::Value> events = sessionRepo_->getSessionEvents(id, "", "", "");
            report["metrics"] = metricsCalculator_->calculateSessionMetrics(events);
        }
        
        // Include learning points if requested
        if (includeLearningPoints) {
            report["learning_points"] = generateLearningPoints(id);
        }
        
        // Generate critical event summary
        std::vector<Json::Value> events = sessionRepo_->getSessionEvents(id, "", "", "");
        std::vector<Json::Value> criticalEvents;
        
        for (const auto& event : events) {
            if (analyticsProcessor_->isCriticalEvent(event)) {
                criticalEvents.push_back(event);
            }
        }
        
        if (!criticalEvents.empty()) {
            Json::Value criticalEventsArray(Json::arrayValue);
            for (const auto& event : criticalEvents) {
                criticalEventsArray.append(event);
            }
            
            report["critical_events"] = criticalEventsArray;
            report["critical_event_count"] = static_cast<int>(criticalEvents.size());
        }
        
        // Generate procedure compliance summary
        report["procedure_compliance"] = extractProcedureCompliance(events, session["training_type"].asString());
        
        // Return report in requested format
        if (format == "pdf") {
            // In a real implementation, this would generate a PDF
            // For this example, we'll return a JSON with a notice
            report["format"] = "pdf";
            report["notice"] = "PDF generation would be implemented in production version";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(report);
            callback(resp);
        }
        else {
            // Return as JSON
            auto resp = drogon::HttpResponse::newHttpJsonResponse(report);
            callback(resp);
        }
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void DebriefingSessionService::flagCriticalEvent(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Validate session exists
        if (!validateSession(id)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Extract event data
        std::string eventId = (*json)["event_id"].asString();
        std::string reason = (*json)["reason"].asString();
        std::string severity = (*json).get("severity", "medium").asString();
        
        // Get the event
        Json::Value event = sessionRepo_->getEvent(id, eventId);
        
        if (event.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Event not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Flag the event as critical
        event["critical"] = true;
        event["critical_reason"] = reason;
        event["critical_severity"] = severity;
        event["flagged_by"] = (*json).get("instructor_id", "system").asString();
        event["flagged_at"] = drogon::utils::getFormattedDate();
        
        // Update the event
        sessionRepo_->updateEvent(id, eventId, event);
        
        // Add an annotation for this critical event
        Json::Value annotation;
        annotation["session_id"] = id;
        annotation["event_id"] = eventId;
        annotation["annotation_id"] = generateAnnotationId();
        annotation["type"] = "critical_flag";
        annotation["text"] = "Critical event: " + reason;
        annotation["timestamp"] = drogon::utils::getFormattedDate();
        annotation["author"] = (*json).get("instructor_id", "system").asString();
        
        sessionRepo_->addAnnotation(id, annotation);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["event_id"] = eventId;
        result["session_id"] = id;
        result["critical"] = true;
        result["critical_reason"] = reason;
        result["critical_severity"] = severity;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void DebriefingSessionService::getSessionMetrics(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string metricType = params.find("type") != params.end() ? params["type"] : "all";
        
        // Validate session exists
        if (!validateSession(id)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Get session events
        std::vector<Json::Value> events = sessionRepo_->getSessionEvents(id, "", "", "");
        
        // Calculate metrics
        Json::Value metrics;
        
        if (metricType == "all" || metricType == "performance") {
            metrics["performance"] = metricsCalculator_->calculatePerformanceMetrics(events);
        }
        
        if (metricType == "all" || metricType == "procedure") {
            metrics["procedure"] = metricsCalculator_->calculateProcedureMetrics(events);
        }
        
        if (metricType == "all" || metricType == "reaction") {
            metrics["reaction"] = metricsCalculator_->calculateReactionTimeMetrics(events);
        }
        
        if (metricType == "all" || metricType == "decision") {
            metrics["decision"] = metricsCalculator_->calculateDecisionQualityMetrics(events);
        }
        
        if (metricType == "all" || metricType == "workload") {
            metrics["workload"] = metricsCalculator_->calculateWorkloadMetrics(events);
        }
        
        if (metricType == "all" || metricType == "communication") {
            metrics["communication"] = metricsCalculator_->calculateCommunicationMetrics(events);
        }
        
        if (metricType == "all") {
            // Add overall metrics
            metrics["overall"] = metricsCalculator_->calculateOverallMetrics(events);
            
            // Add metrics trends
            metrics["trends"] = metricsCalculator_->calculateMetricsTrends(events);
        }
        
        // Prepare response
        Json::Value result;
        result["session_id"] = id;
        result["metrics"] = metrics;
        result["generated_at"] = drogon::utils::getFormattedDate();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void DebriefingSessionService::compareWithReference(const drogon::HttpRequestPtr& req,
                           std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                           const std::string& id) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract reference session ID
        std::string referenceId = (*json)["reference_session_id"].asString();
        bool compareEvents = (*json).get("compare_events", true).asBool();
        bool compareMetrics = (*json).get("compare_metrics", true).asBool();
        
        // Validate both sessions exist
        if (!validateSession(id)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        if (!validateSession(referenceId)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Reference session not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Get session data
        Json::Value session = sessionRepo_->getSession(id);
        Json::Value referenceSession = sessionRepo_->getSession(referenceId);
        
        // Prepare comparison result
        Json::Value comparison;
        comparison["session_id"] = id;
        comparison["reference_session_id"] = referenceId;
        comparison["session_info"] = session;
        comparison["reference_info"] = referenceSession;
        comparison["generated_at"] = drogon::utils::getFormattedDate();
        
        // Compare events if requested
        if (compareEvents) {
            std::vector<Json::Value> events = sessionRepo_->getSessionEvents(id, "", "", "");
            std::vector<Json::Value> referenceEvents = sessionRepo_->getSessionEvents(referenceId, "", "", "");
            
            comparison["event_comparison"] = analyticsProcessor_->compareEventSequences(events, referenceEvents);
        }
        
        // Compare metrics if requested
        if (compareMetrics) {
            std::vector<Json::Value> events = sessionRepo_->getSessionEvents(id, "", "", "");
            std::vector<Json::Value> referenceEvents = sessionRepo_->getSessionEvents(referenceId, "", "", "");
            
            Json::Value sessionMetrics = metricsCalculator_->calculateSessionMetrics(events);
            Json::Value referenceMetrics = metricsCalculator_->calculateSessionMetrics(referenceEvents);
            
            comparison["metrics_comparison"] = metricsCalculator_->compareMetrics(sessionMetrics, referenceMetrics);
        }
        
        // Add improvement suggestions
        comparison["improvement_suggestions"] = generateImprovementSuggestions(id, referenceId);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(comparison);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

// Helper methods
bool DebriefingSessionService::validateSession(const std::string& sessionId) {
    Json::Value session = sessionRepo_->getSession(sessionId);
    return !session.isNull();
}

std::string DebriefingSessionService::generateEventId() {
    // Generate a unique event ID
    auto now = std::chrono::system_clock::now();
    auto now_ms = std::chrono::time_point_cast<std::chrono::milliseconds>(now);
    auto epoch = now_ms.time_since_epoch();
    uint64_t timestamp = static_cast<uint64_t>(epoch.count());
    
    // Combine timestamp with a random number
    std::random_device rd;
    std::mt19937_64 gen(rd());
    std::uniform_int_distribution<uint64_t> dist;
    uint64_t random = dist(gen);
    
    std::stringstream ss;
    ss << "evt-" << std::hex << timestamp << "-" << random;
    return ss.str();
}

std::string DebriefingSessionService::generateAnnotationId() {
    // Generate a unique annotation ID
    auto now = std::chrono::system_clock::now();
    auto now_ms = std::chrono::time_point_cast<std::chrono::milliseconds>(now);
    auto epoch = now_ms.time_since_epoch();
    uint64_t timestamp = static_cast<uint64_t>(epoch.count());
    
    // Combine timestamp with a random number
    std::random_device rd;
    std::mt19937_64 gen(rd());
    std::uniform_int_distribution<uint64_t> dist;
    uint64_t random = dist(gen);
    
    std::stringstream ss;
    ss << "ann-" << std::hex << timestamp << "-" << random;
    return ss.str();
}

Json::Value DebriefingSessionService::analyzeEventSequence(const std::vector<Json::Value>& events) {
    // In a real implementation, this would analyze event sequences for patterns
    // For this example, we'll return a simplified analysis
    
    Json::Value analysis;
    analysis["event_count"] = static_cast<int>(events.size());
    
    // Count events by type
    std::map<std::string, int> eventTypeCounts;
    for (const auto& event : events) {
        std::string eventType = event["event_type"].asString();
        eventTypeCounts[eventType]++;
    }
    
    Json::Value eventCounts(Json::objectValue);
    for (const auto& pair : eventTypeCounts) {
        eventCounts[pair.first] = pair.second;
    }
    
    analysis["event_type_counts"] = eventCounts;
    
    // Detect patterns (simplified for example)
    Json::Value patterns(Json::arrayValue);
    
    // Look for repeated event types
    for (const auto& pair : eventTypeCounts) {
        if (pair.second > 3) {
            Json::Value pattern;
            pattern["type"] = "repeated_event";
            pattern["event_type"] = pair.first;
            pattern["count"] = pair.second;
            pattern["description"] = "Repeated occurrence of " + pair.first + " events";
            
            patterns.append(pattern);
        }
    }
    
    // In a real implementation, more sophisticated pattern detection would be done
    
    analysis["patterns"] = patterns;
    
    return analysis;
}

Json::Value DebriefingSessionService::detectAnomalies(const std::vector<Json::Value>& events) {
    // In a real implementation, this would use statistical methods to detect anomalies
    // For this example, we'll return a simplified analysis
    
    Json::Value anomalies(Json::arrayValue);
    
    // Detect long gaps between events
    if (events.size() >= 2) {
        for (size_t i = 1; i < events.size(); ++i) {
            // Parse timestamps
            std::string prevTime = events[i-1]["timestamp"].asString();
            std::string currTime = events[i]["timestamp"].asString();
            
            // Calculate time difference (simplified for example)
            // In a real implementation, proper timestamp parsing and comparison would be done
            if (currTime.length() > 19 && prevTime.length() > 19) {
                int prevSec = std::stoi(prevTime.substr(17, 2));
                int currSec = std::stoi(currTime.substr(17, 2));
                
                if (currSec - prevSec > 30) {
                    Json::Value anomaly;
                    anomaly["type"] = "time_gap";
                    anomaly["start_event"] = events[i-1]["event_id"];
                    anomaly["end_event"] = events[i]["event_id"];
                    anomaly["description"] = "Unusual time gap between events";
                    
                    anomalies.append(anomaly);
                }
            }
        }
    }
    
    // In a real implementation, more sophisticated anomaly detection would be done
    
    return anomalies;
}

Json::Value DebriefingSessionService::generateLearningPoints(const std::string& sessionId) {
    // In a real implementation, this would analyze session data to generate learning points
    // For this example, we'll return mock learning points
    
    Json::Value learningPoints(Json::arrayValue);
    
    // Get session events
    std::vector<Json::Value> events = sessionRepo_->getSessionEvents(sessionId, "", "", "");
    
    // Get session annotations
    std::vector<Json::Value> annotations = sessionRepo_->getAnnotations(sessionId, "", "");
    
    // Get critical events
    std::vector<Json::Value> criticalEvents;
    for (const auto& event : events) {
        if (event.isMember("critical") && event["critical"].asBool()) {
            criticalEvents.push_back(event);
        }
    }
    
    // Generate learning points from critical events
    for (const auto& event : criticalEvents) {
        Json::Value learningPoint;
        learningPoint["type"] = "critical_event";
        learningPoint["event_id"] = event["event_id"];
        learningPoint["description"] = "Learn from critical event: " + event["critical_reason"].asString();
        learningPoint["priority"] = "high";
        
        learningPoints.append(learningPoint);
    }
    
    // Generate learning points from annotations
    for (const auto& annotation : annotations) {
        if (annotation.isMember("learning_point") && annotation["learning_point"].asBool()) {
            Json::Value learningPoint;
            learningPoint["type"] = "annotation";
            learningPoint["annotation_id"] = annotation["annotation_id"];
            learningPoint["description"] = annotation["text"];
            learningPoint["priority"] = annotation.get("priority", "medium").asString();
            
            learningPoints.append(learningPoint);
        }
    }
    
    // Add mock general learning points
    Json::Value generalPoint1;
    generalPoint1["type"] = "general";
    generalPoint1["description"] = "Focus on maintaining situational awareness during high workload phases";
    generalPoint1["priority"] = "medium";
    learningPoints.append(generalPoint1);
    
    Json::Value generalPoint2;
    generalPoint2["type"] = "general";
    generalPoint2["description"] = "Improve cross-checking procedures for critical flight parameters";
    generalPoint2["priority"] = "high";
    learningPoints.append(generalPoint2);
    
    return learningPoints;
}

Json::Value DebriefingSessionService::extractProcedureCompliance(const std::vector<Json::Value>& events, const std::string& procedureType) {
    // In a real implementation, this would analyze events against standard procedures
    // For this example, we'll return mock procedure compliance data
    
    Json::Value compliance(Json::objectValue);
    
    // Map of procedure types to specific procedures
    std::map<std::string, std::vector<std::string>> procedureMap = {
        {"takeoff", {"Pre-takeoff checklist", "Takeoff roll procedure", "Initial climb procedure"}},
        {"landing", {"Approach checklist", "Final approach procedure", "Landing roll procedure"}},
        {"emergency", {"Engine failure procedure", "Cabin depressurization procedure", "Emergency descent procedure"}}
    };
    
    // Get relevant procedures for this session
    std::vector<std::string> relevantProcedures;
    
    if (procedureMap.find(procedureType) != procedureMap.end()) {
        relevantProcedures = procedureMap[procedureType];
    }
    else {
        // Default procedures if type not found
        relevantProcedures = {"Standard operating procedure", "Normal checklist procedure"};
    }
    
    // Generate mock compliance data
    Json::Value procedures(Json::arrayValue);
    
    for (const auto& procedure : relevantProcedures) {
        Json::Value proc;
        proc["name"] = procedure;
        
        // Generate random compliance percentage for example
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_int_distribution<> dis(70, 100);
        int compliancePercent = dis(gen);
        
        proc["compliance_percentage"] = compliancePercent;
        
        // Add steps based on compliance percentage
        Json::Value steps(Json::arrayValue);
        
        int stepCount = 5;  // Mock number of steps
        
        for (int i = 1; i <= stepCount; ++i) {
            Json::Value step;
            step["name"] = "Step " + std::to_string(i);
            
            // Random compliance for steps
            std::uniform_int_distribution<> stepDis(0, 100);
            int randomVal = stepDis(gen);
            
            // Higher chance of compliance if overall compliance is high
            bool completed = (randomVal < compliancePercent);
            
            step["completed"] = completed;
            
            if (!completed) {
                step["issue"] = "Step was not completed according to procedure";
            }
            
            steps.append(step);
        }
        
        proc["steps"] = steps;
        procedures.append(proc);
    }
    
    compliance["procedures"] = procedures;
    
    // Calculate overall compliance
    int totalProcedures = procedures.size();
    double totalCompliancePercent = 0.0;
    
    for (int i = 0; i < procedures.size(); ++i) {
        totalCompliancePercent += procedures[i]["compliance_percentage"].asDouble();
    }
    
    compliance["overall_compliance"] = totalCompliancePercent / totalProcedures;
    
    return compliance;
}

Json::Value DebriefingSessionService::generateImprovementSuggestions(const std::string& sessionId, const std::string& referenceId) {
    // In a real implementation, this would analyze the comparison data to generate suggestions
    // For this example, we'll return mock suggestions
    
    Json::Value suggestions(Json::arrayValue);
    
    // Get session data
    Json::Value session = sessionRepo_->getSession(sessionId);
    
    // Add mock suggestions based on session type
    if (session["training_type"].asString() == "takeoff") {
        Json::Value suggestion1;
        suggestion1["area"] = "Procedure";
        suggestion1["description"] = "Improve execution of pre-takeoff checklist for completeness";
        suggestion1["priority"] = "high";
        suggestions.append(suggestion1);
        
        Json::Value suggestion2;
        suggestion2["area"] = "Communication";
        suggestion2["description"] = "Enhance communication clarity during takeoff roll";
        suggestion2["priority"] = "medium";
        suggestions.append(suggestion2);
    }
    else if (session["training_type"].asString() == "landing") {
        Json::Value suggestion1;
        suggestion1["area"] = "Technical";
        suggestion1["description"] = "Work on maintaining stabilized approach parameters";
        suggestion1["priority"] = "high";
        suggestions.append(suggestion1);
        
        Json::Value suggestion2;
        suggestion2["area"] = "Decision Making";
        suggestion2["description"] = "Practice decision making for go-around criteria";
        suggestion2["priority"] = "high";
        suggestions.append(suggestion2);
    }
    else {
        Json::Value suggestion1;
        suggestion1["area"] = "General";
        suggestion1["description"] = "Focus on maintaining situational awareness during high workload phases";
        suggestion1["priority"] = "medium";
        suggestions.append(suggestion1);
        
        Json::Value suggestion2;
        suggestion2["area"] = "Procedure";
        suggestion2["description"] = "Improve adherence to standard operating procedures";
        suggestion2["priority"] = "high";
        suggestions.append(suggestion2);
    }
    
    return suggestions;
}

} // namespace debriefing
} // namespace atp

// Main application setup
int main() {
    // Configure Drogon app
    drogon::app().setLogPath("./")
                 .setLogLevel(trantor::Logger::kInfo)
                 .addListener("0.0.0.0", 8084)
                 .setThreadNum(16)
                 .run();
    
    return 0;
}

apiVersion: v1
kind: Namespace
metadata:
  name: pilot-training-platform
  labels:
    name: pilot-training-platform
---
# API Gateway Service
apiVersion: v1
kind: Service
metadata:
  name: api-gateway
  namespace: pilot-training-platform
spec:
  selector:
    app: api-gateway
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  namespace: pilot-training-platform
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: api-gateway
        image: advancedpilottraining/api-gateway:latest
        ports:
        - containerPort: 8080
        env:
        - name: AUTH_SERVICE_URL
          value: "http://auth-service:8080"
        - name: DOCUMENT_SERVICE_URL
          value: "http://document-service:8080"
        - name: SYLLABUS_SERVICE_URL
          value: "http://syllabus-service:8080"
        - name: ASSESSMENT_SERVICE_URL
          value: "http://assessment-service:8080"
        - name: ANALYTICS_SERVICE_URL
          value: "http://analytics-service:8080"
        - name: SCHEDULER_SERVICE_URL
          value: "http://scheduler-service:8080"
        resources:
          limits:
            cpu: "500m"
            memory: "512Mi"
          requests:
            cpu: "200m"
            memory: "256Mi"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
# Auth Service
apiVersion: v1
kind: Service
metadata:
  name: auth-service
  namespace: pilot-training-platform
spec:
  selector:
    app: auth-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: auth-service
  template:
    metadata:
      labels:
        app: auth-service
    spec:
      containers:
      - name: auth-service
        image: advancedpilottraining/auth-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: jwt-secret
              key: key
        - name: ENCRYPTION_KEY
          valueFrom:
            secretKeyRef:
              name: encryption-key
              key: key
        resources:
          limits:
            cpu: "300m"
            memory: "512Mi"
          requests:
            cpu: "150m"
            memory: "256Mi"
---
# Document Service
apiVersion: v1
kind: Service
metadata:
  name: document-service
  namespace: pilot-training-platform
spec:
  selector:
    app: document-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: document-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: document-service
  template:
    metadata:
      labels:
        app: document-service
    spec:
      containers:
      - name: document-service
        image: advancedpilottraining/document-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: STORAGE_BUCKET
          value: "advancedpilottraining-documents"
        - name: AI_SERVICE_URL
          value: "http://ai-service:8080"
        resources:
          limits:
            cpu: "1000m"
            memory: "1Gi"
          requests:
            cpu: "500m"
            memory: "512Mi"
        volumeMounts:
        - name: document-cache
          mountPath: /app/cache
      volumes:
      - name: document-cache
        emptyDir: {}
---
# Syllabus Service
apiVersion: v1
kind: Service
metadata:
  name: syllabus-service
  namespace: pilot-training-platform
spec:
  selector:
    app: syllabus-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: syllabus-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: syllabus-service
  template:
    metadata:
      labels:
        app: syllabus-service
    spec:
      containers:
      - name: syllabus-service
        image: advancedpilottraining/syllabus-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: DOCUMENT_SERVICE_URL
          value: "http://document-service:8080"
        - name: AI_SERVICE_URL
          value: "http://ai-service:8080"
        resources:
          limits:
            cpu: "500m"
            memory: "768Mi"
          requests:
            cpu: "250m"
            memory: "384Mi"
---
# Assessment Service
apiVersion: v1
kind: Service
metadata:
  name: assessment-service
  namespace: pilot-training-platform
spec:
  selector:
    app: assessment-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: assessment-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: assessment-service
  template:
    metadata:
      labels:
        app: assessment-service
    spec:
      containers:
      - name: assessment-service
        image: advancedpilottraining/assessment-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: SYLLABUS_SERVICE_URL
          value: "http://syllabus-service:8080"
        - name: AI_SERVICE_URL
          value: "http://ai-service:8080"
        resources:
          limits:
            cpu: "500m"
            memory: "768Mi"
          requests:
            cpu: "250m"
            memory: "384Mi"
---
# Analytics Service
apiVersion: v1
kind: Service
metadata:
  name: analytics-service
  namespace: pilot-training-platform
spec:
  selector:
    app: analytics-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: analytics-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: analytics-service
  template:
    metadata:
      labels:
        app: analytics-service
    spec:
      containers:
      - name: analytics-service
        image: advancedpilottraining/analytics-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: TIMESCALEDB_HOST
          valueFrom:
            secretKeyRef:
              name: timescaledb-credentials
              key: host
        - name: TIMESCALEDB_PORT
          valueFrom:
            secretKeyRef:
              name: timescaledb-credentials
              key: port
        - name: TIMESCALEDB_USER
          valueFrom:
            secretKeyRef:
              name: timescaledb-credentials
              key: username
        - name: TIMESCALEDB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: timescaledb-credentials
              key: password
        - name: AI_SERVICE_URL
          value: "http://ai-service:8080"
        resources:
          limits:
            cpu: "1000m"
            memory: "1.5Gi"
          requests:
            cpu: "500m"
            memory: "768Mi"
---
# Scheduler Service
apiVersion: v1
kind: Service
metadata:
  name: scheduler-service
  namespace: pilot-training-platform
spec:
  selector:
    app: scheduler-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: scheduler-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: scheduler-service
  template:
    metadata:
      labels:
        app: scheduler-service
    spec:
      containers:
      - name: scheduler-service
        image: advancedpilottraining/scheduler-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        resources:
          limits:
            cpu: "500m"
            memory: "768Mi"
          requests:
            cpu: "250m"
            memory: "384Mi"
---
# AI Service
apiVersion: v1
kind: Service
metadata:
  name: ai-service
  namespace: pilot-training-platform
spec:
  selector:
    app: ai-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: ai-service
  template:
    metadata:
      labels:
        app: ai-service
    spec:
      containers:
      - name: ai-service
        image: advancedpilottraining/ai-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: PYTHON_PATH
          value: "/usr/bin/python3"
        - name: SCRIPT_DIR
          value: "/app/ai-models"
        - name: ZMQ_ENDPOINT
          value: "tcp://*:5555"
        resources:
          limits:
            cpu: "2000m"
            memory: "4Gi"
          requests:
            cpu: "1000m"
            memory: "2Gi"
        volumeMounts:
        - name: ai-models
          mountPath: /app/ai-models
        - name: shared-memory
          mountPath: /dev/shm
      volumes:
      - name: ai-models
        persistentVolumeClaim:
          claimName: ai-models-pvc
      - name: shared-memory
        emptyDir:
          medium: Memory
---
# Workflow Engine Service
apiVersion: v1
kind: Service
metadata:
  name: workflow-service
  namespace: pilot-training-platform
spec:
  selector:
    app: workflow-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: workflow-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: workflow-service
  template:
    metadata:
      labels:
        app: workflow-service
    spec:
      containers:
      - name: workflow-service
        image: advancedpilottraining/workflow-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: DOCUMENT_SERVICE_URL
          value: "http://document-service:8080"
        - name: AI_SERVICE_URL
          value: "http://ai-service:8080"
        - name: NOTIFICATION_SERVICE_URL
          value: "http://notification-service:8080"
        resources:
          limits:
            cpu: "500m"
            memory: "768Mi"
          requests:
            cpu: "250m"
            memory: "384Mi"
---
# Notification Service
apiVersion: v1
kind: Service
metadata:
  name: notification-service
  namespace: pilot-training-platform
spec:
  selector:
    app: notification-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: notification-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: notification-service
  template:
    metadata:
      labels:
        app: notification-service
    spec:
      containers:
      - name: notification-service
        image: advancedpilottraining/notification-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: SMTP_HOST
          valueFrom:
            secretKeyRef:
              name: smtp-credentials
              key: host
        - name: SMTP_PORT
          valueFrom:
            secretKeyRef:
              name: smtp-credentials
              key: port
        - name: SMTP_USER
          valueFrom:
            secretKeyRef:
              name: smtp-credentials
              key: username
        - name: SMTP_PASSWORD
          valueFrom:
            secretKeyRef:
              name: smtp-credentials
              key: password
        resources:
          limits:
            cpu: "300m"
            memory: "512Mi"
          requests:
            cpu: "150m"
            memory: "256Mi"
---
# Collaboration Service
apiVersion: v1
kind: Service
metadata:
  name: collaboration-service
  namespace: pilot-training-platform
spec:
  selector:
    app: collaboration-service
  ports:
  - port: 8080
    targetPort: 8080
  - port: 8081
    targetPort: 8081
    name: websocket
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: collaboration-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: collaboration-service
  template:
    metadata:
      labels:
        app: collaboration-service
    spec:
      containers:
      - name: collaboration-service
        image: advancedpilottraining/collaboration-service:latest
        ports:
        - containerPort: 8080
        - containerPort: 8081
          name: websocket
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: REDIS_HOST
          valueFrom:
            secretKeyRef:
              name: redis-credentials
              key: host
        - name: REDIS_PORT
          valueFrom:
            secretKeyRef:
              name: redis-credentials
              key: port
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: redis-credentials
              key: password
        resources:
          limits:
            cpu: "800m"
            memory: "1Gi"
          requests:
            cpu: "400m"
            memory: "512Mi"
---
# Persistent Volume Claims
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ai-models-pvc
  namespace: pilot-training-platform
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
  storageClassName: managed-nfs-storage
---
# Secrets
apiVersion: v1
kind: Secret
metadata:
  name: db-credentials
  namespace: pilot-training-platform
type: Opaque
data:
  host: cG9zdGdyZXMuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbA== # postgres.default.svc.cluster.local
  port: NTQzMg== # 5432
  username: YWRtaW4= # admin
  password: Y2hhbmdlbWU= # changeme
---
apiVersion: v1
kind: Secret
metadata:
  name: timescaledb-credentials
  namespace: pilot-training-platform
type: Opaque
data:
  host: dGltZXNjYWxlZGIuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbA== # timescaledb.default.svc.cluster.local
  port: NTQzMg== # 5432
  username: YWRtaW4= # admin
  password: Y2hhbmdlbWU= # changeme
---
apiVersion: v1
kind: Secret
metadata:
  name: jwt-secret
  namespace: pilot-training-platform
type: Opaque
data:
  key: Y2hhbmdlbWVjaGFuZ2VtZWNoYW5nZW1lY2hhbmdlbWVjaGFuZ2VtZWNoYW5nZW1lY2hhbmdlbWU= # changemechangemechangemechangemechangemechangeme
---
apiVersion: v1
kind: Secret
metadata:
  name: encryption-key
  namespace: pilot-training-platform
type: Opaque
data:
  key: MWYyZDFlMmU2N2E5YjhiNGY3YThjOTRkZWE4YTBlYTU= # 1f2d1e2e67a9b8b4f7a8c94dea8a0ea5
---
apiVersion: v1
kind: Secret
metadata:
  name: smtp-credentials
  namespace: pilot-training-platform
type: Opaque
data:
  host: c210cC5leGFtcGxlLmNvbQ== # smtp.example.com
  port: NTg3 # 587
  username: bm90aWZpY2F0aW9ucw== # notifications
  password: Y2hhbmdlbWU= # changeme
---
apiVersion: v1
kind: Secret
metadata:
  name: redis-credentials
  namespace: pilot-training-platform
type: Opaque
data:
  host: cmVkaXMuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbA== # redis.default.svc.cluster.local
  port: NjM3OQ== # 6379
  password: Y2hhbmdlbWU= # changeme
---
# Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: pilot-training-platform-ingress
  namespace: pilot-training-platform
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
spec:
  tls:
  - hosts:
    - api.pilottrainingplatform.com
    secretName: pilot-training-tls
  rules:
  - host: api.pilottrainingplatform.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: api-gateway
            port:
              number: 80
---
# ConfigMaps
apiVersion: v1
kind: ConfigMap
metadata:
  name: logging-config
  namespace: pilot-training-platform
data:
  log-level: "info"
  log-format: "json"
---
# Horizontal Pod Autoscaler
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-gateway-hpa
  namespace: pilot-training-platform
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-gateway
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 80
---
# Blue-Green Deployment Configuration (using Argo Rollouts)
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: api-gateway-rollout
  namespace: pilot-training-platform
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: api-gateway
        image: advancedpilottraining/api-gateway:latest
        ports:
        - containerPort: 8080
        env:
        - name: AUTH_SERVICE_URL
          value: "http://auth-service:8080"
        - name: DOCUMENT_SERVICE_URL
          value: "http://document-service:8080"
        - name: SYLLABUS_SERVICE_URL
          value: "http://syllabus-service:8080"
        - name: ASSESSMENT_SERVICE_URL
          value: "http://assessment-service:8080"
        - name: ANALYTICS_SERVICE_URL
          value: "http://analytics-service:8080"
        - name: SCHEDULER_SERVICE_URL
          value: "http://scheduler-service:8080"
        resources:
          limits:
            cpu: "500m"
            memory: "512Mi"
          requests:
            cpu: "200m"
            memory: "256Mi"
  strategy:
    blueGreen:
      activeService: api-gateway
      previewService: api-gateway-preview
      autoPromotionEnabled: false
---
# Centralized Logging with Fluentd
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: pilot-training-platform
  labels:
    app: fluentd
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      serviceAccount: fluentd
      serviceAccountName: fluentd
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1.14-debian-elasticsearch7-1
        env:
          - name: FLUENT_ELASTICSEARCH_HOST
            value: "elasticsearch.logging"
          - name: FLUENT_ELASTICSEARCH_PORT
            value: "9200"
          - name: FLUENT_ELASTICSEARCH_SCHEME
            value: "http"
          - name: FLUENTD_SYSTEMD_CONF
            value: "disable"
        resources:
          limits:
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config-volume
          mountPath: /fluentd/etc/fluent.conf
          subPath: fluent.conf
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config-volume
        configMap:
          name: fluentd-config
---
# ServiceAccount for Fluentd
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: pilot-training-platform
---
# Role for Fluentd
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluentd
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch
---
# RoleBinding for Fluentd
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: fluentd
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: fluentd
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: pilot-training-platform
apiVersion: v1
kind: Namespace
metadata:
  name: pilot-training-platform
  labels:
    name: pilot-training-platform
---
# API Gateway Service
apiVersion: v1
kind: Service
metadata:
  name: api-gateway
  namespace: pilot-training-platform
spec:
  selector:
    app: api-gateway
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  namespace: pilot-training-platform
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: api-gateway
        image: advancedpilottraining/api-gateway:latest
        ports:
        - containerPort: 8080
        env:
        - name: AUTH_SERVICE_URL
          value: "http://auth-service:8080"
        - name: DOCUMENT_SERVICE_URL
          value: "http://document-service:8080"
        - name: SYLLABUS_SERVICE_URL
          value: "http://syllabus-service:8080"
        - name: ASSESSMENT_SERVICE_URL
          value: "http://assessment-service:8080"
        - name: ANALYTICS_SERVICE_URL
          value: "http://analytics-service:8080"
        - name: SCHEDULER_SERVICE_URL
          value: "http://scheduler-service:8080"
        resources:
          limits:
            cpu: "500m"
            memory: "512Mi"
          requests:
            cpu: "200m"
            memory: "256Mi"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
---
# Auth Service
apiVersion: v1
kind: Service
metadata:
  name: auth-service
  namespace: pilot-training-platform
spec:
  selector:
    app: auth-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: auth-service
  template:
    metadata:
      labels:
        app: auth-service
    spec:
      containers:
      - name: auth-service
        image: advancedpilottraining/auth-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: jwt-secret
              key: key
        - name: ENCRYPTION_KEY
          valueFrom:
            secretKeyRef:
              name: encryption-key
              key: key
        resources:
          limits:
            cpu: "300m"
            memory: "512Mi"
          requests:
            cpu: "150m"
            memory: "256Mi"
---
# Document Service
apiVersion: v1
kind: Service
metadata:
  name: document-service
  namespace: pilot-training-platform
spec:
  selector:
    app: document-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: document-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: document-service
  template:
    metadata:
      labels:
        app: document-service
    spec:
      containers:
      - name: document-service
        image: advancedpilottraining/document-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: STORAGE_BUCKET
          value: "advancedpilottraining-documents"
        - name: AI_SERVICE_URL
          value: "http://ai-service:8080"
        resources:
          limits:
            cpu: "1000m"
            memory: "1Gi"
          requests:
            cpu: "500m"
            memory: "512Mi"
        volumeMounts:
        - name: document-cache
          mountPath: /app/cache
      volumes:
      - name: document-cache
        emptyDir: {}
---
# Syllabus Service
apiVersion: v1
kind: Service
metadata:
  name: syllabus-service
  namespace: pilot-training-platform
spec:
  selector:
    app: syllabus-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: syllabus-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: syllabus-service
  template:
    metadata:
      labels:
        app: syllabus-service
    spec:
      containers:
      - name: syllabus-service
        image: advancedpilottraining/syllabus-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: DOCUMENT_SERVICE_URL
          value: "http://document-service:8080"
        - name: AI_SERVICE_URL
          value: "http://ai-service:8080"
        resources:
          limits:
            cpu: "500m"
            memory: "768Mi"
          requests:
            cpu: "250m"
            memory: "384Mi"
---
# Assessment Service
apiVersion: v1
kind: Service
metadata:
  name: assessment-service
  namespace: pilot-training-platform
spec:
  selector:
    app: assessment-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: assessment-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: assessment-service
  template:
    metadata:
      labels:
        app: assessment-service
    spec:
      containers:
      - name: assessment-service
        image: advancedpilottraining/assessment-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: SYLLABUS_SERVICE_URL
          value: "http://syllabus-service:8080"
        - name: AI_SERVICE_URL
          value: "http://ai-service:8080"
        resources:
          limits:
            cpu: "500m"
            memory: "768Mi"
          requests:
            cpu: "250m"
            memory: "384Mi"
---
# Analytics Service
apiVersion: v1
kind: Service
metadata:
  name: analytics-service
  namespace: pilot-training-platform
spec:
  selector:
    app: analytics-service
  ports:
  - port: 8080
    targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: analytics-service
  namespace: pilot-training-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: analytics-service
  template:
    metadata:
      labels:
        app: analytics-service
    spec:
      containers:
      - name: analytics-service
        image: advancedpilottraining/analytics-service:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PORT
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: port
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        - name: TIMESCALEDB_HOST
          valueFrom:
            secretKeyRef:
              name: timescaledb-credentials
              key: host
        - name: TIMESCALEDB_PORT
          valueFrom:
            secretKeyRef:
              name: timescaledb-credentials
              key: port
        - name: TIMESCALEDB_USER
          valueFrom:
            secretKeyRef:
              name: timescaledb-credentials
              key: username
        - name: TIMESCALEDB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: timescaledb-credentials
              key: password
        - name: AI_SERVICE_URL
          value: "http://ai-service:8080"
        resources:
          limits:
            cpu: "1000m"
            memory: "1.5Gi"
          requests:
            cpu: "500m"
            memory: "768Mi"
---
# Scheduler Service
apiVersion:
version: '3.8'

services:
  # API Gateway
  api-gateway:
    build:
      context: ./api-gateway
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - SERVICE_REGISTRY_CONFIG=/app/config/services.json
      - JWT_SECRET=${JWT_SECRET}
      - LOG_LEVEL=info
    volumes:
      - ./config:/app/config
    depends_on:
      - auth-service
      - document-service
      - syllabus-service
      - compliance-service
      - debriefing-service
      - admin-dashboard
      - gamification-service
      - community-service
      - analytics-service
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Auth Service
  auth-service:
    build:
      context: ./auth-service
      dockerfile: Dockerfile
    ports:
      - "8083:8083"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=atp_auth
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - JWT_SECRET=${JWT_SECRET}
      - JWT_EXPIRY=3600
      - REFRESH_TOKEN_EXPIRY=2592000
      - LOG_LEVEL=info
    depends_on:
      - postgres
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Document Intelligence Service
  document-service:
    build:
      context: ./document-service
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=atp_documents
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - NLP_SERVICE_URL=http://nlp-service:5000
      - LOG_LEVEL=info
    volumes:
      - document-storage:/app/storage
    depends_on:
      - postgres
      - nlp-service
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # NLP Service for Document Intelligence
  nlp-service:
    build:
      context: ./nlp-service
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    environment:
      - MODEL_DIR=/app/models
      - DATA_DIR=/app/data
      - LOG_LEVEL=info
    volumes:
      - nlp-models:/app/models
      - nlp-data:/app/data
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s # Longer start period for model loading
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G

  # Syllabus Template System
  syllabus-service:
    build:
      context: ./syllabus-service
      dockerfile: Dockerfile
    ports:
      - "8081:8081"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=atp_syllabus
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - LOG_LEVEL=info
    depends_on:
      - postgres
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Compliance Service
  compliance-service:
    build:
      context: ./compliance-service
      dockerfile: Dockerfile
    ports:
      - "8082:8082"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=atp_compliance
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - LOG_LEVEL=info
    depends_on:
      - postgres
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Debriefing & Session Analytics Service
  debriefing-service:
    build:
      context: ./debriefing-service
      dockerfile: Dockerfile
    ports:
      - "8084:8084"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=atp_debriefing
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - LOG_LEVEL=info
    depends_on:
      - postgres
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8084/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Admin Dashboard Service
  admin-dashboard:
    build:
      context: ./admin-dashboard
      dockerfile: Dockerfile
    ports:
      - "8085:8085"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=atp_admin
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - LOG_LEVEL=info
    depends_on:
      - postgres
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8085/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Gamification Service
  gamification-service:
    build:
      context: ./gamification-service
      dockerfile: Dockerfile
    ports:
      - "8086:8086"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=atp_gamification
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - LOG_LEVEL=info
    depends_on:
      - postgres
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Community Service
  community-service:
    build:
      context: ./community-service
      dockerfile: Dockerfile
    ports:
      - "8087:8087"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=atp_community
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - LOG_LEVEL=info
    depends_on:
      - postgres
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8087/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Analytics Service
  analytics-service:
    build:
      context: ./analytics-service
      dockerfile: Dockerfile
    ports:
      - "5001:5001"
    environment:
      - MODEL_DIR=/app/models
      - DATA_DIR=/app/data
      - LOG_LEVEL=info
    volumes:
      - analytics-models:/app/models
      - analytics-data:/app/data
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s # Longer start period for model loading
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G

  # PostgreSQL Database
  postgres:
    image: postgres:14-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_MULTIPLE_DATABASES=atp_auth,atp_documents,atp_syllabus,atp_compliance,atp_debriefing,atp_admin,atp_gamification,atp_community
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/create-multiple-postgresql-databases.sh:/docker-entrypoint-initdb.d/create-multiple-postgresql-databases.sh
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching and rate limiting
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Elasticsearch for search functionality
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.4
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Prometheus for monitoring
  prometheus:
    image: prom/prometheus:v2.46.0
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.console.libraries=/usr/share/prometheus/console_libraries
      - --web.console.templates=/usr/share/prometheus/consoles
    networks:
      - atp-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "-", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Grafana for dashboards
  grafana:
    image: grafana/grafana:10.1.5
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
    networks:
      - atp-network
    restart: unless-stopped
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "-", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

volumes:
  postgres-data:
  redis-data:
  elasticsearch-data:
  document-storage:
  nlp-models:
  nlp-data:
  analytics-models:
  analytics-data:
  prometheus-data:
  grafana-data:

networks:
  atp-network:
    driver: bridge

# /.github/workflows/backend-ci.yml
name: Backend CI

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '.github/workflows/backend-ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '.github/workflows/backend-ci.yml'

jobs:
  build-and-test-cpp:
    runs-on: ubuntu-latest
    container: gcc:latest

    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_USER: postgres
          POSTGRES_DB: pilot_training_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@v3

    - name: Install dependencies
      run: |
        apt-get update
        apt-get install -y cmake build-essential libssl-dev zlib1g-dev libpq-dev
        apt-get install -y libgtest-dev libbenchmark-dev
        cd /usr/src/googletest
        cmake .
        make
        cp -a lib/. /usr/lib/

    - name: Configure CMake
      working-directory: ${{github.workspace}}/backend
      run: |
        mkdir -p build
        cd build
        cmake ..

    - name: Build
      working-directory: ${{github.workspace}}/backend/build
      run: make -j$(nproc)

    - name: Run tests
      working-directory: ${{github.workspace}}/backend/build
      run: |
        ctest --verbose
        ./tests/unit_tests
        ./tests/integration_tests

    - name: Run benchmarks
      working-directory: ${{github.workspace}}/backend/build
      run: ./tests/performance_benchmarks --benchmark_out=benchmark_results.json

    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: ${{github.workspace}}/backend/build/benchmark_results.json

  build-and-test-python:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov
        pip install -r backend/python/requirements.txt
        
    - name: Run tests
      working-directory: ${{github.workspace}}/backend
      run: |
        python -m pytest python/tests/ --cov=python --cov-report=xml
        
    - name: Upload coverage report
      uses: codecov/codecov-action@v3
      with:
        file: ${{github.workspace}}/backend/coverage.xml

  docker-build:
    needs: [build-and-test-cpp, build-and-test-python]
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
      
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Build and push backend image
      uses: docker/build-push-action@v4
      with:
        context: ./backend
        push: true
        tags: |
          ghcr.io/${{ github.repository }}/backend:latest
          ghcr.io/${{ github.repository }}/backend:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

# /.github/workflows/frontend-ci.yml
name: Frontend CI

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'frontend/**'
      - '.github/workflows/frontend-ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'frontend/**'
      - '.github/workflows/frontend-ci.yml'

jobs:
  lint-and-test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
        
    - name: Install dependencies
      working-directory: ${{github.workspace}}/frontend
      run: npm ci
      
    - name: Lint
      working-directory: ${{github.workspace}}/frontend
      run: npm run lint
      
    - name: Build
      working-directory: ${{github.workspace}}/frontend
      run: npm run build
      
    - name: Test
      working-directory: ${{github.workspace}}/frontend
      run: npm test -- --coverage
      
    - name: Upload coverage report
      uses: codecov/codecov-action@v3
      with:
        directory: ${{github.workspace}}/frontend/coverage

  e2e-tests:
    runs-on: ubuntu-latest
    needs: lint-and-test
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
        
    - name: Install dependencies
      working-directory: ${{github.workspace}}/frontend
      run: npm ci
      
    - name: Cypress run
      uses: cypress-io/github-action@v5
      with:
        working-directory: frontend
        build: npm run build
        start: npm start
        wait-on: 'http://localhost:3000'
        
    - name: Upload screenshots
      uses: actions/upload-artifact@v3
      if: failure()
      with:
        name: cypress-screenshots
        path: frontend/cypress/screenshots

  deploy-vercel:
    runs-on: ubuntu-latest
    needs: e2e-tests
    if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to Vercel
      uses: amondnet/vercel-action@v25
      with:
        vercel-token: ${{ secrets.VERCEL_TOKEN }}
        vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}
        vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}
        working-directory: ./frontend
        vercel-args: '--prod'

# /backend/Dockerfile
FROM gcc:latest as builder

WORKDIR /app

# Install dependencies
RUN apt-get update && apt-get install -y \
    cmake \
    build-essential \
    libssl-dev \
    zlib1g-dev \
    libpq-dev \
    python3 \
    python3-pip \
    python3-dev

# Copy C++ source code
COPY . .

# Build C++ components
RUN mkdir -p build && \
    cd build && \
    cmake .. && \
    make -j$(nproc)

# Install Python dependencies
WORKDIR /app/python
RUN pip3 install --no-cache-dir -r requirements.txt

# Second stage: Runtime image
FROM debian:bullseye-slim

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    libssl1.1 \
    libpq5 \
    python3 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Copy built artifacts from builder stage
COPY --from=builder /app/build/bin /app/bin
COPY --from=builder /app/python /app/python

# Set environment variables
ENV PYTHONPATH=/app

# Set working directory
WORKDIR /app

# Start the service
CMD ["/app/bin/pilot_training_platform"]

# /frontend/.dockerignore
node_modules
.next
out
.git
.github
cypress
coverage
.env*

# /frontend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files
COPY package.json package-lock.json ./

# Install dependencies
RUN npm ci

# Copy source code
COPY . .

# Build application
RUN npm run build

# Second stage: Runtime image
FROM node:18-alpine

WORKDIR /app

# Copy built application
COPY --from=builder /app/package.json /app/package-lock.json ./
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/.next ./.next
COPY --from=builder /app/public ./public

# Set environment variables
ENV NODE_ENV=production

# Start the application
CMD ["npm", "start"]

# /docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:13
    restart: always
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_DB: ${DB_NAME}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app-network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: always
    depends_on:
      - postgres
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_NAME=${DB_NAME}
      - API_KEY=${API_KEY}
      - JWT_SECRET=${JWT_SECRET}
    ports:
      - "8080:8080"
    networks:
      - app-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    restart: always
    depends_on:
      - backend
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8080
    ports:
      - "3000:3000"
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  postgres-data:

# Dockerfile
FROM ubuntu:22.04 AS builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    libssl-dev \
    libpq-dev \
    libboost-all-dev \
    libjsoncpp-dev \
    uuid-dev \
    zlib1g-dev \
    pkg-config \
    libspdlog-dev \
    python3-dev \
    python3-pip \
    python3-venv \
    wget \
    curl

# Install Drogon framework
WORKDIR /tmp
RUN git clone https://github.com/drogonframework/drogon
WORKDIR /tmp/drogon
RUN git checkout v1.8.3 && \
    mkdir build && \
    cd build && \
    cmake .. && \
    make -j$(nproc) && \
    make install

# Install nlohmann_json
WORKDIR /tmp
RUN git clone https://github.com/nlohmann/json.git
WORKDIR /tmp/json
RUN git checkout v3.11.2 && \
    mkdir build && \
    cd build && \
    cmake .. && \
    make -j$(nproc) && \
    make install

# Set up application
WORKDIR /app
COPY . /app/

# Build C++ components
RUN mkdir -p /app/build
WORKDIR /app/build
RUN cmake .. && \
    make -j$(nproc)

# Set up Python environment
WORKDIR /app
RUN python3 -m venv /app/venv
ENV PATH="/app/venv/bin:$PATH"
RUN pip install --upgrade pip && \
    pip install -r requirements.txt

# Final stage with runtime dependencies
FROM ubuntu:22.04

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    libssl-dev \
    libpq-dev \
    libboost-system-dev \
    libboost-filesystem-dev \
    libjsoncpp-dev \
    uuid-runtime \
    zlib1g \
    python3 \
    python3-venv \
    tesseract-ocr \
    && rm -rf /var/lib/apt/lists/*

# Copy built binaries and Python environment
COPY --from=builder /app/build/aptp_server /usr/local/bin/
COPY --from=builder /app/venv /app/venv
COPY --from=builder /app/ai-modules /app/ai-modules
COPY --from=builder /app/config /app/config
COPY --from=builder /app/public /app/public

# Set up environment
ENV PATH="/app/venv/bin:$PATH"
ENV PYTHONPATH=/app
WORKDIR /app

# Expose port
EXPOSE 8080

# Command to run the server
CMD ["aptp_server"]

# docker-compose.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: aptp_server
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      - APTP_DB_HOST=postgres
      - APTP_DB_PORT=5432
      - APTP_DB_USER=aptp_user
      - APTP_DB_PASSWORD=aptp_password
      - APTP_DB_NAME=aptp_db
      - APTP_LOG_LEVEL=info
      - APTP_API_PORT=8080
      - APTP_API_HOST=0.0.0.0
      - APTP_ENABLE_SSL=false
      - APTP_JWT_SECRET=change_this_to_a_secure_secret
    volumes:
      - ./data:/app/data
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    depends_on:
      - postgres
      - redis

  postgres:
    image: timescale/timescaledb:latest-pg13
    container_name: aptp_postgres
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=aptp_user
      - POSTGRES_PASSWORD=aptp_password
      - POSTGRES_DB=aptp_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql

  redis:
    image: redis:6-alpine
    container_name: aptp_redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:

# requirements.txt
# Core dependencies
numpy>=1.20.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0

# NLP and document processing
nltk>=3.6.0
beautifulsoup4>=4.9.0
requests>=2.25.0
PyPDF2>=2.0.0
python-docx>=0.8.10
openpyxl>=3.0.7
pytesseract>=0.3.8
Pillow>=8.2.0

# Deep learning
torch>=1.9.0
transformers>=4.8.0
tensorflow>=2.5.0

# Time series analysis and forecasting
prophet>=1.0.0
statsmodels>=0.12.0
xgboost>=1.4.0

# Web and API 
flask>=2.0.0
gunicorn>=20.1.0
pyjwt>=2.1.0

# Database
psycopg2-binary>=2.9.0
sqlalchemy>=1.4.0
redis>=3.5.3

# Utilities
tqdm>=4.61.0
pyyaml>=5.4.0
schedule>=1.1.0

# sql/init.sql
-- Initialize database for Advanced Pilot Training Platform

-- Enable TimescaleDB extension
CREATE EXTENSION IF NOT EXISTS timescaledb;

-- Create schema
CREATE SCHEMA IF NOT EXISTS aptp;

-- Set search path
SET search_path TO aptp, public;

-- User management tables
CREATE TABLE IF NOT EXISTS users (
    id VARCHAR(36) PRIMARY KEY,
    username VARCHAR(255) NOT NULL UNIQUE,
    email VARCHAR(255) NOT NULL UNIQUE,
    password_hash VARCHAR(512) NOT NULL,
    first_name VARCHAR(255),
    last_name VARCHAR(255),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_login TIMESTAMP WITH TIME ZONE,
    status VARCHAR(20) DEFAULT 'active',
    metadata JSONB
);

CREATE TABLE IF NOT EXISTS roles (
    id VARCHAR(36) PRIMARY KEY,
    name VARCHAR(255) NOT NULL UNIQUE,
    description TEXT,
    permissions JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE TABLE IF NOT EXISTS user_roles (
    user_id VARCHAR(36) REFERENCES users(id) ON DELETE CASCADE,
    role_id VARCHAR(36) REFERENCES roles(id) ON DELETE CASCADE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    PRIMARY KEY (user_id, role_id)
);

-- Document management tables
CREATE TABLE IF NOT EXISTS documents (
    id VARCHAR(36) PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    file_path VARCHAR(512),
    file_type VARCHAR(50),
    file_size BIGINT,
    owner_id VARCHAR(36) REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    content_text TEXT,
    metadata JSONB
);

CREATE TABLE IF NOT EXISTS document_analysis (
    id VARCHAR(36) PRIMARY KEY,
    document_id VARCHAR(36) REFERENCES documents(id) ON DELETE CASCADE,
    analysis_type VARCHAR(50),
    analysis_result JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Syllabus management tables
CREATE TABLE IF NOT EXISTS syllabus (
    id VARCHAR(36) PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    version VARCHAR(50),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_by VARCHAR(36) REFERENCES users(id),
    status VARCHAR(20) DEFAULT 'draft',
    metadata JSONB
);

CREATE TABLE IF NOT EXISTS modules (
    id VARCHAR(36) PRIMARY KEY,
    syllabus_id VARCHAR(36) REFERENCES syllabus(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    sequence_number INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB
);

CREATE TABLE IF NOT EXISTS lessons (
    id VARCHAR(36) PRIMARY KEY,
    module_id VARCHAR(36) REFERENCES modules(id) ON DELETE CASCADE,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    sequence_number INTEGER,
    duration_minutes INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB
);

CREATE TABLE IF NOT EXISTS learning_objectives (
    id VARCHAR(36) PRIMARY KEY,
    lesson_id VARCHAR(36) REFERENCES lessons(id) ON DELETE CASCADE,
    description TEXT NOT NULL,
    competency_level VARCHAR(50),
    sequence_number INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB
);

-- Assessment tables
CREATE TABLE IF NOT EXISTS assessment_forms (
    id VARCHAR(36) PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    syllabus_id VARCHAR(36) REFERENCES syllabus(id),
    module_id VARCHAR(36) REFERENCES modules(id),
    lesson_id VARCHAR(36) REFERENCES lessons(id),
    criteria JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    created_by VARCHAR(36) REFERENCES users(id),
    metadata JSONB
);

CREATE TABLE IF NOT EXISTS assessments (
    id VARCHAR(36) PRIMARY KEY,
    form_id VARCHAR(36) REFERENCES assessment_forms(id),
    trainee_id VARCHAR(36) REFERENCES users(id),
    instructor_id VARCHAR(36) REFERENCES users(id),
    status VARCHAR(20),
    scheduled_time TIMESTAMP WITH TIME ZONE,
    start_time TIMESTAMP WITH TIME ZONE,
    completion_time TIMESTAMP WITH TIME ZONE,
    grades JSONB,
    feedback JSONB,
    attached_media JSONB,
    biometric_data JSONB,
    trainee_signature JSONB,
    instructor_signature JSONB,
    metadata JSONB
);

-- Scheduler tables
CREATE TABLE IF NOT EXISTS scheduled_sessions (
    id VARCHAR(36) PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    type VARCHAR(50),
    start_time TIMESTAMP WITH TIME ZONE,
    end_time TIMESTAMP WITH TIME ZONE,
    location_id VARCHAR(36),
    syllabus_id VARCHAR(36) REFERENCES syllabus(id),
    module_id VARCHAR(36) REFERENCES modules(id),
    lesson_id VARCHAR(36) REFERENCES lessons(id),
    instructor_ids JSONB,
    trainee_ids JSONB,
    resource_ids JSONB,
    status VARCHAR(20),
    previous_session_id VARCHAR(36),
    next_session_id VARCHAR(36),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB
);

CREATE TABLE IF NOT EXISTS resource_availability (
    id VARCHAR(36) PRIMARY KEY,
    resource_id VARCHAR(36),
    resource_type VARCHAR(50),
    start_time TIMESTAMP WITH TIME ZONE,
    end_time TIMESTAMP WITH TIME ZONE,
    is_available BOOLEAN,
    restriction_reason TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB
);

-- Analytics tables
CREATE TABLE IF NOT EXISTS analytics_metrics (
    id VARCHAR(36) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    type INTEGER,
    data_type INTEGER,
    unit VARCHAR(50),
    formula TEXT,
    aggregation_method VARCHAR(50),
    time_aggregation INTEGER,
    category INTEGER,
    is_real_time BOOLEAN,
    is_visible BOOLEAN,
    related_metrics JSONB,
    tags JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB
);

CREATE TABLE IF NOT EXISTS analytics_data (
    id VARCHAR(36),
    metric_id VARCHAR(36) REFERENCES analytics_metrics(id),
    dimension_id VARCHAR(36),
    entity_id VARCHAR(36),
    entity_type VARCHAR(50),
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    value DOUBLE PRECISION,
    tags JSONB,
    metadata JSONB
);

-- Make analytics_data a hypertable
SELECT create_hypertable('analytics_data', 'timestamp');

-- Compliance tables
CREATE TABLE IF NOT EXISTS compliance_requirements (
    id VARCHAR(36) PRIMARY KEY,
    framework INTEGER,
    custom_framework VARCHAR(100),
    section_id VARCHAR(100),
    title VARCHAR(255) NOT NULL,
    description TEXT,
    tags JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB
);

CREATE TABLE IF NOT EXISTS compliance_assessments (
    id VARCHAR(36) PRIMARY KEY,
    requirement_id VARCHAR(36) REFERENCES compliance_requirements(id),
    resource_type VARCHAR(50),
    resource_id VARCHAR(36),
    status INTEGER,
    assessor_id VARCHAR(36) REFERENCES users(id),
    assessment_date TIMESTAMP WITH TIME ZONE,
    justification TEXT,
    evidence_ids JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    metadata JSONB
);

-- Create views
CREATE OR REPLACE VIEW active_courses AS
SELECT 
    s.id AS syllabus_id,
    s.title AS syllabus_title,
    s.description,
    s.version,
    s.status,
    COUNT(DISTINCT m.id) AS module_count,
    COUNT(DISTINCT l.id) AS lesson_count,
    COUNT(DISTINCT lo.id) AS objective_count
FROM 
    syllabus s
    LEFT JOIN modules m ON s.id = m.syllabus_id
    LEFT JOIN lessons l ON m.id = l.module_id
    LEFT JOIN learning_objectives lo ON l.id = lo.lesson_id
WHERE 
    s.status = 'active'
GROUP BY 
    s.id, s.title, s.description, s.version, s.status;

CREATE OR REPLACE VIEW trainee_performance AS
SELECT 
    a.trainee_id,
    u.first_name || ' ' || u.last_name AS trainee_name,
    af.syllabus_id,
    s.title AS syllabus_title,
    COUNT(a.id) AS assessment_count,
    AVG((a.grades->>'average_score')::float) AS average_score,
    MIN(a.completion_time) AS first_assessment,
    MAX(a.completion_time) AS latest_assessment
FROM 
    assessments a
    JOIN users u ON a.trainee_id = u.id
    JOIN assessment_forms af ON a.form_id = af.id
    JOIN syllabus s ON af.syllabus_id = s.id
WHERE 
    a.status = 'completed'
GROUP BY 
    a.trainee_id, trainee_name, af.syllabus_id, s.title;

-- Create indexes
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_documents_owner_id ON documents(owner_id);
CREATE INDEX idx_documents_title ON documents(title);
CREATE INDEX idx_modules_syllabus_id ON modules(syllabus_id);
CREATE INDEX idx_lessons_module_id ON lessons(module_id);
CREATE INDEX idx_learning_objectives_lesson_id ON learning_objectives(lesson_id);
CREATE INDEX idx_assessments_trainee_id ON assessments(trainee_id);
CREATE INDEX idx_assessments_instructor_id ON assessments(instructor_id);
CREATE INDEX idx_scheduled_sessions_start_time ON scheduled_sessions(start_time);
CREATE INDEX idx_analytics_data_metric_id_timestamp ON analytics_data(metric_id, timestamp);

-- Insert initial roles
INSERT INTO roles (id, name, description, permissions)
VALUES 
    ('role-admin', 'Administrator', 'Full system administration access', '["*"]'),
    ('role-instructor', 'Instructor', 'Access to teaching and assessment features', '["DocumentView", "DocumentCreate", "SyllabusView", "AssessmentView", "AssessmentCreate", "AssessmentGrade", "AnalyticsView"]'),
    ('role-trainee', 'Trainee', 'Limited access for students', '["DocumentView", "SyllabusView", "AnalyticsView"]'),
    ('role-scheduler', 'Scheduler', 'Access to scheduling features', '["SyllabusView", "DocumentView", "SchedulerView", "SchedulerCreate", "SchedulerEdit"]')
ON CONFLICT (name) DO NOTHING;

-- Insert admin user (password: admin123 - change in production!)
INSERT INTO users (id, username, email, password_hash, first_name, last_name, status)
VALUES (
    'user-admin',
    'admin',
    'admin@example.com',
    -- This is a placeholder hash, replace with a proper bcrypt hash in production
    '$2a$12$K8GpYeWkOx0hJusA9RzQP.LzcwoCfHL3Z.Ae6QOmGGJRnyYqG1DIW',
    'System',
    'Administrator',
    'active'
)
ON CONFLICT (username) DO NOTHING;

-- Assign admin role to admin user
INSERT INTO user_roles (user_id, role_id)
VALUES ('user-admin', 'role-admin')
ON CONFLICT (user_id, role_id) DO NOTHING;

#include <drogon/drogon.h>
#include <json/json.h>
#include <memory>
#include <string>
#include <vector>
#include <unordered_map>
#include "nlp_client.h"  // Python NLP service client
#include "document_repository.h"
#include "knowledge_graph_builder.h"

namespace atp {
namespace document {

class DocumentIntelligenceService : public drogon::HttpController<DocumentIntelligenceService> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(DocumentIntelligenceService::processDocument, "/api/documents/process", drogon::Post);
    ADD_METHOD_TO(DocumentIntelligenceService::classifyDocument, "/api/documents/classify", drogon::Post);
    ADD_METHOD_TO(DocumentIntelligenceService::buildKnowledgeGraph, "/api/documents/knowledge-graph", drogon::Post);
    ADD_METHOD_TO(DocumentIntelligenceService::verifyCompleteness, "/api/documents/verify-completeness", drogon::Post);
    ADD_METHOD_TO(DocumentIntelligenceService::resolveReferences, "/api/documents/resolve-references", drogon::Post);
    ADD_METHOD_TO(DocumentIntelligenceService::standardizeTerminology, "/api/documents/standardize", drogon::Post);
    METHOD_LIST_END

    DocumentIntelligenceService();

    void processDocument(const drogon::HttpRequestPtr& req, 
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void classifyDocument(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void buildKnowledgeGraph(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void verifyCompleteness(const drogon::HttpRequestPtr& req,
                            std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void resolveReferences(const drogon::HttpRequestPtr& req,
                           std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void standardizeTerminology(const drogon::HttpRequestPtr& req,
                                std::function<void(const drogon::HttpResponsePtr&)>&& callback);

private:
    std::shared_ptr<NLPClient> nlpClient_;
    std::shared_ptr<DocumentRepository> docRepo_;
    std::shared_ptr<KnowledgeGraphBuilder> kgBuilder_;
    
    // Context-aware parsing configurations for different document types
    std::unordered_map<std::string, std::string> parsingConfigs_;
    
    // Caches for improved performance
    drogon::CacheMap<std::string, std::string> documentClassCache_;
    
    // Helper methods
    Json::Value extractStructuredContent(const std::string& content, const std::string& docType);
    std::vector<std::string> detectLanguage(const std::string& content);
    Json::Value translateContent(const std::string& content, const std::string& targetLanguage);
    bool validateAgainstRegulations(const Json::Value& document, const std::string& regulationType);
};

DocumentIntelligenceService::DocumentIntelligenceService() {
    // Initialize NLP client connection to Python service
    nlpClient_ = std::make_shared<NLPClient>("localhost", 5000);
    docRepo_ = std::make_shared<DocumentRepository>();
    kgBuilder_ = std::make_shared<KnowledgeGraphBuilder>();
    
    // Initialize parsing configurations for different document types
    parsingConfigs_["operations_manual"] = "aviation.ops_manual.config";
    parsingConfigs_["training_syllabus"] = "aviation.training.syllabus.config";
    parsingConfigs_["regulatory_document"] = "aviation.regulatory.config";
    parsingConfigs_["technical_manual"] = "aviation.technical.config";
}

void DocumentIntelligenceService::processDocument(const drogon::HttpRequestPtr& req, 
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    std::string documentId = (*json)["document_id"].asString();
    std::string content = (*json)["content"].asString();
    
    // Detect document language
    auto languages = detectLanguage(content);
    std::string primaryLanguage = languages.empty() ? "en" : languages[0];
    
    // Standardize to English if not already
    std::string processedContent = content;
    if (primaryLanguage != "en") {
        Json::Value translatedContent = translateContent(content, "en");
        processedContent = translatedContent["translated_text"].asString();
    }
    
    // First classify the document
    auto classification = nlpClient_->classifyDocument(processedContent);
    std::string docType = classification["document_type"].asString();
    
    // Then extract structured content based on document type
    auto structuredContent = extractStructuredContent(processedContent, docType);
    
    // Store results
    docRepo_->storeProcessedDocument(documentId, structuredContent);
    
    // Prepare response
    Json::Value result;
    result["document_id"] = documentId;
    result["document_type"] = docType;
    result["language"] = primaryLanguage;
    result["structure"] = structuredContent;
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    callback(resp);
}

void DocumentIntelligenceService::buildKnowledgeGraph(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    std::vector<std::string> documentIds;
    for (const auto& id : (*json)["document_ids"]) {
        documentIds.push_back(id.asString());
    }
    
    // Load all documents
    std::vector<Json::Value> documents;
    for (const auto& id : documentIds) {
        documents.push_back(docRepo_->getProcessedDocument(id));
    }
    
    // Build knowledge graph
    auto knowledgeGraph = kgBuilder_->buildGraph(documents);
    
    // Store the knowledge graph
    std::string graphId = kgBuilder_->storeGraph(knowledgeGraph);
    
    // Prepare response
    Json::Value result;
    result["graph_id"] = graphId;
    result["node_count"] = knowledgeGraph["nodes"].size();
    result["edge_count"] = knowledgeGraph["edges"].size();
    result["document_count"] = documents.size();
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    callback(resp);
}

void DocumentIntelligenceService::verifyCompleteness(const drogon::HttpRequestPtr& req,
                            std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    std::string documentId = (*json)["document_id"].asString();
    std::string regulationType = (*json)["regulation_type"].asString(); // e.g., "EASA", "FAA"
    
    // Get the processed document
    auto document = docRepo_->getProcessedDocument(documentId);
    
    // Validate against regulatory requirements
    bool isComplete = validateAgainstRegulations(document, regulationType);
    
    // Get missing sections if not complete
    Json::Value missingItems;
    if (!isComplete) {
        missingItems = nlpClient_->identifyMissingItems(document, regulationType);
    }
    
    // Prepare response
    Json::Value result;
    result["document_id"] = documentId;
    result["regulation_type"] = regulationType;
    result["is_complete"] = isComplete;
    if (!isComplete) {
        result["missing_items"] = missingItems;
    }
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    callback(resp);
}

// Helper method implementations
Json::Value DocumentIntelligenceService::extractStructuredContent(const std::string& content, const std::string& docType) {
    std::string configPath = parsingConfigs_.find(docType) != parsingConfigs_.end() 
                        ? parsingConfigs_[docType] 
                        : "default.config";
    
    return nlpClient_->extractStructure(content, configPath);
}

std::vector<std::string> DocumentIntelligenceService::detectLanguage(const std::string& content) {
    Json::Value result = nlpClient_->detectLanguage(content);
    
    std::vector<std::string> languages;
    for (const auto& lang : result["languages"]) {
        languages.push_back(lang.asString());
    }
    
    return languages;
}

Json::Value DocumentIntelligenceService::translateContent(const std::string& content, const std::string& targetLanguage) {
    return nlpClient_->translate(content, targetLanguage);
}

bool DocumentIntelligenceService::validateAgainstRegulations(const Json::Value& document, const std::string& regulationType) {
    Json::Value validationResult = nlpClient_->validateCompliance(document, regulationType);
    return validationResult["is_compliant"].asBool();
}

} // namespace document
} // namespace atp

// Main application setup
int main() {
    // Configure Drogon app
    drogon::app().setLogPath("./")
                 .setLogLevel(trantor::Logger::kInfo)
                 .addListener("0.0.0.0", 8080)
                 .setThreadNum(16)
                 .run();
    
    return 0;
}

// backend/document/include/DocumentProcessor.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <functional>
#include <optional>
#include <filesystem>
#include <future>
#include <unordered_map>

#include "core/include/ErrorHandling.h"

namespace APTP::Document {

// Enum for document types
enum class DocumentType {
    PDF,
    DOCX,
    XLSX,
    HTML,
    PPTX,
    TXT,
    XML,
    JSON,
    Unknown
};

// Processing status
enum class ProcessingStatus {
    NotStarted,
    Processing,
    Completed,
    Failed
};

// Structure to hold document metadata
struct DocumentMetadata {
    std::string documentId;
    std::string title;
    std::string author;
    std::string creationDate;
    std::string lastModifiedDate;
    std::size_t sizeInBytes;
    DocumentType type;
    std::unordered_map<std::string, std::string> customMetadata;
};

// Structure for document content
struct DocumentContent {
    std::string plainText;
    std::vector<std::string> paragraphs;
    std::vector<std::string> headers;
    std::unordered_map<std::string, std::vector<std::string>> tables;
    std::vector<std::string> images; // Paths or identifiers to extracted images
    std::unordered_map<std::string, std::string> extractedData; // Key-value pairs from forms, etc.
};

// Structure for regulatory mapping
struct RegulatoryMapping {
    std::string regulatoryBody; // e.g., "FAA", "EASA", "ICAO"
    std::string regulationId;   // e.g., "14 CFR Part 61", "EASA Part-FCL"
    std::string sectionId;      // e.g., "61.57", "FCL.060"
    std::string subsectionId;   // e.g., "61.57(c)", "FCL.060(b)"
    std::string description;
    double confidenceScore;     // 0.0 to 1.0
};

// Processing progress
struct ProcessingProgress {
    double percentComplete;
    ProcessingStatus status;
    std::string currentStage;
    std::string message;
    std::vector<std::string> warnings;
    std::vector<std::string> errors;
};

// Callback for progress updates
using ProgressCallback = std::function<void(const ProcessingProgress&)>;

// Result of document processing
struct ProcessingResult {
    std::string documentId;
    DocumentMetadata metadata;
    DocumentContent content;
    std::vector<RegulatoryMapping> regulatoryMappings;
    ProcessingProgress progress;
};

// Abstract base class for document processors
class DocumentProcessor {
public:
    virtual ~DocumentProcessor() = default;
    
    // Process a document from a file path
    virtual APTP::Core::Result<ProcessingResult> processDocument(
        const std::filesystem::path& filePath,
        const ProgressCallback& progressCallback = nullptr) = 0;
    
    // Process a document from a memory buffer
    virtual APTP::Core::Result<ProcessingResult> processDocument(
        const std::vector<uint8_t>& data,
        const std::string& filename,
        const ProgressCallback& progressCallback = nullptr) = 0;
    
    // Process a document asynchronously
    virtual std::future<APTP::Core::Result<ProcessingResult>> processDocumentAsync(
        const std::filesystem::path& filePath,
        const ProgressCallback& progressCallback = nullptr) = 0;
    
    // Detect document type
    static DocumentType detectDocumentType(const std::filesystem::path& filePath);
    static DocumentType detectDocumentType(const std::vector<uint8_t>& data, const std::string& filename);
    
    // Create appropriate processor for the document type
    static std::unique_ptr<DocumentProcessor> createProcessor(DocumentType type);
    static std::unique_ptr<DocumentProcessor> createProcessor(const std::filesystem::path& filePath);
    static std::unique_ptr<DocumentProcessor> createProcessor(const std::vector<uint8_t>& data, const std::string& filename);
};

// Concrete implementation for PDF documents
class PDFProcessor : public DocumentProcessor {
public:
    PDFProcessor();
    ~PDFProcessor() override;
    
    APTP::Core::Result<ProcessingResult> processDocument(
        const std::filesystem::path& filePath,
        const ProgressCallback& progressCallback = nullptr) override;
    
    APTP::Core::Result<ProcessingResult> processDocument(
        const std::vector<uint8_t>& data,
        const std::string& filename,
        const ProgressCallback& progressCallback = nullptr) override;
    
    std::future<APTP::Core::Result<ProcessingResult>> processDocumentAsync(
        const std::filesystem::path& filePath,
        const ProgressCallback& progressCallback = nullptr) override;

private:
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

// Concrete implementation for DOCX documents
class DOCXProcessor : public DocumentProcessor {
public:
    DOCXProcessor();
    ~DOCXProcessor() override;
    
    APTP::Core::Result<ProcessingResult> processDocument(
        const std::filesystem::path& filePath,
        const ProgressCallback& progressCallback = nullptr) override;
    
    APTP::Core::Result<ProcessingResult> processDocument(
        const std::vector<uint8_t>& data,
        const std::string& filename,
        const ProgressCallback& progressCallback = nullptr) override;
    
    std::future<APTP::Core::Result<ProcessingResult>> processDocumentAsync(
        const std::filesystem::path& filePath,
        const ProgressCallback& progressCallback = nullptr) override;

private:
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

// Additional concrete implementations for XLSX, HTML, PPTX, etc. would be defined similarly

// Factory method to create document processors
class DocumentProcessorFactory {
public:
    static std::unique_ptr<DocumentProcessor> createProcessor(DocumentType type);
    static std::unique_ptr<DocumentProcessor> createProcessor(const std::filesystem::path& filePath);
    static std::unique_ptr<DocumentProcessor> createProcessor(const std::vector<uint8_t>& data, const std::string& filename);
};

} // namespace APTP::Document

// backend/document/include/OCRProcessor.h
#pragma once

#include <string>
#include <vector>
#include <filesystem>
#include <memory>
#include <future>

#include "core/include/ErrorHandling.h"

namespace APTP::Document {

struct OCRResult {
    std::string text;
    double confidenceScore;
    std::vector<std::string> warnings;
    std::vector<std::string> errors;
};

// OCR processor for extracting text from images
class OCRProcessor {
public:
    static OCRProcessor& getInstance();
    
    // Process image file
    APTP::Core::Result<OCRResult> processImage(const std::filesystem::path& imagePath);
    
    // Process image data in memory
    APTP::Core::Result<OCRResult> processImage(const std::vector<uint8_t>& imageData);
    
    // Process multiple images and combine results
    APTP::Core::Result<OCRResult> processImages(const std::vector<std::filesystem::path>& imagePaths);
    
    // Process image asynchronously
    std::future<APTP::Core::Result<OCRResult>> processImageAsync(const std::filesystem::path& imagePath);
    
    // Configure OCR settings
    void setLanguage(const std::string& language);
    void setAccuracyMode(bool highAccuracy);
    void setPageSegmentationMode(int mode);

private:
    OCRProcessor();
    ~OCRProcessor();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Document

// backend/document/include/AIDocumentAnalyzer.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <future>
#include <unordered_map>

#include "DocumentProcessor.h"
#include "core/include/ErrorHandling.h"

namespace APTP::Document {

// Entity types that can be extracted
enum class EntityType {
    Person,
    Organization,
    Location,
    Date,
    LearningObjective,
    Competency,
    Regulation,
    Equipment,
    Procedure,
    Safety,
    Custom
};

// Entity found in document
struct Entity {
    std::string text;
    EntityType type;
    std::string customType; // For custom entity types
    double confidenceScore;
    std::size_t startPosition;
    std::size_t endPosition;
    std::unordered_map<std::string, std::string> attributes;
};

// Relation between entities
struct Relation {
    std::string sourceEntityId;
    std::string targetEntityId;
    std::string relationType;
    double confidenceScore;
    std::unordered_map<std::string, std::string> attributes;
};

// Document summarization result
struct DocumentSummary {
    std::string shortSummary; // 1-2 sentences
    std::string detailedSummary; // Paragraph level
    std::vector<std::string> keyPoints;
    double confidenceScore;
};

// Document classification result
struct DocumentClassification {
    std::string primaryCategory;
    std::vector<std::string> secondaryCategories;
    std::unordered_map<std::string, double> categoryConfidences;
};

// AI analysis result
struct AIAnalysisResult {
    std::vector<Entity> entities;
    std::vector<Relation> relations;
    DocumentSummary summary;
    DocumentClassification classification;
    std::unordered_map<std::string, std::string> extractedMetadata;
    std::vector<RegulatoryMapping> regulatoryMappings;
};

// AI Document Analyzer class
class AIDocumentAnalyzer {
public:
    static AIDocumentAnalyzer& getInstance();
    
    // Analyze document content
    APTP::Core::Result<AIAnalysisResult> analyzeDocument(const DocumentContent& content);
    
    // Analyze document directly
    APTP::Core::Result<AIAnalysisResult> analyzeDocument(
        const std::filesystem::path& filePath);
    
    // Analyze document asynchronously
    std::future<APTP::Core::Result<AIAnalysisResult>> analyzeDocumentAsync(
        const DocumentContent& content);
    
    // Extract specific entity types
    APTP::Core::Result<std::vector<Entity>> extractEntities(
        const std::string& text, 
        const std::vector<EntityType>& entityTypes);
    
    // Summarize document
    APTP::Core::Result<DocumentSummary> summarizeDocument(
        const DocumentContent& content);
    
    // Classify document
    APTP::Core::Result<DocumentClassification> classifyDocument(
        const DocumentContent& content);
    
    // Map document to regulatory standards
    APTP::Core::Result<std::vector<RegulatoryMapping>> mapToRegulations(
        const DocumentContent& content,
        const std::vector<std::string>& regulatoryBodies = {"FAA", "EASA", "ICAO"});
    
    // Configure analyzer
    void setAnalysisDepth(int depth); // 1-5, where 5 is most detailed
    void setConfidenceThreshold(double threshold); // 0.0-1.0
    void enableEntityTypes(const std::vector<EntityType>& types);
    void disableEntityTypes(const std::vector<EntityType>& types);

private:
    AIDocumentAnalyzer();
    ~AIDocumentAnalyzer();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Document

// backend/document/src/DocumentProcessor.cpp (partial implementation)
#include "DocumentProcessor.h"
#include "core/include/Logger.h"
#include <thread>

namespace APTP::Document {

// DocumentProcessor static methods
DocumentType DocumentProcessor::detectDocumentType(const std::filesystem::path& filePath) {
    // Implementation for detecting document type based on file extension and content
    std::string extension = filePath.extension().string();
    
    // Convert to lowercase for case-insensitive comparison
    std::transform(extension.begin(), extension.end(), extension.begin(),
                   [](unsigned char c) { return std::tolower(c); });
    
    if (extension == ".pdf") return DocumentType::PDF;
    if (extension == ".docx") return DocumentType::DOCX;
    if (extension == ".xlsx") return DocumentType::XLSX;
    if (extension == ".html" || extension == ".htm") return DocumentType::HTML;
    if (extension == ".pptx") return DocumentType::PPTX;
    if (extension == ".txt") return DocumentType::TXT;
    if (extension == ".xml") return DocumentType::XML;
    if (extension == ".json") return DocumentType::JSON;
    
    // More advanced detection could include content analysis
    return DocumentType::Unknown;
}

DocumentType DocumentProcessor::detectDocumentType(const std::vector<uint8_t>& data, const std::string& filename) {
    // Simple implementation based on filename
    std::filesystem::path path(filename);
    return detectDocumentType(path);
    
    // A more robust implementation would analyze the file headers/magic bytes
}

std::unique_ptr<DocumentProcessor> DocumentProcessor::createProcessor(DocumentType type) {
    return DocumentProcessorFactory::createProcessor(type);
}

std::unique_ptr<DocumentProcessor> DocumentProcessor::createProcessor(const std::filesystem::path& filePath) {
    return DocumentProcessorFactory::createProcessor(filePath);
}

std::unique_ptr<DocumentProcessor> DocumentProcessor::createProcessor(const std::vector<uint8_t>& data, const std::string& filename) {
    return DocumentProcessorFactory::createProcessor(data, filename);
}

// DocumentProcessorFactory implementation
std::unique_ptr<DocumentProcessor> DocumentProcessorFactory::createProcessor(DocumentType type) {
    switch (type) {
        case DocumentType::PDF:
            return std::make_unique<PDFProcessor>();
        case DocumentType::DOCX:
            return std::make_unique<DOCXProcessor>();
        // Additional cases for other document types
        default:
            throw APTP::Core::APTPException(
                APTP::Core::ErrorCode::InvalidArgument,
                "Unsupported document type"
            );
    }
}

std::unique_ptr<DocumentProcessor> DocumentProcessorFactory::createProcessor(const std::filesystem::path& filePath) {
    DocumentType type = DocumentProcessor::detectDocumentType(filePath);
    return createProcessor(type);
}

std::unique_ptr<DocumentProcessor> DocumentProcessorFactory::createProcessor(const std::vector<uint8_t>& data, const std::string& filename) {
    DocumentType type = DocumentProcessor::detectDocumentType(data, filename);
    return createProcessor(type);
}

// PDFProcessor implementation
struct PDFProcessor::Impl {
    // Internal implementation details
};

PDFProcessor::PDFProcessor() : impl_(std::make_unique<Impl>()) {}
PDFProcessor::~PDFProcessor() = default;

APTP::Core::Result<ProcessingResult> PDFProcessor::processDocument(
    const std::filesystem::path& filePath,
    const ProgressCallback& progressCallback) {
    
    APTP::Core::Logger::getInstance().info("Processing PDF document: {}", filePath.string());
    
    ProcessingResult result;
    result.documentId = std::to_string(std::hash<std::string>{}(filePath.string()));
    result.progress.status = ProcessingStatus::Processing;
    
    // Update initial progress
    if (progressCallback) {
        result.progress.percentComplete = 0.0;
        result.progress.currentStage = "Starting PDF processing";
        progressCallback(result.progress);
    }
    
    try {
        // 1. Extract metadata
        result.metadata.type = DocumentType::PDF;
        result.metadata.sizeInBytes = std::filesystem::file_size(filePath);
        // ... more metadata extraction
        
        if (progressCallback) {
            result.progress.percentComplete = 25.0;
            result.progress.currentStage = "Extracted metadata";
            progressCallback(result.progress);
        }
        
        // 2. Extract text content
        // ... implementation for text extraction
        
        if (progressCallback) {
            result.progress.percentComplete = 50.0;
            result.progress.currentStage = "Extracted text content";
            progressCallback(result.progress);
        }
        
        // 3. Extract tables and other structured data
        // ... implementation for structured data extraction
        
        if (progressCallback) {
            result.progress.percentComplete = 75.0;
            result.progress.currentStage = "Extracted structured data";
            progressCallback(result.progress);
        }
        
        // 4. Perform regulatory mapping
        // ... implementation for regulatory mapping
        
        // Complete the processing
        result.progress.status = ProcessingStatus::Completed;
        result.progress.percentComplete = 100.0;
        result.progress.currentStage = "Processing completed";
        if (progressCallback) {
            progressCallback(result.progress);
        }
        
        return APTP::Core::Success(result);
    }
    catch (const std::exception& e) {
        result.progress.status = ProcessingStatus::Failed;
        result.progress.errors.push_back(e.what());
        if (progressCallback) {
            progressCallback(result.progress);
        }
        return APTP::Core::Error<ProcessingResult>(APTP::Core::ErrorCode::DocumentProcessingError);
    }
}

APTP::Core::Result<ProcessingResult> PDFProcessor::processDocument(
    const std::vector<uint8_t>& data,
    const std::string& filename,
    const ProgressCallback& progressCallback) {
    
    // Implementation for processing from memory buffer
    // Similar to the file-based implementation but working with the data buffer
    
    // This is a simplified implementation
    APTP::Core::Logger::getInstance().info("Processing PDF document from memory: {}", filename);
    
    // Create a temporary file
    std::filesystem::path tempPath = std::filesystem::temp_directory_path() / filename;
    try {
        std::ofstream tempFile(tempPath, std::ios::binary);
        tempFile.write(reinterpret_cast<const char*>(data.data()), data.size());
        tempFile.close();
        
        // Process the temporary file
        auto result = processDocument(tempPath, progressCallback);
        
        // Clean up
        std::filesystem::remove(tempPath);
        
        return result;
    }
    catch (const std::exception& e) {
        // Clean up in case of exception
        if (std::filesystem::exists(tempPath)) {
            std::filesystem::remove(tempPath);
        }
        
        ProcessingResult result;
        result.documentId = std::to_string(std::hash<std::string>{}(filename));
        result.progress.status = ProcessingStatus::Failed;
        result.progress.errors.push_back(e.what());
        if (progressCallback) {
            progressCallback(result.progress);
        }
        return APTP::Core::Error<ProcessingResult>(APTP::Core::ErrorCode::DocumentProcessingError);
    }
}

std::future<APTP::Core::Result<ProcessingResult>> PDFProcessor::processDocumentAsync(
    const std::filesystem::path& filePath,
    const ProgressCallback& progressCallback) {
    
    return std::async(std::launch::async, [this, filePath, progressCallback]() {
        return this->processDocument(filePath, progressCallback);
    });
}

// DOCXProcessor implementation would follow a similar pattern
// Other document processor implementations would follow as well

} // namespace APTP::Document

// Additional implementations for OCRProcessor.cpp and AIDocumentAnalyzer.cpp would follow

// src/backend/document/DocumentProcessor.h
#pragma once

#include <memory>
#include <string>
#include <vector>
#include <unordered_map>
#include <functional>
#include <optional>
#include <future>

#include "../core/Result.h"
#include "../core/Logger.h"
#include "../core/MemoryPool.h"
#include "../core/ConfigurationManager.h"

namespace PilotTraining {
namespace Document {

/**
 * Enum representing supported document types
 */
enum class DocumentType {
  PDF,
  DOCX,
  XLSX,
  HTML,
  PPTX,
  UNKNOWN
};

/**
 * Enum representing document processing status
 */
enum class ProcessingStatus {
  PENDING,
  PROCESSING,
  COMPLETED,
  FAILED
};

/**
 * Struct representing document metadata
 */
struct DocumentMetadata {
  std::string id;
  std::string filename;
  std::string contentType;
  std::string organizationId;
  std::string uploadedBy;
  std::string createdAt;
  std::string updatedAt;
  DocumentType type;
  size_t fileSize;
  std::unordered_map<std::string, std::string> additionalMetadata;
};

/**
 * Struct representing document content
 */
struct DocumentContent {
  std::string rawText;
  std::vector<std::string> paragraphs;
  std::vector<std::string> headings;
  std::vector<std::vector<std::string>> tables;
  std::unordered_map<std::string, std::string> metadata;
  float extractionConfidence;
};

/**
 * Struct representing document structure
 */
struct DocumentStructure {
  struct Section {
    std::string title;
    std::string content;
    std::vector<Section> subsections;
    std::unordered_map<std::string, std::string> metadata;
  };

  std::vector<Section> sections;
  std::unordered_map<std::string, std::vector<std::string>> entityReferences;
  std::unordered_map<std::string, std::vector<std::string>> regulatoryReferences;
};

/**
 * Struct representing extracted training elements
 */
struct TrainingElements {
  struct LearningObjective {
    std::string id;
    std::string description;
    std::string category;
    std::vector<std::string> relatedRegulations;
    std::vector<std::string> prerequisites;
    float importance;
  };

  struct Competency {
    std::string id;
    std::string name;
    std::string description;
    std::vector<std::string> assessmentCriteria;
    std::vector<std::string> relatedObjectives;
  };

  struct Procedure {
    std::string id;
    std::string name;
    std::string description;
    std::vector<std::string> steps;
    std::vector<std::string> relatedCompetencies;
    std::vector<std::string> safetyConsiderations;
  };

  std::vector<LearningObjective> learningObjectives;
  std::vector<Competency> competencies;
  std::vector<Procedure> procedures;
  std::unordered_map<std::string, std::vector<std::string>> regulatoryMapping;
};

/**
 * Struct representing quality assessment of processed document
 */
struct QualityAssessment {
  float completenessScore;
  float consistencyScore;
  float regulatoryComplianceScore;
  float overallConfidence;
  std::vector<std::string> potentialGaps;
  std::vector<std::string> inconsistencies;
  std::vector<std::string> complianceIssues;
};

/**
 * Class representing the result of document processing
 */
struct ProcessingResult {
  std::string documentId;
  ProcessingStatus status;
  DocumentContent content;
  DocumentStructure structure;
  TrainingElements trainingElements;
  QualityAssessment qualityAssessment;
  std::vector<std::string> errors;
  std::unordered_map<std::string, float> processingMetrics;
  
  // AI-enhanced features from extended prompt
  std::unordered_map<std::string, float> sentimentAnalysis;
  std::vector<std::string> autoTags;
  std::unordered_map<std::string, std::vector<std::string>> entityRecognition;
  std::string summary;
};

/**
 * Progress callback function type
 */
using ProgressCallback = std::function<void(float progress, const std::string& stage)>;

/**
 * Abstract base class for document processors
 */
class IDocumentProcessor {
public:
  virtual ~IDocumentProcessor() = default;
  
  /**
   * Process a document
   * 
   * @param documentPath Path to the document file
   * @param metadata Document metadata
   * @param progressCallback Optional callback for progress updates
   * @return Result containing processing result or error
   */
  virtual Result<ProcessingResult> processDocument(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback = std::nullopt
  ) = 0;
  
  /**
   * Process a document asynchronously
   * 
   * @param documentPath Path to the document file
   * @param metadata Document metadata
   * @param progressCallback Optional callback for progress updates
   * @return Future result containing processing result or error
   */
  virtual std::future<Result<ProcessingResult>> processDocumentAsync(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback = std::nullopt
  ) = 0;
};

/**
 * PDF Document Processor implementation
 */
class PDFDocumentProcessor : public IDocumentProcessor {
public:
  explicit PDFDocumentProcessor(std::shared_ptr<Core::ConfigurationManager> configManager);
  ~PDFDocumentProcessor() override;
  
  Result<ProcessingResult> processDocument(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback = std::nullopt
  ) override;
  
  std::future<Result<ProcessingResult>> processDocumentAsync(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback = std::nullopt
  ) override;
  
private:
  Result<DocumentContent> extractContent(const std::string& documentPath);
  Result<DocumentStructure> recognizeStructure(const DocumentContent& content);
  Result<TrainingElements> extractTrainingElements(const DocumentStructure& structure);
  Result<QualityAssessment> assessQuality(
    const DocumentContent& content,
    const DocumentStructure& structure,
    const TrainingElements& trainingElements
  );
  
  // Enhanced AI features from extended prompt
  Result<std::string> generateSummary(const DocumentContent& content);
  Result<std::unordered_map<std::string, float>> analyzeSentiment(const DocumentContent& content);
  Result<std::vector<std::string>> generateTags(const DocumentContent& content);
  Result<std::unordered_map<std::string, std::vector<std::string>>> recognizeEntities(const DocumentContent& content);
  
  std::shared_ptr<Core::ConfigurationManager> _configManager;
  Core::MemoryPool _memoryPool;
  
  // Additional members for OCR, text extraction, etc.
};

/**
 * Word Document Processor implementation
 */
class DOCXDocumentProcessor : public IDocumentProcessor {
public:
  explicit DOCXDocumentProcessor(std::shared_ptr<Core::ConfigurationManager> configManager);
  ~DOCXDocumentProcessor() override;
  
  Result<ProcessingResult> processDocument(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback = std::nullopt
  ) override;
  
  std::future<Result<ProcessingResult>> processDocumentAsync(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback = std::nullopt
  ) override;
  
private:
  // Similar private methods as PDFDocumentProcessor
  std::shared_ptr<Core::ConfigurationManager> _configManager;
  Core::MemoryPool _memoryPool;
};

/**
 * Factory for creating document processors based on document type
 */
class DocumentProcessorFactory {
public:
  explicit DocumentProcessorFactory(std::shared_ptr<Core::ConfigurationManager> configManager);
  
  /**
   * Create a document processor for the specified document type
   * 
   * @param type Document type
   * @return Shared pointer to document processor or null if type is not supported
   */
  std::shared_ptr<IDocumentProcessor> createProcessor(DocumentType type);
  
  /**
   * Determine document type from file extension
   * 
   * @param filename Filename with extension
   * @return Document type
   */
  static DocumentType determineType(const std::string& filename);
  
private:
  std::shared_ptr<Core::ConfigurationManager> _configManager;
};

/**
 * Main document processing pipeline
 */
class DocumentProcessingPipeline {
public:
  explicit DocumentProcessingPipeline(std::shared_ptr<Core::ConfigurationManager> configManager);
  
  /**
   * Process a document through the complete pipeline
   * 
   * @param documentPath Path to the document file
   * @param metadata Document metadata
   * @param progressCallback Optional callback for progress updates
   * @return Result containing processing result or error
   */
  Result<ProcessingResult> processDocument(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback = std::nullopt
  );
  
  /**
   * Process a document asynchronously through the complete pipeline
   * 
   * @param documentPath Path to the document file
   * @param metadata Document metadata
   * @param progressCallback Optional callback for progress updates
   * @return Future result containing processing result or error
   */
  std::future<Result<ProcessingResult>> processDocumentAsync(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback = std::nullopt
  );
  
  /**
   * Process multiple documents in batch
   * 
   * @param documentPaths Paths to document files
   * @param metadataList List of document metadata
   * @param progressCallback Optional callback for progress updates
   * @return Vector of results containing processing results or errors
   */
  std::vector<Result<ProcessingResult>> processBatch(
    const std::vector<std::string>& documentPaths,
    const std::vector<DocumentMetadata>& metadataList,
    const std::optional<ProgressCallback>& progressCallback = std::nullopt
  );
  
private:
  DocumentProcessorFactory _processorFactory;
  std::shared_ptr<Core::ConfigurationManager> _configManager;
};

} // namespace Document
} // namespace PilotTraining

// src/backend/document/DocumentProcessor.cpp
#include "DocumentProcessor.h"

#include <chrono>
#include <thread>
#include <fstream>
#include <filesystem>
#include <algorithm>
#include <tuple>

#include "../core/Logger.h"
#include "../core/ErrorCodes.h"

namespace PilotTraining {
namespace Document {

// PDFDocumentProcessor Implementation
PDFDocumentProcessor::PDFDocumentProcessor(std::shared_ptr<Core::ConfigurationManager> configManager)
    : _configManager(std::move(configManager)) {
}

PDFDocumentProcessor::~PDFDocumentProcessor() = default;

Result<ProcessingResult> PDFDocumentProcessor::processDocument(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback) {
    
    if (!std::filesystem::exists(documentPath)) {
        return Result<ProcessingResult>::failure(
            Core::ErrorCode::FileNotFound,
            "Document file not found: " + documentPath
        );
    }
    
    // Start processing
    ProcessingResult result;
    result.documentId = metadata.id;
    result.status = ProcessingStatus::PROCESSING;
    
    try {
        // Stage 1: Extract content
        if (progressCallback) {
            (*progressCallback)(0.1f, "Extracting content");
        }
        
        auto contentResult = extractContent(documentPath);
        if (!contentResult.isSuccess()) {
            result.status = ProcessingStatus::FAILED;
            result.errors.push_back("Content extraction failed: " + contentResult.getError().message);
            return Result<ProcessingResult>::success(result);
        }
        result.content = contentResult.getValue();
        
        // Stage 2: Recognize structure
        if (progressCallback) {
            (*progressCallback)(0.3f, "Recognizing document structure");
        }
        
        auto structureResult = recognizeStructure(result.content);
        if (!structureResult.isSuccess()) {
            result.status = ProcessingStatus::FAILED;
            result.errors.push_back("Structure recognition failed: " + structureResult.getError().message);
            return Result<ProcessingResult>::success(result);
        }
        result.structure = structureResult.getValue();
        
        // Stage 3: Extract training elements
        if (progressCallback) {
            (*progressCallback)(0.5f, "Extracting training elements");
        }
        
        auto elementsResult = extractTrainingElements(result.structure);
        if (!elementsResult.isSuccess()) {
            result.status = ProcessingStatus::FAILED;
            result.errors.push_back("Training element extraction failed: " + elementsResult.getError().message);
            return Result<ProcessingResult>::success(result);
        }
        result.trainingElements = elementsResult.getValue();
        
        // Stage 4: Assess quality
        if (progressCallback) {
            (*progressCallback)(0.7f, "Performing quality assessment");
        }
        
        auto qualityResult = assessQuality(result.content, result.structure, result.trainingElements);
        if (!qualityResult.isSuccess()) {
            result.status = ProcessingStatus::FAILED;
            result.errors.push_back("Quality assessment failed: " + qualityResult.getError().message);
            return Result<ProcessingResult>::success(result);
        }
        result.qualityAssessment = qualityResult.getValue();
        
        // Stage 5: AI-enhanced features (from extended prompt)
        if (progressCallback) {
            (*progressCallback)(0.8f, "Applying AI enhancements");
        }
        
        // Generate summary
        auto summaryResult = generateSummary(result.content);
        if (summaryResult.isSuccess()) {
            result.summary = summaryResult.getValue();
        } else {
            result.errors.push_back("Summary generation failed: " + summaryResult.getError().message);
        }
        
        // Analyze sentiment
        auto sentimentResult = analyzeSentiment(result.content);
        if (sentimentResult.isSuccess()) {
            result.sentimentAnalysis = sentimentResult.getValue();
        } else {
            result.errors.push_back("Sentiment analysis failed: " + sentimentResult.getError().message);
        }
        
        // Generate tags
        auto tagsResult = generateTags(result.content);
        if (tagsResult.isSuccess()) {
            result.autoTags = tagsResult.getValue();
        } else {
            result.errors.push_back("Tag generation failed: " + tagsResult.getError().message);
        }
        
        // Recognize entities
        auto entitiesResult = recognizeEntities(result.content);
        if (entitiesResult.isSuccess()) {
            result.entityRecognition = entitiesResult.getValue();
        } else {
            result.errors.push_back("Entity recognition failed: " + entitiesResult.getError().message);
        }
        
        // Stage 6: Finalize
        if (progressCallback) {
            (*progressCallback)(1.0f, "Processing completed");
        }
        
        result.status = ProcessingStatus::COMPLETED;
        
        // Add processing metrics
        auto now = std::chrono::system_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(now.time_since_epoch()).count();
        result.processingMetrics["processingTime"] = static_cast<float>(duration);
        result.processingMetrics["contentConfidence"] = result.content.extractionConfidence;
        result.processingMetrics["structureQuality"] = result.qualityAssessment.consistencyScore;
        result.processingMetrics["overallQuality"] = result.qualityAssessment.overallConfidence;
        
        return Result<ProcessingResult>::success(result);
    } catch (const std::exception& e) {
        Core::Logger::error("PDF processing exception: {}", e.what());
        result.status = ProcessingStatus::FAILED;
        result.errors.push_back(std::string("Unhandled exception: ") + e.what());
        return Result<ProcessingResult>::success(result);
    }
}

std::future<Result<ProcessingResult>> PDFDocumentProcessor::processDocumentAsync(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback) {
    
    return std::async(std::launch::async, [this, documentPath, metadata, progressCallback]() {
        return processDocument(documentPath, metadata, progressCallback);
    });
}

Result<DocumentContent> PDFDocumentProcessor::extractContent(const std::string& documentPath) {
    // In a real implementation, this would use a PDF parsing library like libpoppler or pdfium
    Core::Logger::info("Extracting content from PDF: {}", documentPath);
    
    try {
        // Simulated content extraction
        DocumentContent content;
        content.rawText = "Simulated content from PDF document";
        
        // Simulated paragraphs extraction
        content.paragraphs = {
            "This is paragraph 1 from the PDF document.",
            "This is paragraph 2 with some aviation terminology.",
            "This paragraph discusses training procedures for pilots."
        };
        
        // Simulated headings extraction
        content.headings = {
            "Introduction to Pilot Training",
            "Basic Flight Maneuvers",
            "Emergency Procedures"
        };
        
        // Simulated table extraction
        content.tables = {
            {"Header1", "Header2", "Header3"},
            {"Cell1_1", "Cell1_2", "Cell1_3"},
            {"Cell2_1", "Cell2_2", "Cell2_3"}
        };
        
        // Set confidence based on extraction quality
        content.extractionConfidence = 0.92f;
        
        // Simulated metadata extraction
        content.metadata["title"] = "Advanced Pilot Training Manual";
        content.metadata["author"] = "Aviation Training Authority";
        content.metadata["created"] = "2023-05-15";
        content.metadata["pages"] = "156";
        
        return Result<DocumentContent>::success(content);
    } catch (const std::exception& e) {
        Core::Logger::error("Content extraction error: {}", e.what());
        return Result<DocumentContent>::failure(
            Core::ErrorCode::ContentExtractionFailed,
            std::string("Failed to extract content: ") + e.what()
        );
    }
}

Result<DocumentStructure> PDFDocumentProcessor::recognizeStructure(const DocumentContent& content) {
    Core::Logger::info("Recognizing document structure");
    
    try {
        DocumentStructure structure;
        
        // Simulate structure recognition
        DocumentStructure::Section introSection;
        introSection.title = "Introduction to Pilot Training";
        introSection.content = "This section introduces the pilot training program.";
        
        DocumentStructure::Section maneuversSection;
        maneuversSection.title = "Basic Flight Maneuvers";
        maneuversSection.content = "This section covers basic flight maneuvers.";
        
        // Add subsections
        DocumentStructure::Section takeoffSubsection;
        takeoffSubsection.title = "Takeoff Procedures";
        takeoffSubsection.content = "Detailed takeoff procedures and checklists.";
        maneuversSection.subsections.push_back(takeoffSubsection);
        
        DocumentStructure::Section landingSubsection;
        landingSubsection.title = "Landing Procedures";
        landingSubsection.content = "Detailed landing procedures and techniques.";
        maneuversSection.subsections.push_back(landingSubsection);
        
        DocumentStructure::Section emergencySection;
        emergencySection.title = "Emergency Procedures";
        emergencySection.content = "This section covers emergency procedures.";
        
        // Add sections to structure
        structure.sections = {introSection, maneuversSection, emergencySection};
        
        // Simulate entity references
        structure.entityReferences["aircraft"] = {"Cessna 172", "Boeing 737"};
        structure.entityReferences["regulations"] = {"FAA Part 61", "FAA Part 91"};
        
        // Simulate regulatory references
        structure.regulatoryReferences["FAA Part 61"] = {
            "Section 61.51 - Pilot logbooks",
            "Section 61.56 - Flight review"
        };
        structure.regulatoryReferences["FAA Part 91"] = {
            "Section 91.103 - Preflight action",
            "Section 91.113 - Right-of-way rules"
        };
        
        return Result<DocumentStructure>::success(structure);
    } catch (const std::exception& e) {
        Core::Logger::error("Structure recognition error: {}", e.what());
        return Result<DocumentStructure>::failure(
            Core::ErrorCode::StructureRecognitionFailed,
            std::string("Failed to recognize structure: ") + e.what()
        );
    }
}

Result<TrainingElements> PDFDocumentProcessor::extractTrainingElements(const DocumentStructure& structure) {
    Core::Logger::info("Extracting training elements");
    
    try {
        TrainingElements elements;
        
        // Simulate learning objectives extraction
        TrainingElements::LearningObjective obj1;
        obj1.id = "LO-001";
        obj1.description = "Demonstrate proper takeoff procedure";
        obj1.category = "Basic Flight";
        obj1.relatedRegulations = {"FAA Part 61.51"};
        obj1.prerequisites = {};
        obj1.importance = 0.9f;
        elements.learningObjectives.push_back(obj1);
        
        TrainingElements::LearningObjective obj2;
        obj2.id = "LO-002";
        obj2.description = "Execute proper landing technique";
        obj2.category = "Basic Flight";
        obj2.relatedRegulations = {"FAA Part 61.51"};
        obj2.prerequisites = {"LO-001"};
        obj2.importance = 0.95f;
        elements.learningObjectives.push_back(obj2);
        
        // Simulate competencies extraction
        TrainingElements::Competency comp1;
        comp1.id = "COMP-001";
        comp1.name = "Takeoff Proficiency";
        comp1.description = "Ability to perform safe and effective takeoffs";
        comp1.assessmentCriteria = {
            "Maintains directional control",
            "Establishes proper climb attitude",
            "Completes checklist items"
        };
        comp1.relatedObjectives = {"LO-001"};
        elements.competencies.push_back(comp1);
        
        // Simulate procedures extraction
        TrainingElements::Procedure proc1;
        proc1.id = "PROC-001";
        proc1.name = "Standard Takeoff Procedure";
        proc1.description = "Steps for executing a standard takeoff";
        proc1.steps = {
            "Complete pre-takeoff checklist",
            "Align aircraft with runway centerline",
            "Apply full throttle smoothly",
            "Maintain directional control with rudder",
            "Rotate at recommended airspeed"
        };
        proc1.relatedCompetencies = {"COMP-001"};
        proc1.safetyConsiderations = {
            "Monitor engine parameters",
            "Abort if abnormal indications observed"
        };
        elements.procedures.push_back(proc1);
        
        // Simulate regulatory mapping
        elements.regulatoryMapping["FAA Part 61.51"] = {"LO-001", "LO-002"};
        
        return Result<TrainingElements>::success(elements);
    } catch (const std::exception& e) {
        Core::Logger::error("Training elements extraction error: {}", e.what());
        return Result<TrainingElements>::failure(
            Core::ErrorCode::TrainingElementsExtractionFailed,
            std::string("Failed to extract training elements: ") + e.what()
        );
    }
}

Result<QualityAssessment> PDFDocumentProcessor::assessQuality(
    const DocumentContent& content,
    const DocumentStructure& structure,
    const TrainingElements& trainingElements) {
    
    Core::Logger::info("Performing quality assessment");
    
    try {
        QualityAssessment assessment;
        
        // Simulate quality assessment
        assessment.completenessScore = 0.87f;
        assessment.consistencyScore = 0.92f;
        assessment.regulatoryComplianceScore = 0.95f;
        assessment.overallConfidence = 0.91f;
        
        // Simulate potential gaps
        assessment.potentialGaps = {
            "Missing detailed emergency procedures for engine failure",
            "No coverage of communication procedures"
        };
        
        // Simulate inconsistencies
        assessment.inconsistencies = {
            "Different terminology used for checklist items in sections 2 and 3"
        };
        
        // Simulate compliance issues
        assessment.complianceIssues = {
            "Limited coverage of FAA Part 91.103 requirements"
        };
        
        return Result<QualityAssessment>::success(assessment);
    } catch (const std::exception& e) {
        Core::Logger::error("Quality assessment error: {}", e.what());
        return Result<QualityAssessment>::failure(
            Core::ErrorCode::QualityAssessmentFailed,
            std::string("Failed to assess quality: ") + e.what()
        );
    }
}

Result<std::string> PDFDocumentProcessor::generateSummary(const DocumentContent& content) {
    Core::Logger::info("Generating document summary");
    
    try {
        // Simulate AI-based summary generation
        std::string summary = "This training manual covers introductory pilot training concepts including "
                             "basic flight maneuvers such as takeoffs and landings, as well as emergency "
                             "procedures. The document is structured in three main sections and includes "
                             "references to FAA regulations Part 61 and Part 91.";
        
        return Result<std::string>::success(summary);
    } catch (const std::exception& e) {
        Core::Logger::error("Summary generation error: {}", e.what());
        return Result<std::string>::failure(
            Core::ErrorCode::SummaryGenerationFailed,
            std::string("Failed to generate summary: ") + e.what()
        );
    }
}

Result<std::unordered_map<std::string, float>> PDFDocumentProcessor::analyzeSentiment(const DocumentContent& content) {
    Core::Logger::info("Analyzing document sentiment");
    
    try {
        // Simulate sentiment analysis
        std::unordered_map<std::string, float> sentiment;
        sentiment["positive"] = 0.65f;
        sentiment["neutral"] = 0.30f;
        sentiment["negative"] = 0.05f;
        sentiment["safety_emphasis"] = 0.85f;
        sentiment["technical_complexity"] = 0.70f;
        
        return Result<std::unordered_map<std::string, float>>::success(sentiment);
    } catch (const std::exception& e) {
        Core::Logger::error("Sentiment analysis error: {}", e.what());
        return Result<std::unordered_map<std::string, float>>::failure(
            Core::ErrorCode::SentimentAnalysisFailed,
            std::string("Failed to analyze sentiment: ") + e.what()
        );
    }
}

Result<std::vector<std::string>> PDFDocumentProcessor::generateTags(const DocumentContent& content) {
    Core::Logger::info("Generating tags");
    
    try {
        // Simulate tag generation
        std::vector<std::string> tags = {
            "pilot training",
            "flight maneuvers",
            "takeoff procedures",
            "landing techniques",
            "emergency procedures",
            "faa regulations",
            "aviation safety"
        };
        
        return Result<std::vector<std::string>>::success(tags);
    } catch (const std::exception& e) {
        Core::Logger::error("Tag generation error: {}", e.what());
        return Result<std::vector<std::string>>::failure(
            Core::ErrorCode::TagGenerationFailed,
            std::string("Failed to generate tags: ") + e.what()
        );
    }
}

Result<std::unordered_map<std::string, std::vector<std::string>>> PDFDocumentProcessor::recognizeEntities(
    const DocumentContent& content) {
    
    Core::Logger::info("Recognizing entities");
    
    try {
        // Simulate entity recognition
        std::unordered_map<std::string, std::vector<std::string>> entities;
        entities["aircraft"] = {"Cessna 172", "Boeing 737"};
        entities["airports"] = {"KJFK", "KLAX", "KORD"};
        entities["regulations"] = {"FAA Part 61", "FAA Part 91"};
        entities["procedures"] = {"Takeoff", "Landing", "Emergency Descent"};
        entities["equipment"] = {"Altimeter", "Airspeed Indicator", "Attitude Indicator"};
        
        return Result<std::unordered_map<std::string, std::vector<std::string>>>::success(entities);
    } catch (const std::exception& e) {
        Core::Logger::error("Entity recognition error: {}", e.what());
        return Result<std::unordered_map<std::string, std::vector<std::string>>>::failure(
            Core::ErrorCode::EntityRecognitionFailed,
            std::string("Failed to recognize entities: ") + e.what()
        );
    }
}

// DocumentProcessorFactory Implementation
DocumentProcessorFactory::DocumentProcessorFactory(std::shared_ptr<Core::ConfigurationManager> configManager)
    : _configManager(std::move(configManager)) {
}

std::shared_ptr<IDocumentProcessor> DocumentProcessorFactory::createProcessor(DocumentType type) {
    switch (type) {
        case DocumentType::PDF:
            return std::make_shared<PDFDocumentProcessor>(_configManager);
        case DocumentType::DOCX:
            return std::make_shared<DOCXDocumentProcessor>(_configManager);
        // Additional cases for other document types
        default:
            Core::Logger::error("Unsupported document type: {}", static_cast<int>(type));
            return nullptr;
    }
}

DocumentType DocumentProcessorFactory::determineType(const std::string& filename) {
    std::string extension = filename.substr(filename.find_last_of('.') + 1);
    std::transform(extension.begin(), extension.end(), extension.begin(), ::tolower);
    
    if (extension == "pdf") {
        return DocumentType::PDF;
    } else if (extension == "docx" || extension == "doc") {
        return DocumentType::DOCX;
    } else if (extension == "xlsx" || extension == "xls") {
        return DocumentType::XLSX;
    } else if (extension == "html" || extension == "htm") {
        return DocumentType::HTML;
    } else if (extension == "pptx" || extension == "ppt") {
        return DocumentType::PPTX;
    } else {
        return DocumentType::UNKNOWN;
    }
}

// DocumentProcessingPipeline Implementation
DocumentProcessingPipeline::DocumentProcessingPipeline(std::shared_ptr<Core::ConfigurationManager> configManager)
    : _processorFactory(configManager), _configManager(std::move(configManager)) {
}

Result<ProcessingResult> DocumentProcessingPipeline::processDocument(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback) {
    
    Core::Logger::info("Processing document: {}", documentPath);
    
    // Determine document type
    DocumentType type = metadata.type;
    if (type == DocumentType::UNKNOWN) {
        type = DocumentProcessorFactory::determineType(documentPath);
    }
    
    // Create appropriate processor
    auto processor = _processorFactory.createProcessor(type);
    if (!processor) {
        return Result<ProcessingResult>::failure(
            Core::ErrorCode::UnsupportedDocumentType,
            "Unsupported document type"
        );
    }
    
    // Process document
    return processor->processDocument(documentPath, metadata, progressCallback);
}

std::future<Result<ProcessingResult>> DocumentProcessingPipeline::processDocumentAsync(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback) {
    
    return std::async(std::launch::async, [this, documentPath, metadata, progressCallback]() {
        return processDocument(documentPath, metadata, progressCallback);
    });
}

std::vector<Result<ProcessingResult>> DocumentProcessingPipeline::processBatch(
    const std::vector<std::string>& documentPaths,
    const std::vector<DocumentMetadata>& metadataList,
    const std::optional<ProgressCallback>& progressCallback) {
    
    if (documentPaths.size() != metadataList.size()) {
        std::vector<Result<ProcessingResult>> results;
        results.push_back(Result<ProcessingResult>::failure(
            Core::ErrorCode::InvalidInput,
            "Document paths and metadata lists must have the same size"
        ));
        return results;
    }
    
    std::vector<std::future<Result<ProcessingResult>>> futures;
    futures.reserve(documentPaths.size());
    
    // Start processing all documents
    for (size_t i = 0; i < documentPaths.size(); ++i) {
        futures.push_back(processDocumentAsync(
            documentPaths[i],
            metadataList[i],
            progressCallback
        ));
    }
    
    // Wait for all to complete
    std::vector<Result<ProcessingResult>> results;
    results.reserve(documentPaths.size());
    
    for (auto& future : futures) {
        results.push_back(future.get());
    }
    
    return results;
}

// DOCXDocumentProcessor Implementation (stub)
DOCXDocumentProcessor::DOCXDocumentProcessor(std::shared_ptr<Core::ConfigurationManager> configManager)
    : _configManager(std::move(configManager)) {
}

DOCXDocumentProcessor::~DOCXDocumentProcessor() = default;

Result<ProcessingResult> DOCXDocumentProcessor::processDocument(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback) {
    
    // Simplified implementation for example
    ProcessingResult result;
    result.documentId = metadata.id;
    result.status = ProcessingStatus::PROCESSING;
    
    // Simulate processing delay
    std::this_thread::sleep_for(std::chrono::milliseconds(500));
    
    result.status = ProcessingStatus::COMPLETED;
    result.content.rawText = "Content extracted from DOCX document";
    result.summary = "Summary of DOCX document";
    
    return Result<ProcessingResult>::success(result);
}

std::future<Result<ProcessingResult>> DOCXDocumentProcessor::processDocumentAsync(
    const std::string& documentPath,
    const DocumentMetadata& metadata,
    const std::optional<ProgressCallback>& progressCallback) {
    
    return std::async(std::launch::async, [this, documentPath, metadata, progressCallback]() {
        return processDocument(documentPath, metadata, progressCallback);
    });
}

} // namespace Document
} // namespace PilotTraining

// src/backend/document/test/DocumentProcessorTest.cpp
#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include <memory>
#include <filesystem>
#include <fstream>

#include "../DocumentProcessor.h"
#include "../../core/ConfigurationManager.h"
#include "../../core/Result.h"

using namespace PilotTraining;
using namespace PilotTraining::Document;
using namespace PilotTraining::Core;
using ::testing::Return;
using ::testing::_;

// Mock ConfigurationManager for testing
class MockConfigurationManager : public ConfigurationManager {
public:
    MOCK_METHOD(std::optional<std::string>, getString, (const std::string&), (const, override));
    MOCK_METHOD(std::optional<int>, getInt, (const std::string&), (const, override));
    MOCK_METHOD(std::optional<double>, getDouble, (const std::string&), (const, override));
    MOCK_METHOD(std::optional<bool>, getBool, (const std::string&), (const, override));
};

class DocumentProcessorTest : public ::testing::Test {
protected:
    void SetUp() override {
        _configManager = std::make_shared<MockConfigurationManager>();
        
        // Create test directory if it doesn't exist
        if (!std::filesystem::exists("test_files")) {
            std::filesystem::create_directory("test_files");
        }
        
        // Create a test PDF file
        _testPdfPath = "test_files/test_document.pdf";
        std::ofstream testFile(_testPdfPath);
        testFile << "%PDF-1.5\nTest PDF content\n%%EOF";
        testFile.close();
        
        // Create test metadata
        _metadata.id = "doc-001";
        _metadata.filename = "test_document.pdf";
        _metadata.contentType = "application/pdf";
        _metadata.organizationId = "org-001";
        _metadata.uploadedBy = "test-user";
        _metadata.createdAt = "2023-05-15T10:30:00Z";
        _metadata.updatedAt = "2023-05-15T10:30:00Z";
        _metadata.type = DocumentType::PDF;
        _metadata.fileSize = 100;
    }
    
    void TearDown() override {
        // Remove test file
        if (std::filesystem::exists(_testPdfPath)) {
            std::filesystem::remove(_testPdfPath);
        }
        
        // Remove test directory
        if (std::filesystem::exists("test_files")) {
            std::filesystem::remove("test_files");
        }
    }
    
    std::shared_ptr<MockConfigurationManager> _configManager;
    std::string _testPdfPath;
    DocumentMetadata _metadata;
};

TEST_F(DocumentProcessorTest, DetermineDocumentTypeFromExtension) {
    // Test PDF detection
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.pdf"), DocumentType::PDF);
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.PDF"), DocumentType::PDF);
    
    // Test DOCX detection
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.docx"), DocumentType::DOCX);
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.doc"), DocumentType::DOCX);
    
    // Test XLSX detection
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.xlsx"), DocumentType::XLSX);
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.xls"), DocumentType::XLSX);
    
    // Test HTML detection
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.html"), DocumentType::HTML);
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.htm"), DocumentType::HTML);
    
    // Test PPTX detection
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.pptx"), DocumentType::PPTX);
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.ppt"), DocumentType::PPTX);
    
    // Test unknown extension
    EXPECT_EQ(DocumentProcessorFactory::determineType("document.unknown"), DocumentType::UNKNOWN);
}

TEST_F(DocumentProcessorTest, CreateProcessorForDocumentType) {
    DocumentProcessorFactory factory(_configManager);
    
    // Test PDF processor creation
    auto pdfProcessor = factory.createProcessor(DocumentType::PDF);
    EXPECT_NE(pdfProcessor, nullptr);
    
    // Test DOCX processor creation
    auto docxProcessor = factory.createProcessor(DocumentType::DOCX);
    EXPECT_NE(docxProcessor, nullptr);
    
    // Test unknown type
    auto unknownProcessor = factory.createProcessor(DocumentType::UNKNOWN);
    EXPECT_EQ(unknownProcessor, nullptr);
}

TEST_F(DocumentProcessorTest, ProcessPDFDocument) {
    // Test processing a PDF document
    PDFDocumentProcessor processor(_configManager);
    
    bool progressCalled = false;
    float lastProgress = 0.0f;
    std::string lastStage;
    
    auto progressCallback = [&progressCalled, &lastProgress, &lastStage](float progress, const std::string& stage) {
        progressCalled = true;
        lastProgress = progress;
        lastStage = stage;
    };
    
    auto result = processor.processDocument(_testPdfPath, _metadata, progressCallback);
    
    // Verify result
    ASSERT_TRUE(result.isSuccess());
    EXPECT_EQ(result.getValue().documentId, _metadata.id);
    EXPECT_EQ(result.getValue().status, ProcessingStatus::COMPLETED);
    EXPECT_FALSE(result.getValue().content.rawText.empty());
    EXPECT_FALSE(result.getValue().summary.empty());
    
    // Verify progress callback was called
    EXPECT_TRUE(progressCalled);
    EXPECT_EQ(lastProgress, 1.0f);
    EXPECT_EQ(lastStage, "Processing completed");
}

TEST_F(DocumentProcessorTest, ProcessNonExistentDocument) {
    // Test processing a non-existent document
    PDFDocumentProcessor processor(_configManager);
    
    auto result = processor.processDocument("non_existent_file.pdf", _metadata, std::nullopt);
    
    // Verify result
    ASSERT_FALSE(result.isSuccess());
    EXPECT_EQ(result.getError().code, ErrorCode::FileNotFound);
}

TEST_F(DocumentProcessorTest, ProcessDocumentAsyncReturnsCorrectResult) {
    // Test asynchronous processing
    PDFDocumentProcessor processor(_configManager);
    
    auto futureResult = processor.processDocumentAsync(_testPdfPath, _metadata, std::nullopt);
    
    // Wait for result
    auto result = futureResult.get();
    
    // Verify result
    ASSERT_TRUE(result.isSuccess());
    EXPECT_EQ(result.getValue().documentId, _metadata.id);
    EXPECT_EQ(result.getValue().status, ProcessingStatus::COMPLETED);
}

TEST_F(DocumentProcessorTest, ProcessingPipelineHandlesDocumentCorrectly) {
    // Test the full processing pipeline
    DocumentProcessingPipeline pipeline(_configManager);
    
    auto result = pipeline.processDocument(_testPdfPath, _metadata, std::nullopt);
    
    // Verify result
    ASSERT_TRUE(result.isSuccess());
    EXPECT_EQ(result.getValue().documentId, _metadata.id);
    EXPECT_EQ(result.getValue().status, ProcessingStatus::COMPLETED);
}

TEST_F(DocumentProcessorTest, ProcessingPipelineHandlesBatchProcessing) {
    // Test batch processing
    DocumentProcessingPipeline pipeline(_configManager);
    
    // Create a second test file
    std::string testDocxPath = "test_files/test_document.docx";
    std::ofstream testFile(testDocxPath);
    testFile << "Test DOCX content";
    testFile.close();
    
    // Create second metadata
    DocumentMetadata metadata2 = _metadata;
    metadata2.id = "doc-002";
    metadata2.filename = "test_document.docx";
    metadata2.contentType = "application/vnd.openxmlformats-officedocument.wordprocessingml.document";
    metadata2.type = DocumentType::DOCX;
    
    // Process batch
    auto results = pipeline.processBatch(
        {_testPdfPath, testDocxPath},
        {_metadata, metadata2},
        std::nullopt
    );
    
    // Verify results
    ASSERT_EQ(results.size(), 2);
    ASSERT_TRUE(results[0].isSuccess());
    EXPECT_EQ(results[0].getValue().documentId, _metadata.id);
    ASSERT_TRUE(results[1].isSuccess());
    EXPECT_EQ(results[1].getValue().documentId, metadata2.id);
    
    // Cleanup
    if (std::filesystem::exists(testDocxPath)) {
        std::filesystem::remove(testDocxPath);
    }
}

TEST_F(DocumentProcessorTest, ProcessingPipelineHandlesInvalidBatchInput) {
    // Test batch processing with mismatched inputs
    DocumentProcessingPipeline pipeline(_configManager);
    
    // Process batch with mismatched lists
    auto results = pipeline.processBatch(
        {_testPdfPath},
        {_metadata, _metadata}, // Two metadata entries but only one path
        std::nullopt
    );
    
    // Verify error
    ASSERT_EQ(results.size(), 1);
    ASSERT_FALSE(results[0].isSuccess());
    EXPECT_EQ(results[0].getError().code, ErrorCode::InvalidInput);
}

// Test the AI-enhanced features
TEST_F(DocumentProcessorTest, GeneratesSummaryCorrectly) {
    PDFDocumentProcessor processor(_configManager);
    
    auto result = processor.processDocument(_testPdfPath, _metadata, std::nullopt);
    
    // Verify summary
    ASSERT_TRUE(result.isSuccess());
    EXPECT_FALSE(result.getValue().summary.empty());
}

TEST_F(DocumentProcessorTest, AnalyzesSentimentCorrectly) {
    PDFDocumentProcessor processor(_configManager);
    
    auto result = processor.processDocument(_testPdfPath, _metadata, std::nullopt);
    
    // Verify sentiment analysis
    ASSERT_TRUE(result.isSuccess());
    EXPECT_FALSE(result.getValue().sentimentAnalysis.empty());
    EXPECT_TRUE(result.getValue().sentimentAnalysis.find("positive") != result.getValue().sentimentAnalysis.end());
}

TEST_F(DocumentProcessorTest, GeneratesTagsCorrectly) {
    PDFDocumentProcessor processor(_configManager);
    
    auto result = processor.processDocument(_testPdfPath, _metadata, std::nullopt);
    
    // Verify tags
    ASSERT_TRUE(result.isSuccess());
    EXPECT_FALSE(result.getValue().autoTags.empty());
}

TEST_F(DocumentProcessorTest, RecognizesEntitiesCorrectly) {
    PDFDocumentProcessor processor(_configManager);
    
    auto result = processor.processDocument(_testPdfPath, _metadata, std::nullopt);
    
    // Verify entity recognition
    ASSERT_TRUE(result.isSuccess());
    EXPECT_FALSE(result.getValue().entityRecognition.empty());
    EXPECT_TRUE(result.getValue().entityRecognition.find("aircraft") != result.getValue().entityRecognition.end());
}

cmake_minimum_required(VERSION 3.20)
project(document-service VERSION 1.0.0 LANGUAGES CXX)

# Set C++20 standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Set output directories
set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)

# Find required packages
find_package(gRPC REQUIRED)
find_package(Protobuf REQUIRED)
find_package(OpenSSL REQUIRED)
find_package(nlohmann_json 3.10.0 REQUIRED)
find_package(spdlog REQUIRED)
find_package(prometheus-cpp REQUIRED)
find_package(Boost REQUIRED COMPONENTS system filesystem)
find_package(cpprestsdk REQUIRED)
find_package(Tesseract REQUIRED)
find_package(Leptonica REQUIRED)
find_package(poppler REQUIRED)

# Include directories
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_BINARY_DIR}/generated
    ${TESSERACT_INCLUDE_DIRS}
    ${LEPTONICA_INCLUDE_DIRS}
)

# Generate protobuf and gRPC code
set(PROTO_FILES
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/document_service.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/core_service.proto
)

protobuf_generate_cpp(PROTO_SRCS PROTO_HDRS ${PROTO_FILES})
grpc_generate_cpp(GRPC_SRCS GRPC_HDRS ${CMAKE_CURRENT_BINARY_DIR}/generated ${PROTO_FILES})

# Source files
file(GLOB_RECURSE SOURCES 
    ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp
)

# Add executable
add_executable(${PROJECT_NAME} ${SOURCES} ${PROTO_SRCS} ${PROTO_HDRS} ${GRPC_SRCS} ${GRPC_HDRS})

# Link libraries
target_link_libraries(${PROJECT_NAME}
    PRIVATE
    gRPC::grpc++
    gRPC::grpc++_reflection
    protobuf::libprotobuf
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
    spdlog::spdlog
    prometheus-cpp::core
    prometheus-cpp::push
    Boost::system
    Boost::filesystem
    cpprestsdk::cpprest
    ${TESSERACT_LIBRARIES}
    ${LEPTONICA_LIBRARIES}
    poppler
    pthread
)

# Copy configuration files to build directory
configure_file(
    ${CMAKE_CURRENT_SOURCE_DIR}/config/config.json
    ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/config/config.json
    COPYONLY
)

# Add tests
enable_testing()
add_subdirectory(tests)

# Installation
install(TARGETS ${PROJECT_NAME}
    RUNTIME DESTINATION bin
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)

install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/config/
    DESTINATION etc/${PROJECT_NAME}
    FILES_MATCHING PATTERN "*.json"
)

# Documentation
find_package(Doxygen)
if(DOXYGEN_FOUND)
    set(DOXYGEN_IN ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in)
    set(DOXYGEN_OUT ${CMAKE_CURRENT_BINARY_DIR}/Doxyfile)
    
    configure_file(${DOXYGEN_IN} ${DOXYGEN_OUT} @ONLY)
    
    add_custom_target(docs
        COMMAND ${DOXYGEN_EXECUTABLE} ${DOXYGEN_OUT}
        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
        COMMENT "Generating API documentation with Doxygen"
        VERBATIM
    )
endif()
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <nlohmann/json.hpp>
#include "parsers/document_parser.h"

namespace document {
namespace extraction {

/**
 * @brief Content type categories
 */
enum class ContentType {
    UNKNOWN,
    REGULATORY,
    TRAINING,
    TECHNICAL,
    REFERENCE,
    PROCEDURE
};

/**
 * @brief Convert ContentType to string
 * @param type Content type
 * @return String representation
 */
std::string contentTypeToString(ContentType type);

/**
 * @brief Convert string to ContentType
 * @param str String representation
 * @return Content type
 */
ContentType contentTypeFromString(const std::string& str);

/**
 * @brief Extracted content section
 */
struct ContentSection {
    std::string id;
    std::string title;
    std::string content;
    int section_level;
    std::vector<std::string> tags;
    std::map<std::string, std::string> metadata;
    std::vector<std::string> references;
    ContentType type;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Content section or nullopt if invalid
     */
    static std::optional<ContentSection> fromJson(const nlohmann::json& json);
};

/**
 * @brief Extracted training objective
 */
struct TrainingObjective {
    std::string id;
    std::string description;
    std::string level;  // Knowledge, Comprehension, Application, Analysis, Synthesis, Evaluation
    std::vector<std::string> related_sections;
    std::vector<std::string> keywords;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Training objective or nullopt if invalid
     */
    static std::optional<TrainingObjective> fromJson(const nlohmann::json& json);
};

/**
 * @brief Extracted regulatory reference
 */
struct RegulatoryReference {
    std::string id;
    std::string regulation;
    std::string section;
    std::string reference;
    std::string description;
    std::vector<std::string> related_sections;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Regulatory reference or nullopt if invalid
     */
    static std::optional<RegulatoryReference> fromJson(const nlohmann::json& json);
};

/**
 * @brief Extracted procedure step
 */
struct ProcedureStep {
    std::string id;
    int step_number;
    std::string description;
    std::string actor;  // Who performs the step
    std::vector<std::string> conditions;  // Conditions for step
    std::vector<std::string> notes;
    std::vector<std::string> warnings;
    std::vector<std::string> related_sections;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Procedure step or nullopt if invalid
     */
    static std::optional<ProcedureStep> fromJson(const nlohmann::json& json);
};

/**
 * @brief Extracted procedure
 */
struct Procedure {
    std::string id;
    std::string title;
    std::string description;
    std::vector<ProcedureStep> steps;
    std::vector<std::string> references;
    std::map<std::string, std::string> metadata;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Procedure or nullopt if invalid
     */
    static std::optional<Procedure> fromJson(const nlohmann::json& json);
};

/**
 * @brief Extracted training content
 */
struct TrainingContent {
    std::string document_id;
    std::string title;
    std::string description;
    std::vector<ContentSection> sections;
    std::vector<TrainingObjective> objectives;
    std::vector<RegulatoryReference> regulations;
    std::vector<Procedure> procedures;
    std::map<std::string, std::string> metadata;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Training content or nullopt if invalid
     */
    static std::optional<TrainingContent> fromJson(const nlohmann::json& json);
};

/**
 * @brief Extraction options
 */
struct ExtractionOptions {
    bool extract_objectives = true;
    bool extract_regulations = true;
    bool extract_procedures = true;
    bool extract_related_content = true;
    std::string language = "en";
    std::string document_type;  // Optional document type hint
    std::vector<std::string> keywords;  // Optional keywords to focus on
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Extraction options or nullopt if invalid
     */
    static std::optional<ExtractionOptions> fromJson(const nlohmann::json& json);
};

/**
 * @brief Content extractor interface
 */
class IContentExtractor {
public:
    virtual ~IContentExtractor() = default;
    
    /**
     * @brief Extract training content from document
     * @param document_content Document content
     * @param options Extraction options
     * @return Training content or nullopt if extraction failed
     */
    virtual std::optional<TrainingContent> extractContent(
        const parsers::DocumentContent& document_content,
        const ExtractionOptions& options = ExtractionOptions()
    ) = 0;
    
    /**
     * @brief Extract training content from file
     * @param file_path File path
     * @param options Extraction options
     * @return Training content or nullopt if extraction failed
     */
    virtual std::optional<TrainingContent> extractFromFile(
        const std::string& file_path,
        const ExtractionOptions& options = ExtractionOptions()
    ) = 0;
    
    /**
     * @brief Extract training content from data
     * @param data Document data
     * @param doc_type Document type
     * @param options Extraction options
     * @return Training content or nullopt if extraction failed
     */
    virtual std::optional<TrainingContent> extractFromData(
        const std::vector<uint8_t>& data,
        parsers::DocumentType doc_type,
        const ExtractionOptions& options = ExtractionOptions()
    ) = 0;
};

/**
 * @brief Standard content extractor
 */
class StandardContentExtractor : public IContentExtractor {
public:
    /**
     * @brief Constructor
     * @param parser_factory Document parser factory
     */
    explicit StandardContentExtractor(
        std::shared_ptr<parsers::DocumentParserFactory> parser_factory = nullptr
    );
    
    /**
     * @brief Destructor
     */
    ~StandardContentExtractor() override;
    
    /**
     * @brief Extract training content from document
     * @param document_content Document content
     * @param options Extraction options
     * @return Training content or nullopt if extraction failed
     */
    std::optional<TrainingContent> extractContent(
        const parsers::DocumentContent& document_content,
        const ExtractionOptions& options = ExtractionOptions()
    ) override;
    
    /**
     * @brief Extract training content from file
     * @param file_path File path
     * @param options Extraction options
     * @return Training content or nullopt if extraction failed
     */
    std::optional<TrainingContent> extractFromFile(
        const std::string& file_path,
        const ExtractionOptions& options = ExtractionOptions()
    ) override;
    
    /**
     * @brief Extract training content from data
     * @param data Document data
     * @param doc_type Document type
     * @param options Extraction options
     * @return Training content or nullopt if extraction failed
     */
    std::optional<TrainingContent> extractFromData(
        const std::vector<uint8_t>& data,
        parsers::DocumentType doc_type,
        const ExtractionOptions& options = ExtractionOptions()
    ) override;
    
private:
    /**
     * @brief Extract sections from document content
     * @param content Document content
     * @param options Extraction options
     * @return Content sections
     */
    std::vector<ContentSection> extractSections(
        const parsers::DocumentContent& content,
        const ExtractionOptions& options
    );
    
    /**
     * @brief Extract training objectives from document content
     * @param content Document content
     * @param sections Extracted sections
     * @param options Extraction options
     * @return Training objectives
     */
    std::vector<TrainingObjective> extractObjectives(
        const parsers::DocumentContent& content,
        const std::vector<ContentSection>& sections,
        const ExtractionOptions& options
    );
    
    /**
     * @brief Extract regulatory references from document content
     * @param content Document content
     * @param sections Extracted sections
     * @param options Extraction options
     * @return Regulatory references
     */
    std::vector<RegulatoryReference> extractRegulations(
        const parsers::DocumentContent& content,
        const std::vector<ContentSection>& sections,
        const ExtractionOptions& options
    );
    
    /**
     * @brief Extract procedures from document content
     * @param content Document content
     * @param sections Extracted sections
     * @param options Extraction options
     * @return Procedures
     */
    std::vector<Procedure> extractProcedures(
        const parsers::DocumentContent& content,
        const std::vector<ContentSection>& sections,
        const ExtractionOptions& options
    );
    
    /**
     * @brief Detect content type
     * @param text Text to analyze
     * @return Content type
     */
    ContentType detectContentType(const std::string& text);
    
    /**
     * @brief Extract section title from heading
     * @param heading Heading text
     * @return Section title
     */
    std::string extractSectionTitle(const std::string& heading);
    
    /**
     * @brief Generate section ID
     * @param title Section title
     * @param level Section level
     * @return Section ID
     */
    std::string generateSectionId(const std::string& title, int level);
    
    std::shared_ptr<parsers::DocumentParserFactory> parser_factory_;
};

/**
 * @brief NLP-based content extractor
 */
class NlpContentExtractor : public IContentExtractor {
public:
    /**
     * @brief Constructor
     * @param parser_factory Document parser factory
     * @param model_path Path to NLP model
     */
    NlpContentExtractor(
        std::shared_ptr<parsers::DocumentParserFactory> parser_factory = nullptr,
        const std::string& model_path = ""
    );
    
    /**
     * @brief Destructor
     */
    ~NlpContentExtractor() override;
    
    /**
     * @brief Extract training content from document
     * @param document_content Document content
     * @param options Extraction options
     * @return Training content or nullopt if extraction failed
     */
    std::optional<TrainingContent> extractContent(
        const parsers::DocumentContent& document_content,
        const ExtractionOptions& options = ExtractionOptions()
    ) override;
    
    /**
     * @brief Extract training content from file
     * @param file_path File path
     * @param options Extraction options
     * @return Training content or nullopt if extraction failed
     */
    std::optional<TrainingContent> extractFromFile(
        const std::string& file_path,
        const ExtractionOptions& options = ExtractionOptions()
    ) override;
    
    /**
     * @brief Extract training content from data
     * @param data Document data
     * @param doc_type Document type
     * @param options Extraction options
     * @return Training content or nullopt if extraction failed
     */
    std::optional<TrainingContent> extractFromData(
        const std::vector<uint8_t>& data,
        parsers::DocumentType doc_type,
        const ExtractionOptions& options = ExtractionOptions()
    ) override;
    
private:
    /**
     * @brief Initialize NLP model
     * @param model_path Path to NLP model
     * @return True if initialized successfully
     */
    bool initializeModel(const std::string& model_path);
    
    /**
     * @brief Process text with NLP model
     * @param text Text to process
     * @return Processed text
     */
    std::string processText(const std::string& text);
    
    /**
     * @brief Extract named entities
     * @param text Text to analyze
     * @return Named entities (type -> text)
     */
    std::map<std::string, std::vector<std::string>> extractNamedEntities(const std::string& text);
    
    std::shared_ptr<parsers::DocumentParserFactory> parser_factory_;
    void* nlp_model_;  // Opaque pointer to NLP model
    std::string model_path_;
    bool model_initialized_;
};

} // namespace extraction
} // namespace document
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <nlohmann/json.hpp>

namespace document {
namespace parsers {

/**
 * @brief Supported document types
 */
enum class DocumentType {
    UNKNOWN,
    PDF,
    DOCX,
    XLSX,
    HTML,
    TXT,
    MD,
    XML,
    JSON
};

/**
 * @brief Convert DocumentType to string
 * @param type Document type
 * @return String representation
 */
std::string documentTypeToString(DocumentType type);

/**
 * @brief Convert string to DocumentType
 * @param str String representation
 * @return Document type
 */
DocumentType documentTypeFromString(const std::string& str);

/**
 * @brief Get document type from file extension
 * @param filename Filename
 * @return Document type
 */
DocumentType documentTypeFromExtension(const std::string& filename);

/**
 * @brief Document content structure
 */
struct DocumentContent {
    std::string text;                       // Plain text content
    std::vector<std::string> paragraphs;    // Text split into paragraphs
    std::map<std::string, std::string> metadata; // Document metadata
    std::vector<std::map<std::string, std::string>> tables; // Extracted tables
    std::vector<std::string> headings;      // Document headings
    std::vector<std::string> links;         // Links in document
    std::map<std::string, std::string> images; // Image descriptions
    nlohmann::json structured_content;      // Structured representation
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Document content or nullopt if invalid
     */
    static std::optional<DocumentContent> fromJson(const nlohmann::json& json);
};

/**
 * @brief Document parser options
 */
struct ParserOptions {
    bool extract_metadata = true;
    bool extract_tables = true;
    bool extract_images = false;
    bool preserve_layout = true;
    bool extract_links = true;
    int max_text_length = 0;  // 0 = no limit
    std::string password;     // For password-protected documents
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Parser options or nullopt if invalid
     */
    static std::optional<ParserOptions> fromJson(const nlohmann::json& json);
};

/**
 * @brief Document parser interface
 */
class IDocumentParser {
public:
    virtual ~IDocumentParser() = default;
    
    /**
     * @brief Parse document from file
     * @param file_path File path
     * @param options Parser options
     * @return Parsed document content or nullopt if parsing failed
     */
    virtual std::optional<DocumentContent> parseFile(
        const std::string& file_path,
        const ParserOptions& options = ParserOptions()
    ) = 0;
    
    /**
     * @brief Parse document from memory
     * @param data Document data
     * @param options Parser options
     * @return Parsed document content or nullopt if parsing failed
     */
    virtual std::optional<DocumentContent> parseData(
        const std::vector<uint8_t>& data,
        const ParserOptions& options = ParserOptions()
    ) = 0;
    
    /**
     * @brief Get supported document type
     * @return Document type
     */
    virtual DocumentType getDocumentType() const = 0;
    
    /**
     * @brief Check if parser supports the given file
     * @param file_path File path
     * @return True if supported
     */
    virtual bool supportsFile(const std::string& file_path) = 0;
    
    /**
     * @brief Check if parser supports the given data
     * @param data Document data
     * @return True if supported
     */
    virtual bool supportsData(const std::vector<uint8_t>& data) = 0;
};

/**
 * @brief PDF document parser
 */
class PdfParser : public IDocumentParser {
public:
    /**
     * @brief Constructor
     */
    PdfParser();
    
    /**
     * @brief Destructor
     */
    ~PdfParser() override;
    
    /**
     * @brief Parse PDF file
     * @param file_path File path
     * @param options Parser options
     * @return Parsed document content or nullopt if parsing failed
     */
    std::optional<DocumentContent> parseFile(
        const std::string& file_path,
        const ParserOptions& options = ParserOptions()
    ) override;
    
    /**
     * @brief Parse PDF data
     * @param data Document data
     * @param options Parser options
     * @return Parsed document content or nullopt if parsing failed
     */
    std::optional<DocumentContent> parseData(
        const std::vector<uint8_t>& data,
        const ParserOptions& options = ParserOptions()
    ) override;
    
    /**
     * @brief Get supported document type
     * @return Document type
     */
    DocumentType getDocumentType() const override {
        return DocumentType::PDF;
    }
    
    /**
     * @brief Check if parser supports the given file
     * @param file_path File path
     * @return True if supported
     */
    bool supportsFile(const std::string& file_path) override;
    
    /**
     * @brief Check if parser supports the given data
     * @param data Document data
     * @return True if supported
     */
    bool supportsData(const std::vector<uint8_t>& data) override;
    
private:
    /**
     * @brief Extract text from PDF
     * @param doc PDF document
     * @param options Parser options
     * @return Document content
     */
    DocumentContent extractContent(void* doc, const ParserOptions& options);
    
    /**
     * @brief Extract metadata from PDF
     * @param doc PDF document
     * @return Metadata
     */
    std::map<std::string, std::string> extractMetadata(void* doc);
    
    /**
     * @brief Extract tables from PDF
     * @param doc PDF document
     * @return Tables
     */
    std::vector<std::map<std::string, std::string>> extractTables(void* doc);
};

/**
 * @brief DOCX document parser
 */
class DocxParser : public IDocumentParser {
public:
    /**
     * @brief Constructor
     */
    DocxParser();
    
    /**
     * @brief Destructor
     */
    ~DocxParser() override;
    
    /**
     * @brief Parse DOCX file
     * @param file_path File path
     * @param options Parser options
     * @return Parsed document content or nullopt if parsing failed
     */
    std::optional<DocumentContent> parseFile(
        const std::string& file_path,
        const ParserOptions& options = ParserOptions()
    ) override;
    
    /**
     * @brief Parse DOCX data
     * @param data Document data
     * @param options Parser options
     * @return Parsed document content or nullopt if parsing failed
     */
    std::optional<DocumentContent> parseData(
        const std::vector<uint8_t>& data,
        const ParserOptions& options = ParserOptions()
    ) override;
    
    /**
     * @brief Get supported document type
     * @return Document type
     */
    DocumentType getDocumentType() const override {
        return DocumentType::DOCX;
    }
    
    /**
     * @brief Check if parser supports the given file
     * @param file_path File path
     * @return True if supported
     */
    bool supportsFile(const std::string& file_path) override;
    
    /**
     * @brief Check if parser supports the given data
     * @param data Document data
     * @return True if supported
     */
    bool supportsData(const std::vector<uint8_t>& data) override;
    
private:
    /**
     * @brief Extract content from DOCX
     * @param doc DOCX document
     * @param options Parser options
     * @return Document content
     */
    DocumentContent extractContent(void* doc, const ParserOptions& options);
    
    /**
     * @brief Extract metadata from DOCX
     * @param doc DOCX document
     * @return Metadata
     */
    std::map<std::string, std::string> extractMetadata(void* doc);
    
    /**
     * @brief Extract tables from DOCX
     * @param doc DOCX document
     * @return Tables
     */
    std::vector<std::map<std::string, std::string>> extractTables(void* doc);
};

/**
 * @brief HTML document parser
 */
class HtmlParser : public IDocumentParser {
public:
    /**
     * @brief Constructor
     */
    HtmlParser();
    
    /**
     * @brief Destructor
     */
    ~HtmlParser() override;
    
    /**
     * @brief Parse HTML file
     * @param file_path File path
     * @param options Parser options
     * @return Parsed document content or nullopt if parsing failed
     */
    std::optional<DocumentContent> parseFile(
        const std::string& file_path,
        const ParserOptions& options = ParserOptions()
    ) override;
    
    /**
     * @brief Parse HTML data
     * @param data Document data
     * @param options Parser options
     * @return Parsed document content or nullopt if parsing failed
     */
    std::optional<DocumentContent> parseData(
        const std::vector<uint8_t>& data,
        const ParserOptions& options = ParserOptions()
    ) override;
    
    /**
     * @brief Get supported document type
     * @return Document type
     */
    DocumentType getDocumentType() const override {
        return DocumentType::HTML;
    }
    
    /**
     * @brief Check if parser supports the given file
     * @param file_path File path
     * @return True if supported
     */
    bool supportsFile(const std::string& file_path) override;
    
    /**
     * @brief Check if parser supports the given data
     * @param data Document data
     * @return True if supported
     */
    bool supportsData(const std::vector<uint8_t>& data) override;
    
private:
    /**
     * @brief Extract content from HTML
     * @param doc HTML document
     * @param options Parser options
     * @return Document content
     */
    DocumentContent extractContent(void* doc, const ParserOptions& options);
    
    /**
     * @brief Extract metadata from HTML
     * @param doc HTML document
     * @return Metadata
     */
    std::map<std::string, std::string> extractMetadata(void* doc);
    
    /**
     * @brief Extract tables from HTML
     * @param doc HTML document
     * @return Tables
     */
    std::vector<std::map<std::string, std::string>> extractTables(void* doc);
    
    /**
     * @brief Extract links from HTML
     * @param doc HTML document
     * @return Links
     */
    std::vector<std::string> extractLinks(void* doc);
};

/**
 * @brief Document parser factory
 */
class DocumentParserFactory {
public:
    /**
     * @brief Get the singleton instance
     * @return Factory instance
     */
    static DocumentParserFactory& getInstance();
    
    /**
     * @brief Register a parser type
     * @tparam T Parser type
     */
    template<typename T>
    void registerParser() {
        auto parser = std::make_unique<T>();
        parsers_[parser->getDocumentType()] = std::move(parser);
    }
    
    /**
     * @brief Get parser for document type
     * @param type Document type
     * @return Parser or nullptr if not found
     */
    std::shared_ptr<IDocumentParser> getParser(DocumentType type);
    
    /**
     * @brief Get parser for file
     * @param file_path File path
     * @return Parser or nullptr if not found
     */
    std::shared_ptr<IDocumentParser> getParserForFile(const std::string& file_path);
    
    /**
     * @brief Get parser for data
     * @param data Document data
     * @return Parser or nullptr if not found
     */
    std::shared_ptr<IDocumentParser> getParserForData(const std::vector<uint8_t>& data);
    
private:
    DocumentParserFactory();
    ~DocumentParserFactory() = default;
    
    DocumentParserFactory(const DocumentParserFactory&) = delete;
    DocumentParserFactory& operator=(const DocumentParserFactory&) = delete;
    
    std::map<DocumentType, std::unique_ptr<IDocumentParser>> parsers_;
};

} // namespace parsers
} // namespace document
syntax = "proto3";

package document;

// Service definition for document management
service DocumentService {
  // Document management operations
  rpc UploadDocument (UploadDocumentRequest) returns (DocumentResponse);
  rpc GetDocument (GetDocumentRequest) returns (Document);
  rpc UpdateDocument (UpdateDocumentRequest) returns (DocumentResponse);
  rpc DeleteDocument (DeleteDocumentRequest) returns (DocumentResponse);
  rpc ListDocuments (ListDocumentsRequest) returns (ListDocumentsResponse);
  
  // Content extraction
  rpc ExtractContent (ExtractContentRequest) returns (ExtractContentResponse);
  rpc SearchDocuments (SearchRequest) returns (SearchResponse);
  rpc AnalyzeDocument (AnalyzeDocumentRequest) returns (AnalyzeDocumentResponse);
  
  // Version control
  rpc GetDocumentVersion (GetDocumentVersionRequest) returns (Document);
  rpc ListDocumentVersions (ListVersionsRequest) returns (ListVersionsResponse);
  rpc CompareVersions (CompareVersionsRequest) returns (CompareVersionsResponse);
}

// Document type
enum DocumentType {
  UNKNOWN = 0;
  PDF = 1;
  DOCX = 2;
  XLSX = 3;
  HTML = 4;
  TXT = 5;
  IMAGE = 6;
}

// Document status
enum DocumentStatus {
  DRAFT = 0;
  PUBLISHED = 1;
  ARCHIVED = 2;
}

// Document security classification
enum SecurityClassification {
  PUBLIC = 0;
  INTERNAL = 1;
  CONFIDENTIAL = 2;
  RESTRICTED = 3;
}

// Document
message Document {
  string document_id = 1;
  string title = 2;
  string description = 3;
  DocumentType document_type = 4;
  DocumentStatus status = 5;
  SecurityClassification classification = 6;
  string author_id = 7;
  string version = 8;
  int64 created_at = 9;  // Milliseconds since epoch
  int64 updated_at = 10;  // Milliseconds since epoch
  int64 size_bytes = 11;
  string content_type = 12;
  string filename = 13;
  map<string, string> metadata = 14;
  repeated string tags = 15;
  string category = 16;
  bytes content = 17;  // Document content (may be empty for large documents)
}

// Upload document request
message UploadDocumentRequest {
  string title = 1;
  string description = 2;
  bytes content = 3;
  string filename = 4;
  string content_type = 5;
  DocumentStatus status = 6;
  SecurityClassification classification = 7;
  map<string, string> metadata = 8;
  repeated string tags = 9;
  string category = 10;
  bool extract_text = 11;  // Whether to extract text content
  bool generate_preview = 12;  // Whether to generate preview
}

// Get document request
message GetDocumentRequest {
  string document_id = 1;
  bool include_content = 2;  // Whether to include document content
}

// Update document request
message UpdateDocumentRequest {
  string document_id = 1;
  string title = 2;
  string description = 3;
  bytes content = 4;  // Optional - only if content is updated
  DocumentStatus status = 5;
  SecurityClassification classification = 6;
  map<string, string> metadata = 7;
  repeated string tags = 8;
  string category = 9;
}

// Delete document request
message DeleteDocumentRequest {
  string document_id = 1;
  bool permanently = 2;  // Whether to permanently delete
}

// Document response
message DocumentResponse {
  bool success = 1;
  string document_id = 2;
  string error_message = 3;
  int64 timestamp = 4;  // Milliseconds since epoch
}

// List documents request
message ListDocumentsRequest {
  string author_id = 1;  // Filter by author
  DocumentType document_type = 2;  // Filter by type
  DocumentStatus status = 3;  // Filter by status
  string category = 4;  // Filter by category
  repeated string tags = 5;  // Filter by tags
  int64 start_date = 6;  // Filter by date range (start)
  int64 end_date = 7;  // Filter by date range (end)
  int32 page = 8;
  int32 page_size = 9;
  string sort_by = 10;
  bool ascending = 11;
  string query = 12;  // Free text search
}

// List documents response
message ListDocumentsResponse {
  bool success = 1;
  repeated DocumentSummary documents = 2;
  int32 total_count = 3;
  int32 page = 4;
  int32 page_size = 5;
  string error_message = 6;
}

// Document summary (without content)
message DocumentSummary {
  string document_id = 1;
  string title = 2;
  string description = 3;
  DocumentType document_type = 4;
  DocumentStatus status = 5;
  SecurityClassification classification = 6;
  string author_id = 7;
  string version = 8;
  int64 created_at = 9;
  int64 updated_at = 10;
  int64 size_bytes = 11;
  string content_type = 12;
  string filename = 13;
  repeated string tags = 14;
  string category = 15;
  bool has_text = 16;  // Whether text has been extracted
  bool has_preview = 17;  // Whether preview is available
}

// Extract content request
message ExtractContentRequest {
  string document_id = 1;
  bool extract_text = 2;
  bool extract_metadata = 3;
  bool extract_images = 4;
  bool extract_tables = 5;
  bool use_ocr = 6;  // Whether to use OCR for images and PDFs
  string language = 7;  // Language hint for OCR
}

// Extract content response
message ExtractContentResponse {
  bool success = 1;
  string document_id = 2;
  string text_content = 3;
  repeated TableData tables = 4;
  repeated ImageData images = 5;
  map<string, string> extracted_metadata = 6;
  string error_message = 7;
}

// Table data
message TableData {
  int32 table_index = 1;
  repeated string headers = 2;
  repeated Row rows = 3;
  int32 page_number = 4;
  
  message Row {
    repeated string cells = 1;
  }
}

// Image data
message ImageData {
  int32 image_index = 1;
  bytes image_data = 2;
  string image_type = 3;
  int32 width = 4;
  int32 height = 5;
  int32 page_number = 6;
}

// Search request
message SearchRequest {
  string query = 1;
  repeated string document_ids = 2;  // Restrict to these documents (optional)
  string category = 3;  // Restrict to category (optional)
  repeated string tags = 4;  // Restrict to tags (optional)
  DocumentType document_type = 5;  // Restrict to type (optional)
  int32 page = 6;
  int32 page_size = 7;
  bool highlight_results = 8;  // Whether to highlight matching text
}

// Search response
message SearchResponse {
  bool success = 1;
  repeated SearchResult results = 2;
  int32 total_count = 3;
  int32 page = 4;
  int32 page_size = 5;
  string error_message = 6;
}

// Search result
message SearchResult {
  DocumentSummary document = 1;
  double relevance_score = 2;
  repeated string highlights = 3;  // Highlighted text snippets
}

// Analyze document request
message AnalyzeDocumentRequest {
  string document_id = 1;
  bool analyze_sentiment = 2;
  bool analyze_entities = 3;
  bool analyze_categories = 4;
  bool analyze_key_phrases = 5;
  bool analyze_language = 6;
}

// Analyze document response
message AnalyzeDocumentResponse {
  bool success = 1;
  string document_id = 2;
  Sentiment sentiment = 3;
  repeated Entity entities = 4;
  repeated Category categories = 5;
  repeated string key_phrases = 6;
  string detected_language = 7;
  float language_confidence = 8;
  string error_message = 9;
}

// Sentiment analysis
message Sentiment {
  float score = 1;  // -1.0 to 1.0
  string label = 2;  // POSITIVE, NEGATIVE, NEUTRAL
}

// Entity
message Entity {
  string name = 1;
  string type = 2;  // PERSON, ORGANIZATION, LOCATION, etc.
  float confidence = 3;
}

// Category
message Category {
  string name = 1;
  float confidence = 2;
}

// Get document version request
message GetDocumentVersionRequest {
  string document_id = 1;
  string version = 2;
  bool include_content = 3;
}

// List versions request
message ListVersionsRequest {
  string document_id = 1;
  int32 page = 2;
  int32 page_size = 3;
}

// List versions response
message ListVersionsResponse {
  bool success = 1;
  string document_id = 2;
  repeated VersionInfo versions = 3;
  int32 total_count = 4;
  int32 page = 5;
  int32 page_size = 6;
  string error_message = 7;
}

// Version info
message VersionInfo {
  string version = 1;
  string author_id = 2;
  int64 created_at = 3;
  string comment = 4;
  int64 size_bytes = 5;
  DocumentStatus status = 6;
}

// Compare versions request
message CompareVersionsRequest {
  string document_id = 1;
  string version1 = 2;
  string version2 = 3;
}

// Compare versions response
message CompareVersionsResponse {
  bool success = 1;
  string document_id = 2;
  string version1 = 3;
  string version2 = 4;
  repeated Difference differences = 5;
  string error_message = 6;
}

// Difference between versions
message Difference {
  enum DiffType {
    ADDED = 0;
    REMOVED = 1;
    CHANGED = 2;
  }
  
  DiffType type = 1;
  string path = 2;  // Path to the changed element (for structured docs)
  string old_value = 3;
  string new_value = 4;
}
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <optional>
#include <chrono>
#include <map>
#include "document/document_model.h"
#include "persistence/database_connection.h"

namespace document {
namespace repository {

/**
 * @brief Document repository interface
 */
class IDocumentRepository {
public:
    virtual ~IDocumentRepository() = default;
    
    /**
     * @brief Create a document
     * @param document Document to create
     * @return Created document ID or empty string if failed
     */
    virtual std::string createDocument(const Document& document) = 0;
    
    /**
     * @brief Get a document by ID
     * @param document_id Document ID
     * @param include_content Whether to include document content
     * @return Document or nullopt if not found
     */
    virtual std::optional<Document> getDocument(
        const std::string& document_id,
        bool include_content = false
    ) = 0;
    
    /**
     * @brief Update a document
     * @param document Document to update
     * @return True if updated, false if not found
     */
    virtual bool updateDocument(const Document& document) = 0;
    
    /**
     * @brief Delete a document
     * @param document_id Document ID
     * @param permanently Whether to permanently delete
     * @return True if deleted, false if not found
     */
    virtual bool deleteDocument(
        const std::string& document_id,
        bool permanently = false
    ) = 0;
    
    /**
     * @brief List documents matching criteria
     * @param author_id Author ID (optional)
     * @param document_type Document type (optional)
     * @param status Document status (optional)
     * @param category Category (optional)
     * @param tags Tags (optional)
     * @param start_date Start date (optional)
     * @param end_date End date (optional)
     * @param query Search query (optional)
     * @param page Page number (starting from 1)
     * @param page_size Page size
     * @param sort_by Sort field
     * @param ascending Sort direction
     * @return Pair of document summaries and total count
     */
    virtual std::pair<std::vector<DocumentSummary>, int> listDocuments(
        const std::optional<std::string>& author_id = std::nullopt,
        const std::optional<DocumentType>& document_type = std::nullopt,
        const std::optional<DocumentStatus>& status = std::nullopt,
        const std::optional<std::string>& category = std::nullopt,
        const std::optional<std::vector<std::string>>& tags = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& start_date = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& end_date = std::nullopt,
        const std::optional<std::string>& query = std::nullopt,
        int page = 1,
        int page_size = 10,
        const std::string& sort_by = "updated_at",
        bool ascending = false
    ) = 0;
    
    /**
     * @brief Store document content
     * @param document_id Document ID
     * @param content Document content
     * @param version Version
     * @return True if stored successfully
     */
    virtual bool storeContent(
        const std::string& document_id,
        const std::vector<uint8_t>& content,
        const std::string& version = "latest"
    ) = 0;
    
    /**
     * @brief Get document content
     * @param document_id Document ID
     * @param version Version (optional)
     * @return Document content or empty vector if not found
     */
    virtual std::vector<uint8_t> getContent(
        const std::string& document_id,
        const std::string& version = "latest"
    ) = 0;
    
    /**
     * @brief Store extracted text
     * @param document_id Document ID
     * @param text Extracted text
     * @return True if stored successfully
     */
    virtual bool storeExtractedText(
        const std::string& document_id,
        const std::string& text
    ) = 0;
    
    /**
     * @brief Get extracted text
     * @param document_id Document ID
     * @return Extracted text or empty string if not found
     */
    virtual std::string getExtractedText(const std::string& document_id) = 0;
    
    /**
     * @brief Store metadata
     * @param document_id Document ID
     * @param metadata Metadata
     * @return True if stored successfully
     */
    virtual bool storeMetadata(
        const std::string& document_id,
        const std::map<std::string, std::string>& metadata
    ) = 0;
    
    /**
     * @brief Get metadata
     * @param document_id Document ID
     * @return Metadata or empty map if not found
     */
    virtual std::map<std::string, std::string> getMetadata(const std::string& document_id) = 0;
    
    /**
     * @brief Create document version
     * @param document_id Document ID
     * @param version Version
     * @param author_id Author ID
     * @param comment Comment
     * @param content Document content
     * @return True if created successfully
     */
    virtual bool createVersion(
        const std::string& document_id,
        const std::string& version,
        const std::string& author_id,
        const std::string& comment,
        const std::vector<uint8_t>& content
    ) = 0;
    
    /**
     * @brief Get document version
     * @param document_id Document ID
     * @param version Version
     * @param include_content Whether to include document content
     * @return Document or nullopt if not found
     */
    virtual std::optional<Document> getVersion(
        const std::string& document_id,
        const std::string& version,
        bool include_content = false
    ) = 0;
    
    /**
     * @brief List document versions
     * @param document_id Document ID
     * @param page Page number (starting from 1)
     * @param page_size Page size
     * @return Pair of version info and total count
     */
    virtual std::pair<std::vector<VersionInfo>, int> listVersions(
        const std::string& document_id,
        int page = 1,
        int page_size = 10
    ) = 0;
    
    /**
     * @brief Search documents
     * @param query Search query
     * @param document_ids Document IDs to search (optional)
     * @param category Category (optional)
     * @param tags Tags (optional)
     * @param document_type Document type (optional)
     * @param page Page number (starting from 1)
     * @param page_size Page size
     * @param highlight_results Whether to highlight matching text
     * @return Pair of search results and total count
     */
    virtual std::pair<std::vector<SearchResult>, int> searchDocuments(
        const std::string& query,
        const std::optional<std::vector<std::string>>& document_ids = std::nullopt,
        const std::optional<std::string>& category = std::nullopt,
        const std::optional<std::vector<std::string>>& tags = std::nullopt,
        const std::optional<DocumentType>& document_type = std::nullopt,
        int page = 1,
        int page_size = 10,
        bool highlight_results = true
    ) = 0;
};

/**
 * @brief PostgreSQL document repository implementation
 */
class PostgresDocumentRepository : public IDocumentRepository {
public:
    /**
     * @brief Constructor
     * @param db_connection Database connection
     * @param content_base_path Base path for document content storage
     */
    PostgresDocumentRepository(
        std::shared_ptr<persistence::DatabaseConnection> db_connection,
        const std::string& content_base_path = "/app/data/documents"
    );
    
    /**
     * @brief Destructor
     */
    ~PostgresDocumentRepository() override;
    
    // IDocumentRepository implementation
    std::string createDocument(const Document& document) override;
    std::optional<Document> getDocument(const std::string& document_id, bool include_content) override;
    bool updateDocument(const Document& document) override;
    bool deleteDocument(const std::string& document_id, bool permanently) override;
    std::pair<std::vector<DocumentSummary>, int> listDocuments(
        const std::optional<std::string>& author_id,
        const std::optional<DocumentType>& document_type,
        const std::optional<DocumentStatus>& status,
        const std::optional<std::string>& category,
        const std::optional<std::vector<std::string>>& tags,
        const std::optional<std::chrono::system_clock::time_point>& start_date,
        const std::optional<std::chrono::system_clock::time_point>& end_date,
        const std::optional<std::string>& query,
        int page,
        int page_size,
        const std::string& sort_by,
        bool ascending
    ) override;
    bool storeContent(
        const std::string& document_id,
        const std::vector<uint8_t>& content,
        const std::string& version
    ) override;
    std::vector<uint8_t> getContent(
        const std::string& document_id,
        const std::string& version
    ) override;
    bool storeExtractedText(
        const std::string& document_id,
        const std::string& text
    ) override;
    std::string getExtractedText(const std::string& document_id) override;
    bool storeMetadata(
        const std::string& document_id,
        const std::map<std::string, std::string>& metadata
    ) override;
    std::map<std::string, std::string> getMetadata(const std::string& document_id) override;
    bool createVersion(
        const std::string& document_id,
        const std::string& version,
        const std::string& author_id,
        const std::string& comment,
        const std::vector<uint8_t>& content
    ) override;
    std::optional<Document> getVersion(
        const std::string& document_id,
        const std::string& version,
        bool include_content
    ) override;
    std::pair<std::vector<VersionInfo>, int> listVersions(
        const std::string& document_id,
        int page,
        int page_size
    ) override;
    std::pair<std::vector<SearchResult>, int> searchDocuments(
        const std::string& query,
        const std::optional<std::vector<std::string>>& document_ids,
        const std::optional<std::string>& category,
        const std::optional<std::vector<std::string>>& tags,
        const std::optional<DocumentType>& document_type,
        int page,
        int page_size,
        bool highlight_results
    ) override;
    
private:
    /**
     * @brief Generate content path for document
     * @param document_id Document ID
     * @param version Version
     * @return Content path
     */
    std::string generateContentPath(
        const std::string& document_id,
        const std::string& version
    );
    
    /**
     * @brief Store tags for document
     * @param document_id Document ID
     * @param tags Tags
     * @param transaction Transaction
     * @return True if stored successfully
     */
    bool storeTags(
        const std::string& document_id,
        const std::vector<std::string>& tags,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get tags for document
     * @param document_id Document ID
     * @return Tags
     */
    std::vector<std::string> getTags(const std::string& document_id);
    
    /**
     * @brief Extract document from result row
     * @param result Result
     * @param row_index Row index
     * @param include_content Whether to include content
     * @return Document
     */
    Document extractDocumentFromRow(
        const persistence::PgResult& result,
        int row_index,
        bool include_content
    );
    
    /**
     * @brief Extract document summary from result row
     * @param result Result
     * @param row_index Row index
     * @return Document summary
     */
    DocumentSummary extractSummaryFromRow(
        const persistence::PgResult& result,
        int row_index
    );
    
    /**
     * @brief Generate parameters for document query
     * @param author_id Author ID (optional)
     * @param document_type Document type (optional)
     * @param status Document status (optional)
     * @param category Category (optional)
     * @param tags Tags (optional)
     * @param start_date Start date (optional)
     * @param end_date End date (optional)
     * @param query Search query (optional)
     * @return Pair of (query conditions, parameters)
     */
    std::pair<std::string, std::vector<persistence::PgParam>> generateQueryParams(
        const std::optional<std::string>& author_id,
        const std::optional<DocumentType>& document_type,
        const std::optional<DocumentStatus>& status,
        const std::optional<std::string>& category,
        const std::optional<std::vector<std::string>>& tags,
        const std::optional<std::chrono::system_clock::time_point>& start_date,
        const std::optional<std::chrono::system_clock::time_point>& end_date,
        const std::optional<std::string>& query
    );
    
    /**
     * @brief Generate unique ID
     * @return Unique ID
     */
    std::string generateUniqueId();
    
    std::shared_ptr<persistence::DatabaseConnection> db_connection_;
    std::string content_base_path_;
};

} // namespace repository
} // namespace document
// src/frontend/components/DocumentUpload/DocumentUpload.tsx
import React, { useState, useCallback, useRef, useEffect } from 'react';
import { useDropzone } from 'react-dropzone';
import { 
  Upload, 
  File, 
  AlertCircle, 
  Check, 
  X,
  Loader, 
  FileText
} from 'lucide-react';

import { 
  Card, 
  CardContent, 
  CardDescription, 
  CardFooter, 
  CardHeader, 
  CardTitle 
} from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Badge } from '@/components/ui/badge';
import { Progress } from '@/components/ui/progress';
import { Alert, AlertDescription, AlertTitle } from '@/components/ui/alert';
import { 
  Table, 
  TableBody, 
  TableCell, 
  TableHead, 
  TableHeader, 
  TableRow 
} from '@/components/ui/table';
import { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';

// Types
export interface DocumentFile {
  id: string;
  file: File;
  status: 'pending' | 'uploading' | 'processing' | 'completed' | 'failed';
  progress: number;
  error?: string;
  processingStage?: string;
  result?: DocumentProcessingResult;
}

export interface DocumentProcessingResult {
  documentId: string;
  status: string;
  summary?: string;
  autoTags?: string[];
  qualityAssessment?: {
    completenessScore: number;
    consistencyScore: number;
    regulatoryComplianceScore: number;
    overallConfidence: number;
    potentialGaps?: string[];
    inconsistencies?: string[];
    complianceIssues?: string[];
  };
  sentiment?: Record<string, number>;
  entities?: Record<string, string[]>;
}

export interface DocumentUploadProps {
  organizationId: string;
  supportedFileTypes?: string[];
  maxFileSize?: number; // in bytes
  maxFiles?: number;
  onUploadComplete?: (results: DocumentProcessingResult[]) => void;
  onUploadError?: (error: string) => void;
  showAdvancedFeatures?: boolean;
}

// Document upload API service
const documentUploadService = {
  uploadDocument: async (
    file: File, 
    organizationId: string, 
    onProgress: (progress: number, stage?: string) => void
  ): Promise<DocumentProcessingResult> => {
    // Mock implementation that would be replaced with actual API calls
    return new Promise((resolve, reject) => {
      // Simulate upload progress
      let progress = 0;
      const interval = setInterval(() => {
        progress += 5;
        onProgress(progress, 'uploading');
        
        if (progress >= 100) {
          clearInterval(interval);
          
          // Simulate processing stages
          setTimeout(() => {
            onProgress(30, 'Extracting content');
          }, 300);
          
          setTimeout(() => {
            onProgress(60, 'Recognizing document structure');
          }, 600);
          
          setTimeout(() => {
            onProgress(80, 'Extracting training elements');
          }, 900);
          
          setTimeout(() => {
            onProgress(100, 'Processing completed');
            
            // Simulate processing result
            resolve({
              documentId: `doc-${Date.now()}`,
              status: 'completed',
              summary: `This is a summary of ${file.name}. The document appears to be a training manual covering aviation procedures.`,
              autoTags: ['aviation', 'training', 'procedures', 'safety', 'regulations'],
              qualityAssessment: {
                completenessScore: 0.87,
                consistencyScore: 0.92,
                regulatoryComplianceScore: 0.95,
                overallConfidence: 0.91,
                potentialGaps: ['Missing detailed emergency procedures for engine failure'],
                inconsistencies: ['Different terminology used for checklist items in sections 2 and 3'],
                complianceIssues: ['Limited coverage of FAA Part 91.103 requirements']
              },
              sentiment: {
                positive: 0.65,
                neutral: 0.30,
                negative: 0.05,
                safety_emphasis: 0.85
              },
              entities: {
                aircraft: ['Cessna 172', 'Boeing 737'],
                airports: ['KJFK', 'KLAX', 'KORD'],
                regulations: ['FAA Part 61', 'FAA Part 91']
              }
            });
          }, 1200);
        }
      }, 100);
    });
  }
};

const DocumentUpload: React.FC<DocumentUploadProps> = ({
  organizationId,
  supportedFileTypes = ['.pdf', '.docx', '.xlsx', '.html', '.pptx'],
  maxFileSize = 10 * 1024 * 1024, // 10MB default
  maxFiles = 5,
  onUploadComplete,
  onUploadError,
  showAdvancedFeatures = true
}) => {
  const [documents, setDocuments] = useState<DocumentFile[]>([]);
  const [activeTab, setActiveTab] = useState<string>('upload');
  const [error, setError] = useState<string | null>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  
  // Check if all documents are processed
  useEffect(() => {
    const allCompleted = documents.length > 0 && 
      documents.every(doc => doc.status === 'completed' || doc.status === 'failed');
    
    if (allCompleted && onUploadComplete) {
      const results = documents
        .filter(doc => doc.status === 'completed' && doc.result)
        .map(doc => doc.result as DocumentProcessingResult);
      
      onUploadComplete(results);
    }
  }, [documents, onUploadComplete]);
  
  // Handle file drop
  const onDrop = useCallback((acceptedFiles: File[]) => {
    setError(null);
    
    // Check if adding these files would exceed the maximum
    if (documents.length + acceptedFiles.length > maxFiles) {
      setError(`You can only upload up to ${maxFiles} files at a time.`);
      return;
    }
    
    // Filter out files that are too large
    const validFiles = acceptedFiles.filter(file => file.size <= maxFileSize);
    const invalidFiles = acceptedFiles.filter(file => file.size > maxFileSize);
    
    if (invalidFiles.length > 0) {
      setError(`${invalidFiles.length} file(s) exceeded the maximum size of ${formatFileSize(maxFileSize)}.`);
    }
    
    // Create document objects for valid files
    const newDocuments = validFiles.map(file => ({
      id: `file-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
      file,
      status: 'pending' as const,
      progress: 0
    }));
    
    setDocuments(prev => [...prev, ...newDocuments]);
    
    // Start uploading new documents
    newDocuments.forEach(doc => {
      uploadDocument(doc);
    });
  }, [documents, maxFiles, maxFileSize]);
  
  // Configure dropzone
  const { getRootProps, getInputProps, isDragActive } = useDropzone({
    onDrop,
    accept: supportedFileTypes.reduce((acc, type) => {
      acc[type] = [];
      return acc;
    }, {} as Record<string, string[]>),
    maxSize: maxFileSize,
    maxFiles
  });
  
  // Upload a document
  const uploadDocument = async (doc: DocumentFile) => {
    // Update status to uploading
    setDocuments(prev => 
      prev.map(d => (d.id === doc.id ? { ...d, status: 'uploading' as const } : d))
    );
    
    try {
      // Upload document and track progress
      const result = await documentUploadService.uploadDocument(
        doc.file,
        organizationId,
        (progress, stage) => {
          setDocuments(prev => 
            prev.map(d => {
              if (d.id === doc.id) {
                const newDoc = { ...d, progress };
                if (stage) {
                  if (stage === 'uploading') {
                    newDoc.status = 'uploading' as const;
                  } else {
                    newDoc.status = 'processing' as const;
                    newDoc.processingStage = stage;
                  }
                }
                return newDoc;
              }
              return d;
            })
          );
        }
      );
      
      // Update with result
      setDocuments(prev => 
        prev.map(d => {
          if (d.id === doc.id) {
            return { 
              ...d, 
              status: 'completed' as const, 
              progress: 100,
              result
            };
          }
          return d;
        })
      );
      
      // Switch to results tab after first successful upload
      setActiveTab('results');
    } catch (err) {
      // Handle error
      const errorMessage = err instanceof Error ? err.message : 'Upload failed';
      
      setDocuments(prev => 
        prev.map(d => {
          if (d.id === doc.id) {
            return { 
              ...d, 
              status: 'failed' as const, 
              error: errorMessage
            };
          }
          return d;
        })
      );
      
      if (onUploadError) {
        onUploadError(errorMessage);
      }
    }
  };
  
  // Handle manual file selection
  const handleSelectFiles = () => {
    if (fileInputRef.current) {
      fileInputRef.current.click();
    }
  };
  
  // Remove a document
  const removeDocument = (docId: string) => {
    setDocuments(prev => prev.filter(d => d.id !== docId));
  };
  
  // Reset everything
  const handleReset = () => {
    setDocuments([]);
    setError(null);
    setActiveTab('upload');
  };
  
  // Format file size for display
  const formatFileSize = (bytes: number): string => {
    if (bytes === 0) return '0 Bytes';
    
    const k = 1024;
    const sizes = ['Bytes', 'KB', 'MB', 'GB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
  };
  
  // Get document status badge
  const getStatusBadge = (status: DocumentFile['status']) => {
    switch (status) {
      case 'pending':
        return <Badge variant="outline">Pending</Badge>;
      case 'uploading':
        return <Badge variant="secondary">Uploading</Badge>;
      case 'processing':
        return <Badge variant="secondary">Processing</Badge>;
      case 'completed':
        return <Badge variant="success">Completed</Badge>;
      case 'failed':
        return <Badge variant="destructive">Failed</Badge>;
      default:
        return null;
    }
  };
  
  return (
    <Card className="w-full">
      <CardHeader>
        <CardTitle>Document Upload</CardTitle>
        <CardDescription>
          Upload training documents for processing. Supported formats: 
          {supportedFileTypes.join(', ')}
        </CardDescription>
      </CardHeader>
      
      <Tabs value={activeTab} onValueChange={setActiveTab}>
        <TabsList className="mx-6">
          <TabsTrigger value="upload">Upload</TabsTrigger>
          <TabsTrigger value="results">Results</TabsTrigger>
        </TabsList>
        
        <CardContent>
          <TabsContent value="upload">
            {/* Dropzone area */}
            <div
              {...getRootProps()}
              className={`
                border-2 border-dashed rounded-lg p-10 text-center cursor-pointer
                transition-colors duration-200 ease-in-out
                ${isDragActive ? 'border-primary bg-primary/10' : 'border-gray-300 hover:border-primary'}
              `}
            >
              <input 
                {...getInputProps()} 
                ref={fileInputRef}
                accept={supportedFileTypes.join(',')}
              />
              
              <div className="flex flex-col items-center justify-center space-y-4">
                <Upload className="h-12 w-12 text-gray-400" />
                
                <div>
                  <p className="text-lg font-medium">
                    {isDragActive ? 'Drop files here' : 'Drag and drop files here'}
                  </p>
                  <p className="text-sm text-gray-500 mt-1">
                    or <span className="text-primary cursor-pointer" onClick={handleSelectFiles}>browse</span> to select files
                  </p>
                </div>
                
                <p className="text-xs text-gray-400">
                  Maximum file size: {formatFileSize(maxFileSize)}
                </p>
                <p className="text-xs text-gray-400">
                  Up to {maxFiles} files can be uploaded at once
                </p>
              </div>
            </div>
            
            {/* Error message */}
            {error && (
              <Alert variant="destructive" className="mt-4">
                <AlertCircle className="h-4 w-4" />
                <AlertTitle>Error</AlertTitle>
                <AlertDescription>{error}</AlertDescription>
              </Alert>
            )}
            
            {/* File list */}
            {documents.length > 0 && (
              <div className="mt-6">
                <h3 className="text-lg font-medium mb-4">Files</h3>
                
                <div className="space-y-4">
                  {documents.map(doc => (
                    <div 
                      key={doc.id} 
                      className="flex items-center justify-between border rounded-lg p-4"
                    >
                      <div className="flex items-center space-x-4">
                        <FileText className="h-8 w-8 text-gray-400" />
                        
                        <div>
                          <p className="font-medium">{doc.file.name}</p>
                          <p className="text-sm text-gray-500">
                            {formatFileSize(doc.file.size)}
                          </p>
                        </div>
                      </div>
                      
                      <div className="flex items-center space-x-4">
                        {getStatusBadge(doc.status)}
                        
                        {(doc.status === 'uploading' || doc.status === 'processing') && (
                          <div className="w-32">
                            <Progress value={doc.progress} className="h-2" />
                            {doc.processingStage && (
                              <p className="text-xs text-gray-500 mt-1">{doc.processingStage}</p>
                            )}
                          </div>
                        )}
                        
                        {doc.status === 'failed' && (
                          <Button
                            variant="ghost"
                            size="sm"
                            onClick={() => uploadDocument(doc)}
                          >
                            Retry
                          </Button>
                        )}
                        
                        <Button
                          variant="ghost"
                          size="sm"
                          onClick={() => removeDocument(doc.id)}
                        >
                          <X className="h-4 w-4" />
                        </Button>
                      </div>
                    </div>
                  ))}
                </div>
              </div>
            )}
          </TabsContent>
          
          <TabsContent value="results">
            {documents.length === 0 ? (
              <div className="text-center py-10">
                <p className="text-gray-500">No documents have been uploaded yet.</p>
              </div>
            ) : (
              <div>
                <Table>
                  <TableHeader>
                    <TableRow>
                      <TableHead>Document</TableHead>
                      <TableHead>Status</TableHead>
                      <TableHead>Summary</TableHead>
                      <TableHead>Tags</TableHead>
                      {showAdvancedFeatures && (
                        <TableHead>Quality Score</TableHead>
                      )}
                    </TableRow>
                  </TableHeader>
                  
                  <TableBody>
                    {documents.map(doc => (
                      <TableRow key={doc.id}>
                        <TableCell className="font-medium">{doc.file.name}</TableCell>
                        <TableCell>{getStatusBadge(doc.status)}</TableCell>
                        <TableCell>
                          {doc.result?.summary && doc.status === 'completed' ? (
                            <div className="max-w-md">
                              <p className="text-sm truncate">{doc.result.summary}</p>
                            </div>
                          ) : doc.status === 'processing' ? (
                            <div className="flex items-center">
                              <Loader className="h-4 w-4 mr-2 animate-spin" />
                              <span className="text-sm">{doc.processingStage || 'Processing...'}</span>
                            </div>
                          ) : doc.status === 'failed' ? (
                            <p className="text-sm text-red-500">{doc.error || 'Processing failed'}</p>
                          ) : (
                            <p className="text-sm text-gray-500">Not yet processed</p>
                          )}
                        </TableCell>
                        <TableCell>
                          {doc.result?.autoTags && doc.status === 'completed' ? (
                            <div className="flex flex-wrap gap-1">
                              {doc.result.autoTags.slice(0, 3).map(tag => (
                                <Badge key={tag} variant="outline">{tag}</Badge>
                              ))}
                              {doc.result.autoTags.length > 3 && (
                                <Badge variant="outline">+{doc.result.autoTags.length - 3} more</Badge>
                              )}
                            </div>
                          ) : (
                            <p className="text-sm text-gray-500">-</p>
                          )}
                        </TableCell>
                        {showAdvancedFeatures && (
                          <TableCell>
                            {doc.result?.qualityAssessment && doc.status === 'completed' ? (
                              <div className="flex items-center">
                                <span className="font-medium mr-2">
                                  {Math.round(doc.result.qualityAssessment.overallConfidence * 100)}%
                                </span>
                                {doc.result.qualityAssessment.overallConfidence > 0.8 ? (
                                  <Check className="h-4 w-4 text-green-500" />
                                ) : doc.result.qualityAssessment.overallConfidence > 0.5 ? (
                                  <AlertCircle className="h-4 w-4 text-yellow-500" />
                                ) : (
                                  <X className="h-4 w-4 text-red-500" />
                                )}
                              </div>
                            ) : (
                              <p className="text-sm text-gray-500">-</p>
                            )}
                          </TableCell>
                        )}
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </div>
            )}
          </TabsContent>
        </CardContent>
      </Tabs>
      
      <CardFooter className="flex justify-between">
        <Button
          variant="ghost"
          onClick={handleReset}
          disabled={documents.length === 0}
        >
          Reset
        </Button>
        
        <div className="flex space-x-2">
          <Button 
            variant="secondary"
            onClick={handleSelectFiles}
            disabled={documents.length >= maxFiles}
          >
            Add More Files
          </Button>
          
          <Button 
            variant="default"
            onClick={() => setActiveTab('results')}
            disabled={documents.length === 0}
          >
            View Results
          </Button>
        </div>
      </CardFooter>
    </Card>
  );
};

export default DocumentUpload;

// src/frontend/components/DocumentUpload/DocumentUpload.test.tsx
import React from 'react';
import { render, screen, fireEvent, waitFor, act } from '@testing-library/react';
import userEvent from '@testing-library/user-event';
import DocumentUpload from './DocumentUpload';

// Mock the dropzone hook
jest.mock('react-dropzone', () => ({
  useDropzone: () => ({
    getRootProps: () => ({
      onClick: jest.fn(),
    }),
    getInputProps: () => ({
      accept: 'pdf',
      multiple: true,
    }),
    isDragActive: false,
  }),
}));

// Mock lucide-react icons
jest.mock('lucide-react', () => ({
  Upload: () => <div data-testid="upload-icon">Upload Icon</div>,
  File: () => <div data-testid="file-icon">File Icon</div>,
  AlertCircle: () => <div data-testid="alert-circle-icon">Alert Circle Icon</div>,
  Check: () => <div data-testid="check-icon">Check Icon</div>,
  X: () => <div data-testid="x-icon">X Icon</div>,
  Loader: () => <div data-testid="loader-icon">Loader Icon</div>,
  FileText: () => <div data-testid="file-text-icon">File Text Icon</div>,
}));

// Mock document upload service
jest.mock('./documentUploadService', () => ({
  uploadDocument: jest.fn().mockImplementation((file, organizationId, onProgress) => {
    // Simulate progress updates
    setTimeout(() => onProgress(50, 'uploading'), 100);
    setTimeout(() => onProgress(100, 'uploading'), 200);
    setTimeout(() => onProgress(30, 'Extracting content'), 300);
    setTimeout(() => onProgress(100, 'Processing completed'), 400);
    
    // Return mock result
    return Promise.resolve({
      documentId: 'test-doc-id',
      status: 'completed',
      summary: 'Test summary',
      autoTags: ['tag1', 'tag2'],
      qualityAssessment: {
        completenessScore: 0.87,
        consistencyScore: 0.92,
        regulatoryComplianceScore: 0.95,
        overallConfidence: 0.91,
      },
    });
  }),
}));

describe('DocumentUpload Component', () => {
  const defaultProps = {
    organizationId: 'org-123',
  };
  
  beforeEach(() => {
    jest.clearAllMocks();
  });
  
  it('renders the upload component initially', () => {
    render(<DocumentUpload {...defaultProps} />);
    
    expect(screen.getByText('Document Upload')).toBeInTheDocument();
    expect(screen.getByText(/Drag and drop files here/i)).toBeInTheDocument();
    expect(screen.getByText(/or browse to select files/i)).toBeInTheDocument();
  });
  
  it('displays supportedFileTypes in the description', () => {
    const supportedTypes = ['.pdf', '.docx'];
    render(<DocumentUpload {...defaultProps} supportedFileTypes={supportedTypes} />);
    
    expect(screen.getByText(/Supported formats:/i)).toBeInTheDocument();
    expect(screen.getByText(/\.pdf, \.docx/i)).toBeInTheDocument();
  });
  
  it('displays maximum file size information', () => {
    const maxSize = 5 * 1024 * 1024; // 5MB
    render(<DocumentUpload {...defaultProps} maxFileSize={maxSize} />);
    
    expect(screen.getByText(/Maximum file size: 5 MB/i)).toBeInTheDocument();
  });
  
  it('displays maximum number of files information', () => {
    const maxFiles = 3;
    render(<DocumentUpload {...defaultProps} maxFiles={maxFiles} />);
    
    expect(screen.getByText(/Up to 3 files can be uploaded at once/i)).toBeInTheDocument();
  });
  
  it('handles file selection through the browse button', async () => {
    render(<DocumentUpload {...defaultProps} />);
    
    // Create a test file
    const file = new File(['test content'], 'test.pdf', { type: 'application/pdf' });
    
    // Get the hidden file input
    const input = screen.getByRole('button', { name: /browse/i });
    
    // Simulate clicking the browse text
    userEvent.click(input);
    
    // This would normally trigger the file dialog, but we can't test that directly
    // Instead, we can verify that the click handler was called
    expect(input).toHaveBeenCalledTimes(1);
  });
  
  it('shows the results tab after uploading files', async () => {
    render(<DocumentUpload {...defaultProps} />);
    
    // Switch to results tab
    const resultsTab = screen.getByRole('tab', { name: /results/i });
    userEvent.click(resultsTab);
    
    // Verify empty state
    expect(screen.getByText(/No documents have been uploaded yet/i)).toBeInTheDocument();
    
    // Switch back to upload tab
    const uploadTab = screen.getByRole('tab', { name: /upload/i });
    userEvent.click(uploadTab);
    
    // Simulate file upload (this is a simplification; in real testing we'd need to mock more)
    const file = new File(['test content'], 'test.pdf', { type: 'application/pdf' });
    await act(async () => {
      // Directly call the onDrop function that useDropzone would normally provide
      // We'd need access to the component's internal state for this in a real test
      // This is just an illustration
    });
    
    // Wait for processing to complete and UI to update
    await waitFor(() => {
      expect(screen.getByText(/View Results/i)).not.toBeDisabled();
    });
    
    // Click view results
    userEvent.click(screen.getByText(/View Results/i));
    
    // Verify results are shown
    await waitFor(() => {
      expect(screen.getByRole('table')).toBeInTheDocument();
    });
  });

  // Additional tests would include:
  // - Testing error handling when files are too large
  // - Testing batch uploads
  // - Testing removal of files
  // - Testing retry functionality
  // - Testing the reset button
  // - Testing the advanced features display
});

#include "signature/certificate_repository.h"
#include "logging/logger.h"
#include <chrono>

namespace etr {
namespace signature {

// Implementation of the Certificate Repository
CertificateRepository::CertificateRepository(
    std::shared_ptr<persistence::DatabaseConnection> db_connection
) : db_connection_(std::move(db_connection)) {
    logging::Logger::getInstance().info("CertificateRepository initialized");
}

CertificateRepository::~CertificateRepository() = default;

bool CertificateRepository::storeCertificate(const CertificateInfo& certificate) {
    try {
        persistence::Transaction transaction = db_connection_->createTransaction();
        
        // Check if certificate already exists
        std::string query = R"(
            SELECT certificate_id FROM etr.certificates 
            WHERE certificate_id = $1
        )";
        
        auto result = db_connection_->executeQuery(query, {
            {.name = "certificate_id", .value = certificate.certificate_id, .type = persistence::PgParamType::TEXT, .is_null = false}
        });
        
        bool exists = !result.isEmpty();
        
        if (exists) {
            // Update existing certificate
            query = R"(
                UPDATE etr.certificates SET
                    user_id = $1,
                    subject_name = $2,
                    issuer_name = $3,
                    serial_number = $4,
                    not_before = $5,
                    not_after = $6,
                    raw_data = $7,
                    is_valid = $8
                WHERE certificate_id = $9
            )";
        } else {
            // Insert new certificate
            query = R"(
                INSERT INTO etr.certificates (
                    user_id, subject_name, issuer_name, serial_number,
                    not_before, not_after, raw_data, is_valid, certificate_id
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
            )";
        }
        
        // Extract user_id from subject name (simplified)
        std::string user_id = extractUserIdFromSubject(certificate.subject_name);
        
        // Convert dates to strings in ISO format
        auto not_before_time_t = std::chrono::system_clock::to_time_t(certificate.not_before);
        auto not_after_time_t = std::chrono::system_clock::to_time_t(certificate.not_after);
        
        char not_before_str[100], not_after_str[100];
        std::strftime(not_before_str, sizeof(not_before_str), "%Y-%m-%d %H:%M:%S", std::gmtime(&not_before_time_t));
        std::strftime(not_after_str, sizeof(not_after_str), "%Y-%m-%d %H:%M:%S", std::gmtime(&not_after_time_t));
        
        // Execute query
        auto update_result = db_connection_->executeQuery(query, {
            {.name = "user_id", .value = user_id, .type = persistence::PgParamType::TEXT, .is_null = false},
            {.name = "subject_name", .value = certificate.subject_name, .type = persistence::PgParamType::TEXT, .is_null = false},
            {.name = "issuer_name", .value = certificate.issuer_name, .type = persistence::PgParamType::TEXT, .is_null = false},
            {.name = "serial_number", .value = certificate.serial_number, .type = persistence::PgParamType::TEXT, .is_null = false},
            {.name = "not_before", .value = not_before_str, .type = persistence::PgParamType::TIMESTAMP, .is_null = false},
            {.name = "not_after", .value = not_after_str, .type = persistence::PgParamType::TIMESTAMP, .is_null = false},
            {.name = "raw_data", .value = "", .type = persistence::PgParamType::BYTEA, .is_null = false}, // Raw data would be properly handled in real implementation
            {.name = "is_valid", .value = certificate.is_valid ? "true" : "false", .type = persistence::PgParamType::BOOLEAN, .is_null = false},
            {.name = "certificate_id", .value = certificate.certificate_id, .type = persistence::PgParamType::TEXT, .is_null = false}
        });
        
        if (update_result.hasError()) {
            logging::Logger::getInstance().error("Error storing certificate: {}", update_result.getErrorMessage());
            transaction.rollback();
            return false;
        }
        
        transaction.commit();
        
        logging::Logger::getInstance().info("Certificate {} stored successfully", certificate.certificate_id);
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error storing certificate: {}", e.what());
        return false;
    }
}

std::optional<CertificateInfo> CertificateRepository::getCertificate(const std::string& certificate_id) {
    try {
        std::string query = R"(
            SELECT 
                certificate_id, user_id, subject_name, issuer_name, serial_number,
                not_before, not_after, raw_data, is_valid, is_revoked
            FROM etr.certificates
            WHERE certificate_id = $1
        )";
        
        auto result = db_connection_->executeQuery(query, {
            {.name = "certificate_id", .value = certificate_id, .type = persistence::PgParamType::TEXT, .is_null = false}
        });
        
        if (result.isEmpty()) {
            logging::Logger::getInstance().debug("Certificate {} not found", certificate_id);
            return std::nullopt;
        }
        
        // Parse result row into CertificateInfo
        CertificateInfo certificate;
        
        certificate.certificate_id = result.getString(0, "certificate_id");
        certificate.subject_name = result.getString(0, "subject_name");
        certificate.issuer_name = result.getString(0, "issuer_name");
        certificate.serial_number = result.getString(0, "serial_number");
        
        // Parse dates from ISO format string
        auto not_before_tp = result.getTimestamp(0, "not_before");
        auto not_after_tp = result.getTimestamp(0, "not_after");
        
        if (not_before_tp) {
            certificate.not_before = *not_before_tp;
        }
        
        if (not_after_tp) {
            certificate.not_after = *not_after_tp;
        }
        
        // Get raw data (binary)
        certificate.raw_data = result.getBinary(0, "raw_data");
        
        certificate.is_valid = result.getBool(0, "is_valid");
        
        bool is_revoked = result.getBool(0, "is_revoked");
        
        // A certificate is valid only if it's marked as valid and not revoked
        certificate.is_valid = certificate.is_valid && !is_revoked;
        
        logging::Logger::getInstance().debug("Retrieved certificate {}", certificate_id);
        
        return certificate;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error retrieving certificate {}: {}", certificate_id, e.what());
        return std::nullopt;
    }
}

std::vector<CertificateInfo> CertificateRepository::getCertificatesByUserId(const std::string& user_id) {
    std::vector<CertificateInfo> certificates;
    
    try {
        std::string query = R"(
            SELECT 
                certificate_id, user_id, subject_name, issuer_name, serial_number,
                not_before, not_after, raw_data, is_valid, is_revoked
            FROM etr.certificates
            WHERE user_id = $1
            ORDER BY not_after DESC
        )";
        
        auto result = db_connection_->executeQuery(query, {
            {.name = "user_id", .value = user_id, .type = persistence::PgParamType::TEXT, .is_null = false}
        });
        
        for (int i = 0; i < result.getNumRows(); i++) {
            CertificateInfo certificate;
            
            certificate.certificate_id = result.getString(i, "certificate_id");
            certificate.subject_name = result.getString(i, "subject_name");
            certificate.issuer_name = result.getString(i, "issuer_name");
            certificate.serial_number = result.getString(i, "serial_number");
            
            // Parse dates from ISO format string
            auto not_before_tp = result.getTimestamp(i, "not_before");
            auto not_after_tp = result.getTimestamp(i, "not_after");
            
            if (not_before_tp) {
                certificate.not_before = *not_before_tp;
            }
            
            if (not_after_tp) {
                certificate.not_after = *not_after_tp;
            }
            
            // Get raw data (binary)
            certificate.raw_data = result.getBinary(i, "raw_data");
            
            certificate.is_valid = result.getBool(i, "is_valid");
            
            bool is_revoked = result.getBool(i, "is_revoked");
            
            // A certificate is valid only if it's marked as valid and not revoked
            certificate.is_valid = certificate.is_valid && !is_revoked;
            
            certificates.push_back(certificate);
        }
        
        logging::Logger::getInstance().debug("Retrieved {} certificates for user {}", certificates.size(), user_id);
        
        return certificates;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error retrieving certificates for user {}: {}", user_id, e.what());
        return {};
    }
}

bool CertificateRepository::revokeCertificate(const std::string& certificate_id, const std::string& reason) {
    try {
        persistence::Transaction transaction = db_connection_->createTransaction();
        
        std::string query = R"(
            UPDATE etr.certificates
            SET is_revoked = true,
                revocation_reason = $1,
                revocation_time = NOW()
            WHERE certificate_id = $2
        )";
        
        auto result = db_connection_->executeQuery(query, {
            {.name = "reason", .value = reason, .type = persistence::PgParamType::TEXT, .is_null = false},
            {.name = "certificate_id", .value = certificate_id, .type = persistence::PgParamType::TEXT, .is_null = false}
        });
        
        if (result.getAffectedRows() == 0) {
            logging::Logger::getInstance().warn("Certificate {} not found for revocation", certificate_id);
            transaction.rollback();
            return false;
        }
        
        transaction.commit();
        
        logging::Logger::getInstance().info("Certificate {} revoked: {}", certificate_id, reason);
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error revoking certificate {}: {}", certificate_id, e.what());
        return false;
    }
}

bool CertificateRepository::isCertificateRevoked(const std::string& certificate_id) {
    try {
        std::string query = R"(
            SELECT is_revoked
            FROM etr.certificates
            WHERE certificate_id = $1
        )";
        
        auto result = db_connection_->executeQuery(query, {
            {.name = "certificate_id", .value = certificate_id, .type = persistence::PgParamType::TEXT, .is_null = false}
        });
        
        if (result.isEmpty()) {
            logging::Logger::getInstance().warn("Certificate {} not found for revocation check", certificate_id);
            return false;
        }
        
        bool is_revoked = result.getBool(0, "is_revoked");
        
        logging::Logger::getInstance().debug("Certificate {} revocation status: {}", 
            certificate_id, is_revoked ? "revoked" : "not revoked");
        
        return is_revoked;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error checking revocation for certificate {}: {}", 
            certificate_id, e.what());
        return false;
    }
}

std::vector<std::pair<std::string, std::string>> CertificateRepository::getCertificateRevocationList() {
    std::vector<std::pair<std::string, std::string>> crl;
    
    try {
        std::string query = R"(
            SELECT certificate_id, revocation_reason
            FROM etr.certificates
            WHERE is_revoked = true
        )";
        
        auto result = db_connection_->executeQuery(query, {});
        
        for (int i = 0; i < result.getNumRows(); i++) {
            std::string cert_id = result.getString(i, "certificate_id");
            std::string reason = result.getString(i, "revocation_reason");
            
            crl.emplace_back(cert_id, reason);
        }
        
        logging::Logger::getInstance().debug("Retrieved {} revoked certificates", crl.size());
        
        return crl;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error retrieving certificate revocation list: {}", e.what());
        return {};
    }
}

std::string CertificateRepository::extractUserIdFromSubject(const std::string& subject) {
    // Extract user ID from subject name
    // This is a simplified implementation - in a real system, this would parse the DN properly
    
    // Look for CN= in the subject
    size_t cn_pos = subject.find("CN=");
    if (cn_pos == std::string::npos) {
        return "";
    }
    
    // Find the end of the CN value (either a comma or end of string)
    size_t end_pos = subject.find(',', cn_pos);
    if (end_pos == std::string::npos) {
        end_pos = subject.length();
    }
    
    // Extract the CN value
    std::string cn = subject.substr(cn_pos + 3, end_pos - cn_pos - 3);
    
    // Trim whitespace
    cn.erase(0, cn.find_first_not_of(" \n\r\t"));
    cn.erase(cn.find_last_not_of(" \n\r\t") + 1);
    
    return cn;
}

} // namespace signature
} // namespace etr
#pragma once

#include <string>
#include <vector>
#include <optional>
#include <memory>
#include "signature/digital_signature.h"
#include "persistence/database_connection.h"

namespace etr {
namespace signature {

/**
 * @brief Certificate repository interface
 */
class ICertificateRepository {
public:
    virtual ~ICertificateRepository() = default;
    
    /**
     * @brief Store certificate
     * @param certificate Certificate info
     * @return True if stored successfully
     */
    virtual bool storeCertificate(const CertificateInfo& certificate) = 0;
    
    /**
     * @brief Get certificate by ID
     * @param certificate_id Certificate ID
     * @return Certificate info or nullopt if not found
     */
    virtual std::optional<CertificateInfo> getCertificate(const std::string& certificate_id) = 0;
    
    /**
     * @brief Get certificates by user ID
     * @param user_id User ID
     * @return Certificates
     */
    virtual std::vector<CertificateInfo> getCertificatesByUserId(const std::string& user_id) = 0;
    
    /**
     * @brief Revoke certificate
     * @param certificate_id Certificate ID
     * @param reason Revocation reason
     * @return True if revoked successfully
     */
    virtual bool revokeCertificate(const std::string& certificate_id, const std::string& reason) = 0;
    
    /**
     * @brief Check if certificate is revoked
     * @param certificate_id Certificate ID
     * @return True if revoked
     */
    virtual bool isCertificateRevoked(const std::string& certificate_id) = 0;
    
    /**
     * @brief Get certificate revocation list
     * @return Certificate revocation list
     */
    virtual std::vector<std::pair<std::string, std::string>> getCertificateRevocationList() = 0;
};

/**
 * @brief Certificate repository implementation
 */
class CertificateRepository : public ICertificateRepository {
public:
    /**
     * @brief Constructor
     * @param db_connection Database connection
     */
    explicit CertificateRepository(std::shared_ptr<persistence::DatabaseConnection> db_connection);
    
    /**
     * @brief Destructor
     */
    ~CertificateRepository() override;
    
    // ICertificateRepository implementation
    bool storeCertificate(const CertificateInfo& certificate) override;
    std::optional<CertificateInfo> getCertificate(const std::string& certificate_id) override;
    std::vector<CertificateInfo> getCertificatesByUserId(const std::string& user_id) override;
    bool revokeCertificate(const std::string& certificate_id, const std::string& reason) override;
    bool isCertificateRevoked(const std::string& certificate_id) override;
    std::vector<std::pair<std::string, std::string>> getCertificateRevocationList() override;
    
private:
    /**
     * @brief Extract user ID from subject
     * @param subject Subject name
     * @return User ID
     */
    std::string extractUserIdFromSubject(const std::string& subject);
    
    std::shared_ptr<persistence::DatabaseConnection> db_connection_;
};

} // namespace signature
} // namespace etr
#include <iostream>
#include <memory>
#include <string>
#include <grpcpp/grpcpp.h>
#include "etr_service.grpc.pb.h"

// Helper function to print record details
void printRecord(const etr::TrainingRecord& record) {
    std::cout << "Record ID: " << record.record_id() << std::endl;
    std::cout << "Trainee: " << record.trainee_id() << std::endl;
    std::cout << "Instructor: " << record.instructor_id() << std::endl;
    std::cout << "Type: " << record.record_type() << std::endl;
    std::cout << "Course: " << record.course_id() << std::endl;
    std::cout << "Syllabus: " << record.syllabus_id() << std::endl;
    std::cout << "Exercise: " << record.exercise_id() << std::endl;
    std::cout << "Date: " << record.date() << std::endl;
    std::cout << "Duration: " << record.duration_minutes() << " minutes" << std::endl;
    std::cout << "Location: " << record.location() << std::endl;
    
    std::cout << "Grades:" << std::endl;
    for (const auto& grade : record.grades()) {
        std::cout << "  - " << grade.criteria_name() << ": " << grade.grade() 
                  << " (" << grade.comments() << ")" << std::endl;
    }
    
    std::cout << "Comments: " << record.comments() << std::endl;
    std::cout << "Draft: " << (record.is_draft() ? "Yes" : "No") << std::endl;
    
    if (record.has_trainee_signature()) {
        std::cout << "Signed by trainee: " << record.trainee_signature().signer_name() << std::endl;
    }
    
    if (record.has_instructor_signature()) {
        std::cout << "Signed by instructor: " << record.instructor_signature().signer_name() << std::endl;
    }
    
    std::cout << std::endl;
}

int main(int argc, char** argv) {
    // Parse command line arguments
    std::string server_address = "localhost:50053";
    if (argc > 1) {
        server_address = argv[1];
    }
    
    // Set up credentials
    std::shared_ptr<grpc::ChannelCredentials> creds = grpc::InsecureChannelCredentials();
    
    // Create channel
    std::shared_ptr<grpc::Channel> channel = grpc::CreateChannel(server_address, creds);
    
    // Create stub
    std::unique_ptr<etr::ElectronicTrainingRecordsService::Stub> stub = 
        etr::ElectronicTrainingRecordsService::NewStub(channel);
    
    // Setup call credentials (JWT token)
    std::string jwt_token = "your_jwt_token_here"; // Replace with actual token
    
    grpc::ClientContext context;
    context.AddMetadata("authorization", "Bearer " + jwt_token);
    
    // Example 1: Create a training record
    {
        etr::TrainingRecord record;
        record.set_trainee_id("trainee123");
        record.set_instructor_id("instructor456");
        record.set_record_type(etr::RecordType::TRAINING_SESSION);
        record.set_course_id("course789");
        record.set_syllabus_id("syllabus101");
        record.set_exercise_id("exercise202");
        record.set_date(std::chrono::duration_cast<std::chrono::milliseconds>(
            std::chrono::system_clock::now().time_since_epoch()
        ).count());
        record.set_duration_minutes(60);
        record.set_location("Simulator Room A");
        record.set_aircraft_type("B737-800");
        
        // Add grades
        auto grade1 = record.add_grades();
        grade1->set_criteria_id("criteria1");
        grade1->set_criteria_name("Procedural Knowledge");
        grade1->set_grade(3);
        grade1->set_comments("Good knowledge of procedures");
        
        auto grade2 = record.add_grades();
        grade2->set_criteria_id("criteria2");
        grade2->set_criteria_name("Communication");
        grade2->set_grade(4);
        grade2->set_comments("Excellent communication skills");
        
        record.set_comments("Overall good performance");
        record.set_is_draft(true);
        
        // Create client context
        grpc::ClientContext create_context;
        create_context.AddMetadata("authorization", "Bearer " + jwt_token);
        
        // Call the CreateTrainingRecord method
        etr::RecordResponse response;
        grpc::Status status = stub->CreateTrainingRecord(&create_context, record, &response);
        
        if (status.ok()) {
            std::cout << "Successfully created record: " << response.record_id() << std::endl;
            
            // Save the record ID for later use
            std::string record_id = response.record_id();
            
            // Example 2: Get the record we just created
            {
                grpc::ClientContext get_context;
                get_context.AddMetadata("authorization", "Bearer " + jwt_token);
                
                etr::RecordRequest request;
                request.set_record_id(record_id);
                
                etr::TrainingRecord get_response;
                grpc::Status get_status = stub->GetTrainingRecord(&get_context, request, &get_response);
                
                if (get_status.ok()) {
                    std::cout << "Retrieved record:" << std::endl;
                    printRecord(get_response);
                } else {
                    std::cerr << "Error getting record: " << get_status.error_message() << std::endl;
                }
            }
            
            // Example 3: Update the record
            {
                grpc::ClientContext update_context;
                update_context.AddMetadata("authorization", "Bearer " + jwt_token);
                
                // Get record again for update
                grpc::ClientContext get_context;
                get_context.AddMetadata("authorization", "Bearer " + jwt_token);
                
                etr::RecordRequest get_request;
                get_request.set_record_id(record_id);
                
                etr::TrainingRecord record_to_update;
                grpc::Status get_status = stub->GetTrainingRecord(&get_context, get_request, &record_to_update);
                
                if (get_status.ok()) {
                    // Update the record
                    record_to_update.set_comments("Updated comments: performance needs improvement in some areas");
                    
                    // Add another grade
                    auto grade3 = record_to_update.add_grades();
                    grade3->set_criteria_id("criteria3");
                    grade3->set_criteria_name("Situational Awareness");
                    grade3->set_grade(2);
                    grade3->set_comments("Needs improvement in maintaining situational awareness");
                    
                    // Submit update
                    etr::RecordResponse update_response;
                    grpc::Status update_status = stub->UpdateTrainingRecord(&update_context, record_to_update, &update_response);
                    
                    if (update_status.ok()) {
                        std::cout << "Successfully updated record: " << update_response.record_id() << std::endl;
                    } else {
                        std::cerr << "Error updating record: " << update_status.error_message() << std::endl;
                    }
                } else {
                    std::cerr << "Error getting record for update: " << get_status.error_message() << std::endl;
                }
            }
            
            // Example 4: Sign the record as instructor
            {
                grpc::ClientContext sign_context;
                sign_context.AddMetadata("authorization", "Bearer " + jwt_token);
                
                etr::SignatureRequest sign_request;
                sign_request.set_record_id(record_id);
                sign_request.set_signer_id("instructor456");
                sign_request.set_is_instructor(true);
                
                // In a real scenario, this would be a digital signature
                std::vector<uint8_t> dummy_signature(32, 0);
                sign_request.set_signature_data(dummy_signature.data(), dummy_signature.size());
                
                etr::SignatureResponse sign_response;
                grpc::Status sign_status = stub->SignRecord(&sign_context, sign_request, &sign_response);
                
                if (sign_status.ok()) {
                    std::cout << "Successfully signed record as instructor" << std::endl;
                } else {
                    std::cerr << "Error signing record: " << sign_status.error_message() << std::endl;
                }
            }
            
            // Example 5: List all records for the trainee
            {
                grpc::ClientContext list_context;
                list_context.AddMetadata("authorization", "Bearer " + jwt_token);
                
                etr::ListRecordsRequest list_request;
                list_request.set_trainee_id("trainee123");
                list_request.set_page(1);
                list_request.set_page_size(10);
                list_request.set_sort_by("date");
                list_request.set_ascending(false);
                
                etr::ListRecordsResponse list_response;
                grpc::Status list_status = stub->ListTrainingRecords(&list_context, list_request, &list_response);
                
                if (list_status.ok()) {
                    std::cout << "Found " << list_response.records_size() << " records (total: " 
                              << list_response.total_count() << ")" << std::endl;
                    
                    for (int i = 0; i < list_response.records_size(); ++i) {
                        std::cout << "Record " << (i+1) << ":" << std::endl;
                        printRecord(list_response.records(i));
                    }
                } else {
                    std::cerr << "Error listing records: " << list_status.error_message() << std::endl;
                }
            }
            
            // Example 6: Check compliance for the trainee
            {
                grpc::ClientContext compliance_context;
                compliance_context.AddMetadata("authorization", "Bearer " + jwt_token);
                
                etr::ComplianceRequest compliance_request;
                compliance_request.set_trainee_id("trainee123");
                compliance_request.set_regulation_id("FAA-61");
                compliance_request.set_certification_type("CPL");
                
                etr::ComplianceResponse compliance_response;
                grpc::Status compliance_status = stub->CheckCompliance(&compliance_context, compliance_request, &compliance_response);
                
                if (compliance_status.ok()) {
                    std::cout << "Compliance status: " << (compliance_response.is_compliant() ? "Compliant" : "Not Compliant") << std::endl;
                    
                    std::cout << "Compliance items:" << std::endl;
                    for (const auto& item : compliance_response.compliance_items()) {
                        std::cout << "  - " << item.requirement_name() << ": " 
                                  << (item.is_satisfied() ? "Satisfied" : "Not Satisfied")
                                  << " (" << item.completed_count() << "/" << item.required_count() << ")" << std::endl;
                    }
                } else {
                    std::cerr << "Error checking compliance: " << compliance_status.error_message() << std::endl;
                }
            }
            
        } else {
            std::cerr << "Error creating record: " << status.error_message() << std::endl;
        }
    }
    
    return 0;
}
cmake_minimum_required(VERSION 3.20)
project(etr-service VERSION 1.0.0 LANGUAGES CXX)

# Set C++20 standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Set output directories
set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)

# Find required packages
find_package(gRPC REQUIRED)
find_package(Protobuf REQUIRED)
find_package(OpenSSL REQUIRED)
find_package(nlohmann_json 3.10.0 REQUIRED)
find_package(spdlog REQUIRED)
find_package(prometheus-cpp REQUIRED)
find_package(cpprestsdk REQUIRED)
find_package(Boost REQUIRED COMPONENTS system filesystem)

# Include directories
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_BINARY_DIR}/generated
)

# Generate protobuf and gRPC code
set(PROTO_FILES
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/etr_service.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/core_service.proto
)

protobuf_generate_cpp(PROTO_SRCS PROTO_HDRS ${PROTO_FILES})
grpc_generate_cpp(GRPC_SRCS GRPC_HDRS ${CMAKE_CURRENT_BINARY_DIR}/generated ${PROTO_FILES})

# Source files
file(GLOB_RECURSE SOURCES 
    ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp
)

# Add executable
add_executable(${PROJECT_NAME} ${SOURCES} ${PROTO_SRCS} ${PROTO_HDRS} ${GRPC_SRCS} ${GRPC_HDRS})

# Link libraries
target_link_libraries(${PROJECT_NAME}
    PRIVATE
    gRPC::grpc++
    gRPC::grpc++_reflection
    protobuf::libprotobuf
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
    spdlog::spdlog
    prometheus-cpp::core
    prometheus-cpp::push
    cpprestsdk::cpprest
    Boost::system
    Boost::filesystem
    pthread
)

# Copy configuration files to build directory
configure_file(
    ${CMAKE_CURRENT_SOURCE_DIR}/config/config.json
    ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/config/config.json
    COPYONLY
)

# Add tests
enable_testing()
add_subdirectory(tests)

# Installation
install(TARGETS ${PROJECT_NAME}
    RUNTIME DESTINATION bin
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)

install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/config/
    DESTINATION etc/${PROJECT_NAME}
    FILES_MATCHING PATTERN "*.json"
)

# Documentation
find_package(Doxygen)
if(DOXYGEN_FOUND)
    set(DOXYGEN_IN ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in)
    set(DOXYGEN_OUT ${CMAKE_CURRENT_BINARY_DIR}/Doxyfile)
    
    configure_file(${DOXYGEN_IN} ${DOXYGEN_OUT} @ONLY)
    
    add_custom_target(docs
        COMMAND ${DOXYGEN_EXECUTABLE} ${DOXYGEN_OUT}
        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
        COMMENT "Generating API documentation with Doxygen"
        VERBATIM
    )
endif()
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <chrono>
#include <nlohmann/json.hpp>
#include "records/record_model.h"

namespace etr {
namespace compliance {

/**
 * @brief Compliance requirement
 */
struct ComplianceRequirement {
    std::string requirement_id;
    std::string requirement_name;
    std::string regulation_id;
    std::string regulation_name;
    std::string regulation_reference;
    std::string description;
    int required_count;
    std::optional<int> duration_days;  // If time-limited requirement
    std::vector<std::string> equivalent_requirements;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Compliance requirement or nullopt if invalid
     */
    static std::optional<ComplianceRequirement> fromJson(const nlohmann::json& json);
};

/**
 * @brief Regulation mapping
 */
struct RegulationMapping {
    std::string source_requirement_id;
    std::string source_requirement_name;
    std::string target_requirement_id;
    std::string target_requirement_name;
    double equivalence_factor;  // 1.0 = full equivalence
    std::string notes;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Regulation mapping or nullopt if invalid
     */
    static std::optional<RegulationMapping> fromJson(const nlohmann::json& json);
};

/**
 * @brief Compliance item
 */
struct ComplianceItem {
    std::string requirement_id;
    std::string requirement_name;
    std::string regulation_reference;
    bool is_satisfied;
    int required_count;
    int completed_count;
    std::vector<std::string> satisfied_by_records;
    std::optional<std::chrono::system_clock::time_point> expiration_date;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Compliance item or nullopt if invalid
     */
    static std::optional<ComplianceItem> fromJson(const nlohmann::json& json);
};

/**
 * @brief Compliance status
 */
struct ComplianceStatus {
    bool is_compliant;
    std::vector<ComplianceItem> compliance_items;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Compliance status or nullopt if invalid
     */
    static std::optional<ComplianceStatus> fromJson(const nlohmann::json& json);
};

/**
 * @brief Compliance repository interface
 */
class IComplianceRepository {
public:
    virtual ~IComplianceRepository() = default;
    
    /**
     * @brief Add or update a compliance requirement
     * @param requirement Compliance requirement
     * @return True if added or updated successfully
     */
    virtual bool addOrUpdateRequirement(const ComplianceRequirement& requirement) = 0;
    
    /**
     * @brief Delete a compliance requirement
     * @param requirement_id Requirement ID
     * @return True if deleted successfully
     */
    virtual bool deleteRequirement(const std::string& requirement_id) = 0;
    
    /**
     * @brief Get a compliance requirement
     * @param requirement_id Requirement ID
     * @return Compliance requirement or nullopt if not found
     */
    virtual std::optional<ComplianceRequirement> getRequirement(const std::string& requirement_id) = 0;
    
    /**
     * @brief List compliance requirements
     * @param regulation_id Regulation ID (optional)
     * @param certification_type Certification type (optional)
     * @return Compliance requirements
     */
    virtual std::vector<ComplianceRequirement> listRequirements(
        const std::optional<std::string>& regulation_id = std::nullopt,
        const std::optional<std::string>& certification_type = std::nullopt
    ) = 0;
    
    /**
     * @brief Add or update a regulation mapping
     * @param mapping Regulation mapping
     * @return True if added or updated successfully
     */
    virtual bool addOrUpdateMapping(const RegulationMapping& mapping) = 0;
    
    /**
     * @brief Delete a regulation mapping
     * @param source_requirement_id Source requirement ID
     * @param target_requirement_id Target requirement ID
     * @return True if deleted successfully
     */
    virtual bool deleteMapping(
        const std::string& source_requirement_id,
        const std::string& target_requirement_id
    ) = 0;
    
    /**
     * @brief Get mappings between regulations
     * @param source_regulation_id Source regulation ID
     * @param target_regulation_id Target regulation ID
     * @return Regulation mappings
     */
    virtual std::vector<RegulationMapping> getMappings(
        const std::optional<std::string>& source_regulation_id = std::nullopt,
        const std::optional<std::string>& target_regulation_id = std::nullopt
    ) = 0;
};

/**
 * @brief Compliance service interface
 */
class IComplianceService {
public:
    virtual ~IComplianceService() = default;
    
    /**
     * @brief Check trainee compliance
     * @param trainee_id Trainee ID
     * @param regulation_id Regulation ID
     * @param certification_type Certification type
     * @return Compliance status
     */
    virtual ComplianceStatus checkCompliance(
        const std::string& trainee_id,
        const std::string& regulation_id,
        const std::string& certification_type
    ) = 0;
    
    /**
     * @brief List compliance requirements
     * @param regulation_id Regulation ID (optional)
     * @param certification_type Certification type (optional)
     * @return Compliance requirements
     */
    virtual std::vector<ComplianceRequirement> listRequirements(
        const std::optional<std::string>& regulation_id = std::nullopt,
        const std::optional<std::string>& certification_type = std::nullopt
    ) = 0;
    
    /**
     * @brief Map regulations
     * @param source_regulation_id Source regulation ID
     * @param target_regulation_id Target regulation ID
     * @return Regulation mappings
     */
    virtual std::vector<RegulationMapping> mapRegulations(
        const std::string& source_regulation_id,
        const std::string& target_regulation_id
    ) = 0;
    
    /**
     * @brief Import FAA regulations
     * @param filename Filename
     * @return True if imported successfully
     */
    virtual bool importFAARegulations(const std::string& filename) = 0;
    
    /**
     * @brief Import EASA regulations
     * @param filename Filename
     * @return True if imported successfully
     */
    virtual bool importEASARegulations(const std::string& filename) = 0;
    
    /**
     * @brief Update trainee compliance
     * @param trainee_id Trainee ID
     * @param record Record
     * @return True if updated successfully
     */
    virtual bool updateTraineeCompliance(
        const std::string& trainee_id,
        const records::TrainingRecord& record
    ) = 0;
};

/**
 * @brief Compliance service implementation
 */
class ComplianceService : public IComplianceService {
public:
    /**
     * @brief Constructor
     * @param compliance_repository Compliance repository
     * @param record_repository Record repository
     */
    ComplianceService(
        std::shared_ptr<IComplianceRepository> compliance_repository,
        std::shared_ptr<records::IRecordRepository> record_repository
    );
    
    /**
     * @brief Destructor
     */
    ~ComplianceService() override;
    
    ComplianceStatus checkCompliance(
        const std::string& trainee_id,
        const std::string& regulation_id,
        const std::string& certification_type
    ) override;
    
    std::vector<ComplianceRequirement> listRequirements(
        const std::optional<std::string>& regulation_id,
        const std::optional<std::string>& certification_type
    ) override;
    
    std::vector<RegulationMapping> mapRegulations(
        const std::string& source_regulation_id,
        const std::string& target_regulation_id
    ) override;
    
    bool importFAARegulations(const std::string& filename) override;
    
    bool importEASARegulations(const std::string& filename) override;
    
    bool updateTraineeCompliance(
        const std::string& trainee_id,
        const records::TrainingRecord& record
    ) override;
    
private:
    /**
     * @brief Calculate compliance for a requirement
     * @param trainee_id Trainee ID
     * @param requirement Requirement
     * @param records Records
     * @return Compliance item
     */
    ComplianceItem calculateComplianceForRequirement(
        const std::string& trainee_id,
        const ComplianceRequirement& requirement,
        const std::vector<records::TrainingRecord>& records
    );
    
    /**
     * @brief Parse FAA regulations
     * @param content File content
     * @return Compliance requirements
     */
    std::vector<ComplianceRequirement> parseFAARegulations(const std::string& content);
    
    /**
     * @brief Parse EASA regulations
     * @param content File content
     * @return Compliance requirements
     */
    std::vector<ComplianceRequirement> parseEASARegulations(const std::string& content);
    
    std::shared_ptr<IComplianceRepository> compliance_repository_;
    std::shared_ptr<records::IRecordRepository> record_repository_;
};

} // namespace compliance
} // namespace etr
#include "compliance/compliance_service.h"
#include "logging/logger.h"
#include <fstream>
#include <sstream>
#include <algorithm>
#include <regex>

namespace etr {
namespace compliance {

// ComplianceService implementation
ComplianceService::ComplianceService(
    std::shared_ptr<IComplianceRepository> compliance_repository,
    std::shared_ptr<records::IRecordRepository> record_repository
) : compliance_repository_(std::move(compliance_repository)),
    record_repository_(std::move(record_repository)) {
    
    logging::Logger::getInstance().info("ComplianceService initialized");
}

ComplianceService::~ComplianceService() {
    logging::Logger::getInstance().info("ComplianceService shutdown");
}

ComplianceStatus ComplianceService::checkCompliance(
    const std::string& trainee_id,
    const std::string& regulation_id,
    const std::string& certification_type
) {
    ComplianceStatus status;
    status.is_compliant = true; // Will be set to false if any requirement is not satisfied
    
    try {
        // Get all requirements for this regulation and certification type
        auto requirements = compliance_repository_->listRequirements(
            regulation_id,
            certification_type
        );
        
        // Get all records for the trainee
        auto [records, _] = record_repository_->listRecords(
            trainee_id,
            std::nullopt,
            std::nullopt,
            std::nullopt,
            std::nullopt,
            std::nullopt,
            std::nullopt,
            1,
            1000, // Fetch a large batch
            "date",
            false
        );
        
        // Check compliance for each requirement
        for (const auto& requirement : requirements) {
            ComplianceItem item = calculateComplianceForRequirement(
                trainee_id, 
                requirement, 
                records
            );
            
            status.compliance_items.push_back(item);
            
            // Update overall compliance status
            if (!item.is_satisfied) {
                status.is_compliant = false;
            }
        }
        
        logging::Logger::getInstance().info(
            "Checked compliance for trainee {}, regulation {}, certification {}: {}",
            trainee_id, regulation_id, certification_type,
            status.is_compliant ? "compliant" : "not compliant"
        );
        
        return status;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error checking compliance for trainee {}, regulation {}, certification {}: {}",
            trainee_id, regulation_id, certification_type, e.what()
        );
        
        // Return not compliant status
        status.is_compliant = false;
        return status;
    }
}

std::vector<ComplianceRequirement> ComplianceService::listRequirements(
    const std::optional<std::string>& regulation_id,
    const std::optional<std::string>& certification_type
) {
    try {
        auto requirements = compliance_repository_->listRequirements(
            regulation_id,
            certification_type
        );
        
        logging::Logger::getInstance().debug(
            "Listed {} compliance requirements",
            requirements.size()
        );
        
        return requirements;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error listing compliance requirements: {}", e.what());
        return {};
    }
}

std::vector<RegulationMapping> ComplianceService::mapRegulations(
    const std::string& source_regulation_id,
    const std::string& target_regulation_id
) {
    try {
        auto mappings = compliance_repository_->getMappings(
            source_regulation_id,
            target_regulation_id
        );
        
        logging::Logger::getInstance().debug(
            "Mapped {} requirements between regulations {} and {}",
            mappings.size(), source_regulation_id, target_regulation_id
        );
        
        return mappings;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error mapping regulations {} to {}: {}",
            source_regulation_id, target_regulation_id, e.what()
        );
        return {};
    }
}

bool ComplianceService::importFAARegulations(const std::string& filename) {
    try {
        std::ifstream file(filename);
        if (!file.is_open()) {
            logging::Logger::getInstance().error("Failed to open FAA regulations file: {}", filename);
            return false;
        }
        
        std::stringstream buffer;
        buffer << file.rdbuf();
        
        auto requirements = parseFAARegulations(buffer.str());
        
        if (requirements.empty()) {
            logging::Logger::getInstance().error("No requirements parsed from FAA regulations file");
            return false;
        }
        
        // Add or update requirements in repository
        for (const auto& requirement : requirements) {
            if (!compliance_repository_->addOrUpdateRequirement(requirement)) {
                logging::Logger::getInstance().error(
                    "Failed to add/update requirement: {}",
                    requirement.requirement_id
                );
                return false;
            }
        }
        
        logging::Logger::getInstance().info(
            "Imported {} FAA regulations from {}",
            requirements.size(), filename
        );
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error importing FAA regulations: {}", e.what());
        return false;
    }
}

bool ComplianceService::importEASARegulations(const std::string& filename) {
    try {
        std::ifstream file(filename);
        if (!file.is_open()) {
            logging::Logger::getInstance().error("Failed to open EASA regulations file: {}", filename);
            return false;
        }
        
        std::stringstream buffer;
        buffer << file.rdbuf();
        
        auto requirements = parseEASARegulations(buffer.str());
        
        if (requirements.empty()) {
            logging::Logger::getInstance().error("No requirements parsed from EASA regulations file");
            return false;
        }
        
        // Add or update requirements in repository
        for (const auto& requirement : requirements) {
            if (!compliance_repository_->addOrUpdateRequirement(requirement)) {
                logging::Logger::getInstance().error(
                    "Failed to add/update requirement: {}",
                    requirement.requirement_id
                );
                return false;
            }
        }
        
        logging::Logger::getInstance().info(
            "Imported {} EASA regulations from {}",
            requirements.size(), filename
        );
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error importing EASA regulations: {}", e.what());
        return false;
    }
}

bool ComplianceService::updateTraineeCompliance(
    const std::string& trainee_id,
    const records::TrainingRecord& record
) {
    try {
        // This method would update the trainee's compliance status based on a new record
        // For simplicity, we'll just log the update and return true
        logging::Logger::getInstance().info(
            "Updated compliance status for trainee {} based on record {}",
            trainee_id, record.getRecordId()
        );
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error updating trainee compliance: {}",
            e.what()
        );
        return false;
    }
}

ComplianceItem ComplianceService::calculateComplianceForRequirement(
    const std::string& trainee_id,
    const ComplianceRequirement& requirement,
    const std::vector<records::TrainingRecord>& records
) {
    ComplianceItem item;
    item.requirement_id = requirement.requirement_id;
    item.requirement_name = requirement.requirement_name;
    item.regulation_reference = requirement.regulation_reference;
    item.required_count = requirement.required_count;
    item.completed_count = 0;
    
    // Filter records that satisfy this requirement
    for (const auto& record : records) {
        // Skip draft or unsigned records
        if (record.isDraft() || !record.isFullySigned()) {
            continue;
        }
        
        // Check if record has grades that satisfy this requirement
        bool satisfies_requirement = false;
        
        for (const auto& grade : record.getGrades()) {
            // This is a simplified check - in a real implementation,
            // we would need to check against specific criteria IDs or other factors
            if (grade.grade >= 2) { // 2 is passing (1-4 scale)
                satisfies_requirement = true;
                break;
            }
        }
        
        if (satisfies_requirement) {
            item.completed_count++;
            item.satisfied_by_records.push_back(record.getRecordId());
        }
    }
    
    // Check if duration-based requirement (e.g., recency)
    if (requirement.duration_days) {
        // Check for records within the duration period
        auto now = std::chrono::system_clock::now();
        auto duration_ago = now - std::chrono::hours(24 * requirement.duration_days.value());
        
        bool has_recent = false;
        
        for (const auto& record_id : item.satisfied_by_records) {
            // Find the record
            auto it = std::find_if(records.begin(), records.end(),
                [&record_id](const records::TrainingRecord& record) {
                    return record.getRecordId() == record_id;
                });
            
            if (it != records.end() && it->getDate() >= duration_ago) {
                has_recent = true;
                break;
            }
        }
        
        if (!has_recent) {
            item.completed_count = 0; // Reset count if recency requirement not met
        }
        
        // Set expiration date
        if (item.completed_count > 0) {
            // Find most recent record
            std::chrono::system_clock::time_point most_recent = std::chrono::system_clock::time_point::min();
            
            for (const auto& record_id : item.satisfied_by_records) {
                auto it = std::find_if(records.begin(), records.end(),
                    [&record_id](const records::TrainingRecord& record) {
                        return record.getRecordId() == record_id;
                    });
                
                if (it != records.end() && it->getDate() > most_recent) {
                    most_recent = it->getDate();
                }
            }
            
            // Expiration is most recent record date + duration
            if (most_recent != std::chrono::system_clock::time_point::min()) {
                item.expiration_date = most_recent + std::chrono::hours(24 * requirement.duration_days.value());
            }
        }
    }
    
    // Determine if requirement is satisfied
    item.is_satisfied = (item.completed_count >= item.required_count);
    
    return item;
}

std::vector<ComplianceRequirement> ComplianceService::parseFAARegulations(const std::string& content) {
    std::vector<ComplianceRequirement> requirements;
    
    try {
        // Parse the content as JSON
        nlohmann::json json = nlohmann::json::parse(content);
        
        // Extract requirements
        for (const auto& item : json) {
            ComplianceRequirement requirement;
            
            requirement.requirement_id = item["id"].get<std::string>();
            requirement.requirement_name = item["name"].get<std::string>();
            requirement.regulation_id = item["regulation_id"].get<std::string>();
            requirement.regulation_name = item["regulation_name"].get<std::string>();
            requirement.regulation_reference = item["reference"].get<std::string>();
            requirement.description = item["description"].get<std::string>();
            requirement.required_count = item["required_count"].get<int>();
            
            if (item.contains("duration_days") && !item["duration_days"].is_null()) {
                requirement.duration_days = item["duration_days"].get<int>();
            }
            
            if (item.contains("equivalent_requirements") && item["equivalent_requirements"].is_array()) {
                for (const auto& eq : item["equivalent_requirements"]) {
                    requirement.equivalent_requirements.push_back(eq.get<std::string>());
                }
            }
            
            requirements.push_back(requirement);
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing FAA regulations: {}", e.what());
    }
    
    return requirements;
}

std::vector<ComplianceRequirement> ComplianceService::parseEASARegulations(const std::string& content) {
    std::vector<ComplianceRequirement> requirements;
    
    try {
        // Parse the content as JSON
        nlohmann::json json = nlohmann::json::parse(content);
        
        // Extract requirements
        for (const auto& item : json) {
            ComplianceRequirement requirement;
            
            requirement.requirement_id = item["id"].get<std::string>();
            requirement.requirement_name = item["name"].get<std::string>();
            requirement.regulation_id = item["regulation_id"].get<std::string>();
            requirement.regulation_name = item["regulation_name"].get<std::string>();
            requirement.regulation_reference = item["reference"].get<std::string>();
            requirement.description = item["description"].get<std::string>();
            requirement.required_count = item["required_count"].get<int>();
            
            if (item.contains("duration_days") && !item["duration_days"].is_null()) {
                requirement.duration_days = item["duration_days"].get<int>();
            }
            
            if (item.contains("equivalent_requirements") && item["equivalent_requirements"].is_array()) {
                for (const auto& eq : item["equivalent_requirements"]) {
                    requirement.equivalent_requirements.push_back(eq.get<std::string>());
                }
            }
            
            requirements.push_back(requirement);
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing EASA regulations: {}", e.what());
    }
    
    return requirements;
}

// ComplianceRequirement methods

nlohmann::json ComplianceRequirement::toJson() const {
    nlohmann::json json;
    json["requirement_id"] = requirement_id;
    json["requirement_name"] = requirement_name;
    json["regulation_id"] = regulation_id;
    json["regulation_name"] = regulation_name;
    json["regulation_reference"] = regulation_reference;
    json["description"] = description;
    json["required_count"] = required_count;
    
    if (duration_days) {
        json["duration_days"] = *duration_days;
    }
    
    json["equivalent_requirements"] = equivalent_requirements;
    
    return json;
}

std::optional<ComplianceRequirement> ComplianceRequirement::fromJson(const nlohmann::json& json) {
    try {
        ComplianceRequirement requirement;
        
        requirement.requirement_id = json["requirement_id"];
        requirement.requirement_name = json["requirement_name"];
        requirement.regulation_id = json["regulation_id"];
        requirement.regulation_name = json["regulation_name"];
        requirement.regulation_reference = json["regulation_reference"];
        requirement.description = json["description"];
        requirement.required_count = json["required_count"];
        
        if (json.contains("duration_days") && !json["duration_days"].is_null()) {
            requirement.duration_days = json["duration_days"];
        }
        
        if (json.contains("equivalent_requirements") && json["equivalent_requirements"].is_array()) {
            requirement.equivalent_requirements = json["equivalent_requirements"].get<std::vector<std::string>>();
        }
        
        return requirement;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing compliance requirement from JSON: {}", e.what());
        return std::nullopt;
    }
}

// RegulationMapping methods

nlohmann::json RegulationMapping::toJson() const {
    nlohmann::json json;
    json["source_requirement_id"] = source_requirement_id;
    json["source_requirement_name"] = source_requirement_name;
    json["target_requirement_id"] = target_requirement_id;
    json["target_requirement_name"] = target_requirement_name;
    json["equivalence_factor"] = equivalence_factor;
    json["notes"] = notes;
    
    return json;
}

std::optional<RegulationMapping> RegulationMapping::fromJson(const nlohmann::json& json) {
    try {
        RegulationMapping mapping;
        
        mapping.source_requirement_id = json["source_requirement_id"];
        mapping.source_requirement_name = json["source_requirement_name"];
        mapping.target_requirement_id = json["target_requirement_id"];
        mapping.target_requirement_name = json["target_requirement_name"];
        mapping.equivalence_factor = json["equivalence_factor"];
        mapping.notes = json["notes"];
        
        return mapping;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing regulation mapping from JSON: {}", e.what());
        return std::nullopt;
    }
}

// ComplianceItem methods

nlohmann::json ComplianceItem::toJson() const {
    nlohmann::json json;
    json["requirement_id"] = requirement_id;
    json["requirement_name"] = requirement_name;
    json["regulation_reference"] = regulation_reference;
    json["is_satisfied"] = is_satisfied;
    json["required_count"] = required_count;
    json["completed_count"] = completed_count;
    json["satisfied_by_records"] = satisfied_by_records;
    
    if (expiration_date) {
        json["expiration_date"] = std::chrono::duration_cast<std::chrono::milliseconds>(
            expiration_date->time_since_epoch()).count();
    }
    
    return json;
}

std::optional<ComplianceItem> ComplianceItem::fromJson(const nlohmann::json& json) {
    try {
        ComplianceItem item;
        
        item.requirement_id = json["requirement_id"];
        item.requirement_name = json["requirement_name"];
        item.regulation_reference = json["regulation_reference"];
        item.is_satisfied = json["is_satisfied"];
        item.required_count = json["required_count"];
        item.completed_count = json["completed_count"];
        item.satisfied_by_records = json["satisfied_by_records"].get<std::vector<std::string>>();
        
        if (json.contains("expiration_date") && !json["expiration_date"].is_null()) {
            item.expiration_date = std::chrono::system_clock::time_point(
                std::chrono::milliseconds(json["expiration_date"].get<int64_t>())
            );
        }
        
        return item;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing compliance item from JSON: {}", e.what());
        return std::nullopt;
    }
}

// ComplianceStatus methods

nlohmann::json ComplianceStatus::toJson() const {
    nlohmann::json json;
    json["is_compliant"] = is_compliant;
    
    json["compliance_items"] = nlohmann::json::array();
    for (const auto& item : compliance_items) {
        json["compliance_items"].push_back(item.toJson());
    }
    
    return json;
}

std::optional<ComplianceStatus> ComplianceStatus::fromJson(const nlohmann::json& json) {
    try {
        ComplianceStatus status;
        
        status.is_compliant = json["is_compliant"];
        
        for (const auto& item_json : json["compliance_items"]) {
            auto item = ComplianceItem::fromJson(item_json);
            if (item) {
                status.compliance_items.push_back(*item);
            }
        }
        
        return status;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing compliance status from JSON: {}", e.what());
        return std::nullopt;
    }
}

} // namespace compliance
} // namespace etr
#include "compliance/compliance_repository.h"
#include "logging/logger.h"
#include "persistence/database_connection.h"

namespace etr {
namespace compliance {

class ComplianceRepository : public IComplianceRepository {
public:
    ComplianceRepository(std::shared_ptr<persistence::DatabaseConnection> db_connection)
        : db_connection_(std::move(db_connection)) {
        logging::Logger::getInstance().info("ComplianceRepository initialized");
    }

    ~ComplianceRepository() override {
        logging::Logger::getInstance().info("ComplianceRepository shutdown");
    }

    bool addOrUpdateRequirement(const ComplianceRequirement& requirement) override {
        try {
            // Check if requirement exists
            std::string check_query = 
                "SELECT requirement_id FROM etr.compliance_requirements WHERE requirement_id = $1";
            
            auto result = db_connection_->executeQuery(check_query, {
                {":requirement_id", requirement.requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            bool exists = !result.isEmpty();
            
            persistence::Transaction transaction = db_connection_->createTransaction();
            
            if (exists) {
                // Update existing requirement
                std::string update_query = 
                    "UPDATE etr.compliance_requirements SET "
                    "requirement_name = $1, "
                    "regulation_id = $2, "
                    "regulation_name = $3, "
                    "regulation_reference = $4, "
                    "description = $5, "
                    "required_count = $6, "
                    "duration_days = $7, "
                    "updated_at = NOW() "
                    "WHERE requirement_id = $8";
                
                auto update_result = db_connection_->executeQuery(update_query, {
                    {":requirement_name", requirement.requirement_name, persistence::PgParamType::TEXT, false},
                    {":regulation_id", requirement.regulation_id, persistence::PgParamType::TEXT, false},
                    {":regulation_name", requirement.regulation_name, persistence::PgParamType::TEXT, false},
                    {":regulation_reference", requirement.regulation_reference, persistence::PgParamType::TEXT, false},
                    {":description", requirement.description, persistence::PgParamType::TEXT, false},
                    {":required_count", std::to_string(requirement.required_count), persistence::PgParamType::INTEGER, false},
                    {":duration_days", requirement.duration_days ? std::to_string(*requirement.duration_days) : "", 
                     persistence::PgParamType::INTEGER, !requirement.duration_days.has_value()},
                    {":requirement_id", requirement.requirement_id, persistence::PgParamType::TEXT, false}
                });
                
                if (update_result.hasError()) {
                    transaction.rollback();
                    logging::Logger::getInstance().error("Failed to update requirement: {}", update_result.getErrorMessage());
                    return false;
                }
            } else {
                // Insert new requirement
                std::string insert_query = 
                    "INSERT INTO etr.compliance_requirements "
                    "(requirement_id, requirement_name, regulation_id, regulation_name, "
                    "regulation_reference, description, required_count, duration_days, "
                    "created_at, updated_at) "
                    "VALUES ($1, $2, $3, $4, $5, $6, $7, $8, NOW(), NOW())";
                
                auto insert_result = db_connection_->executeQuery(insert_query, {
                    {":requirement_id", requirement.requirement_id, persistence::PgParamType::TEXT, false},
                    {":requirement_name", requirement.requirement_name, persistence::PgParamType::TEXT, false},
                    {":regulation_id", requirement.regulation_id, persistence::PgParamType::TEXT, false},
                    {":regulation_name", requirement.regulation_name, persistence::PgParamType::TEXT, false},
                    {":regulation_reference", requirement.regulation_reference, persistence::PgParamType::TEXT, false},
                    {":description", requirement.description, persistence::PgParamType::TEXT, false},
                    {":required_count", std::to_string(requirement.required_count), persistence::PgParamType::INTEGER, false},
                    {":duration_days", requirement.duration_days ? std::to_string(*requirement.duration_days) : "", 
                     persistence::PgParamType::INTEGER, !requirement.duration_days.has_value()}
                });
                
                if (insert_result.hasError()) {
                    transaction.rollback();
                    logging::Logger::getInstance().error("Failed to insert requirement: {}", insert_result.getErrorMessage());
                    return false;
                }
            }
            
            // Delete existing equivalent requirements
            std::string delete_equiv_query = 
                "DELETE FROM etr.equivalent_requirements WHERE source_requirement_id = $1";
            
            auto delete_equiv_result = db_connection_->executeQuery(delete_equiv_query, {
                {":source_requirement_id", requirement.requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            if (delete_equiv_result.hasError()) {
                transaction.rollback();
                logging::Logger::getInstance().error("Failed to delete equivalent requirements: {}", 
                    delete_equiv_result.getErrorMessage());
                return false;
            }
            
            // Insert equivalent requirements
            for (const auto& equiv_id : requirement.equivalent_requirements) {
                std::string insert_equiv_query = 
                    "INSERT INTO etr.equivalent_requirements "
                    "(source_requirement_id, target_requirement_id) "
                    "VALUES ($1, $2)";
                
                auto insert_equiv_result = db_connection_->executeQuery(insert_equiv_query, {
                    {":source_requirement_id", requirement.requirement_id, persistence::PgParamType::TEXT, false},
                    {":target_requirement_id", equiv_id, persistence::PgParamType::TEXT, false}
                });
                
                if (insert_equiv_result.hasError()) {
                    transaction.rollback();
                    logging::Logger::getInstance().error("Failed to insert equivalent requirement: {}", 
                        insert_equiv_result.getErrorMessage());
                    return false;
                }
            }
            
            transaction.commit();
            
            logging::Logger::getInstance().info("Added/updated requirement: {}", requirement.requirement_id);
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error adding/updating requirement: {}", e.what());
            return false;
        }
    }

    bool deleteRequirement(const std::string& requirement_id) override {
        try {
            persistence::Transaction transaction = db_connection_->createTransaction();
            
            // Delete equivalent requirements
            std::string delete_equiv_query = 
                "DELETE FROM etr.equivalent_requirements WHERE source_requirement_id = $1 OR target_requirement_id = $1";
            
            auto delete_equiv_result = db_connection_->executeQuery(delete_equiv_query, {
                {":requirement_id", requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            if (delete_equiv_result.hasError()) {
                transaction.rollback();
                logging::Logger::getInstance().error("Failed to delete equivalent requirements: {}", 
                    delete_equiv_result.getErrorMessage());
                return false;
            }
            
            // Delete regulation mappings
            std::string delete_mapping_query = 
                "DELETE FROM etr.regulation_mappings WHERE source_requirement_id = $1 OR target_requirement_id = $1";
            
            auto delete_mapping_result = db_connection_->executeQuery(delete_mapping_query, {
                {":requirement_id", requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            if (delete_mapping_result.hasError()) {
                transaction.rollback();
                logging::Logger::getInstance().error("Failed to delete regulation mappings: {}", 
                    delete_mapping_result.getErrorMessage());
                return false;
            }
            
            // Delete trainee compliance records
            std::string delete_trainee_records_query = 
                "DELETE FROM etr.trainee_compliance_records WHERE requirement_id = $1";
            
            auto delete_trainee_records_result = db_connection_->executeQuery(delete_trainee_records_query, {
                {":requirement_id", requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            if (delete_trainee_records_result.hasError()) {
                transaction.rollback();
                logging::Logger::getInstance().error("Failed to delete trainee compliance records: {}", 
                    delete_trainee_records_result.getErrorMessage());
                return false;
            }
            
            // Delete trainee compliance
            std::string delete_trainee_query = 
                "DELETE FROM etr.trainee_compliance WHERE requirement_id = $1";
            
            auto delete_trainee_result = db_connection_->executeQuery(delete_trainee_query, {
                {":requirement_id", requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            if (delete_trainee_result.hasError()) {
                transaction.rollback();
                logging::Logger::getInstance().error("Failed to delete trainee compliance: {}", 
                    delete_trainee_result.getErrorMessage());
                return false;
            }
            
            // Delete requirement
            std::string delete_query = 
                "DELETE FROM etr.compliance_requirements WHERE requirement_id = $1";
            
            auto delete_result = db_connection_->executeQuery(delete_query, {
                {":requirement_id", requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            if (delete_result.hasError()) {
                transaction.rollback();
                logging::Logger::getInstance().error("Failed to delete requirement: {}", 
                    delete_result.getErrorMessage());
                return false;
            }
            
            transaction.commit();
            
            logging::Logger::getInstance().info("Deleted requirement: {}", requirement_id);
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error deleting requirement: {}", e.what());
            return false;
        }
    }

    std::optional<ComplianceRequirement> getRequirement(const std::string& requirement_id) override {
        try {
            std::string query = 
                "SELECT requirement_id, requirement_name, regulation_id, regulation_name, "
                "regulation_reference, description, required_count, duration_days "
                "FROM etr.compliance_requirements WHERE requirement_id = $1";
            
            auto result = db_connection_->executeQuery(query, {
                {":requirement_id", requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            if (result.isEmpty()) {
                logging::Logger::getInstance().debug("Requirement not found: {}", requirement_id);
                return std::nullopt;
            }
            
            ComplianceRequirement requirement;
            requirement.requirement_id = result.getString(0, "requirement_id");
            requirement.requirement_name = result.getString(0, "requirement_name");
            requirement.regulation_id = result.getString(0, "regulation_id");
            requirement.regulation_name = result.getString(0, "regulation_name");
            requirement.regulation_reference = result.getString(0, "regulation_reference");
            requirement.description = result.getString(0, "description");
            requirement.required_count = result.getInt(0, "required_count");
            
            if (!result.isNull(0, "duration_days")) {
                requirement.duration_days = result.getInt(0, "duration_days");
            }
            
            // Get equivalent requirements
            std::string equiv_query = 
                "SELECT target_requirement_id FROM etr.equivalent_requirements WHERE source_requirement_id = $1";
            
            auto equiv_result = db_connection_->executeQuery(equiv_query, {
                {":source_requirement_id", requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            for (int i = 0; i < equiv_result.getNumRows(); ++i) {
                requirement.equivalent_requirements.push_back(equiv_result.getString(i, "target_requirement_id"));
            }
            
            logging::Logger::getInstance().debug("Retrieved requirement: {}", requirement_id);
            return requirement;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting requirement: {}", e.what());
            return std::nullopt;
        }
    }

    std::vector<ComplianceRequirement> listRequirements(
        const std::optional<std::string>& regulation_id,
        const std::optional<std::string>& certification_type
    ) override {
        try {
            std::stringstream query_ss;
            query_ss << "SELECT requirement_id, requirement_name, regulation_id, regulation_name, "
                     << "regulation_reference, description, required_count, duration_days "
                     << "FROM etr.compliance_requirements WHERE 1=1";
            
            std::vector<persistence::PgParam> params;
            
            if (regulation_id) {
                query_ss << " AND regulation_id = $" << (params.size() + 1);
                params.push_back({":regulation_id", *regulation_id, persistence::PgParamType::TEXT, false});
            }
            
            // In a real implementation, we would have a link table for certification types
            // For simplicity, we'll assume certification_type is stored in metadata or similar
            
            query_ss << " ORDER BY regulation_id, requirement_name";
            
            auto result = db_connection_->executeQuery(query_ss.str(), params);
            
            std::vector<ComplianceRequirement> requirements;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                ComplianceRequirement requirement;
                requirement.requirement_id = result.getString(i, "requirement_id");
                requirement.requirement_name = result.getString(i, "requirement_name");
                requirement.regulation_id = result.getString(i, "regulation_id");
                requirement.regulation_name = result.getString(i, "regulation_name");
                requirement.regulation_reference = result.getString(i, "regulation_reference");
                requirement.description = result.getString(i, "description");
                requirement.required_count = result.getInt(i, "required_count");
                
                if (!result.isNull(i, "duration_days")) {
                    requirement.duration_days = result.getInt(i, "duration_days");
                }
                
                // Get equivalent requirements
                std::string equiv_query = 
                    "SELECT target_requirement_id FROM etr.equivalent_requirements WHERE source_requirement_id = $1";
                
                auto equiv_result = db_connection_->executeQuery(equiv_query, {
                    {":source_requirement_id", requirement.requirement_id, persistence::PgParamType::TEXT, false}
                });
                
                for (int j = 0; j < equiv_result.getNumRows(); ++j) {
                    requirement.equivalent_requirements.push_back(equiv_result.getString(j, "target_requirement_id"));
                }
                
                requirements.push_back(requirement);
            }
            
            logging::Logger::getInstance().debug("Listed {} requirements", requirements.size());
            return requirements;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error listing requirements: {}", e.what());
            return {};
        }
    }

    bool addOrUpdateMapping(const RegulationMapping& mapping) override {
        try {
            // Check if mapping exists
            std::string check_query = 
                "SELECT source_requirement_id FROM etr.regulation_mappings "
                "WHERE source_requirement_id = $1 AND target_requirement_id = $2";
            
            auto result = db_connection_->executeQuery(check_query, {
                {":source_requirement_id", mapping.source_requirement_id, persistence::PgParamType::TEXT, false},
                {":target_requirement_id", mapping.target_requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            bool exists = !result.isEmpty();
            
            if (exists) {
                // Update existing mapping
                std::string update_query = 
                    "UPDATE etr.regulation_mappings SET "
                    "equivalence_factor = $1, "
                    "notes = $2 "
                    "WHERE source_requirement_id = $3 AND target_requirement_id = $4";
                
                auto update_result = db_connection_->executeQuery(update_query, {
                    {":equivalence_factor", std::to_string(mapping.equivalence_factor), persistence::PgParamType::DOUBLE, false},
                    {":notes", mapping.notes, persistence::PgParamType::TEXT, false},
                    {":source_requirement_id", mapping.source_requirement_id, persistence::PgParamType::TEXT, false},
                    {":target_requirement_id", mapping.target_requirement_id, persistence::PgParamType::TEXT, false}
                });
                
                if (update_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to update mapping: {}", update_result.getErrorMessage());
                    return false;
                }
            } else {
                // Insert new mapping
                std::string insert_query = 
                    "INSERT INTO etr.regulation_mappings "
                    "(source_requirement_id, target_requirement_id, equivalence_factor, notes) "
                    "VALUES ($1, $2, $3, $4)";
                
                auto insert_result = db_connection_->executeQuery(insert_query, {
                    {":source_requirement_id", mapping.source_requirement_id, persistence::PgParamType::TEXT, false},
                    {":target_requirement_id", mapping.target_requirement_id, persistence::PgParamType::TEXT, false},
                    {":equivalence_factor", std::to_string(mapping.equivalence_factor), persistence::PgParamType::DOUBLE, false},
                    {":notes", mapping.notes, persistence::PgParamType::TEXT, false}
                });
                
                if (insert_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert mapping: {}", insert_result.getErrorMessage());
                    return false;
                }
            }
            
            logging::Logger::getInstance().info("Added/updated mapping: {} -> {}", 
                mapping.source_requirement_id, mapping.target_requirement_id);
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error adding/updating mapping: {}", e.what());
            return false;
        }
    }

    bool deleteMapping(
        const std::string& source_requirement_id,
        const std::string& target_requirement_id
    ) override {
        try {
            std::string delete_query = 
                "DELETE FROM etr.regulation_mappings "
                "WHERE source_requirement_id = $1 AND target_requirement_id = $2";
            
            auto delete_result = db_connection_->executeQuery(delete_query, {
                {":source_requirement_id", source_requirement_id, persistence::PgParamType::TEXT, false},
                {":target_requirement_id", target_requirement_id, persistence::PgParamType::TEXT, false}
            });
            
            if (delete_result.hasError()) {
                logging::Logger::getInstance().error("Failed to delete mapping: {}", delete_result.getErrorMessage());
                return false;
            }
            
            logging::Logger::getInstance().info("Deleted mapping: {} -> {}", 
                source_requirement_id, target_requirement_id);
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error deleting mapping: {}", e.what());
            return false;
        }
    }

    std::vector<RegulationMapping> getMappings(
        const std::optional<std::string>& source_regulation_id,
        const std::optional<std::string>& target_regulation_id
    ) override {
        try {
            std::stringstream query_ss;
            query_ss << "SELECT m.source_requirement_id, src.requirement_name as source_requirement_name, "
                     << "m.target_requirement_id, tgt.requirement_name as target_requirement_name, "
                     << "m.equivalence_factor, m.notes "
                     << "FROM etr.regulation_mappings m "
                     << "JOIN etr.compliance_requirements src ON m.source_requirement_id = src.requirement_id "
                     << "JOIN etr.compliance_requirements tgt ON m.target_requirement_id = tgt.requirement_id "
                     << "WHERE 1=1";
            
            std::vector<persistence::PgParam> params;
            
            if (source_regulation_id) {
                query_ss << " AND src.regulation_id = $" << (params.size() + 1);
                params.push_back({":source_regulation_id", *source_regulation_id, persistence::PgParamType::TEXT, false});
            }
            
            if (target_regulation_id) {
                query_ss << " AND tgt.regulation_id = $" << (params.size() + 1);
                params.push_back({":target_regulation_id", *target_regulation_id, persistence::PgParamType::TEXT, false});
            }
            
            query_ss << " ORDER BY src.requirement_name, tgt.requirement_name";
            
            auto result = db_connection_->executeQuery(query_ss.str(), params);
            
            std::vector<RegulationMapping> mappings;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                RegulationMapping mapping;
                mapping.source_requirement_id = result.getString(i, "source_requirement_id");
                mapping.source_requirement_name = result.getString(i, "source_requirement_name");
                mapping.target_requirement_id = result.getString(i, "target_requirement_id");
                mapping.target_requirement_name = result.getString(i, "target_requirement_name");
                mapping.equivalence_factor = result.getDouble(i, "equivalence_factor");
                mapping.notes = result.getString(i, "notes");
                
                mappings.push_back(mapping);
            }
            
            logging::Logger::getInstance().debug("Listed {} mappings", mappings.size());
            return mappings;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting mappings: {}", e.what());
            return {};
        }
    }

private:
    std::shared_ptr<persistence::DatabaseConnection> db_connection_;
};

// Factory function to create compliance repository
std::shared_ptr<IComplianceRepository> createComplianceRepository(
    std::shared_ptr<persistence::DatabaseConnection> db_connection
) {
    return std::make_shared<ComplianceRepository>(std::move(db_connection));
}

} // namespace compliance
} // namespace etr
#include "compliance/compliance_repository.h"
#include "logging/logger.h"
#include <chrono>

namespace etr {
namespace compliance {

ComplianceRepository::ComplianceRepository(
    std::shared_ptr<persistence::DatabaseConnection> db_connection
) : db_connection_(std::move(db_connection)) {
    logging::Logger::getInstance().info("ComplianceRepository initialized");
}

bool ComplianceRepository::addOrUpdateRequirement(const ComplianceRequirement& requirement) {
    try {
        // Start transaction
        auto transaction = db_connection_->createTransaction();
        
        // Check if requirement exists
        std::string check_query = 
            "SELECT requirement_id FROM etr.compliance_requirements WHERE requirement_id = $1";
        
        auto check_result = db_connection_->executeQuery(
            check_query,
            {
                {
                    "requirement_id",
                    requirement.requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                }
            }
        );
        
        bool exists = check_result.getNumRows() > 0;
        
        std::string query;
        std::vector<persistence::PgParam> params;
        
        if (exists) {
            // Update existing requirement
            query = 
                "UPDATE etr.compliance_requirements SET "
                "requirement_name = $1, "
                "regulation_id = $2, "
                "regulation_name = $3, "
                "regulation_reference = $4, "
                "description = $5, "
                "required_count = $6, "
                "duration_days = $7, "
                "updated_at = $8 "
                "WHERE requirement_id = $9";
            
            params = {
                {
                    "requirement_name",
                    requirement.requirement_name,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "regulation_id",
                    requirement.regulation_id,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "regulation_name",
                    requirement.regulation_name,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "regulation_reference",
                    requirement.regulation_reference,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "description",
                    requirement.description,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "required_count",
                    std::to_string(requirement.required_count),
                    persistence::PgParamType::INTEGER,
                    false
                },
                {
                    "duration_days",
                    requirement.duration_days ? std::to_string(*requirement.duration_days) : "",
                    persistence::PgParamType::INTEGER,
                    !requirement.duration_days.has_value()
                },
                {
                    "updated_at",
                    std::to_string(std::chrono::duration_cast<std::chrono::seconds>(
                        std::chrono::system_clock::now().time_since_epoch()
                    ).count()),
                    persistence::PgParamType::TIMESTAMP,
                    false
                },
                {
                    "requirement_id",
                    requirement.requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                }
            };
        } else {
            // Insert new requirement
            query = 
                "INSERT INTO etr.compliance_requirements ("
                "requirement_id, requirement_name, regulation_id, regulation_name, "
                "regulation_reference, description, required_count, duration_days, "
                "created_at, updated_at) "
                "VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $9)";
            
            params = {
                {
                    "requirement_id",
                    requirement.requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "requirement_name",
                    requirement.requirement_name,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "regulation_id",
                    requirement.regulation_id,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "regulation_name",
                    requirement.regulation_name,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "regulation_reference",
                    requirement.regulation_reference,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "description",
                    requirement.description,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "required_count",
                    std::to_string(requirement.required_count),
                    persistence::PgParamType::INTEGER,
                    false
                },
                {
                    "duration_days",
                    requirement.duration_days ? std::to_string(*requirement.duration_days) : "",
                    persistence::PgParamType::INTEGER,
                    !requirement.duration_days.has_value()
                },
                {
                    "created_at",
                    std::to_string(std::chrono::duration_cast<std::chrono::seconds>(
                        std::chrono::system_clock::now().time_since_epoch()
                    ).count()),
                    persistence::PgParamType::TIMESTAMP,
                    false
                }
            };
        }
        
        // Execute query
        auto result = db_connection_->executeQuery(query, params);
        
        // Handle equivalent requirements
        if (exists) {
            // Delete existing equivalent requirements
            std::string delete_eq_query = 
                "DELETE FROM etr.equivalent_requirements WHERE source_requirement_id = $1";
            
            db_connection_->executeQuery(
                delete_eq_query,
                {
                    {
                        "requirement_id",
                        requirement.requirement_id,
                        persistence::PgParamType::TEXT,
                        false
                    }
                }
            );
        }
        
        // Add equivalent requirements
        for (const auto& eq_req : requirement.equivalent_requirements) {
            std::string eq_query = 
                "INSERT INTO etr.equivalent_requirements (source_requirement_id, target_requirement_id) "
                "VALUES ($1, $2)";
            
            db_connection_->executeQuery(
                eq_query,
                {
                    {
                        "source_requirement_id",
                        requirement.requirement_id,
                        persistence::PgParamType::TEXT,
                        false
                    },
                    {
                        "target_requirement_id",
                        eq_req,
                        persistence::PgParamType::TEXT,
                        false
                    }
                }
            );
        }
        
        // Commit transaction
        transaction.commit();
        
        logging::Logger::getInstance().info(
            "Added/updated compliance requirement: {}",
            requirement.requirement_id
        );
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error adding/updating compliance requirement: {}",
            e.what()
        );
        return false;
    }
}

bool ComplianceRepository::deleteRequirement(const std::string& requirement_id) {
    try {
        // Start transaction
        auto transaction = db_connection_->createTransaction();
        
        // Delete equivalent requirements
        std::string delete_eq_query = 
            "DELETE FROM etr.equivalent_requirements WHERE source_requirement_id = $1 OR target_requirement_id = $1";
        
        db_connection_->executeQuery(
            delete_eq_query,
            {
                {
                    "requirement_id",
                    requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                }
            }
        );
        
        // Delete regulation mappings
        std::string delete_map_query = 
            "DELETE FROM etr.regulation_mappings WHERE source_requirement_id = $1 OR target_requirement_id = $1";
        
        db_connection_->executeQuery(
            delete_map_query,
            {
                {
                    "requirement_id",
                    requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                }
            }
        );
        
        // Delete requirement
        std::string delete_query = 
            "DELETE FROM etr.compliance_requirements WHERE requirement_id = $1";
        
        auto result = db_connection_->executeQuery(
            delete_query,
            {
                {
                    "requirement_id",
                    requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                }
            }
        );
        
        // Commit transaction
        transaction.commit();
        
        logging::Logger::getInstance().info(
            "Deleted compliance requirement: {}",
            requirement_id
        );
        
        return result.getAffectedRows() > 0;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error deleting compliance requirement: {}",
            e.what()
        );
        return false;
    }
}

std::optional<ComplianceRequirement> ComplianceRepository::getRequirement(const std::string& requirement_id) {
    try {
        // Query for requirement
        std::string query = 
            "SELECT requirement_id, requirement_name, regulation_id, regulation_name, "
            "regulation_reference, description, required_count, duration_days "
            "FROM etr.compliance_requirements WHERE requirement_id = $1";
        
        auto result = db_connection_->executeQuery(
            query,
            {
                {
                    "requirement_id",
                    requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                }
            }
        );
        
        if (result.getNumRows() == 0) {
            return std::nullopt;
        }
        
        // Create requirement object
        ComplianceRequirement requirement;
        requirement.requirement_id = result.getString(0, "requirement_id");
        requirement.requirement_name = result.getString(0, "requirement_name");
        requirement.regulation_id = result.getString(0, "regulation_id");
        requirement.regulation_name = result.getString(0, "regulation_name");
        requirement.regulation_reference = result.getString(0, "regulation_reference");
        requirement.description = result.getString(0, "description");
        requirement.required_count = result.getInt(0, "required_count");
        
        if (!result.isNull(0, "duration_days")) {
            requirement.duration_days = result.getInt(0, "duration_days");
        }
        
        // Query for equivalent requirements
        std::string eq_query = 
            "SELECT target_requirement_id FROM etr.equivalent_requirements WHERE source_requirement_id = $1";
        
        auto eq_result = db_connection_->executeQuery(
            eq_query,
            {
                {
                    "requirement_id",
                    requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                }
            }
        );
        
        for (int i = 0; i < eq_result.getNumRows(); i++) {
            requirement.equivalent_requirements.push_back(
                eq_result.getString(i, "target_requirement_id")
            );
        }
        
        logging::Logger::getInstance().debug(
            "Retrieved compliance requirement: {}",
            requirement_id
        );
        
        return requirement;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error getting compliance requirement: {}",
            e.what()
        );
        return std::nullopt;
    }
}

std::vector<ComplianceRequirement> ComplianceRepository::listRequirements(
    const std::optional<std::string>& regulation_id,
    const std::optional<std::string>& certification_type
) {
    try {
        std::vector<ComplianceRequirement> requirements;
        
        // Construct query based on filters
        std::string query = 
            "SELECT requirement_id, requirement_name, regulation_id, regulation_name, "
            "regulation_reference, description, required_count, duration_days "
            "FROM etr.compliance_requirements";
        
        std::vector<persistence::PgParam> params;
        std::vector<std::string> conditions;
        
        if (regulation_id) {
            conditions.push_back("regulation_id = $" + std::to_string(params.size() + 1));
            params.push_back({
                "regulation_id",
                *regulation_id,
                persistence::PgParamType::TEXT,
                false
            });
        }
        
        // Apply certification type filter through metadata
        if (certification_type) {
            // In a real implementation, this would join with a metadata table
            // For simplicity, we'll just log that this filter was requested
            logging::Logger::getInstance().info(
                "Certification type filter not implemented in this version"
            );
        }
        
        // Add WHERE clause if there are conditions
        if (!conditions.empty()) {
            query += " WHERE " + conditions[0];
            for (size_t i = 1; i < conditions.size(); i++) {
                query += " AND " + conditions[i];
            }
        }
        
        // Execute query
        auto result = db_connection_->executeQuery(query, params);
        
        // Process results
        for (int i = 0; i < result.getNumRows(); i++) {
            ComplianceRequirement requirement;
            requirement.requirement_id = result.getString(i, "requirement_id");
            requirement.requirement_name = result.getString(i, "requirement_name");
            requirement.regulation_id = result.getString(i, "regulation_id");
            requirement.regulation_name = result.getString(i, "regulation_name");
            requirement.regulation_reference = result.getString(i, "regulation_reference");
            requirement.description = result.getString(i, "description");
            requirement.required_count = result.getInt(i, "required_count");
            
            if (!result.isNull(i, "duration_days")) {
                requirement.duration_days = result.getInt(i, "duration_days");
            }
            
            // Get equivalent requirements
            std::string eq_query = 
                "SELECT target_requirement_id FROM etr.equivalent_requirements WHERE source_requirement_id = $1";
            
            auto eq_result = db_connection_->executeQuery(
                eq_query,
                {
                    {
                        "requirement_id",
                        requirement.requirement_id,
                        persistence::PgParamType::TEXT,
                        false
                    }
                }
            );
            
            for (int j = 0; j < eq_result.getNumRows(); j++) {
                requirement.equivalent_requirements.push_back(
                    eq_result.getString(j, "target_requirement_id")
                );
            }
            
            requirements.push_back(requirement);
        }
        
        logging::Logger::getInstance().debug(
            "Listed {} compliance requirements",
            requirements.size()
        );
        
        return requirements;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error listing compliance requirements: {}",
            e.what()
        );
        return {};
    }
}

bool ComplianceRepository::addOrUpdateMapping(const RegulationMapping& mapping) {
    try {
        // Start transaction
        auto transaction = db_connection_->createTransaction();
        
        // Check if mapping exists
        std::string check_query = 
            "SELECT source_requirement_id FROM etr.regulation_mappings "
            "WHERE source_requirement_id = $1 AND target_requirement_id = $2";
        
        auto check_result = db_connection_->executeQuery(
            check_query,
            {
                {
                    "source_requirement_id",
                    mapping.source_requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "target_requirement_id",
                    mapping.target_requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                }
            }
        );
        
        bool exists = check_result.getNumRows() > 0;
        
        std::string query;
        
        if (exists) {
            // Update existing mapping
            query = 
                "UPDATE etr.regulation_mappings SET "
                "equivalence_factor = $1, "
                "notes = $2 "
                "WHERE source_requirement_id = $3 AND target_requirement_id = $4";
        } else {
            // Insert new mapping
            query = 
                "INSERT INTO etr.regulation_mappings ("
                "source_requirement_id, source_requirement_name, "
                "target_requirement_id, target_requirement_name, "
                "equivalence_factor, notes) "
                "VALUES ($3, $5, $4, $6, $1, $2)";
        }
        
        auto result = db_connection_->executeQuery(
            query,
            {
                {
                    "equivalence_factor",
                    std::to_string(mapping.equivalence_factor),
                    persistence::PgParamType::DOUBLE,
                    false
                },
                {
                    "notes",
                    mapping.notes,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "source_requirement_id",
                    mapping.source_requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "target_requirement_id",
                    mapping.target_requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "source_requirement_name",
                    mapping.source_requirement_name,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "target_requirement_name",
                    mapping.target_requirement_name,
                    persistence::PgParamType::TEXT,
                    false
                }
            }
        );
        
        // Commit transaction
        transaction.commit();
        
        logging::Logger::getInstance().info(
            "Added/updated regulation mapping: {} -> {}",
            mapping.source_requirement_id,
            mapping.target_requirement_id
        );
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error adding/updating regulation mapping: {}",
            e.what()
        );
        return false;
    }
}

bool ComplianceRepository::deleteMapping(
    const std::string& source_requirement_id,
    const std::string& target_requirement_id
) {
    try {
        // Delete mapping
        std::string query = 
            "DELETE FROM etr.regulation_mappings "
            "WHERE source_requirement_id = $1 AND target_requirement_id = $2";
        
        auto result = db_connection_->executeQuery(
            query,
            {
                {
                    "source_requirement_id",
                    source_requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                },
                {
                    "target_requirement_id",
                    target_requirement_id,
                    persistence::PgParamType::TEXT,
                    false
                }
            }
        );
        
        logging::Logger::getInstance().info(
            "Deleted regulation mapping: {} -> {}",
            source_requirement_id,
            target_requirement_id
        );
        
        return result.getAffectedRows() > 0;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error deleting regulation mapping: {}",
            e.what()
        );
        return false;
    }
}

std::vector<RegulationMapping> ComplianceRepository::getMappings(
    const std::optional<std::string>& source_regulation_id,
    const std::optional<std::string>& target_regulation_id
) {
    try {
        std::vector<RegulationMapping> mappings;
        
        // Construct query based on filters
        std::string query = 
            "SELECT rm.source_requirement_id, rm.source_requirement_name, "
            "rm.target_requirement_id, rm.target_requirement_name, "
            "rm.equivalence_factor, rm.notes, "
            "cr1.regulation_id AS source_regulation_id, "
            "cr2.regulation_id AS target_regulation_id "
            "FROM etr.regulation_mappings rm "
            "JOIN etr.compliance_requirements cr1 ON rm.source_requirement_id = cr1.requirement_id "
            "JOIN etr.compliance_requirements cr2 ON rm.target_requirement_id = cr2.requirement_id";
        
        std::vector<persistence::PgParam> params;
        std::vector<std::string> conditions;
        
        if (source_regulation_id) {
            conditions.push_back("cr1.regulation_id = $" + std::to_string(params.size() + 1));
            params.push_back({
                "source_regulation_id",
                *source_regulation_id,
                persistence::PgParamType::TEXT,
                false
            });
        }
        
        if (target_regulation_id) {
            conditions.push_back("cr2.regulation_id = $" + std::to_string(params.size() + 1));
            params.push_back({
                "target_regulation_id",
                *target_regulation_id,
                persistence::PgParamType::TEXT,
                false
            });
        }
        
        // Add WHERE clause if there are conditions
        if (!conditions.empty()) {
            query += " WHERE " + conditions[0];
            for (size_t i = 1; i < conditions.size(); i++) {
                query += " AND " + conditions[i];
            }
        }
        
        // Execute query
        auto result = db_connection_->executeQuery(query, params);
        
        // Process results
        for (int i = 0; i < result.getNumRows(); i++) {
            RegulationMapping mapping;
            mapping.source_requirement_id = result.getString(i, "source_requirement_id");
            mapping.source_requirement_name = result.getString(i, "source_requirement_name");
            mapping.target_requirement_id = result.getString(i, "target_requirement_id");
            mapping.target_requirement_name = result.getString(i, "target_requirement_name");
            mapping.equivalence_factor = result.getDouble(i, "equivalence_factor");
            mapping.notes = result.getString(i, "notes");
            
            mappings.push_back(mapping);
        }
        
        logging::Logger::getInstance().debug(
            "Listed {} regulation mappings",
            mappings.size()
        );
        
        return mappings;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error getting regulation mappings: {}",
            e.what()
        );
        return {};
    }
}

} // namespace compliance
} // namespace etr
#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include <memory>
#include <chrono>

#include "compliance/compliance_service.h"
#include "records/record_model.h"

using namespace etr::compliance;
using namespace etr::records;
using namespace testing;

// Mock compliance repository
class MockComplianceRepository : public IComplianceRepository {
public:
    MOCK_METHOD(bool, addOrUpdateRequirement, (const ComplianceRequirement&), (override));
    MOCK_METHOD(bool, deleteRequirement, (const std::string&), (override));
    MOCK_METHOD(std::optional<ComplianceRequirement>, getRequirement, (const std::string&), (override));
    MOCK_METHOD(std::vector<ComplianceRequirement>, listRequirements, 
        (const std::optional<std::string>&, const std::optional<std::string>&), (override));
    MOCK_METHOD(bool, addOrUpdateMapping, (const RegulationMapping&), (override));
    MOCK_METHOD(bool, deleteMapping, (const std::string&, const std::string&), (override));
    MOCK_METHOD(std::vector<RegulationMapping>, getMappings, 
        (const std::optional<std::string>&, const std::optional<std::string>&), (override));
};

// Mock record repository
class MockRecordRepository : public IRecordRepository {
public:
    MOCK_METHOD(std::string, createRecord, (const TrainingRecord&), (override));
    MOCK_METHOD(std::optional<TrainingRecord>, getRecord, (const std::string&), (override));
    MOCK_METHOD(bool, updateRecord, (const TrainingRecord&), (override));
    MOCK_METHOD(bool, deleteRecord, (const std::string&), (override));
    MOCK_METHOD((std::pair<std::vector<TrainingRecord>, int>), listRecords, 
        (const std::optional<std::string>&, 
         const std::optional<std::string>&, 
         const std::optional<std::string>&, 
         const std::optional<std::string>&, 
         const std::optional<RecordType>&,
         const std::optional<std::chrono::system_clock::time_point>&,
         const std::optional<std::chrono::system_clock::time_point>&,
         int, int, const std::string&, bool), (override));
    MOCK_METHOD(bool, logAuditEvent, 
        (const std::string&, const std::string&, const std::string&, const std::string&), (override));
    MOCK_METHOD(std::vector<nlohmann::json>, getAuditLogs, (const std::string&), (override));
};

class ComplianceServiceTest : public Test {
protected:
    void SetUp() override {
        // Create mock repositories
        mock_compliance_repository_ = std::make_shared<MockComplianceRepository>();
        mock_record_repository_ = std::make_shared<MockRecordRepository>();
        
        // Create service with mock repositories
        compliance_service_ = std::make_unique<ComplianceService>(
            mock_compliance_repository_,
            mock_record_repository_
        );
        
        // Setup test data
        setupTestRequirements();
        setupTestRecords();
    }
    
    void setupTestRequirements() {
        // Create test requirements
        faa_ifr_requirement_.requirement_id = "FAA-61.57-c-1";
        faa_ifr_requirement_.requirement_name = "IFR Currency";
        faa_ifr_requirement_.regulation_id = "FAA-61";
        faa_ifr_requirement_.regulation_name = "FAA Part 61";
        faa_ifr_requirement_.regulation_reference = "61.57(c)(1)";
        faa_ifr_requirement_.description = "Six instrument approaches, holding procedures, and intercepting/tracking courses";
        faa_ifr_requirement_.required_count = 6;
        faa_ifr_requirement_.duration_days = 180; // 6 months
        
        easa_type_rating_requirement_.requirement_id = "EASA-FCL.740.A-a";
        easa_type_rating_requirement_.requirement_name = "Type Rating Revalidation";
        easa_type_rating_requirement_.regulation_id = "EASA-FCL";
        easa_type_rating_requirement_.regulation_name = "EASA Part-FCL";
        easa_type_rating_requirement_.regulation_reference = "FCL.740.A(a)";
        easa_type_rating_requirement_.description = "At least 10 route sectors as pilot or proficiency check within validity period";
        easa_type_rating_requirement_.required_count = 10;
        easa_type_rating_requirement_.duration_days = 365; // 12 months
    }
    
    void setupTestRecords() {
        // Create test records
        for (int i = 0; i < 10; i++) {
            TrainingRecord record("record-" + std::to_string(i));
            record.setTraineeId("test-trainee");
            record.setInstructorId("test-instructor");
            record.setRecordType(RecordType::TRAINING_SESSION);
            record.setCourseId("test-course");
            record.setSyllabusId("test-syllabus");
            record.setExerciseId("test-exercise-" + std::to_string(i));
            
            // Set date - some recent, some older
            auto now = std::chrono::system_clock::now();
            if (i < 5) {
                // Recent records (within last 3 months)
                record.setDate(now - std::chrono::hours(24 * 30 * (i + 1)));
            } else {
                // Older records (more than 6 months ago)
                record.setDate(now - std::chrono::hours(24 * 30 * (i + 6)));
            }
            
            record.setDurationMinutes(60);
            record.setLocation("Test Location");
            
            // Add grades
            GradeItem grade;
            grade.criteria_id = "test-criteria";
            grade.criteria_name = "Test Criteria";
            grade.grade = (i % 4) + 1; // Grades 1-4
            grade.comments = "Performance comment";
            record.addGrade(grade);
            
            record.setComments("Test record " + std::to_string(i));
            record.setDraft(false);
            
            // Add signatures to make records "complete"
            SignatureInfo trainee_sig;
            trainee_sig.signer_id = "test-trainee";
            trainee_sig.signer_name = "Test Trainee";
            trainee_sig.certificate_id = "test-cert";
            trainee_sig.timestamp = record.getDate() + std::chrono::hours(1);
            trainee_sig.is_valid = true;
            record.setTraineeSignature(trainee_sig);
            
            SignatureInfo instructor_sig;
            instructor_sig.signer_id = "test-instructor";
            instructor_sig.signer_name = "Test Instructor";
            instructor_sig.certificate_id = "test-cert";
            instructor_sig.timestamp = record.getDate() + std::chrono::hours(2);
            instructor_sig.is_valid = true;
            record.setInstructorSignature(instructor_sig);
            
            test_records_.push_back(record);
        }
    }
    
    std::shared_ptr<MockComplianceRepository> mock_compliance_repository_;
    std::shared_ptr<MockRecordRepository> mock_record_repository_;
    std::unique_ptr<ComplianceService> compliance_service_;
    
    ComplianceRequirement faa_ifr_requirement_;
    ComplianceRequirement easa_type_rating_requirement_;
    std::vector<TrainingRecord> test_records_;
};

TEST_F(ComplianceServiceTest, ListRequirements) {
    // Setup expectations
    std::vector<ComplianceRequirement> requirements = {
        faa_ifr_requirement_,
        easa_type_rating_requirement_
    };
    
    EXPECT_CALL(*mock_compliance_repository_, listRequirements(std::optional<std::string>("FAA-61"), std::nullopt))
        .WillOnce(Return(std::vector<ComplianceRequirement>{faa_ifr_requirement_}));
    
    // Call service method
    auto result = compliance_service_->listRequirements("FAA-61", std::nullopt);
    
    // Verify result
    ASSERT_EQ(result.size(), 1);
    EXPECT_EQ(result[0].requirement_id, faa_ifr_requirement_.requirement_id);
}

TEST_F(ComplianceServiceTest, MapRegulations) {
    // Setup expectations
    RegulationMapping mapping;
    mapping.source_requirement_id = faa_ifr_requirement_.requirement_id;
    mapping.source_requirement_name = faa_ifr_requirement_.requirement_name;
    mapping.target_requirement_id = easa_type_rating_requirement_.requirement_id;
    mapping.target_requirement_name = easa_type_rating_requirement_.requirement_name;
    mapping.equivalence_factor = 0.75;
    mapping.notes = "Partial equivalence";
    
    std::vector<RegulationMapping> mappings = {mapping};
    
    EXPECT_CALL(*mock_compliance_repository_, getMappings(
        std::optional<std::string>("FAA-61"), 
        std::optional<std::string>("EASA-FCL")
    )).WillOnce(Return(mappings));
    
    // Call service method
    auto result = compliance_service_->mapRegulations("FAA-61", "EASA-FCL");
    
    // Verify result
    ASSERT_EQ(result.size(), 1);
    EXPECT_EQ(result[0].source_requirement_id, mapping.source_requirement_id);
    EXPECT_EQ(result[0].target_requirement_id, mapping.target_requirement_id);
    EXPECT_FLOAT_EQ(result[0].equivalence_factor, mapping.equivalence_factor);
}

TEST_F(ComplianceServiceTest, CheckCompliance_Compliant) {
    // Setup expectations
    EXPECT_CALL(*mock_compliance_repository_, listRequirements(
        std::optional<std::string>("FAA-61"), 
        std::optional<std::string>("CPL")
    )).WillOnce(Return(std::vector<ComplianceRequirement>{faa_ifr_requirement_}));
    
    // Only 5 recent records should be enough to satisfy requirement of 3
    faa_ifr_requirement_.required_count = 3;
    
    EXPECT_CALL(*mock_record_repository_, listRecords(
        std::optional<std::string>("test-trainee"), 
        std::nullopt, std::nullopt, std::nullopt, std::nullopt, 
        std::nullopt, std::nullopt, 1, 1000, "date", false
    )).WillOnce(Return(std::make_pair(test_records_, test_records_.size())));
    
    // Call service method
    auto result = compliance_service_->checkCompliance("test-trainee", "FAA-61", "CPL");
    
    // Verify result
    EXPECT_TRUE(result.is_compliant);
    ASSERT_EQ(result.compliance_items.size(), 1);
    EXPECT_EQ(result.compliance_items[0].requirement_id, faa_ifr_requirement_.requirement_id);
    EXPECT_TRUE(result.compliance_items[0].is_satisfied);
}

TEST_F(ComplianceServiceTest, CheckCompliance_NotCompliant) {
    // Setup expectations
    EXPECT_CALL(*mock_compliance_repository_, listRequirements(
        std::optional<std::string>("FAA-61"), 
        std::optional<std::string>("CPL")
    )).WillOnce(Return(std::vector<ComplianceRequirement>{faa_ifr_requirement_}));
    
    // Requirement of 8 is more than the 5 recent records
    faa_ifr_requirement_.required_count = 8;
    
    EXPECT_CALL(*mock_record_repository_, listRecords(
        std::optional<std::string>("test-trainee"), 
        std::nullopt, std::nullopt, std::nullopt, std::nullopt, 
        std::nullopt, std::nullopt, 1, 1000, "date", false
    )).WillOnce(Return(std::make_pair(test_records_, test_records_.size())));
    
    // Call service method
    auto result = compliance_service_->checkCompliance("test-trainee", "FAA-61", "CPL");
    
    // Verify result
    EXPECT_FALSE(result.is_compliant);
    ASSERT_EQ(result.compliance_items.size(), 1);
    EXPECT_EQ(result.compliance_items[0].requirement_id, faa_ifr_requirement_.requirement_id);
    EXPECT_FALSE(result.compliance_items[0].is_satisfied);
}

TEST_F(ComplianceServiceTest, ImportFAARegulations) {
    // Mock file content
    std::string json_content = R"([
        {
            "id": "FAA-61.57-c-1",
            "name": "IFR Currency",
            "regulation_id": "FAA-61",
            "regulation_name": "FAA Part 61",
            "reference": "61.57(c)(1)",
            "description": "Six instrument approaches, holding procedures, and intercepting/tracking courses",
            "required_count": 6,
            "duration_days": 180
        }
    ])";
    
    // Override file opening
    // In a real test, you would use a framework that allows mocking file operations
    // or use dependency injection to replace the file operations
    
    // For this test, we can verify the repository is called correctly
    EXPECT_CALL(*mock_compliance_repository_, addOrUpdateRequirement(
        AllOf(
            Field(&ComplianceRequirement::requirement_id, "FAA-61.57-c-1"),
            Field(&ComplianceRequirement::requirement_name, "IFR Currency"),
            Field(&ComplianceRequirement::required_count, 6)
        )
    )).WillOnce(Return(true));
    
    // This test will not actually call importFAARegulations since it depends on file reading
    // In a real test, you would need to inject the file content or mock the file operations
    
    // For demonstration, assume the method has been called and validate the repository calls
    SUCCEED();
}

int main(int argc, char** argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
{
    "server": {
        "host": "0.0.0.0",
        "port": 50053,
        "max_message_size_mb": 100,
        "max_concurrent_requests": 100,
        "keep_alive_ms": 20000
    },
    "database": {
        "host": "postgres",
        "port": 5432,
        "name": "training_platform",
        "user": "postgres",
        "password": "postgres",
        "pool_size": 10,
        "connection_timeout_ms": 5000,
        "idle_timeout_ms": 30000,
        "max_lifetime_ms": 300000
    },
    "security": {
        "tls_enabled": false,
        "cert_path": "/app/certs/server.crt",
        "key_path": "/app/certs/server.key",
        "ca_certificate_path": "/app/certs/ca.crt",
        "crl_path": "/app/certs/crl.pem",
        "jwt_secret": "change_me_in_production",
        "token_expiry_seconds": 3600,
        "refresh_expiry_seconds": 86400
    },
    "logging": {
        "level": "info",
        "file_path": "/app/logs/etr-service.log",
        "max_file_size_mb": 10,
        "max_files": 5,
        "console_logging": true
    },
    "metrics": {
        "enabled": true,
        "host": "0.0.0.0",
        "port": 9103,
        "push_gateway": false,
        "push_address": "prometheus-pushgateway",
        "push_port": 9091,
        "push_interval_seconds": 15
    },
    "records": {
        "storage_path": "/app/data/records",
        "attachment_path": "/app/data/attachments",
        "max_attachment_size_mb": 50,
        "allowed_attachment_types": [
            "application/pdf",
            "image/jpeg",
            "image/png",
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        ]
    },
    "syllabus": {
        "storage_path": "/app/data/syllabi",
        "version_control": true,
        "approval_required": true,
        "auto_increment_version": true
    },
    "compliance": {
        "regulations_path": "/app/data/regulations",
        "auto_update": true,
        "faa_regulations_url": "https://www.faa.gov/regulations_policies/current",
        "easa_regulations_url": "https://www.easa.europa.eu/en/regulations"
    },
    "services": {
        "core_platform_service": {
            "host": "core-platform-service",
            "port": 50051
        },
        "data_acquisition_service": {
            "host": "data-acquisition-service",
            "port": 50052
        }
    },
    "cors": {
        "allowed_origins": ["*"],
        "allowed_methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "allowed_headers": ["Content-Type", "Authorization"],
        "allow_credentials": false,
        "max_age_seconds": 86400
    },
    "performance": {
        "cache_enabled": true,
        "cache_size": 1000,
        "cache_ttl_seconds": 300,
        "batch_size": 100,
        "thread_pool_size": 4
    }
}
#pragma once

#include <string>
#include <memory>
#include <mutex>
#include <vector>
#include <unordered_map>
#include <optional>
#include <libpq-fe.h>
#include <nlohmann/json.hpp>
#include "logging/logger.h"

namespace etr {
namespace persistence {

/**
 * @brief PostgreSQL parameter type
 */
enum class PgParamType {
    TEXT,
    INTEGER,
    BIGINT,
    BOOLEAN,
    TIMESTAMP,
    DOUBLE,
    BYTEA,
    JSONB
};

/**
 * @brief PostgreSQL parameter
 */
struct PgParam {
    std::string name;
    std::string value;
    PgParamType type;
    bool is_null;
};

/**
 * @brief PostgreSQL query result
 */
class PgResult {
public:
    /**
     * @brief Constructor
     * @param result PGresult pointer
     */
    explicit PgResult(PGresult* result);
    
    /**
     * @brief Destructor
     */
    ~PgResult();
    
    /**
     * @brief Move constructor
     * @param other Other result
     */
    PgResult(PgResult&& other) noexcept;
    
    /**
     * @brief Move assignment
     * @param other Other result
     * @return This result
     */
    PgResult& operator=(PgResult&& other) noexcept;
    
    // Delete copy constructor and assignment
    PgResult(const PgResult&) = delete;
    PgResult& operator=(const PgResult&) = delete;
    
    /**
     * @brief Get number of rows
     * @return Number of rows
     */
    int getNumRows() const;
    
    /**
     * @brief Get number of columns
     * @return Number of columns
     */
    int getNumColumns() const;
    
    /**
     * @brief Get column name
     * @param column_index Column index
     * @return Column name
     */
    std::string getColumnName(int column_index) const;
    
    /**
     * @brief Get column index
     * @param column_name Column name
     * @return Column index or -1 if not found
     */
    int getColumnIndex(const std::string& column_name) const;
    
    /**
     * @brief Get value as string
     * @param row_index Row index
     * @param column_index Column index
     * @return Value or empty string if null or out of bounds
     */
    std::string getString(int row_index, int column_index) const;
    
    /**
     * @brief Get value as string by column name
     * @param row_index Row index
     * @param column_name Column name
     * @return Value or empty string if null or not found
     */
    std::string getString(int row_index, const std::string& column_name) const;
    
    /**
     * @brief Get value as integer
     * @param row_index Row index
     * @param column_index Column index
     * @param default_value Default value if null or invalid
     * @return Value
     */
    int getInt(int row_index, int column_index, int default_value = 0) const;
    
    /**
     * @brief Get value as integer by column name
     * @param row_index Row index
     * @param column_name Column name
     * @param default_value Default value if null or invalid
     * @return Value
     */
    int getInt(int row_index, const std::string& column_name, int default_value = 0) const;
    
    /**
     * @brief Get value as 64-bit integer
     * @param row_index Row index
     * @param column_index Column index
     * @param default_value Default value if null or invalid
     * @return Value
     */
    int64_t getInt64(int row_index, int column_index, int64_t default_value = 0) const;
    
    /**
     * @brief Get value as 64-bit integer by column name
     * @param row_index Row index
     * @param column_name Column name
     * @param default_value Default value if null or invalid
     * @return Value
     */
    int64_t getInt64(int row_index, const std::string& column_name, int64_t default_value = 0) const;
    
    /**
     * @brief Get value as double
     * @param row_index Row index
     * @param column_index Column index
     * @param default_value Default value if null or invalid
     * @return Value
     */
    double getDouble(int row_index, int column_index, double default_value = 0.0) const;
    
    /**
     * @brief Get value as double by column name
     * @param row_index Row index
     * @param column_name Column name
     * @param default_value Default value if null or invalid
     * @return Value
     */
    double getDouble(int row_index, const std::string& column_name, double default_value = 0.0) const;
    
    /**
     * @brief Get value as boolean
     * @param row_index Row index
     * @param column_index Column index
     * @param default_value Default value if null or invalid
     * @return Value
     */
    bool getBool(int row_index, int column_index, bool default_value = false) const;
    
    /**
     * @brief Get value as boolean by column name
     * @param row_index Row index
     * @param column_name Column name
     * @param default_value Default value if null or invalid
     * @return Value
     */
    bool getBool(int row_index, const std::string& column_name, bool default_value = false) const;
    
    /**
     * @brief Get value as binary data
     * @param row_index Row index
     * @param column_index Column index
     * @return Binary data or empty vector if null or not found
     */
    std::vector<uint8_t> getBinary(int row_index, int column_index) const;
    
    /**
     * @brief Get value as binary data by column name
     * @param row_index Row index
     * @param column_name Column name
     * @return Binary data or empty vector if null or not found
     */
    std::vector<uint8_t> getBinary(int row_index, const std::string& column_name) const;
    
    /**
     * @brief Get value as JSON
     * @param row_index Row index
     * @param column_index Column index
     * @return JSON object or null if invalid
     */
    nlohmann::json getJson(int row_index, int column_index) const;
    
    /**
     * @brief Get value as JSON by column name
     * @param row_index Row index
     * @param column_name Column name
     * @return JSON object or null if invalid
     */
    nlohmann::json getJson(int row_index, const std::string& column_name) const;
    
    /**
     * @brief Get timestamp as time_point
     * @param row_index Row index
     * @param column_index Column index
     * @return Time point or nullopt if null or invalid
     */
    std::optional<std::chrono::system_clock::time_point> getTimestamp(int row_index, int column_index) const;
    
    /**
     * @brief Get timestamp as time_point by column name
     * @param row_index Row index
     * @param column_name Column name
     * @return Time point or nullopt if null or invalid
     */
    std::optional<std::chrono::system_clock::time_point> getTimestamp(int row_index, const std::string& column_name) const;
    
    /**
     * @brief Check if value is null
     * @param row_index Row index
     * @param column_index Column index
     * @return True if null
     */
    bool isNull(int row_index, int column_index) const;
    
    /**
     * @brief Check if value is null by column name
     * @param row_index Row index
     * @param column_name Column name
     * @return True if null
     */
    bool isNull(int row_index, const std::string& column_name) const;
    
    /**
     * @brief Convert row to JSON object
     * @param row_index Row index
     * @return JSON object
     */
    nlohmann::json getRowAsJson(int row_index) const;
    
    /**
     * @brief Convert all rows to JSON array
     * @return JSON array
     */
    nlohmann::json getAllRowsAsJson() const;
    
    /**
     * @brief Check if result is empty
     * @return True if empty
     */
    bool isEmpty() const;
    
    /**
     * @brief Check if result has error
     * @return True if error
     */
    bool hasError() const;
    
    /**
     * @brief Get error message
     * @return Error message
     */
    std::string getErrorMessage() const;
    
    /**
     * @brief Get affected row count
     * @return Affected row count
     */
    int getAffectedRows() const;
    
private:
    PGresult* result_;
    bool has_error_;
    std::string error_message_;
};

/**
 * @brief Database transaction
 */
class Transaction {
public:
    /**
     * @brief Constructor
     * @param conn Database connection
     */
    explicit Transaction(class DatabaseConnection& conn);
    
    /**
     * @brief Destructor - rolls back if not committed
     */
    ~Transaction();
    
    /**
     * @brief Commit transaction
     * @return True if committed successfully
     */
    bool commit();
    
    /**
     * @brief Rollback transaction
     * @return True if rolled back successfully
     */
    bool rollback();
    
    /**
     * @brief Check if transaction is active
     * @return True if active
     */
    bool isActive() const;
    
private:
    class DatabaseConnection& conn_;
    bool active_;
};

/**
 * @brief Database connection
 */
class DatabaseConnection {
public:
    /**
     * @brief Constructor
     * @param host Host
     * @param port Port
     * @param dbname Database name
     * @param user User
     * @param password Password
     */
    DatabaseConnection(
        const std::string& host,
        int port,
        const std::string& dbname,
        const std::string& user,
        const std::string& password
    );
    
    /**
     * @brief Destructor
     */
    ~DatabaseConnection();
    
    /**
     * @brief Connect to database
     * @return True if connected successfully
     */
    bool connect();
    
    /**
     * @brief Disconnect from database
     */
    void disconnect();
    
    /**
     * @brief Check if connected
     * @return True if connected
     */
    bool isConnected() const;
    
    /**
     * @brief Execute query with parameters
     * @param query Query string
     * @param params Parameters
     * @return Query result
     */
    PgResult executeQuery(
        const std::string& query,
        const std::vector<PgParam>& params = {}
    );
    
    /**
     * @brief Execute query and get first row as JSON
     * @param query Query string
     * @param params Parameters
     * @return JSON object or null if no rows
     */
    nlohmann::json queryFirstRowAsJson(
        const std::string& query,
        const std::vector<PgParam>& params = {}
    );
    
    /**
     * @brief Execute query and get all rows as JSON
     * @param query Query string
     * @param params Parameters
     * @return JSON array
     */
    nlohmann::json queryAllRowsAsJson(
        const std::string& query,
        const std::vector<PgParam>& params = {}
    );
    
    /**
     * @brief Begin transaction
     * @return True if transaction started successfully
     */
    bool beginTransaction();
    
    /**
     * @brief Commit transaction
     * @return True if committed successfully
     */
    bool commitTransaction();
    
    /**
     * @brief Rollback transaction
     * @return True if rolled back successfully
     */
    bool rollbackTransaction();
    
    /**
     * @brief Check if in transaction
     * @return True if in transaction
     */
    bool inTransaction() const;
    
    /**
     * @brief Create transaction object
     * @return Transaction
     */
    Transaction createTransaction();
    
    /**
     * @brief Escape string
     * @param str String to escape
     * @return Escaped string
     */
    std::string escapeString(const std::string& str) const;
    
    /**
     * @brief Escape identifier
     * @param identifier Identifier to escape
     * @return Escaped identifier
     */
    std::string escapeIdentifier(const std::string& identifier) const;
    
    /**
     * @brief Get last error message
     * @return Error message
     */
    std::string getLastError() const;
    
    /**
     * @brief Get connection info
     * @return Connection info
     */
    std::string getConnectionInfo() const;
    
private:
    friend class Transaction;
    
    std::string host_;
    int port_;
    std::string dbname_;
    std::string user_;
    std::string password_;
    PGconn* conn_;
    bool in_transaction_;
    mutable std::mutex mutex_;
};

} // namespace persistence
} // namespace etr
#include "persistence/database_connection.h"
#include "logging/logger.h"

#include <chrono>
#include <sstream>
#include <iomanip>

namespace etr {
namespace persistence {

// PgResult implementation

PgResult::PgResult(PGresult* result)
    : result_(result), has_error_(false), error_message_("") {
    
    // Check for errors
    if (result_) {
        ExecStatusType status = PQresultStatus(result_);
        if (status != PGRES_COMMAND_OK && status != PGRES_TUPLES_OK) {
            has_error_ = true;
            error_message_ = PQresultErrorMessage(result_);
        }
    } else {
        has_error_ = true;
        error_message_ = "Null PGresult";
    }
}

PgResult::~PgResult() {
    if (result_) {
        PQclear(result_);
        result_ = nullptr;
    }
}

PgResult::PgResult(PgResult&& other) noexcept
    : result_(other.result_), has_error_(other.has_error_), error_message_(std::move(other.error_message_)) {
    other.result_ = nullptr;
}

PgResult& PgResult::operator=(PgResult&& other) noexcept {
    if (this != &other) {
        if (result_) {
            PQclear(result_);
        }
        
        result_ = other.result_;
        has_error_ = other.has_error_;
        error_message_ = std::move(other.error_message_);
        
        other.result_ = nullptr;
    }
    
    return *this;
}

int PgResult::getNumRows() const {
    return result_ ? PQntuples(result_) : 0;
}

int PgResult::getNumColumns() const {
    return result_ ? PQnfields(result_) : 0;
}

std::string PgResult::getColumnName(int column_index) const {
    if (!result_ || column_index < 0 || column_index >= getNumColumns()) {
        return "";
    }
    
    return PQfname(result_, column_index);
}

int PgResult::getColumnIndex(const std::string& column_name) const {
    if (!result_) {
        return -1;
    }
    
    return PQfnumber(result_, column_name.c_str());
}

std::string PgResult::getString(int row_index, int column_index) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows() ||
        column_index < 0 || column_index >= getNumColumns() ||
        PQgetisnull(result_, row_index, column_index)) {
        return "";
    }
    
    return PQgetvalue(result_, row_index, column_index);
}

std::string PgResult::getString(int row_index, const std::string& column_name) const {
    return getString(row_index, getColumnIndex(column_name));
}

int PgResult::getInt(int row_index, int column_index, int default_value) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows() ||
        column_index < 0 || column_index >= getNumColumns() ||
        PQgetisnull(result_, row_index, column_index)) {
        return default_value;
    }
    
    try {
        return std::stoi(PQgetvalue(result_, row_index, column_index));
    } catch (const std::exception&) {
        return default_value;
    }
}

int PgResult::getInt(int row_index, const std::string& column_name, int default_value) const {
    return getInt(row_index, getColumnIndex(column_name), default_value);
}

int64_t PgResult::getInt64(int row_index, int column_index, int64_t default_value) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows() ||
        column_index < 0 || column_index >= getNumColumns() ||
        PQgetisnull(result_, row_index, column_index)) {
        return default_value;
    }
    
    try {
        return std::stoll(PQgetvalue(result_, row_index, column_index));
    } catch (const std::exception&) {
        return default_value;
    }
}

int64_t PgResult::getInt64(int row_index, const std::string& column_name, int64_t default_value) const {
    return getInt64(row_index, getColumnIndex(column_name), default_value);
}

double PgResult::getDouble(int row_index, int column_index, double default_value) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows() ||
        column_index < 0 || column_index >= getNumColumns() ||
        PQgetisnull(result_, row_index, column_index)) {
        return default_value;
    }
    
    try {
        return std::stod(PQgetvalue(result_, row_index, column_index));
    } catch (const std::exception&) {
        return default_value;
    }
}

double PgResult::getDouble(int row_index, const std::string& column_name, double default_value) const {
    return getDouble(row_index, getColumnIndex(column_name), default_value);
}

bool PgResult::getBool(int row_index, int column_index, bool default_value) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows() ||
        column_index < 0 || column_index >= getNumColumns() ||
        PQgetisnull(result_, row_index, column_index)) {
        return default_value;
    }
    
    std::string value = PQgetvalue(result_, row_index, column_index);
    return (value == "t" || value == "true" || value == "1");
}

bool PgResult::getBool(int row_index, const std::string& column_name, bool default_value) const {
    return getBool(row_index, getColumnIndex(column_name), default_value);
}

std::vector<uint8_t> PgResult::getBinary(int row_index, int column_index) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows() ||
        column_index < 0 || column_index >= getNumColumns() ||
        PQgetisnull(result_, row_index, column_index)) {
        return {};
    }
    
    // Get binary data
    size_t size = PQgetlength(result_, row_index, column_index);
    const char* data = PQgetvalue(result_, row_index, column_index);
    
    // Convert from hex format (bytea)
    size_t out_size;
    unsigned char* binary_data = PQunescapeBytea(reinterpret_cast<const unsigned char*>(data), &out_size);
    
    if (!binary_data) {
        return {};
    }
    
    // Copy to vector
    std::vector<uint8_t> result(binary_data, binary_data + out_size);
    
    // Free allocated memory
    PQfreemem(binary_data);
    
    return result;
}

std::vector<uint8_t> PgResult::getBinary(int row_index, const std::string& column_name) const {
    return getBinary(row_index, getColumnIndex(column_name));
}

nlohmann::json PgResult::getJson(int row_index, int column_index) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows() ||
        column_index < 0 || column_index >= getNumColumns() ||
        PQgetisnull(result_, row_index, column_index)) {
        return nlohmann::json::object();
    }
    
    try {
        return nlohmann::json::parse(PQgetvalue(result_, row_index, column_index));
    } catch (const std::exception&) {
        return nlohmann::json::object();
    }
}

nlohmann::json PgResult::getJson(int row_index, const std::string& column_name) const {
    return getJson(row_index, getColumnIndex(column_name));
}

std::optional<std::chrono::system_clock::time_point> PgResult::getTimestamp(
    int row_index, int column_index
) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows() ||
        column_index < 0 || column_index >= getNumColumns() ||
        PQgetisnull(result_, row_index, column_index)) {
        return std::nullopt;
    }
    
    std::string timestamp_str = PQgetvalue(result_, row_index, column_index);
    
    // Parse PostgreSQL timestamp (e.g., "2023-01-01 12:34:56")
    std::tm tm = {};
    std::istringstream ss(timestamp_str);
    ss >> std::get_time(&tm, "%Y-%m-%d %H:%M:%S");
    
    if (ss.fail()) {
        return std::nullopt;
    }
    
    // Convert to time_point
    std::time_t time = std::mktime(&tm);
    return std::chrono::system_clock::from_time_t(time);
}

std::optional<std::chrono::system_clock::time_point> PgResult::getTimestamp(
    int row_index, const std::string& column_name
) const {
    return getTimestamp(row_index, getColumnIndex(column_name));
}

bool PgResult::isNull(int row_index, int column_index) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows() ||
        column_index < 0 || column_index >= getNumColumns()) {
        return true;
    }
    
    return PQgetisnull(result_, row_index, column_index);
}

bool PgResult::isNull(int row_index, const std::string& column_name) const {
    return isNull(row_index, getColumnIndex(column_name));
}

nlohmann::json PgResult::getRowAsJson(int row_index) const {
    if (!result_ || row_index < 0 || row_index >= getNumRows()) {
        return nlohmann::json::object();
    }
    
    nlohmann::json row = nlohmann::json::object();
    
    for (int col = 0; col < getNumColumns(); ++col) {
        std::string column_name = getColumnName(col);
        
        if (isNull(row_index, col)) {
            row[column_name] = nullptr;
        } else {
            // Get OID (PostgreSQL data type)
            Oid type_oid = PQftype(result_, col);
            
            switch (type_oid) {
                case 16: // bool
                    row[column_name] = getBool(row_index, col);
                    break;
                case 20: // int8
                case 21: // int2
                case 23: // int4
                    row[column_name] = getInt64(row_index, col);
                    break;
                case 700: // float4
                case 701: // float8
                    row[column_name] = getDouble(row_index, col);
                    break;
                case 114: // json
                case 3802: // jsonb
                    row[column_name] = getJson(row_index, col);
                    break;
                case 17: // bytea
                    {
                        auto binary = getBinary(row_index, col);
                        std::stringstream ss;
                        ss << "\\x";
                        for (const auto& byte : binary) {
                            ss << std::hex << std::setw(2) << std::setfill('0') << static_cast<int>(byte);
                        }
                        row[column_name] = ss.str();
                    }
                    break;
                default: // text, varchar, etc.
                    row[column_name] = getString(row_index, col);
                    break;
            }
        }
    }
    
    return row;
}

nlohmann::json PgResult::getAllRowsAsJson() const {
    nlohmann::json rows = nlohmann::json::array();
    
    for (int row = 0; row < getNumRows(); ++row) {
        rows.push_back(getRowAsJson(row));
    }
    
    return rows;
}

bool PgResult::isEmpty() const {
    return getNumRows() == 0;
}

bool PgResult::hasError() const {
    return has_error_;
}

std::string PgResult::getErrorMessage() const {
    return error_message_;
}

int PgResult::getAffectedRows() const {
    if (!result_) {
        return 0;
    }
    
    const char* affected = PQcmdTuples(result_);
    if (!affected || *affected == '\0') {
        return 0;
    }
    
    try {
        return std::stoi(affected);
    } catch (const std::exception&) {
        return 0;
    }
}

// Transaction implementation

Transaction::Transaction(DatabaseConnection& conn)
    : conn_(conn), active_(false) {
    active_ = conn_.beginTransaction();
}

Transaction::~Transaction() {
    if (active_) {
        conn_.rollbackTransaction();
    }
}

bool Transaction::commit() {
    if (!active_) {
        return false;
    }
    
    active_ = false;
    return conn_.commitTransaction();
}

bool Transaction::rollback() {
    if (!active_) {
        return false;
    }
    
    active_ = false;
    return conn_.rollbackTransaction();
}

bool Transaction::isActive() const {
    return active_;
}

// DatabaseConnection implementation

DatabaseConnection::DatabaseConnection(
    const std::string& host,
    int port,
    const std::string& dbname,
    const std::string& user,
    const std::string& password
)
    : host_(host), port_(port), dbname_(dbname), user_(user), password_(password),
      conn_(nullptr), in_transaction_(false) {
}

DatabaseConnection::~DatabaseConnection() {
    disconnect();
}

bool DatabaseConnection::connect() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (conn_) {
        // Already connected
        return true;
    }
    
    // Build connection string
    std::string conninfo = "host=" + host_ +
                          " port=" + std::to_string(port_) +
                          " dbname=" + dbname_ +
                          " user=" + user_ +
                          " password=" + password_;
    
    // Connect to database
    conn_ = PQconnectdb(conninfo.c_str());
    
    if (PQstatus(conn_) != CONNECTION_OK) {
        std::string error = PQerrorMessage(conn_);
        PQfinish(conn_);
        conn_ = nullptr;
        
        logging::Logger::getInstance().error("Database connection failed: {}", error);
        return false;
    }
    
    logging::Logger::getInstance().info("Connected to database {}@{}:{}/{}",
        user_, host_, port_, dbname_);
    return true;
}

void DatabaseConnection::disconnect() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (conn_) {
        PQfinish(conn_);
        conn_ = nullptr;
        in_transaction_ = false;
        
        logging::Logger::getInstance().info("Disconnected from database");
    }
}

bool DatabaseConnection::isConnected() const {
    std::lock_guard<std::mutex> lock(mutex_);
    return conn_ && PQstatus(conn_) == CONNECTION_OK;
}

PgResult DatabaseConnection::executeQuery(
    const std::string& query,
    const std::vector<PgParam>& params
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (!conn_) {
        logging::Logger::getInstance().error("Cannot execute query: not connected to database");
        return PgResult(nullptr);
    }
    
    // Prepare parameters
    std::vector<const char*> param_values;
    std::vector<int> param_lengths;
    std::vector<int> param_formats;
    std::vector<std::string> string_values; // Keep strings alive
    std::vector<std::vector<uint8_t>> binary_values; // Keep binary data alive
    
    for (const auto& param : params) {
        if (param.is_null) {
            param_values.push_back(nullptr);
            param_lengths.push_back(0);
            param_formats.push_back(0);
        } else {
            switch (param.type) {
                case PgParamType::BYTEA:
                    {
                        // Convert from hex string to binary
                        if (param.value.substr(0, 2) == "\\x") {
                            std::string hex = param.value.substr(2);
                            std::vector<uint8_t> binary;
                            
                            for (size_t i = 0; i < hex.length(); i += 2) {
                                std::string byte_hex = hex.substr(i, 2);
                                uint8_t byte = std::stoi(byte_hex, nullptr, 16);
                                binary.push_back(byte);
                            }
                            
                            binary_values.push_back(binary);
                            param_values.push_back(reinterpret_cast<const char*>(binary_values.back().data()));
                            param_lengths.push_back(static_cast<int>(binary_values.back().size()));
                            param_formats.push_back(1); // Binary format
                        } else {
                            string_values.push_back(param.value);
                            param_values.push_back(string_values.back().c_str());
                            param_lengths.push_back(static_cast<int>(string_values.back().length()));
                            param_formats.push_back(0); // Text format
                        }
                    }
                    break;
                default:
                    string_values.push_back(param.value);
                    param_values.push_back(string_values.back().c_str());
                    param_lengths.push_back(static_cast<int>(string_values.back().length()));
                    param_formats.push_back(0); // Text format
                    break;
            }
        }
    }
    
    // Execute query
    PGresult* result = PQexecParams(
        conn_,
        query.c_str(),
        static_cast<int>(params.size()),
        nullptr, // Let server determine param types
        param_values.empty() ? nullptr : param_values.data(),
        param_lengths.empty() ? nullptr : param_lengths.data(),
        param_formats.empty() ? nullptr : param_formats.data(),
        0 // Result in text format
    );
    
    // Check result
    PgResult pg_result(result);
    
    if (pg_result.hasError()) {
        logging::Logger::getInstance().error("Query error: {}", pg_result.getErrorMessage());
    }
    
    return pg_result;
}

nlohmann::json DatabaseConnection::queryFirstRowAsJson(
    const std::string& query,
    const std::vector<PgParam>& params
) {
    PgResult result = executeQuery(query, params);
    
    if (result.hasError() || result.isEmpty()) {
        return nlohmann::json::object();
    }
    
    return result.getRowAsJson(0);
}

nlohmann::json DatabaseConnection::queryAllRowsAsJson(
    const std::string& query,
    const std::vector<PgParam>& params
) {
    PgResult result = executeQuery(query, params);
    
    if (result.hasError()) {
        return nlohmann::json::array();
    }
    
    return result.getAllRowsAsJson();
}

bool DatabaseConnection::beginTransaction() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (!conn_) {
        logging::Logger::getInstance().error("Cannot begin transaction: not connected to database");
        return false;
    }
    
    if (in_transaction_) {
        logging::Logger::getInstance().warn("Transaction already in progress");
        return true;
    }
    
    PGresult* result = PQexec(conn_, "BEGIN");
    bool success = (PQresultStatus(result) == PGRES_COMMAND_OK);
    PQclear(result);
    
    if (success) {
        in_transaction_ = true;
        logging::Logger::getInstance().debug("Transaction begun");
    } else {
        logging::Logger::getInstance().error("Failed to begin transaction: {}", PQerrorMessage(conn_));
    }
    
    return success;
}

bool DatabaseConnection::commitTransaction() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (!conn_) {
        logging::Logger::getInstance().error("Cannot commit transaction: not connected to database");
        return false;
    }
    
    if (!in_transaction_) {
        logging::Logger::getInstance().warn("No transaction in progress to commit");
        return false;
    }
    
    PGresult* result = PQexec(conn_, "COMMIT");
    bool success = (PQresultStatus(result) == PGRES_COMMAND_OK);
    PQclear(result);
    
    in_transaction_ = false;
    
    if (success) {
        logging::Logger::getInstance().debug("Transaction committed");
    } else {
        logging::Logger::getInstance().error("Failed to commit transaction: {}", PQerrorMessage(conn_));
    }
    
    return success;
}

bool DatabaseConnection::rollbackTransaction() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (!conn_) {
        logging::Logger::getInstance().error("Cannot rollback transaction: not connected to database");
        return false;
    }
    
    if (!in_transaction_) {
        logging::Logger::getInstance().warn("No transaction in progress to rollback");
        return false;
    }
    
    PGresult* result = PQexec(conn_, "ROLLBACK");
    bool success = (PQresultStatus(result) == PGRES_COMMAND_OK);
    PQclear(result);
    
    in_transaction_ = false;
    
    if (success) {
        logging::Logger::getInstance().debug("Transaction rolled back");
    } else {
        logging::Logger::getInstance().error("Failed to rollback transaction: {}", PQerrorMessage(conn_));
    }
    
    return success;
}

bool DatabaseConnection::inTransaction() const {
    std::lock_guard<std::mutex> lock(mutex_);
    return in_transaction_;
}

Transaction DatabaseConnection::createTransaction() {
    return Transaction(*this);
}

std::string DatabaseConnection::escapeString(const std::string& str) const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (!conn_) {
        return str;
    }
    
    // Allocate enough space for escaped string
    size_t buf_size = str.size() * 2 + 1;
    std::vector<char> buf(buf_size);
    
    // Escape string
    int error;
    size_t escaped_size = PQescapeStringConn(conn_, buf.data(), str.c_str(), str.size(), &error);
    
    if (error) {
        logging::Logger::getInstance().error("Error escaping string: {}", PQerrorMessage(conn_));
        return str;
    }
    
    return std::string(buf.data(), escaped_size);
}

std::string DatabaseConnection::escapeIdentifier(const std::string& identifier) const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (!conn_) {
        return "\"" + identifier + "\"";
    }
    
    // Escape identifier
    char* escaped = PQescapeIdentifier(conn_, identifier.c_str(), identifier.size());
    
    if (!escaped) {
        logging::Logger::getInstance().error("Error escaping identifier: {}", PQerrorMessage(conn_));
        return "\"" + identifier + "\"";
    }
    
    std::string result = escaped;
    PQfreemem(escaped);
    
    return result;
}

std::string DatabaseConnection::getLastError() const {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (!conn_) {
        return "Not connected to database";
    }
    
    return PQerrorMessage(conn_);
}

std::string DatabaseConnection::getConnectionInfo() const {
    return user_ + "@" + host_ + ":" + std::to_string(port_) + "/" + dbname_;
}

} // namespace persistence
} // namespace etr
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <chrono>
#include <openssl/evp.h>
#include <openssl/x509.h>
#include <openssl/pem.h>
#include "records/record_model.h"

namespace etr {
namespace signature {

/**
 * @brief Certificate information
 */
struct CertificateInfo {
    std::string certificate_id;
    std::string subject_name;
    std::string issuer_name;
    std::string serial_number;
    std::chrono::system_clock::time_point not_before;
    std::chrono::system_clock::time_point not_after;
    std::vector<uint8_t> raw_data;
    bool is_valid;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Certificate info or nullopt if invalid
     */
    static std::optional<CertificateInfo> fromJson(const nlohmann::json& json);
};

/**
 * @brief Digital signature service interface
 */
class IDigitalSignatureService {
public:
    virtual ~IDigitalSignatureService() = default;
    
    /**
     * @brief Sign a record
     * @param record Record to sign
     * @param signer_id Signer ID
     * @param certificate_data Certificate data in PEM format
     * @param signature_data Signature data
     * @param is_instructor Whether signer is instructor
     * @return Signature info or nullopt if signing failed
     */
    virtual std::optional<records::SignatureInfo> signRecord(
        records::TrainingRecord& record,
        const std::string& signer_id,
        const std::string& certificate_data,
        const std::vector<uint8_t>& signature_data,
        bool is_instructor
    ) = 0;
    
    /**
     * @brief Verify a record signature
     * @param record Record to verify
     * @param signer_id Signer ID
     * @return Pair of (is_valid, signature_info) or nullopt if signature not found
     */
    virtual std::optional<std::pair<bool, records::SignatureInfo>> verifySignature(
        const records::TrainingRecord& record,
        const std::string& signer_id
    ) = 0;
    
    /**
     * @brief Parse certificate
     * @param certificate_data Certificate data in PEM format
     * @return Certificate info or nullopt if parsing failed
     */
    virtual std::optional<CertificateInfo> parseCertificate(
        const std::string& certificate_data
    ) = 0;
    
    /**
     * @brief Validate certificate
     * @param certificate_data Certificate data in PEM format
     * @return True if certificate is valid
     */
    virtual bool validateCertificate(
        const std::string& certificate_data
    ) = 0;
    
    /**
     * @brief Extract user ID from certificate
     * @param certificate_data Certificate data in PEM format
     * @return User ID or empty string if extraction failed
     */
    virtual std::string extractUserIdFromCertificate(
        const std::string& certificate_data
    ) = 0;
    
    /**
     * @brief Generate digest for record
     * @param record Record to generate digest for
     * @return Digest or empty vector if generation failed
     */
    virtual std::vector<uint8_t> generateDigest(
        const records::TrainingRecord& record
    ) = 0;
};

/**
 * @brief X.509 digital signature service implementation
 */
class X509DigitalSignatureService : public IDigitalSignatureService {
public:
    /**
     * @brief Constructor
     * @param ca_certificate_path Path to CA certificate
     * @param crl_path Path to certificate revocation list
     */
    X509DigitalSignatureService(
        const std::string& ca_certificate_path = "",
        const std::string& crl_path = ""
    );
    
    /**
     * @brief Destructor
     */
    ~X509DigitalSignatureService() override;
    
    std::optional<records::SignatureInfo> signRecord(
        records::TrainingRecord& record,
        const std::string& signer_id,
        const std::string& certificate_data,
        const std::vector<uint8_t>& signature_data,
        bool is_instructor
    ) override;
    
    std::optional<std::pair<bool, records::SignatureInfo>> verifySignature(
        const records::TrainingRecord& record,
        const std::string& signer_id
    ) override;
    
    std::optional<CertificateInfo> parseCertificate(
        const std::string& certificate_data
    ) override;
    
    bool validateCertificate(
        const std::string& certificate_data
    ) override;
    
    std::string extractUserIdFromCertificate(
        const std::string& certificate_data
    ) override;
    
    std::vector<uint8_t> generateDigest(
        const records::TrainingRecord& record
    ) override;
    
private:
    /**
     * @brief Get X509 certificate from PEM data
     * @param certificate_data Certificate data in PEM format
     * @return X509 certificate or nullptr if parsing failed
     */
    X509* getX509Certificate(const std::string& certificate_data);
    
    /**
     * @brief Verify signature
     * @param cert X509 certificate
     * @param digest Digest
     * @param signature Signature
     * @return True if signature is valid
     */
    bool verifySignatureWithCertificate(
        X509* cert,
        const std::vector<uint8_t>& digest,
        const std::vector<uint8_t>& signature
    );
    
    /**
     * @brief Check certificate revocation
     * @param cert X509 certificate
     * @return True if certificate is not revoked
     */
    bool checkCertificateRevocation(X509* cert);
    
    std::string ca_certificate_path_;
    std::string crl_path_;
    std::unique_ptr<X509_STORE, decltype(&X509_STORE_free)> cert_store_;
    const EVP_MD* digest_algorithm_;
};

/**
 * @brief Certificate repository interface
 */
class ICertificateRepository {
public:
    virtual ~ICertificateRepository() = default;
    
    /**
     * @brief Store certificate
     * @param certificate Certificate info
     * @return True if stored successfully
     */
    virtual bool storeCertificate(const CertificateInfo& certificate) = 0;
    
    /**
     * @brief Get certificate by ID
     * @param certificate_id Certificate ID
     * @return Certificate info or nullopt if not found
     */
    virtual std::optional<CertificateInfo> getCertificate(const std::string& certificate_id) = 0;
    
    /**
     * @brief Get certificates by user ID
     * @param user_id User ID
     * @return Certificates
     */
    virtual std::vector<CertificateInfo> getCertificatesByUserId(const std::string& user_id) = 0;
    
    /**
     * @brief Revoke certificate
     * @param certificate_id Certificate ID
     * @param reason Revocation reason
     * @return True if revoked successfully
     */
    virtual bool revokeCertificate(const std::string& certificate_id, const std::string& reason) = 0;
    
    /**
     * @brief Check if certificate is revoked
     * @param certificate_id Certificate ID
     * @return True if revoked
     */
    virtual bool isCertificateRevoked(const std::string& certificate_id) = 0;
    
    /**
     * @brief Get certificate revocation list
     * @return Certificate revocation list
     */
    virtual std::vector<std::pair<std::string, std::string>> getCertificateRevocationList() = 0;
};

} // namespace signature
} // namespace etr
#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include "signature/digital_signature.h"
#include "records/record_model.h"
#include <filesystem>
#include <fstream>
#include <openssl/pem.h>
#include <openssl/rsa.h>
#include <openssl/evp.h>

using namespace etr::signature;
using namespace etr::records;
using namespace testing;

// Mock certificate repository
class MockCertificateRepository : public ICertificateRepository {
public:
    MOCK_METHOD(bool, storeCertificate, (const CertificateInfo&), (override));
    MOCK_METHOD(std::optional<CertificateInfo>, getCertificate, (const std::string&), (override));
    MOCK_METHOD(std::vector<CertificateInfo>, getCertificatesByUserId, (const std::string&), (override));
    MOCK_METHOD(bool, revokeCertificate, (const std::string&, const std::string&), (override));
    MOCK_METHOD(bool, isCertificateRevoked, (const std::string&), (override));
    MOCK_METHOD(std::vector<std::pair<std::string, std::string>>, getCertificateRevocationList, (), (override));
};

class DigitalSignatureTest : public Test {
protected:
    void SetUp() override {
        // Create temporary directory for test certificates
        test_dir_ = std::filesystem::temp_directory_path() / "etr_test_certs";
        std::filesystem::create_directories(test_dir_);
        
        // Generate test certificates
        generateTestCertificates();
        
        // Create mock repository
        mock_repository_ = std::make_shared<MockCertificateRepository>();
        
        // Create signature service
        signature_service_ = std::make_unique<X509DigitalSignatureService>(
            (test_dir_ / "ca_cert.pem").string(),
            ""
        );
    }
    
    void TearDown() override {
        // Clean up test directory
        std::filesystem::remove_all(test_dir_);
    }
    
    // Helper to generate test certificates
    void generateTestCertificates() {
        // Generate CA key and certificate
        EVP_PKEY* ca_key = generateRSAKey();
        X509* ca_cert = generateCertificate(ca_key, nullptr, "CN=Test CA,O=ETR Test,C=US", true);
        
        // Generate user key and certificate
        EVP_PKEY* user_key = generateRSAKey();
        X509* user_cert = generateCertificate(user_key, ca_key, "CN=test-user,O=ETR Test,C=US", false);
        
        // Save CA certificate
        saveCertificate(ca_cert, (test_dir_ / "ca_cert.pem").string());
        
        // Save user certificate and private key
        saveCertificate(user_cert, (test_dir_ / "user_cert.pem").string());
        savePrivateKey(user_key, (test_dir_ / "user_key.pem").string());
        
        // Clean up
        EVP_PKEY_free(ca_key);
        X509_free(ca_cert);
        EVP_PKEY_free(user_key);
        X509_free(user_cert);
    }
    
    // Helper to generate RSA key
    EVP_PKEY* generateRSAKey() {
        EVP_PKEY* key = EVP_PKEY_new();
        RSA* rsa = RSA_generate_key(2048, RSA_F4, nullptr, nullptr);
        EVP_PKEY_assign_RSA(key, rsa);
        return key;
    }
    
    // Helper to generate certificate
    X509* generateCertificate(EVP_PKEY* key, EVP_PKEY* issuer_key, const std::string& subject, bool is_ca) {
        X509* cert = X509_new();
        
        // Set version
        X509_set_version(cert, 2);  // X509v3
        
        // Set serial number
        ASN1_INTEGER_set(X509_get_serialNumber(cert), 1);
        
        // Set validity
        X509_gmtime_adj(X509_get_notBefore(cert), 0);
        X509_gmtime_adj(X509_get_notAfter(cert), 31536000L);  // 1 year
        
        // Set subject
        X509_NAME* name = X509_get_subject_name(cert);
        
        // Parse subject string
        std::istringstream subject_stream(subject);
        std::string token;
        while (std::getline(subject_stream, token, ',')) {
            size_t pos = token.find('=');
            if (pos != std::string::npos) {
                std::string field = token.substr(0, pos);
                std::string value = token.substr(pos + 1);
                
                if (field == "CN") {
                    X509_NAME_add_entry_by_txt(name, "commonName", MBSTRING_ASC, 
                        reinterpret_cast<const unsigned char*>(value.c_str()), -1, -1, 0);
                } else if (field == "O") {
                    X509_NAME_add_entry_by_txt(name, "organizationName", MBSTRING_ASC, 
                        reinterpret_cast<const unsigned char*>(value.c_str()), -1, -1, 0);
                } else if (field == "C") {
                    X509_NAME_add_entry_by_txt(name, "countryName", MBSTRING_ASC, 
                        reinterpret_cast<const unsigned char*>(value.c_str()), -1, -1, 0);
                }
            }
        }
        
        // Set issuer
        if (issuer_key) {
            // Signed by issuer
            X509* issuer_cert = X509_new();
            X509_NAME* issuer_name = X509_get_subject_name(issuer_cert);
            X509_NAME_add_entry_by_txt(issuer_name, "commonName", MBSTRING_ASC, 
                reinterpret_cast<const unsigned char*>("Test CA"), -1, -1, 0);
            X509_set_issuer_name(cert, issuer_name);
            X509_free(issuer_cert);
        } else {
            // Self-signed
            X509_set_issuer_name(cert, name);
        }
        
        // Set public key
        X509_set_pubkey(cert, key);
        
        // Set CA extension if needed
        if (is_ca) {
            X509_EXTENSION* ext = X509V3_EXT_conf_nid(nullptr, nullptr, NID_basic_constraints, "critical,CA:TRUE");
            X509_add_ext(cert, ext, -1);
            X509_EXTENSION_free(ext);
        }
        
        // Sign the certificate
        if (issuer_key) {
            X509_sign(cert, issuer_key, EVP_sha256());
        } else {
            X509_sign(cert, key, EVP_sha256());
        }
        
        return cert;
    }
    
    // Helper to save certificate to file
    void saveCertificate(X509* cert, const std::string& filename) {
        FILE* file = fopen(filename.c_str(), "w");
        if (file) {
            PEM_write_X509(file, cert);
            fclose(file);
        }
    }
    
    // Helper to save private key to file
    void savePrivateKey(EVP_PKEY* key, const std::string& filename) {
        FILE* file = fopen(filename.c_str(), "w");
        if (file) {
            PEM_write_PrivateKey(file, key, nullptr, nullptr, 0, nullptr, nullptr);
            fclose(file);
        }
    }
    
    // Helper to read file content
    std::string readFile(const std::string& filename) {
        std::ifstream file(filename);
        std::stringstream buffer;
        buffer << file.rdbuf();
        return buffer.str();
    }
    
    // Helper to create a valid record for testing
    TrainingRecord createValidRecord() {
        TrainingRecord record("test-record-id");
        record.setTraineeId("test-user");
        record.setInstructorId("test-instructor");
        record.setRecordType(RecordType::TRAINING_SESSION);
        record.setCourseId("test-course");
        record.setSyllabusId("test-syllabus");
        record.setExerciseId("test-exercise");
        record.setDate(std::chrono::system_clock::now());
        record.setDurationMinutes(60);
        record.setLocation("Test Location");
        
        GradeItem grade;
        grade.criteria_id = "test-criteria";
        grade.criteria_name = "Test Criteria";
        grade.grade = 3;
        grade.comments = "Good performance";
        record.addGrade(grade);
        
        record.setComments("Test comments");
        record.setDraft(true);
        
        return record;
    }
    
    // Helper to create a signature
    std::vector<uint8_t> createSignature(const std::string& private_key_path, const std::vector<uint8_t>& digest) {
        // Load private key
        FILE* key_file = fopen(private_key_path.c_str(), "r");
        if (!key_file) {
            return {};
        }
        
        EVP_PKEY* pkey = PEM_read_PrivateKey(key_file, nullptr, nullptr, nullptr);
        fclose(key_file);
        
        if (!pkey) {
            return {};
        }
        
        // Create signature
        EVP_MD_CTX* md_ctx = EVP_MD_CTX_new();
        EVP_PKEY_CTX* pkey_ctx = nullptr;
        std::vector<uint8_t> signature(EVP_PKEY_size(pkey));
        size_t sig_len = signature.size();
        
        EVP_DigestSignInit(md_ctx, &pkey_ctx, EVP_sha256(), nullptr, pkey);
        EVP_DigestSignUpdate(md_ctx, digest.data(), digest.size());
        EVP_DigestSignFinal(md_ctx, signature.data(), &sig_len);
        
        EVP_MD_CTX_free(md_ctx);
        EVP_PKEY_free(pkey);
        
        signature.resize(sig_len);
        return signature;
    }
    
    std::filesystem::path test_dir_;
    std::shared_ptr<MockCertificateRepository> mock_repository_;
    std::unique_ptr<X509DigitalSignatureService> signature_service_;
};

TEST_F(DigitalSignatureTest, ParseCertificate) {
    // Read test certificate
    std::string cert_data = readFile((test_dir_ / "user_cert.pem").string());
    
    // Parse certificate
    auto cert_info = signature_service_->parseCertificate(cert_data);
    
    // Verify result
    ASSERT_TRUE(cert_info.has_value());
    EXPECT_EQ(cert_info->subject_name, "/CN=test-user/O=ETR Test/C=US");
    EXPECT_EQ(cert_info->issuer_name, "/CN=Test CA/O=ETR Test/C=US");
    EXPECT_FALSE(cert_info->certificate_id.empty());
}

TEST_F(DigitalSignatureTest, ValidateCertificate) {
    // Read test certificate
    std::string cert_data = readFile((test_dir_ / "user_cert.pem").string());
    
    // Validate certificate
    bool result = signature_service_->validateCertificate(cert_data);
    
    // Verify result
    EXPECT_TRUE(result);
}

TEST_F(DigitalSignatureTest, ExtractUserIdFromCertificate) {
    // Read test certificate
    std::string cert_data = readFile((test_dir_ / "user_cert.pem").string());
    
    // Extract user ID
    std::string user_id = signature_service_->extractUserIdFromCertificate(cert_data);
    
    // Verify result
    EXPECT_EQ(user_id, "test-user");
}

TEST_F(DigitalSignatureTest, SignRecord) {
    // Create test record
    auto record = createValidRecord();
    
    // Read test certificate
    std::string cert_data = readFile((test_dir_ / "user_cert.pem").string());
    
    // Generate digest
    std::vector<uint8_t> digest = signature_service_->generateDigest(record);
    
    // Create signature
    std::vector<uint8_t> signature = createSignature((test_dir_ / "user_key.pem").string(), digest);
    
    // Sign record
    auto result = signature_service_->signRecord(
        record,
        "test-user",
        cert_data,
        signature,
        false  // Trainee signature
    );
    
    // Verify result
    ASSERT_TRUE(result.has_value());
    EXPECT_TRUE(result->is_valid);
    EXPECT_EQ(result->signer_id, "test-user");
    
    // Verify record has signature
    ASSERT_TRUE(record.getTraineeSignature().has_value());
    EXPECT_EQ(record.getTraineeSignature()->signer_id, "test-user");
    EXPECT_TRUE(record.getTraineeSignature()->is_valid);
}

TEST_F(DigitalSignatureTest, VerifySignature) {
    // Create test record
    auto record = createValidRecord();
    
    // Read test certificate
    std::string cert_data = readFile((test_dir_ / "user_cert.pem").string());
    
    // Generate digest
    std::vector<uint8_t> digest = signature_service_->generateDigest(record);
    
    // Create signature
    std::vector<uint8_t> signature = createSignature((test_dir_ / "user_key.pem").string(), digest);
    
    // Sign record
    auto sign_result = signature_service_->signRecord(
        record,
        "test-user",
        cert_data,
        signature,
        false  // Trainee signature
    );
    
    ASSERT_TRUE(sign_result.has_value());
    
    // Verify signature
    auto verify_result = signature_service_->verifySignature(record, "test-user");
    
    // Verify result
    ASSERT_TRUE(verify_result.has_value());
    EXPECT_TRUE(verify_result->first);  // Signature is valid
    EXPECT_EQ(verify_result->second.signer_id, "test-user");
}

TEST_F(DigitalSignatureTest, GenerateDigest) {
    // Create test record
    auto record = createValidRecord();
    
    // Generate digest
    std::vector<uint8_t> digest = signature_service_->generateDigest(record);
    
    // Verify digest is not empty
    EXPECT_FALSE(digest.empty());
    
    // Modify record
    record.setComments("Modified comments");
    
    // Generate new digest
    std::vector<uint8_t> new_digest = signature_service_->generateDigest(record);
    
    // Verify digests are different
    EXPECT_NE(digest, new_digest);
}

int main(int argc, char** argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include <openssl/pem.h>
#include <openssl/x509.h>
#include <openssl/evp.h>

#include "signature/digital_signature.h"
#include "records/record_model.h"

using namespace etr::signature;
using namespace testing;

// Helper to generate a test certificate
std::string generateTestCertificate(const std::string& common_name) {
    X509* cert = X509_new();
    EVP_PKEY* pkey = EVP_PKEY_new();
    RSA* rsa = RSA_new();
    BIGNUM* bn = BN_new();
    BN_set_word(bn, RSA_F4);
    RSA_generate_key_ex(rsa, 2048, bn, nullptr);
    EVP_PKEY_assign_RSA(pkey, rsa);

    X509_set_version(cert, 2);
    ASN1_INTEGER_set(X509_get_serialNumber(cert), 1);
    X509_gmtime_adj(X509_get_notBefore(cert), 0);
    X509_gmtime_adj(X509_get_notAfter(cert), 60 * 60 * 24 * 365);
    X509_set_pubkey(cert, pkey);

    X509_NAME* name = X509_get_subject_name(cert);
    X509_NAME_add_entry_by_txt(name, "CN", MBSTRING_ASC, 
        reinterpret_cast<const unsigned char*>(common_name.c_str()), -1, -1, 0);
    X509_set_issuer_name(cert, name);

    X509_sign(cert, pkey, EVP_sha256());

    BIO* bio = BIO_new(BIO_s_mem());
    PEM_write_bio_X509(bio, cert);
    char* pem_data;
    long pem_size = BIO_get_mem_data(bio, &pem_data);
    std::string cert_pem(pem_data, pem_size);

    BIO_free(bio);
    X509_free(cert);
    EVP_PKEY_free(pkey);
    BN_free(bn);

    return cert_pem;
}

// Helper to sign data with a key
std::vector<uint8_t> signData(const std::vector<uint8_t>& data, EVP_PKEY* pkey) {
    EVP_MD_CTX* md_ctx = EVP_MD_CTX_new();
    EVP_SignInit(md_ctx, EVP_sha256());
    EVP_SignUpdate(md_ctx, data.data(), data.size());
    
    unsigned int sig_len = 0;
    EVP_SignFinal(md_ctx, nullptr, &sig_len, pkey);
    
    std::vector<uint8_t> signature(sig_len);
    EVP_SignFinal(md_ctx, signature.data(), &sig_len, pkey);
    EVP_MD_CTX_free(md_ctx);
    
    return signature;
}

class DigitalSignatureTest : public Test {
protected:
    void SetUp() override {
        // Initialize OpenSSL
        OpenSSL_add_all_algorithms();
        ERR_load_crypto_strings();
        
        // Create service
        signature_service_ = std::make_unique<X509DigitalSignatureService>();
        
        // Generate test certificates
        trainee_cert_ = generateTestCertificate("trainee123");
        instructor_cert_ = generateTestCertificate("instructor456");
        
        // Create test record
        test_record_ = etr::records::TrainingRecord("test-record-id");
        test_record_.setTraineeId("trainee123");
        test_record_.setInstructorId("instructor456");
        test_record_.setRecordType(etr::records::RecordType::TRAINING_SESSION);
        test_record_.setCourseId("test-course");
        test_record_.setSyllabusId("test-syllabus");
        test_record_.setExerciseId("test-exercise");
        test_record_.setDate(std::chrono::system_clock::now());
        test_record_.setDurationMinutes(60);
        test_record_.setLocation("Test Location");
        test_record_.setComments("Test comments");
        
        etr::records::GradeItem grade;
        grade.criteria_id = "test-criteria";
        grade.criteria_name = "Test Criteria";
        grade.grade = 3;
        grade.comments = "Good performance";
        test_record_.addGrade(grade);
    }
    
    void TearDown() override {
        // Cleanup OpenSSL
        EVP_cleanup();
        ERR_free_strings();
    }
    
    std::unique_ptr<X509DigitalSignatureService> signature_service_;
    std::string trainee_cert_;
    std::string instructor_cert_;
    etr::records::TrainingRecord test_record_;
};

TEST_F(DigitalSignatureTest, ParseCertificate) {
    auto cert_info = signature_service_->parseCertificate(trainee_cert_);
    
    ASSERT_TRUE(cert_info.has_value());
    EXPECT_EQ(cert_info->subject_name, "/CN=trainee123");
    EXPECT_FALSE(cert_info->certificate_id.empty());
    EXPECT_TRUE(cert_info->is_valid);
}

TEST_F(DigitalSignatureTest, ExtractUserIdFromCertificate) {
    std::string user_id = signature_service_->extractUserIdFromCertificate(trainee_cert_);
    
    EXPECT_EQ(user_id, "trainee123");
}

TEST_F(DigitalSignatureTest, GenerateDigest) {
    std::vector<uint8_t> digest = signature_service_->generateDigest(test_record_);
    
    EXPECT_FALSE(digest.empty());
    
    // Changing the record should change the digest
    etr::records::TrainingRecord modified_record = test_record_;
    modified_record.setComments("Modified comments");
    
    std::vector<uint8_t> modified_digest = signature_service_->generateDigest(modified_record);
    
    EXPECT_NE(digest, modified_digest);
}

TEST_F(DigitalSignatureTest, SignRecord) {
    // Create a dummy signature
    std::vector<uint8_t> dummy_signature(32, 0);
    
    // Sign record as trainee
    auto trainee_signature = signature_service_->signRecord(
        test_record_, 
        "trainee123", 
        trainee_cert_, 
        dummy_signature, 
        false
    );
    
    ASSERT_TRUE(trainee_signature.has_value());
    EXPECT_EQ(trainee_signature->signer_id, "trainee123");
    EXPECT_TRUE(test_record_.isSignedByTrainee());
    
    // Sign record as instructor
    auto instructor_signature = signature_service_->signRecord(
        test_record_, 
        "instructor456", 
        instructor_cert_, 
        dummy_signature, 
        true
    );
    
    ASSERT_TRUE(instructor_signature.has_value());
    EXPECT_EQ(instructor_signature->signer_id, "instructor456");
    EXPECT_TRUE(test_record_.isSignedByInstructor());
    
    // Record should be fully signed
    EXPECT_TRUE(test_record_.isFullySigned());
}

TEST_F(DigitalSignatureTest, VerifySignature) {
    // Create a dummy signature
    std::vector<uint8_t> dummy_signature(32, 0);
    
    // Sign record as trainee
    auto trainee_signature = signature_service_->signRecord(
        test_record_, 
        "trainee123", 
        trainee_cert_, 
        dummy_signature, 
        false
    );
    
    ASSERT_TRUE(trainee_signature.has_value());
    
    // Verify trainee signature
    auto verify_result = signature_service_->verifySignature(
        test_record_, 
        "trainee123"
    );
    
    ASSERT_TRUE(verify_result.has_value());
    EXPECT_TRUE(verify_result->first);
    EXPECT_EQ(verify_result->second.signer_id, "trainee123");
}

int main(int argc, char** argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
# Stage 1: Build environment
FROM ubuntu:22.04 AS builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    libssl-dev \
    pkg-config \
    curl \
    unzip \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Install vcpkg for dependency management
WORKDIR /opt
RUN git clone https://github.com/Microsoft/vcpkg.git && \
    ./vcpkg/bootstrap-vcpkg.sh -disableMetrics && \
    ./vcpkg/vcpkg integrate install

# Install dependencies with vcpkg
RUN ./vcpkg/vcpkg install \
    grpc \
    protobuf \
    openssl \
    nlohmann-json \
    spdlog \
    prometheus-cpp \
    cpprestsdk \
    boost-system \
    boost-filesystem \
    postgresql-libpq

# Copy source code
WORKDIR /app
COPY . .

# Create build directory
RUN mkdir -p build

# Configure and build
WORKDIR /app/build
RUN cmake .. \
    -DCMAKE_TOOLCHAIN_FILE=/opt/vcpkg/scripts/buildsystems/vcpkg.cmake \
    -DCMAKE_BUILD_TYPE=Release && \
    cmake --build . --config Release -j$(nproc)

# Stage 2: Runtime environment
FROM ubuntu:22.04

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    libssl3 \
    ca-certificates \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

# Create app directories
RUN mkdir -p /app/bin /app/config /app/logs /app/data /app/certs

# Copy build artifacts
COPY --from=builder /app/build/bin/etr-service /app/bin/
COPY --from=builder /app/config/*.json /app/config/

# Set working directory
WORKDIR /app

# Set environment variables
ENV ETR_SERVER_HOST=0.0.0.0
ENV ETR_SERVER_PORT=50053
ENV ETR_DB_HOST=postgres
ENV ETR_DB_PORT=5432
ENV ETR_DB_NAME=training_platform
ENV ETR_DB_USER=postgres
ENV ETR_DB_PASSWORD=postgres
ENV ETR_METRICS_HOST=0.0.0.0
ENV ETR_METRICS_PORT=9103

# Create non-root user
RUN useradd -m -s /bin/bash appuser && \
    chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Expose ports
EXPOSE 50053
EXPOSE 9103

# Define health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD nc -z localhost 50053 || exit 1

# Start the service
CMD ["/app/bin/etr-service", "/app/config/config.json"]
#pragma once

#include <memory>
#include <string>
#include <vector>
#include <chrono>
#include <grpcpp/grpcpp.h>

#include "etr_service.grpc.pb.h"
#include "records/record_service.h"
#include "signature/digital_signature.h"
#include "compliance/compliance_service.h"
#include "syllabus/syllabus_service.h"

namespace etr {
namespace service {

/**
 * @brief gRPC service implementation for Electronic Training Records
 */
class ETRServiceImpl final : public ElectronicTrainingRecordsService::Service {
public:
    /**
     * @brief Constructor
     * @param record_service Record service
     * @param signature_service Signature service
     * @param compliance_service Compliance service
     * @param syllabus_service Syllabus service
     */
    ETRServiceImpl(
        std::shared_ptr<records::IRecordService> record_service,
        std::shared_ptr<signature::IDigitalSignatureService> signature_service,
        std::shared_ptr<compliance::IComplianceService> compliance_service,
        std::shared_ptr<syllabus::ISyllabusService> syllabus_service
    );

    // Records management
    grpc::Status CreateTrainingRecord(
        grpc::ServerContext* context,
        const TrainingRecord* request,
        RecordResponse* response
    ) override;

    grpc::Status GetTrainingRecord(
        grpc::ServerContext* context,
        const RecordRequest* request,
        TrainingRecord* response
    ) override;

    grpc::Status UpdateTrainingRecord(
        grpc::ServerContext* context,
        const TrainingRecord* request,
        RecordResponse* response
    ) override;

    grpc::Status DeleteTrainingRecord(
        grpc::ServerContext* context,
        const RecordRequest* request,
        RecordResponse* response
    ) override;

    grpc::Status ListTrainingRecords(
        grpc::ServerContext* context,
        const ListRecordsRequest* request,
        ListRecordsResponse* response
    ) override;

    // Digital signature
    grpc::Status SignRecord(
        grpc::ServerContext* context,
        const SignatureRequest* request,
        SignatureResponse* response
    ) override;

    grpc::Status VerifySignature(
        grpc::ServerContext* context,
        const VerifyRequest* request,
        VerifyResponse* response
    ) override;

    // Compliance tracking
    grpc::Status CheckCompliance(
        grpc::ServerContext* context,
        const ComplianceRequest* request,
        ComplianceResponse* response
    ) override;

    grpc::Status ListComplianceRequirements(
        grpc::ServerContext* context,
        const ListComplianceRequest* request,
        ListComplianceResponse* response
    ) override;

    grpc::Status MapRegulations(
        grpc::ServerContext* context,
        const RegulationMappingRequest* request,
        RegulationMappingResponse* response
    ) override;

    // Syllabus management
    grpc::Status CreateSyllabus(
        grpc::ServerContext* context,
        const Syllabus* request,
        SyllabusResponse* response
    ) override;

    grpc::Status GetSyllabus(
        grpc::ServerContext* context,
        const SyllabusRequest* request,
        Syllabus* response
    ) override;

    grpc::Status UpdateSyllabus(
        grpc::ServerContext* context,
        const Syllabus* request,
        SyllabusResponse* response
    ) override;

    grpc::Status DeleteSyllabus(
        grpc::ServerContext* context,
        const SyllabusRequest* request,
        SyllabusResponse* response
    ) override;

    grpc::Status ListSyllabi(
        grpc::ServerContext* context,
        const ListSyllabiRequest* request,
        ListSyllabiResponse* response
    ) override;

    grpc::Status TrackSyllabusChanges(
        grpc::ServerContext* context,
        const SyllabusChangeRequest* request,
        SyllabusChangeResponse* response
    ) override;

private:
    /**
     * @brief Convert internal training record to protobuf
     * @param record Internal record
     * @return Protobuf record
     */
    TrainingRecord convertToProto(const records::TrainingRecord& record);

    /**
     * @brief Convert protobuf training record to internal
     * @param proto_record Protobuf record
     * @return Internal record
     */
    records::TrainingRecord convertFromProto(const TrainingRecord& proto_record);

    /**
     * @brief Convert internal syllabus to protobuf
     * @param syllabus Internal syllabus
     * @return Protobuf syllabus
     */
    Syllabus convertToProto(const syllabus::Syllabus& syllabus);

    /**
     * @brief Convert protobuf syllabus to internal
     * @param proto_syllabus Protobuf syllabus
     * @return Internal syllabus
     */
    syllabus::Syllabus convertFromProto(const Syllabus& proto_syllabus);

    /**
     * @brief Convert internal signature info to protobuf
     * @param signature Internal signature info
     * @return Protobuf signature info
     */
    SignatureInfo convertToProto(const records::SignatureInfo& signature);

    /**
     * @brief Convert protobuf signature info to internal
     * @param proto_signature Protobuf signature info
     * @return Internal signature info
     */
    records::SignatureInfo convertFromProto(const SignatureInfo& proto_signature);

    /**
     * @brief Convert internal compliance status to protobuf
     * @param status Internal compliance status
     * @return Protobuf compliance response
     */
    ComplianceResponse convertToProto(const compliance::ComplianceStatus& status);

    /**
     * @brief Convert internal compliance requirement to protobuf
     * @param requirement Internal compliance requirement
     * @return Protobuf compliance requirement
     */
    ComplianceRequirement convertToProto(const compliance::ComplianceRequirement& requirement);

    /**
     * @brief Convert internal regulation mapping to protobuf
     * @param mapping Internal regulation mapping
     * @return Protobuf regulation mapping
     */
    RegulationMapping convertToProto(const compliance::RegulationMapping& mapping);

    /**
     * @brief Convert internal syllabus changes to protobuf
     * @param changes Internal syllabus changes
     * @return Protobuf syllabus changes
     */
    std::vector<SyllabusChange> convertToProto(const std::vector<syllabus::SyllabusChange>& changes);

    /**
     * @brief Extract authentication token from context
     * @param context gRPC server context
     * @return Token or empty string if not found
     */
    std::string extractToken(const grpc::ServerContext* context);

    /**
     * @brief Validate authentication token
     * @param token Authentication token
     * @return True if valid
     */
    bool validateToken(const std::string& token);

    /**
     * @brief Extract user ID from token
     * @param token Authentication token
     * @return User ID or empty string if extraction failed
     */
    std::string extractUserId(const std::string& token);

    std::shared_ptr<records::IRecordService> record_service_;
    std::shared_ptr<signature::IDigitalSignatureService> signature_service_;
    std::shared_ptr<compliance::IComplianceService> compliance_service_;
    std::shared_ptr<syllabus::ISyllabusService> syllabus_service_;
};

} // namespace service
} // namespace etr
#include "service/etr_service_impl.h"
#include "logging/logger.h"
#include "metrics/metrics_service.h"

#include <sstream>
#include <chrono>
#include <jwt-cpp/jwt.h>

namespace etr {
namespace service {

ETRServiceImpl::ETRServiceImpl(
    std::shared_ptr<records::IRecordService> record_service,
    std::shared_ptr<signature::IDigitalSignatureService> signature_service,
    std::shared_ptr<compliance::IComplianceService> compliance_service,
    std::shared_ptr<syllabus::ISyllabusService> syllabus_service
)
    : record_service_(std::move(record_service)),
      signature_service_(std::move(signature_service)),
      compliance_service_(std::move(compliance_service)),
      syllabus_service_(std::move(syllabus_service)) {
    
    logging::Logger::getInstance().info("ETR Service Implementation initialized");
}

grpc::Status ETRServiceImpl::CreateTrainingRecord(
    grpc::ServerContext* context,
    const TrainingRecord* request,
    RecordResponse* response
) {
    // Create metric for request timing
    auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
        "etr_request_duration_seconds",
        "ETR request duration in seconds",
        {{"method", "CreateTrainingRecord"}}
    );
    
    auto start_time = std::chrono::steady_clock::now();
    
    // Check authentication
    std::string token = extractToken(context);
    if (!validateToken(token)) {
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        return grpc::Status(grpc::StatusCode::UNAUTHENTICATED, "Invalid authentication token");
    }
    
    try {
        // Convert protobuf to internal model
        records::TrainingRecord record = convertFromProto(*request);
        
        // Create record
        std::string record_id = record_service_->createRecord(record);
        
        if (record_id.empty()) {
            auto end_time = std::chrono::steady_clock::now();
            double duration = std::chrono::duration<double>(end_time - start_time).count();
            request_duration.Observe(duration);
            
            return grpc::Status(grpc::StatusCode::INTERNAL, "Failed to create training record");
        }
        
        // Set response
        response->set_success(true);
        response->set_record_id(record_id);
        response->set_timestamp(
            std::chrono::duration_cast<std::chrono::milliseconds>(
                std::chrono::system_clock::now().time_since_epoch()
            ).count()
        );
        
        // Log success
        logging::Logger::getInstance().info("Created training record with ID: {}", record_id);
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& success_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "create"}, {"status", "success"}}
        );
        success_counter.Increment();
        
        return grpc::Status::OK;
    } 
    catch (const std::exception& e) {
        // Log error
        logging::Logger::getInstance().error("Error creating training record: {}", e.what());
        
        // Set error response
        response->set_success(false);
        response->set_error_message(e.what());
        response->set_timestamp(
            std::chrono::duration_cast<std::chrono::milliseconds>(
                std::chrono::system_clock::now().time_since_epoch()
            ).count()
        );
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& error_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "create"}, {"status", "error"}}
        );
        error_counter.Increment();
        
        return grpc::Status(grpc::StatusCode::INTERNAL, e.what());
    }
}

grpc::Status ETRServiceImpl::GetTrainingRecord(
    grpc::ServerContext* context,
    const RecordRequest* request,
    TrainingRecord* response
) {
    // Create metric for request timing
    auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
        "etr_request_duration_seconds",
        "ETR request duration in seconds",
        {{"method", "GetTrainingRecord"}}
    );
    
    auto start_time = std::chrono::steady_clock::now();
    
    // Check authentication
    std::string token = extractToken(context);
    if (!validateToken(token)) {
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        return grpc::Status(grpc::StatusCode::UNAUTHENTICATED, "Invalid authentication token");
    }
    
    try {
        // Get record
        std::optional<records::TrainingRecord> record = record_service_->getRecord(request->record_id());
        
        if (!record) {
            auto end_time = std::chrono::steady_clock::now();
            double duration = std::chrono::duration<double>(end_time - start_time).count();
            request_duration.Observe(duration);
            
            return grpc::Status(grpc::StatusCode::NOT_FOUND, "Training record not found");
        }
        
        // Convert internal model to protobuf
        *response = convertToProto(*record);
        
        // Log success
        logging::Logger::getInstance().info("Retrieved training record with ID: {}", request->record_id());
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& success_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "get"}, {"status", "success"}}
        );
        success_counter.Increment();
        
        return grpc::Status::OK;
    } 
    catch (const std::exception& e) {
        // Log error
        logging::Logger::getInstance().error("Error getting training record: {}", e.what());
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& error_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "get"}, {"status", "error"}}
        );
        error_counter.Increment();
        
        return grpc::Status(grpc::StatusCode::INTERNAL, e.what());
    }
}

grpc::Status ETRServiceImpl::UpdateTrainingRecord(
    grpc::ServerContext* context,
    const TrainingRecord* request,
    RecordResponse* response
) {
    // Create metric for request timing
    auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
        "etr_request_duration_seconds",
        "ETR request duration in seconds",
        {{"method", "UpdateTrainingRecord"}}
    );
    
    auto start_time = std::chrono::steady_clock::now();
    
    // Check authentication
    std::string token = extractToken(context);
    if (!validateToken(token)) {
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        return grpc::Status(grpc::StatusCode::UNAUTHENTICATED, "Invalid authentication token");
    }
    
    try {
        // Convert protobuf to internal model
        records::TrainingRecord record = convertFromProto(*request);
        
        // Update record
        bool success = record_service_->updateRecord(record);
        
        if (!success) {
            auto end_time = std::chrono::steady_clock::now();
            double duration = std::chrono::duration<double>(end_time - start_time).count();
            request_duration.Observe(duration);
            
            return grpc::Status(grpc::StatusCode::NOT_FOUND, "Training record not found");
        }
        
        // Set response
        response->set_success(true);
        response->set_record_id(record.getRecordId());
        response->set_timestamp(
            std::chrono::duration_cast<std::chrono::milliseconds>(
                std::chrono::system_clock::now().time_since_epoch()
            ).count()
        );
        
        // Log success
        logging::Logger::getInstance().info("Updated training record with ID: {}", record.getRecordId());
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& success_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "update"}, {"status", "success"}}
        );
        success_counter.Increment();
        
        return grpc::Status::OK;
    } 
    catch (const std::exception& e) {
        // Log error
        logging::Logger::getInstance().error("Error updating training record: {}", e.what());
        
        // Set error response
        response->set_success(false);
        response->set_error_message(e.what());
        response->set_timestamp(
            std::chrono::duration_cast<std::chrono::milliseconds>(
                std::chrono::system_clock::now().time_since_epoch()
            ).count()
        );
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& error_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "update"}, {"status", "error"}}
        );
        error_counter.Increment();
        
        return grpc::Status(grpc::StatusCode::INTERNAL, e.what());
    }
}

grpc::Status ETRServiceImpl::DeleteTrainingRecord(
    grpc::ServerContext* context,
    const RecordRequest* request,
    RecordResponse* response
) {
    // Create metric for request timing
    auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
        "etr_request_duration_seconds",
        "ETR request duration in seconds",
        {{"method", "DeleteTrainingRecord"}}
    );
    
    auto start_time = std::chrono::steady_clock::now();
    
    // Check authentication
    std::string token = extractToken(context);
    if (!validateToken(token)) {
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        return grpc::Status(grpc::StatusCode::UNAUTHENTICATED, "Invalid authentication token");
    }
    
    // Check authorization
    std::string user_id = extractUserId(token);
    
    try {
        // Delete record
        bool success = record_service_->deleteRecord(request->record_id());
        
        if (!success) {
            auto end_time = std::chrono::steady_clock::now();
            double duration = std::chrono::duration<double>(end_time - start_time).count();
            request_duration.Observe(duration);
            
            return grpc::Status(grpc::StatusCode::NOT_FOUND, "Training record not found");
        }
        
        // Set response
        response->set_success(true);
        response->set_record_id(request->record_id());
        response->set_timestamp(
            std::chrono::duration_cast<std::chrono::milliseconds>(
                std::chrono::system_clock::now().time_since_epoch()
            ).count()
        );
        
        // Log success
        logging::Logger::getInstance().info("Deleted training record with ID: {}", request->record_id());
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& success_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "delete"}, {"status", "success"}}
        );
        success_counter.Increment();
        
        return grpc::Status::OK;
    } 
    catch (const std::exception& e) {
        // Log error
        logging::Logger::getInstance().error("Error deleting training record: {}", e.what());
        
        // Set error response
        response->set_success(false);
        response->set_error_message(e.what());
        response->set_timestamp(
            std::chrono::duration_cast<std::chrono::milliseconds>(
                std::chrono::system_clock::now().time_since_epoch()
            ).count()
        );
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& error_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "delete"}, {"status", "error"}}
        );
        error_counter.Increment();
        
        return grpc::Status(grpc::StatusCode::INTERNAL, e.what());
    }
}

grpc::Status ETRServiceImpl::ListTrainingRecords(
    grpc::ServerContext* context,
    const ListRecordsRequest* request,
    ListRecordsResponse* response
) {
    // Create metric for request timing
    auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
        "etr_request_duration_seconds",
        "ETR request duration in seconds",
        {{"method", "ListTrainingRecords"}}
    );
    
    auto start_time = std::chrono::steady_clock::now();
    
    // Check authentication
    std::string token = extractToken(context);
    if (!validateToken(token)) {
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        return grpc::Status(grpc::StatusCode::UNAUTHENTICATED, "Invalid authentication token");
    }
    
    try {
        // Convert parameters
        std::optional<std::string> trainee_id;
        if (!request->trainee_id().empty()) {
            trainee_id = request->trainee_id();
        }
        
        std::optional<std::string> instructor_id;
        if (!request->instructor_id().empty()) {
            instructor_id = request->instructor_id();
        }
        
        std::optional<std::string> course_id;
        if (!request->course_id().empty()) {
            course_id = request->course_id();
        }
        
        std::optional<std::string> syllabus_id;
        if (!request->syllabus_id().empty()) {
            syllabus_id = request->syllabus_id();
        }
        
        std::optional<records::RecordType> record_type;
        if (request->record_type() != RecordType::UNKNOWN_RECORD) {
            record_type = static_cast<records::RecordType>(
                static_cast<int>(request->record_type()) - 1
            );
        }
        
        std::optional<std::chrono::system_clock::time_point> start_date;
        if (request->start_date() > 0) {
            start_date = std::chrono::system_clock::time_point(
                std::chrono::milliseconds(request->start_date())
            );
        }
        
        std::optional<std::chrono::system_clock::time_point> end_date;
        if (request->end_date() > 0) {
            end_date = std::chrono::system_clock::time_point(
                std::chrono::milliseconds(request->end_date())
            );
        }
        
        // List records
        auto [records, total_count] = record_service_->listRecords(
            trainee_id,
            instructor_id,
            course_id,
            syllabus_id,
            record_type,
            start_date,
            end_date,
            request->page(),
            request->page_size(),
            request->sort_by(),
            request->ascending()
        );
        
        // Set response
        response->set_success(true);
        response->set_total_count(total_count);
        response->set_page(request->page());
        response->set_page_size(request->page_size());
        
        // Add records to response
        for (const auto& record : records) {
            *response->add_records() = convertToProto(record);
        }
        
        // Log success
        logging::Logger::getInstance().info("Listed {} training records", records.size());
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& success_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "list"}, {"status", "success"}}
        );
        success_counter.Increment();
        
        return grpc::Status::OK;
    } 
    catch (const std::exception& e) {
        // Log error
        logging::Logger::getInstance().error("Error listing training records: {}", e.what());
        
        // Set error response
        response->set_success(false);
        response->set_error_message(e.what());
        
        // Update metrics
        auto end_time = std::chrono::steady_clock::now();
        double duration = std::chrono::duration<double>(end_time - start_time).count();
        request_duration.Observe(duration);
        
        auto& error_counter = metrics::MetricsService::getInstance().createCounter(
            "etr_record_operations_total",
            "ETR record operations",
            {{"operation", "list"}, {"status", "error"}}
        );
        error_counter.Increment();
        
        return grpc::Status(grpc::StatusCode::INTERNAL, e.what());
    }
}

// Conversion methods
TrainingRecord ETRServiceImpl::convertToProto(const records::TrainingRecord& record) {
    TrainingRecord proto_record;
    
    // Set basic fields
    proto_record.set_record_id(record.getRecordId());
    proto_record.set_trainee_id(record.getTraineeId());
    proto_record.set_instructor_id(record.getInstructorId());
    proto_record.set_record_type(static_cast<RecordType>(
        static_cast<int>(record.getRecordType()) + 1
    ));
    proto_record.set_course_id(record.getCourseId());
    proto_record.set_syllabus_id(record.getSyllabusId());
    proto_record.set_exercise_id(record.getExerciseId());
    
    // Set date
    proto_record.set_date(
        std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getDate().time_since_epoch()
        ).count()
    );
    
    proto_record.set_duration_minutes(record.getDurationMinutes());
    proto_record.set_location(record.getLocation());
    proto_record.set_aircraft_type(record.getAircraftType());
    
    // Set grades
    for (const auto& grade : record.getGrades()) {
        auto* proto_grade = proto_record.add_grades();
        proto_grade->set_criteria_id(grade.criteria_id);
        proto_grade->set_criteria_name(grade.criteria_name);
        proto_grade->set_grade(grade.grade);
        proto_grade->set_comments(grade.comments);
    }
    
    // Set attachments
    for (const auto& attachment : record.getAttachments()) {
        proto_record.add_attachments(attachment);
    }
    
    proto_record.set_comments(record.getComments());
    
    // Set trainee signature
    if (record.getTraineeSignature()) {
        auto* proto_sig = proto_record.mutable_trainee_signature();
        *proto_sig = convertToProto(*record.getTraineeSignature());
    }
    
    // Set instructor signature
    if (record.getInstructorSignature()) {
        auto* proto_sig = proto_record.mutable_instructor_signature();
        *proto_sig = convertToProto(*record.getInstructorSignature());
    }
    
    proto_record.set_is_draft(record.isDraft());
    
    // Set timestamps
    proto_record.set_created_at(
        std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getCreatedAt().time_since_epoch()
        ).count()
    );
    
    proto_record.set_updated_at(
        std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getUpdatedAt().time_since_epoch()
        ).count()
    );
    
    // Set metadata
    for (const auto& [key, value] : record.getMetadata()) {
        (*proto_record.mutable_metadata())[key] = value;
    }
    
    return proto_record;
}

records::TrainingRecord ETRServiceImpl::convertFromProto(const TrainingRecord& proto_record) {
    records::TrainingRecord record(proto_record.record_id());
    
    // Set basic fields
    record.setTraineeId(proto_record.trainee_id());
    record.setInstructorId(proto_record.instructor_id());
    record.setRecordType(static_cast<records::RecordType>(
        static_cast<int>(proto_record.record_type()) - 1
    ));
    record.setCourseId(proto_record.course_id());
    record.setSyllabusId(proto_record.syllabus_id());
    record.setExerciseId(proto_record.exercise_id());
    
    // Set date
    if (proto_record.date() > 0) {
        record.setDate(std::chrono::system_clock::time_point(
            std::chrono::milliseconds(proto_record.date())
        ));
    }
    
    record.setDurationMinutes(proto_record.duration_minutes());
    record.setLocation(proto_record.location());
    record.setAircraftType(proto_record.aircraft_type());
    
    // Set grades
    std::vector<records::GradeItem> grades;
    for (const auto& proto_grade : proto_record.grades()) {
        records::GradeItem grade;
        grade.criteria_id = proto_grade.criteria_id();
        grade.criteria_name = proto_grade.criteria_name();
        grade.grade = proto_grade.grade();
        grade.comments = proto_grade.comments();
        grades.push_back(grade);
    }
    record.setGrades(grades);
    
    // Set attachments
    std::vector<std::string> attachments;
    for (const auto& attachment : proto_record.attachments()) {
        attachments.push_back(attachment);
    }
    record.setAttachments(attachments);
    
    record.setComments(proto_record.comments());
    
    // Set trainee signature
    if (proto_record.has_trainee_signature()) {
        record.setTraineeSignature(convertFromProto(proto_record.trainee_signature()));
    }
    
    // Set instructor signature
    if (proto_record.has_instructor_signature()) {
        record.setInstructorSignature(convertFromProto(proto_record.instructor_signature()));
    }
    
    record.setDraft(proto_record.is_draft());
    
    // Set timestamps
    if (proto_record.created_at() > 0) {
        record.setCreatedAt(std::chrono::system_clock::time_point(
            std::chrono::milliseconds(proto_record.created_at())
        ));
    }
    
    if (proto_record.updated_at() > 0) {
        record.setUpdatedAt(std::chrono::system_clock::time_point(
            std::chrono::milliseconds(proto_record.updated_at())
        ));
    }
    
    // Set metadata
    std::map<std::string, std::string> metadata;
    for (const auto& [key, value] : proto_record.metadata()) {
        metadata[key] = value;
    }
    record.setMetadata(metadata);
    
    return record;
}

SignatureInfo ETRServiceImpl::convertToProto(const records::SignatureInfo& signature) {
    SignatureInfo proto_signature;
    
    proto_signature.set_signer_id(signature.signer_id);
    proto_signature.set_signer_name(signature.signer_name);
    proto_signature.set_certificate_id(signature.certificate_id);
    proto_signature.set_signature_data(
        signature.signature_data.data(),
        signature.signature_data.size()
    );
    proto_signature.set_timestamp(
        std::chrono::duration_cast<std::chrono::milliseconds>(
            signature.timestamp.time_since_epoch()
        ).count()
    );
    proto_signature.set_is_valid(signature.is_valid);
    
    return proto_signature;
}

records::SignatureInfo ETRServiceImpl::convertFromProto(const SignatureInfo& proto_signature) {
    records::SignatureInfo signature;
    
    signature.signer_id = proto_signature.signer_id();
    signature.signer_name = proto_signature.signer_name();
    signature.certificate_id = proto_signature.certificate_id();
    
    // Copy signature data
    const std::string& sig_data = proto_signature.signature_data();
    signature.signature_data.assign(sig_data.begin(), sig_data.end());
    
    // Set timestamp
    signature.timestamp = std::chrono::system_clock::time_point(
        std::chrono::milliseconds(proto_signature.timestamp())
    );
    
    signature.is_valid = proto_signature.is_valid();
    
    return signature;
}

// Authentication & Authorization methods
std::string ETRServiceImpl::extractToken(const grpc::ServerContext* context) {
    // Find authorization metadata
    auto auth_iter = context->client_metadata().find("authorization");
    if (auth_iter != context->client_metadata().end()) {
        const std::string auth_header(auth_iter->second.data(), auth_iter->second.size());
        
        // Check Bearer prefix
        if (auth_header.substr(0, 7) == "Bearer ") {
            return auth_header.substr(7);
        }
    }
    
    return "";
}

bool ETRServiceImpl::validateToken(const std::string& token) {
    // For demo purposes, just check if token is not empty
    // In a real implementation, this would validate with the core platform service
    if (token.empty()) {
        return false;
    }
    
    try {
        // Basic JWT validation
        auto decoded = jwt::decode(token);
        
        // Check expiration
        if (decoded.has_expires_at() && decoded.get_expires_at() < std::chrono::system_clock::now()) {
            logging::Logger::getInstance().warn("Token expired");
            return false;
        }
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().warn("Token validation error: {}", e.what());
        return false;
    }
}

std::string ETRServiceImpl::extractUserId(const std::string& token) {
    if (token.empty()) {
        return "";
    }
    
    try {
        // Decode JWT to extract user ID
        auto decoded = jwt::decode(token);
        return decoded.get_subject();
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().warn("Error extracting user ID from token: {}", e.what());
        return "";
    }
}

// Implement other methods...
// For brevity, I'm showing a few key methods. In a real implementation, you would implement all the methods.

} // namespace service
} // namespace etr
#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include <memory>
#include <chrono>
#include <thread>

#include "records/record_service.h"
#include "records/record_repository.h"
#include "signature/digital_signature.h"
#include "compliance/compliance_service.h"
#include "compliance/compliance_repository.h"
#include "syllabus/syllabus_service.h"
#include "syllabus/syllabus_repository.h"
#include "persistence/database_connection.h"
#include "service/etr_service_impl.h"

using namespace etr;
using namespace testing;

// Mock database connection to avoid actual database operations
class MockDatabaseConnection : public persistence::DatabaseConnection {
public:
    MockDatabaseConnection() 
        : persistence::DatabaseConnection("localhost", 5432, "test_db", "test_user", "test_password") {}
    
    MOCK_METHOD(bool, connect, (), (override));
    MOCK_METHOD(void, disconnect, (), (override));
    MOCK_METHOD(bool, isConnected, (), (const, override));
    MOCK_METHOD(persistence::PgResult, executeQuery, 
                (const std::string&, const std::vector<persistence::PgParam>&), (override));
    MOCK_METHOD(nlohmann::json, queryFirstRowAsJson, 
                (const std::string&, const std::vector<persistence::PgParam>&), (override));
    MOCK_METHOD(nlohmann::json, queryAllRowsAsJson, 
                (const std::string&, const std::vector<persistence::PgParam>&), (override));
    MOCK_METHOD(bool, beginTransaction, (), (override));
    MOCK_METHOD(bool, commitTransaction, (), (override));
    MOCK_METHOD(bool, rollbackTransaction, (), (override));
    MOCK_METHOD(bool, inTransaction, (), (const, override));
    MOCK_METHOD(std::string, escapeString, (const std::string&), (const, override));
    MOCK_METHOD(std::string, escapeIdentifier, (const std::string&), (const, override));
    MOCK_METHOD(std::string, getLastError, (), (const, override));
    MOCK_METHOD(std::string, getConnectionInfo, (), (const, override));
};

// Fixture for integration tests
class ETRServiceIntegrationTest : public Test {
protected:
    void SetUp() override {
        // Create mock database connection
        db_connection_ = std::make_shared<MockDatabaseConnection>();
        EXPECT_CALL(*db_connection_, connect()).WillRepeatedly(Return(true));
        EXPECT_CALL(*db_connection_, isConnected()).WillRepeatedly(Return(true));
        
        // Create repositories with mock connection
        record_repository_ = std::make_shared<records::RecordRepository>(db_connection_);
        compliance_repository_ = std::make_shared<compliance::ComplianceRepository>(db_connection_);
        syllabus_repository_ = std::make_shared<syllabus::SyllabusRepository>(db_connection_);
        
        // Create services
        record_service_ = std::make_shared<records::RecordService>(record_repository_);
        signature_service_ = std::make_shared<signature::X509DigitalSignatureService>();
        compliance_service_ = std::make_shared<compliance::ComplianceService>(
            compliance_repository_, record_repository_);
        syllabus_service_ = std::make_shared<syllabus::SyllabusService>(
            syllabus_repository_, signature_service_);
        
        // Create gRPC service implementation
        etr_service_ = std::make_unique<service::ETRServiceImpl>(
            record_service_, signature_service_, compliance_service_, syllabus_service_);
        
        // Setup common test data
        setupTestData();
    }
    
    void setupTestData() {
        // Create test record
        test_record_ = createTestRecord();
        
        // Create test syllabus
        test_syllabus_ = createTestSyllabus();
        
        // Set up mock repository responses
        setupMockRepositoryResponses();
    }
    
    records::TrainingRecord createTestRecord() {
        records::TrainingRecord record("test-record-id");
        record.setTraineeId("test-trainee");
        record.setInstructorId("test-instructor");
        record.setRecordType(records::RecordType::TRAINING_SESSION);
        record.setCourseId("test-course");
        record.setSyllabusId("test-syllabus");
        record.setExerciseId("test-exercise");
        record.setDate(std::chrono::system_clock::now());
        record.setDurationMinutes(60);
        record.setLocation("Test Location");
        
        records::GradeItem grade;
        grade.criteria_id = "test-criteria";
        grade.criteria_name = "Test Criteria";
        grade.grade = 3;
        grade.comments = "Good performance";
        record.addGrade(grade);
        
        record.setComments("Test comments");
        record.setDraft(true);
        
        return record;
    }
    
    syllabus::Syllabus createTestSyllabus() {
        syllabus::Syllabus syllabus("test-syllabus-id");
        syllabus.setCourseId("test-course");
        syllabus.setTitle("Test Syllabus");
        syllabus.setDescription("Test Description");
        syllabus.setVersion("1.0");
        syllabus.setEffectiveDate(std::chrono::system_clock::now());
        syllabus.setStatus(syllabus::SyllabusStatus::APPROVED);
        syllabus.setAuthorId("test-author");
        
        // Add a section
        syllabus::SyllabusSection section;
        section.section_id = "test-section";
        section.title = "Test Section";
        section.description = "Test Section Description";
        section.order = 1;
        
        // Add an exercise to the section
        syllabus::SyllabusExercise exercise;
        exercise.exercise_id = "test-exercise";
        exercise.title = "Test Exercise";
        exercise.description = "Test Exercise Description";
        exercise.order = 1;
        exercise.duration_minutes = 60;
        exercise.exercise_type = "SIMULATOR";
        exercise.objectives.push_back("Test Objective 1");
        exercise.objectives.push_back("Test Objective 2");
        
        // Add grading criteria to the exercise
        syllabus::GradingCriteria criteria;
        criteria.criteria_id = "test-criteria";
        criteria.name = "Test Criteria";
        criteria.description = "Test Criteria Description";
        criteria.is_required = true;
        
        // Add grade definitions to the criteria
        syllabus::GradeDefinition grade1;
        grade1.grade = 1;
        grade1.description = "Unsatisfactory";
        grade1.is_passing = false;
        criteria.grade_definitions.push_back(grade1);
        
        syllabus::GradeDefinition grade2;
        grade2.grade = 2;
        grade2.description = "Needs Improvement";
        grade2.is_passing = true;
        criteria.grade_definitions.push_back(grade2);
        
        syllabus::GradeDefinition grade3;
        grade3.grade = 3;
        grade3.description = "Meets Standards";
        grade3.is_passing = true;
        criteria.grade_definitions.push_back(grade3);
        
        syllabus::GradeDefinition grade4;
        grade4.grade = 4;
        grade4.description = "Exceeds Standards";
        grade4.is_passing = true;
        criteria.grade_definitions.push_back(grade4);
        
        exercise.grading_criteria.push_back(criteria);
        
        section.exercises.push_back(exercise);
        
        syllabus.addSection(section);
        
        return syllabus;
    }
    
    void setupMockRepositoryResponses() {
        // Setup record repository responses
        ON_CALL(*db_connection_, executeQuery(_, _))
            .WillByDefault(Return(persistence::PgResult(nullptr)));
        
        ON_CALL(*db_connection_, queryFirstRowAsJson(_, _))
            .WillByDefault(Return(nlohmann::json::object()));
        
        ON_CALL(*db_connection_, queryAllRowsAsJson(_, _))
            .WillByDefault(Return(nlohmann::json::array()));
        
        // Add specific mock responses as needed for tests
    }
    
    // Helper methods for tests
    etr::TrainingRecord convertToProtoRecord(const records::TrainingRecord& record) {
        etr::TrainingRecord proto_record;
        
        proto_record.set_record_id(record.getRecordId());
        proto_record.set_trainee_id(record.getTraineeId());
        proto_record.set_instructor_id(record.getInstructorId());
        proto_record.set_record_type(static_cast<etr::RecordType>(
            static_cast<int>(record.getRecordType()) + 1
        ));
        proto_record.set_course_id(record.getCourseId());
        proto_record.set_syllabus_id(record.getSyllabusId());
        proto_record.set_exercise_id(record.getExerciseId());
        
        proto_record.set_date(
            std::chrono::duration_cast<std::chrono::milliseconds>(
                record.getDate().time_since_epoch()
            ).count()
        );
        
        proto_record.set_duration_minutes(record.getDurationMinutes());
        proto_record.set_location(record.getLocation());
        proto_record.set_aircraft_type(record.getAircraftType());
        
        // Add grades
        for (const auto& grade : record.getGrades()) {
            auto* proto_grade = proto_record.add_grades();
            proto_grade->set_criteria_id(grade.criteria_id);
            proto_grade->set_criteria_name(grade.criteria_name);
            proto_grade->set_grade(grade.grade);
            proto_grade->set_comments(grade.comments);
        }
        
        // Add attachments
        for (const auto& attachment : record.getAttachments()) {
            proto_record.add_attachments(attachment);
        }
        
        proto_record.set_comments(record.getComments());
        proto_record.set_is_draft(record.isDraft());
        
        return proto_record;
    }
    
    // Member variables
    std::shared_ptr<MockDatabaseConnection> db_connection_;
    std::shared_ptr<records::RecordRepository> record_repository_;
    std::shared_ptr<compliance::ComplianceRepository> compliance_repository_;
    std::shared_ptr<syllabus::SyllabusRepository> syllabus_repository_;
    
    std::shared_ptr<records::RecordService> record_service_;
    std::shared_ptr<signature::X509DigitalSignatureService> signature_service_;
    std::shared_ptr<compliance::ComplianceService> compliance_service_;
    std::shared_ptr<syllabus::SyllabusService> syllabus_service_;
    
    std::unique_ptr<service::ETRServiceImpl> etr_service_;
    
    records::TrainingRecord test_record_;
    syllabus::Syllabus test_syllabus_;
};

// Test Cases

TEST_F(ETRServiceIntegrationTest, CreateTrainingRecordFlow) {
    // Setup mock for createRecord
    auto pgResult = persistence::PgResult(nullptr); // Mock empty result
    EXPECT_CALL(*db_connection_, executeQuery(
        HasSubstr("INSERT INTO etr.training_records"), _))
        .WillOnce(Return(pgResult));
    
    // Convert internal record to proto
    etr::TrainingRecord proto_record = convertToProtoRecord(test_record_);
    
    // Setup context and response
    grpc::ServerContext context;
    etr::RecordResponse response;
    
    // Add authentication metadata
    context.AddMetadata("authorization", "Bearer test_token");
    
    // Call the service method
    auto status = etr_service_->CreateTrainingRecord(&context, &proto_record, &response);
    
    // Verify the result
    EXPECT_TRUE(status.ok()) << status.error_message();
    EXPECT_TRUE(response.success());
    EXPECT_FALSE(response.record_id().empty());
}

TEST_F(ETRServiceIntegrationTest, GetTrainingRecordFlow) {
    // Setup mock for getRecord
    nlohmann::json record_json = test_record_.toJson();
    EXPECT_CALL(*db_connection_, queryFirstRowAsJson(
        HasSubstr("SELECT * FROM etr.training_records"), _))
        .WillOnce(Return(record_json));
    
    // Setup context and request/response
    grpc::ServerContext context;
    etr::RecordRequest request;
    etr::TrainingRecord response;
    
    // Add authentication metadata
    context.AddMetadata("authorization", "Bearer test_token");
    
    // Set request parameters
    request.set_record_id("test-record-id");
    
    // Call the service method
    auto status = etr_service_->GetTrainingRecord(&context, &request, &response);
    
    // Verify the result
    EXPECT_TRUE(status.ok()) << status.error_message();
    EXPECT_EQ(response.record_id(), "test-record-id");
    EXPECT_EQ(response.trainee_id(), "test-trainee");
    EXPECT_EQ(response.instructor_id(), "test-instructor");
}

TEST_F(ETRServiceIntegrationTest, SignRecordFlow) {
    // Setup mock for getRecord and updateRecord
    nlohmann::json record_json = test_record_.toJson();
    EXPECT_CALL(*db_connection_, queryFirstRowAsJson(
        HasSubstr("SELECT * FROM etr.training_records"), _))
        .WillOnce(Return(record_json));
    
    auto pgResult = persistence::PgResult(nullptr); // Mock empty result
    EXPECT_CALL(*db_connection_, executeQuery(
        HasSubstr("UPDATE etr.training_records"), _))
        .WillOnce(Return(pgResult));
    
    // Setup context and request/response
    grpc::ServerContext context;
    etr::SignatureRequest request;
    etr::SignatureResponse response;
    
    // Add authentication metadata
    context.AddMetadata("authorization", "Bearer test_token");
    
    // Set request parameters
    request.set_record_id("test-record-id");
    request.set_signer_id("test-instructor");
    request.set_is_instructor(true);
    
    // Create dummy signature data
    std::vector<uint8_t> signature_data(32, 1); // 32 bytes of 1s
    request.set_signature_data(signature_data.data(), signature_data.size());
    
    // Create mock certificate data
    std::string cert_data = "-----BEGIN CERTIFICATE-----\n"
                           "MIIDvTCCAqWgAwIBAgIUJjw/8D5VHf9WihxF5AvZkbA1VBcwDQYJKoZIhvcNAQEL\n"
                           "BQAwbjELMAkGA1UEBhMCVVMxCzAJBgNVBAgMAkNBMRYwFAYDVQQHDA1TYW4gRnJh\n"
                           "bmNpc2NvMRAwDgYDVQQKDAdUZXN0IE9yZzETMBEGA1UECwwKRW5naW5lZXJpbmcx\n"
                           "DzANBgNVBAMMBnRlc3RDQTAeFw0yMDAzMDEwMDAwMDBaFw0zMDAzMDEwMDAwMDBa\n"
                           "MG4xCzAJBgNVBAYTAlVTMQswCQYDVQQIDAJDQTEWMBQGA1UEBwwNU2FuIEZyYW5j\n"
                           "aXNjbzEQMA4GA1UECgwHVGVzdCBPcmcxEzARBgNVBAsMCkVuZ2luZWVyaW5nMQ8w\n"
                           "DQYDVQQDDAZpeG90ZXN0MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA\n"
                           "y8kvL7wJjCqj4tnxLqSgAHjDNvPG7rSvYrQoiFnLZD0PnCN+9Mbz3qGQbZUYUhwJ\n"
                           "VVv7VxsZVFJUZY4zE6CxMcxJwbVc1xZOUBHLJTRWjDm7y5/YbfNLJkGXlS7WYgQ1\n"
                           "sCOl+B1nsQ5qpvWYM+di4Yp0WTuCfCBPy5DoWr2vElKdapOJir1NXMpnH1MZ6W1n\n"
                           "7DfZ+5McQuXJUkBnNKpKPD1V/Bxf2Mq7Q3xN+oETBuYI/fUQzsNvhlQj/AeS0LLj\n"
                           "nECkY7msYAzCMXkPpnEMfHbYeaiYgGGY0bKas3PQ6yFQQCqW+6iyo22Y8x7DWMBO\n"
                           "yOjMGwmNvRvE3L8jG2sldwIDAQABo1MwUTAdBgNVHQ4EFgQUdjvMJPrRsvsMk5Tr\n"
                           "1wzl7iQMvbowHwYDVR0jBBgwFoAUdjvMJPrRsvsMk5Tr1wzl7iQMvbowDwYDVR0T\n"
                           "AQH/BAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAGR/9vbpCBaE16QhojmYH1kKd\n"
                           "rkziNl9k5TYTwJgptAMStCH93HEUihEwo9QzO/jSVGGJQ1I3bNJ+lUoiWNQiB9KP\n"
                           "kOKvYjG9GYuXDnKvKlkr+Pvo9iGUG8D5HHXcYRZzOE80TGMZpPwGEpOC1Y8pHZPT\n"
                           "GkNlCnDmVSIbBJzW/GBhP0KlMX+qMrm+KgFJWnzCPpviMdFCYw1gTQKYcQ1OHh2z\n"
                           "v9i+sRUJZVTgFPYOTGZlFXgUDQ9P9PW+Zv8d3dhmELmXwFsFySRvQJ4ZJGnIuxkJ\n"
                           "qE6Yg0sINl985SdjHkzKFYRqVGBBQBCNLNTd7dOdAp8B59H2nmOPwyZx9ABH4w==\n"
                           "-----END CERTIFICATE-----\n";
    request.set_certificate_data(cert_data);
    
    // Call the service method
    auto status = etr_service_->SignRecord(&context, &request, &response);
    
    // Verify the result - this should fail in integration test without a real certificate
    // but we're testing the flow, not the actual signature verification
    EXPECT_FALSE(status.ok());
}

TEST_F(ETRServiceIntegrationTest, CheckComplianceFlow) {
    // Setup mock for compliance check
    EXPECT_CALL(*db_connection_, queryAllRowsAsJson(
        HasSubstr("SELECT * FROM etr.compliance_requirements"), _))
        .WillOnce(Return(nlohmann::json::array({
            {
                {"requirement_id", "FAA-61.57-1"},
                {"requirement_name", "Recent Flight Experience"},
                {"regulation_id", "FAA-61"},
                {"regulation_name", "Pilot Certification"},
                {"regulation_reference", "61.57(a)"},
                {"description", "Recent takeoff and landing experience"},
                {"required_count", 3},
                {"duration_days", 90}
            }
        })));
    
    EXPECT_CALL(*db_connection_, queryAllRowsAsJson(
        HasSubstr("SELECT * FROM etr.training_records"), _))
        .WillOnce(Return(nlohmann::json::array({test_record_.toJson()})));
    
    // Setup context and request/response
    grpc::ServerContext context;
    etr::ComplianceRequest request;
    etr::ComplianceResponse response;
    
    // Add authentication metadata
    context.AddMetadata("authorization", "Bearer test_token");
    
    // Set request parameters
    request.set_trainee_id("test-trainee");
    request.set_regulation_id("FAA-61");
    request.set_certification_type("CPL");
    
    // Call the service method
    auto status = etr_service_->CheckCompliance(&context, &request, &response);
    
    // Verify the result
    EXPECT_TRUE(status.ok()) << status.error_message();
    EXPECT_FALSE(response.is_compliant()); // Not compliant with only one record
    EXPECT_GT(response.compliance_items_size(), 0);
}

// More tests for other service methods...

int main(int argc, char** argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
#pragma once

#include <string>
#include <memory>
#include <mutex>
#include <spdlog/spdlog.h>
#include <spdlog/sinks/rotating_file_sink.h>
#include <spdlog/sinks/stdout_color_sinks.h>

namespace etr {
namespace logging {

/**
 * @brief Log level enumeration
 */
enum class LogLevel {
    TRACE = spdlog::level::trace,
    DEBUG = spdlog::level::debug,
    INFO = spdlog::level::info,
    WARN = spdlog::level::warn,
    ERROR = spdlog::level::err,
    CRITICAL = spdlog::level::critical,
    OFF = spdlog::level::off
};

/**
 * @brief Convert string to log level
 * @param level Level string (case-insensitive)
 * @return LogLevel value
 */
LogLevel logLevelFromString(const std::string& level);

/**
 * @brief Convert log level to string
 * @param level LogLevel value
 * @return Level string
 */
std::string logLevelToString(LogLevel level);

/**
 * @brief Logging service
 */
class Logger {
public:
    /**
     * @brief Get the singleton logger instance
     * @return Logger instance
     */
    static Logger& getInstance();
    
    /**
     * @brief Initialize the logger
     * @param service_name Service name for log identification
     * @param log_level Default log level
     * @param log_path Path to log file (empty for console only)
     * @param max_file_size Maximum log file size in bytes
     * @param max_files Maximum number of log files for rotation
     * @param console_logging Whether to log to console
     */
    void initialize(
        const std::string& service_name,
        LogLevel log_level = LogLevel::INFO,
        const std::string& log_path = "",
        size_t max_file_size = 10 * 1024 * 1024,
        size_t max_files = 5,
        bool console_logging = true
    );
    
    /**
     * @brief Set the log level
     * @param level New log level
     */
    void setLevel(LogLevel level);
    
    /**
     * @brief Get the current log level
     * @return Current log level
     */
    LogLevel getLevel() const;
    
    /**
     * @brief Log a trace message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void trace(const std::string& fmt, const Args&... args) {
        logger_->trace(fmt, args...);
    }
    
    /**
     * @brief Log a debug message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void debug(const std::string& fmt, const Args&... args) {
        logger_->debug(fmt, args...);
    }
    
    /**
     * @brief Log an info message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void info(const std::string& fmt, const Args&... args) {
        logger_->info(fmt, args...);
    }
    
    /**
     * @brief Log a warning message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void warn(const std::string& fmt, const Args&... args) {
        logger_->warn(fmt, args...);
    }
    
    /**
     * @brief Log an error message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void error(const std::string& fmt, const Args&... args) {
        logger_->error(fmt, args...);
    }
    
    /**
     * @brief Log a critical message
     * @tparam Args Variadic template for format arguments
     * @param fmt Format string
     * @param args Format arguments
     */
    template<typename... Args>
    void critical(const std::string& fmt, const Args&... args) {
        logger_->critical(fmt, args...);
    }
    
    /**
     * @brief Flush the logger
     */
    void flush();
    
private:
    Logger();
    ~Logger() = default;
    
    Logger(const Logger&) = delete;
    Logger& operator=(const Logger&) = delete;
    
    std::shared_ptr<spdlog::logger> logger_;
    std::mutex mutex_;
    bool initialized_;
};

} // namespace logging
} // namespace etr
#include "logging/logger.h"
#include <algorithm>
#include <cctype>
#include <iostream>
#include <filesystem>
#include <spdlog/async.h>
#include <spdlog/sinks/daily_file_sink.h>

namespace etr {
namespace logging {

LogLevel logLevelFromString(const std::string& level) {
    std::string level_lower = level;
    std::transform(level_lower.begin(), level_lower.end(), level_lower.begin(),
                   [](unsigned char c) { return std::tolower(c); });
    
    if (level_lower == "trace") return LogLevel::TRACE;
    if (level_lower == "debug") return LogLevel::DEBUG;
    if (level_lower == "info") return LogLevel::INFO;
    if (level_lower == "warn" || level_lower == "warning") return LogLevel::WARN;
    if (level_lower == "error" || level_lower == "err") return LogLevel::ERROR;
    if (level_lower == "critical" || level_lower == "fatal") return LogLevel::CRITICAL;
    if (level_lower == "off") return LogLevel::OFF;
    
    // Default to INFO if not recognized
    return LogLevel::INFO;
}

std::string logLevelToString(LogLevel level) {
    switch (level) {
        case LogLevel::TRACE: return "trace";
        case LogLevel::DEBUG: return "debug";
        case LogLevel::INFO: return "info";
        case LogLevel::WARN: return "warn";
        case LogLevel::ERROR: return "error";
        case LogLevel::CRITICAL: return "critical";
        case LogLevel::OFF: return "off";
        default: return "unknown";
    }
}

Logger::Logger() : initialized_(false) {
    // Create a default console logger until properly initialized
    logger_ = spdlog::stdout_color_mt("etr_service");
    logger_->set_level(spdlog::level::info);
}

Logger& Logger::getInstance() {
    static Logger instance;
    return instance;
}

void Logger::initialize(
    const std::string& service_name,
    LogLevel log_level,
    const std::string& log_path,
    size_t max_file_size,
    size_t max_files,
    bool console_logging
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    if (initialized_) {
        logger_->warn("Logger already initialized, skipping re-initialization");
        return;
    }
    
    try {
        // Register the async logger with a thread pool of 8 threads and a queue size of 8192
        spdlog::init_thread_pool(8192, 8);
        
        std::vector<spdlog::sink_ptr> sinks;
        
        // Add console output sink if enabled
        if (console_logging) {
            auto console_sink = std::make_shared<spdlog::sinks::stdout_color_sink_mt>();
            console_sink->set_level(static_cast<spdlog::level::level_enum>(log_level));
            sinks.push_back(console_sink);
        }
        
        // Add file sink if path provided
        if (!log_path.empty()) {
            std::filesystem::path log_dir = std::filesystem::path(log_path).parent_path();
            
            // Create log directory if it doesn't exist
            if (!log_dir.empty() && !std::filesystem::exists(log_dir)) {
                std::filesystem::create_directories(log_dir);
            }
            
            auto file_sink = std::make_shared<spdlog::sinks::rotating_file_sink_mt>(
                log_path, max_file_size, max_files);
            file_sink->set_level(static_cast<spdlog::level::level_enum>(log_level));
            sinks.push_back(file_sink);
        }
        
        // Create an async logger with multiple sinks
        logger_ = std::make_shared<spdlog::async_logger>(
            service_name, sinks.begin(), sinks.end(),
            spdlog::thread_pool(), spdlog::async_overflow_policy::block);
        
        // Set log pattern with timestamp, service name, and thread ID
        logger_->set_pattern("%Y-%m-%d %H:%M:%S.%e [%n] [%t] [%l] %v");
        
        // Set log level
        logger_->set_level(static_cast<spdlog::level::level_enum>(log_level));
        
        // Register the logger in the registry
        spdlog::register_logger(logger_);
        
        // Set as default logger
        spdlog::set_default_logger(logger_);
        
        initialized_ = true;
        
        logger_->info("Logger initialized for service: {}", service_name);
    }
    catch (const std::exception& ex) {
        std::cerr << "Logger initialization failed: " << ex.what() << std::endl;
        
        // Fallback to console logger
        logger_ = spdlog::stdout_color_mt(service_name);
        logger_->set_level(static_cast<spdlog::level::level_enum>(log_level));
        logger_->error("Failed to initialize logger with file sink: {}", ex.what());
    }
}

void Logger::setLevel(LogLevel level) {
    std::lock_guard<std::mutex> lock(mutex_);
    logger_->set_level(static_cast<spdlog::level::level_enum>(level));
    logger_->info("Log level set to: {}", logLevelToString(level));
}

LogLevel Logger::getLevel() const {
    return static_cast<LogLevel>(logger_->level());
}

void Logger::flush() {
    logger_->flush();
}

} // namespace logging
} // namespace etr
#include <iostream>
#include <memory>
#include <string>
#include <csignal>
#include <thread>
#include <chrono>
#include <fstream>
#include <sstream>

#include <grpcpp/grpcpp.h>
#include <grpcpp/health_check_service_interface.h>
#include <grpcpp/ext/proto_server_reflection_plugin.h>
#include <nlohmann/json.hpp>

#include "service/etr_service_impl.h"
#include "records/record_service.h"
#include "records/record_repository.h"
#include "signature/digital_signature.h"
#include "compliance/compliance_service.h"
#include "compliance/compliance_repository.h"
#include "syllabus/syllabus_service.h"
#include "syllabus/syllabus_repository.h"
#include "persistence/database_connection.h"
#include "logging/logger.h"
#include "metrics/metrics_service.h"

using namespace etr;

// Global flag for graceful shutdown
std::atomic<bool> running{true};

// Signal handler
void signalHandler(int signal) {
    logging::Logger::getInstance().info("Received signal {}, shutting down...", signal);
    running = false;
}

// Load configuration from file
nlohmann::json loadConfig(const std::string& config_path) {
    try {
        std::ifstream config_file(config_path);
        if (!config_file.is_open()) {
            throw std::runtime_error("Failed to open config file: " + config_path);
        }
        
        nlohmann::json config;
        config_file >> config;
        return config;
    } catch (const std::exception& e) {
        std::cerr << "Error loading configuration: " << e.what() << std::endl;
        return nlohmann::json::object();
    }
}

int main(int argc, char** argv) {
    try {
        // Register signal handlers
        std::signal(SIGINT, signalHandler);
        std::signal(SIGTERM, signalHandler);
        
        // Load configuration
        std::string config_path = "config/config.json";
        if (argc > 1) {
            config_path = argv[1];
        }
        
        auto config = loadConfig(config_path);
        
        // Initialize logger
        logging::Logger::getInstance().initialize(
            "etr-service",
            logging::LogLevel::INFO,
            config.value("logging", nlohmann::json::object()).value("file_path", "logs/etr-service.log")
        );
        
        logging::Logger::getInstance().info("ETR Service starting up");
        
        // Initialize metrics
        std::string metrics_host = config.value("metrics", nlohmann::json::object()).value("host", "0.0.0.0");
        int metrics_port = config.value("metrics", nlohmann::json::object()).value("port", 9103);
        
        metrics::MetricsService::getInstance().initialize(
            "etr-service",
            true,
            metrics_host,
            metrics_port
        );
        
        // Initialize database connection
        std::string db_host = config.value("database", nlohmann::json::object()).value("host", "localhost");
        int db_port = config.value("database", nlohmann::json::object()).value("port", 5432);
        std::string db_name = config.value("database", nlohmann::json::object()).value("name", "etr_db");
        std::string db_user = config.value("database", nlohmann::json::object()).value("user", "etr_user");
        std::string db_password = config.value("database", nlohmann::json::object()).value("password", "etr_password");
        
        auto db_connection = std::make_shared<persistence::DatabaseConnection>(
            db_host,
            db_port,
            db_name,
            db_user,
            db_password
        );
        
        if (!db_connection->connect()) {
            throw std::runtime_error("Failed to connect to database");
        }
        
        // Create repositories
        auto record_repository = std::make_shared<records::RecordRepository>(db_connection);
        auto certificate_repository = std::make_shared<signature::CertificateRepository>(db_connection);
        auto compliance_repository = std::make_shared<compliance::ComplianceRepository>(db_connection);
        auto syllabus_repository = std::make_shared<syllabus::SyllabusRepository>(db_connection);
        
        // Create services
        auto record_service = std::make_shared<records::RecordService>(record_repository);
        
        std::string ca_certificate_path = config.value("security", nlohmann::json::object()).value("ca_certificate_path", "");
        std::string crl_path = config.value("security", nlohmann::json::object()).value("crl_path", "");
        
        auto signature_service = std::make_shared<signature::X509DigitalSignatureService>(
            ca_certificate_path,
            crl_path
        );
        
        auto compliance_service = std::make_shared<compliance::ComplianceService>(
            compliance_repository,
            record_repository
        );
        
        auto syllabus_service = std::make_shared<syllabus::SyllabusService>(
            syllabus_repository,
            signature_service
        );
        
        // Initialize gRPC server
        std::string server_address = 
            config.value("server", nlohmann::json::object()).value("host", "0.0.0.0") + ":" + 
            std::to_string(config.value("server", nlohmann::json::object()).value("port", 50053));
        
        service::ETRServiceImpl service(
            record_service,
            signature_service,
            compliance_service,
            syllabus_service
        );
        
        grpc::EnableDefaultHealthCheckService(true);
        grpc::reflection::InitProtoReflectionServerBuilderPlugin();
        
        grpc::ServerBuilder builder;
        
        // Set authentication credentials if TLS is enabled
        if (config.value("security", nlohmann::json::object()).value("tls_enabled", false)) {
            std::string key_path = config.value("security", nlohmann::json::object()).value("key_path", "");
            std::string cert_path = config.value("security", nlohmann::json::object()).value("cert_path", "");
            
            std::ifstream key_file(key_path);
            std::ifstream cert_file(cert_path);
            
            if (!key_file.is_open() || !cert_file.is_open()) {
                throw std::runtime_error("Failed to open TLS key or certificate file");
            }
            
            std::stringstream key_buffer, cert_buffer;
            key_buffer << key_file.rdbuf();
            cert_buffer << cert_file.rdbuf();
            
            grpc::SslServerCredentialsOptions ssl_opts;
            ssl_opts.pem_key_cert_pairs.push_back({key_buffer.str(), cert_buffer.str()});
            
            builder.AddListeningPort(server_address, grpc::SslServerCredentials(ssl_opts));
        } else {
            builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());
        }
        
        // Add authentication interceptor
        // Note: In a real-world implementation, you would add proper authentication here
        
        builder.RegisterService(&service);
        
        // Set server options
        builder.SetMaxReceiveMessageSize(config.value("server", nlohmann::json::object()).value("max_message_size_mb", 100) * 1024 * 1024);
        builder.SetMaxSendMessageSize(config.value("server", nlohmann::json::object()).value("max_message_size_mb", 100) * 1024 * 1024);
        
        // Add metrics recorder
        // Note: In a real-world implementation, you would add a proper metrics interceptor here
        
        // Build and start server
        std::unique_ptr<grpc::Server> server(builder.BuildAndStart());
        logging::Logger::getInstance().info("Server listening on {}", server_address);
        
        // Create performance metrics
        auto& request_counter = metrics::MetricsService::getInstance().createCounter(
            "requests_total",
            "Total number of requests",
            {{"service", "etr-service"}}
        );
        
        auto& request_duration = metrics::MetricsService::getInstance().createHistogram(
            "request_duration_seconds",
            "Request duration in seconds",
            {{"service", "etr-service"}}
        );
        
        auto& active_connections = metrics::MetricsService::getInstance().createGauge(
            "active_connections",
            "Number of active connections",
            {{"service", "etr-service"}}
        );
        
        // Main loop
        while (running) {
            // Update metrics (in a real implementation, these would be updated by the interceptor)
            active_connections.Set(server->GetNumActiveConnections());
            
            // Sleep to avoid busy waiting
            std::this_thread::sleep_for(std::chrono::seconds(1));
        }
        
        // Graceful shutdown
        logging::Logger::getInstance().info("Shutting down server...");
        server->Shutdown();
        logging::Logger::getInstance().info("Server shutting down");
        
        // Shutdown metrics
        metrics::MetricsService::getInstance().shutdown();
        
        // Close database connection
        db_connection->disconnect();
        
        logging::Logger::getInstance().info("ETR Service shut down successfully");
        return 0;
    } catch (const std::exception& e) {
        std::cerr << "Fatal error: " << e.what() << std::endl;
        
        try {
            logging::Logger::getInstance().critical("Fatal error: {}", e.what());
        } catch (...) {
            // Ignore if logging fails
        }
        
        return 1;
    }
}
#pragma once

#include <string>
#include <memory>
#include <unordered_map>
#include <mutex>
#include <vector>
#include <thread>
#include <atomic>
#include <prometheus/counter.h>
#include <prometheus/gauge.h>
#include <prometheus/histogram.h>
#include <prometheus/registry.h>
#include <prometheus/exposer.h>
#include <prometheus/push_gateway.h>

#include "logging/logger.h"

namespace etr {
namespace metrics {

/**
 * @brief Metrics service for collecting and exposing metrics
 */
class MetricsService {
public:
    /**
     * @brief Get the singleton instance
     * @return MetricsService singleton
     */
    static MetricsService& getInstance();
    
    /**
     * @brief Initialize the metrics service
     * @param service_name Service name for metrics namespace
     * @param expose_http Enable HTTP exposition on given address:port
     * @param http_address Address to expose metrics on
     * @param http_port Port to expose metrics on
     * @param push_gateway Enable push gateway publishing
     * @param push_address Push gateway address
     * @param push_port Push gateway port
     * @param push_interval_sec Push interval in seconds
     */
    void initialize(
        const std::string& service_name,
        bool expose_http = true,
        const std::string& http_address = "0.0.0.0",
        int http_port = 9103,
        bool push_gateway = false,
        const std::string& push_address = "localhost",
        int push_port = 9091,
        int push_interval_sec = 15
    );
    
    /**
     * @brief Create or get a counter
     * @param name Counter name
     * @param help Counter help text
     * @param labels Counter labels
     * @return Counter reference
     */
    prometheus::Counter& createCounter(
        const std::string& name,
        const std::string& help,
        const std::map<std::string, std::string>& labels = {}
    );
    
    /**
     * @brief Create or get a gauge
     * @param name Gauge name
     * @param help Gauge help text
     * @param labels Gauge labels
     * @return Gauge reference
     */
    prometheus::Gauge& createGauge(
        const std::string& name,
        const std::string& help,
        const std::map<std::string, std::string>& labels = {}
    );
    
    /**
     * @brief Create or get a histogram
     * @param name Histogram name
     * @param help Histogram help text
     * @param labels Histogram labels
     * @param buckets Histogram buckets
     * @return Histogram reference
     */
    prometheus::Histogram& createHistogram(
        const std::string& name,
        const std::string& help,
        const std::map<std::string, std::string>& labels = {},
        const std::vector<double>& buckets = prometheus::Histogram::ExponentialBuckets(0.005, 2, 10)
    );
    
    /**
     * @brief Push metrics to push gateway
     * Called automatically by timer if push gateway is enabled
     */
    void pushMetrics();
    
    /**
     * @brief Start HTTP exposition server
     * Called automatically by initialize if expose_http is true
     */
    void startHttpServer();
    
    /**
     * @brief Stop HTTP exposition server and push timer
     */
    void shutdown();

private:
    MetricsService();
    ~MetricsService();
    
    MetricsService(const MetricsService&) = delete;
    MetricsService& operator=(const MetricsService&) = delete;
    
    std::shared_ptr<prometheus::Registry> registry_;
    std::string service_name_;
    
    // HTTP exposition
    bool expose_http_;
    std::string http_address_;
    int http_port_;
    std::unique_ptr<prometheus::Exposer> exposer_;
    
    // Push gateway
    bool push_gateway_;
    std::string push_address_;
    int push_port_;
    int push_interval_sec_;
    std::unique_ptr<prometheus::PushGateway> push_gateway_client_;
    
    // Push timer
    std::thread push_thread_;
    std::atomic<bool> running_;
    
    // Families cache
    std::unordered_map<std::string, prometheus::Family<prometheus::Counter>*> counter_families_;
    std::unordered_map<std::string, prometheus::Family<prometheus::Gauge>*> gauge_families_;
    std::unordered_map<std::string, prometheus::Family<prometheus::Histogram>*> histogram_families_;
    
    std::mutex mutex_;
};

/**
 * @brief Utility class for timing operations and recording metrics
 */
class ScopedTimer {
public:
    /**
     * @brief Constructor
     * @param histogram Histogram to record duration
     */
    explicit ScopedTimer(prometheus::Histogram& histogram);
    
    /**
     * @brief Destructor - records elapsed time
     */
    ~ScopedTimer();
    
private:
    prometheus::Histogram& histogram_;
    std::chrono::steady_clock::time_point start_time_;
};

} // namespace metrics
} // namespace etr
#include "metrics/metrics_service.h"
#include <thread>
#include <chrono>

namespace etr {
namespace metrics {

MetricsService::MetricsService()
    : registry_(std::make_shared<prometheus::Registry>()),
      expose_http_(false),
      http_port_(9103),
      push_gateway_(false),
      push_port_(9091),
      push_interval_sec_(15),
      running_(false) {
}

MetricsService::~MetricsService() {
    shutdown();
}

MetricsService& MetricsService::getInstance() {
    static MetricsService instance;
    return instance;
}

void MetricsService::initialize(
    const std::string& service_name,
    bool expose_http,
    const std::string& http_address,
    int http_port,
    bool push_gateway,
    const std::string& push_address,
    int push_port,
    int push_interval_sec
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    service_name_ = service_name;
    expose_http_ = expose_http;
    http_address_ = http_address;
    http_port_ = http_port;
    push_gateway_ = push_gateway;
    push_address_ = push_address;
    push_port_ = push_port;
    push_interval_sec_ = push_interval_sec;
    
    // Start HTTP exposition server if enabled
    if (expose_http_) {
        startHttpServer();
    }
    
    // Setup push gateway client if enabled
    if (push_gateway_) {
        std::string push_gateway_url = push_address_ + ":" + std::to_string(push_port_);
        push_gateway_client_ = std::make_unique<prometheus::PushGateway>(push_gateway_url);
        
        // Start push thread
        running_ = true;
        push_thread_ = std::thread([this]() {
            while (running_) {
                try {
                    pushMetrics();
                } 
                catch (const std::exception& e) {
                    logging::Logger::getInstance().error("Error pushing metrics: {}", e.what());
                }
                
                // Sleep for push interval
                for (int i = 0; i < push_interval_sec_ && running_; ++i) {
                    std::this_thread::sleep_for(std::chrono::seconds(1));
                }
            }
        });
    }
    
    logging::Logger::getInstance().info("MetricsService initialized for service: {}", service_name_);
}

prometheus::Counter& MetricsService::createCounter(
    const std::string& name,
    const std::string& help,
    const std::map<std::string, std::string>& labels
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Check if family exists
    auto family_it = counter_families_.find(name);
    if (family_it == counter_families_.end()) {
        // Create new family
        auto& family = prometheus::BuildCounter()
            .Name(name)
            .Help(help)
            .Register(*registry_);
        
        counter_families_[name] = &family;
        family_it = counter_families_.find(name);
        
        logging::Logger::getInstance().debug("Created counter family: {}", name);
    }
    
    // Create or get counter with labels
    return family_it->second->Add(labels);
}

prometheus::Gauge& MetricsService::createGauge(
    const std::string& name,
    const std::string& help,
    const std::map<std::string, std::string>& labels
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Check if family exists
    auto family_it = gauge_families_.find(name);
    if (family_it == gauge_families_.end()) {
        // Create new family
        auto& family = prometheus::BuildGauge()
            .Name(name)
            .Help(help)
            .Register(*registry_);
        
        gauge_families_[name] = &family;
        family_it = gauge_families_.find(name);
        
        logging::Logger::getInstance().debug("Created gauge family: {}", name);
    }
    
    // Create or get gauge with labels
    return family_it->second->Add(labels);
}

prometheus::Histogram& MetricsService::createHistogram(
    const std::string& name,
    const std::string& help,
    const std::map<std::string, std::string>& labels,
    const std::vector<double>& buckets
) {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // Check if family exists
    auto family_it = histogram_families_.find(name);
    if (family_it == histogram_families_.end()) {
        // Create new family
        auto& family = prometheus::BuildHistogram()
            .Name(name)
            .Help(help)
            .Buckets(buckets)
            .Register(*registry_);
        
        histogram_families_[name] = &family;
        family_it = histogram_families_.find(name);
        
        logging::Logger::getInstance().debug("Created histogram family: {}", name);
    }
    
    // Create or get histogram with labels
    return family_it->second->Add(labels);
}

void MetricsService::pushMetrics() {
    if (!push_gateway_ || !push_gateway_client_) {
        return;
    }
    
    try {
        push_gateway_client_->Push(registry_, service_name_, {{"instance", service_name_}});
        logging::Logger::getInstance().debug("Pushed metrics to push gateway");
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Failed to push metrics: {}", e.what());
    }
}

void MetricsService::startHttpServer() {
    if (!expose_http_) {
        return;
    }
    
    try {
        std::string endpoint = http_address_ + ":" + std::to_string(http_port_);
        exposer_ = std::make_unique<prometheus::Exposer>(endpoint);
        exposer_->RegisterCollectable(registry_);
        
        logging::Logger::getInstance().info("Started metrics HTTP server on {}", endpoint);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Failed to start metrics HTTP server: {}", e.what());
        expose_http_ = false;
    }
}

void MetricsService::shutdown() {
    // Stop push thread
    if (push_thread_.joinable()) {
        running_ = false;
        push_thread_.join();
    }
    
    // Clean up resources
    exposer_.reset();
    push_gateway_client_.reset();
    
    logging::Logger::getInstance().info("MetricsService shut down");
}

// ScopedTimer implementation

ScopedTimer::ScopedTimer(prometheus::Histogram& histogram)
    : histogram_(histogram), start_time_(std::chrono::steady_clock::now()) {
}

ScopedTimer::~ScopedTimer() {
    auto end_time = std::chrono::steady_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::seconds>(end_time - start_time_).count();
    histogram_.Observe(duration);
}

} // namespace metrics
} // namespace etr
syntax = "proto3";

package etr;

// Service definition for electronic training records
service ElectronicTrainingRecordsService {
  // Records management
  rpc CreateTrainingRecord (TrainingRecord) returns (RecordResponse);
  rpc GetTrainingRecord (RecordRequest) returns (TrainingRecord);
  rpc UpdateTrainingRecord (TrainingRecord) returns (RecordResponse);
  rpc DeleteTrainingRecord (RecordRequest) returns (RecordResponse);
  rpc ListTrainingRecords (ListRecordsRequest) returns (ListRecordsResponse);
  
  // Digital signature
  rpc SignRecord (SignatureRequest) returns (SignatureResponse);
  rpc VerifySignature (VerifyRequest) returns (VerifyResponse);
  
  // Compliance tracking
  rpc CheckCompliance (ComplianceRequest) returns (ComplianceResponse);
  rpc ListComplianceRequirements (ListComplianceRequest) returns (ListComplianceResponse);
  rpc MapRegulations (RegulationMappingRequest) returns (RegulationMappingResponse);
  
  // Syllabus management
  rpc CreateSyllabus (Syllabus) returns (SyllabusResponse);
  rpc GetSyllabus (SyllabusRequest) returns (Syllabus);
  rpc UpdateSyllabus (Syllabus) returns (SyllabusResponse);
  rpc DeleteSyllabus (SyllabusRequest) returns (SyllabusResponse);
  rpc ListSyllabi (ListSyllabiRequest) returns (ListSyllabiResponse);
  rpc TrackSyllabusChanges (SyllabusChangeRequest) returns (SyllabusChangeResponse);
}

// Record type
enum RecordType {
  UNKNOWN_RECORD = 0;
  TRAINING_SESSION = 1;
  ASSESSMENT = 2;
  CERTIFICATION = 3;
  QUALIFICATION = 4;
  ENDORSEMENT = 5;
}

// Training record
message TrainingRecord {
  string record_id = 1;
  string trainee_id = 2;
  string instructor_id = 3;
  RecordType record_type = 4;
  string course_id = 5;
  string syllabus_id = 6;
  string exercise_id = 7;
  int64 date = 8;  // Milliseconds since epoch
  int32 duration_minutes = 9;
  string location = 10;
  string aircraft_type = 11;
  repeated GradeItem grades = 12;
  repeated string attachments = 13;
  string comments = 14;
  SignatureInfo trainee_signature = 15;
  SignatureInfo instructor_signature = 16;
  bool is_draft = 17;
  int64 created_at = 18;  // Milliseconds since epoch
  int64 updated_at = 19;  // Milliseconds since epoch
  map<string, string> metadata = 20;
}

// Grade item
message GradeItem {
  string criteria_id = 1;
  string criteria_name = 2;
  int32 grade = 3;  // 1-4 scale
  string comments = 4;
}

// Signature information
message SignatureInfo {
  string signer_id = 1;
  string signer_name = 2;
  string certificate_id = 3;
  bytes signature_data = 4;
  int64 timestamp = 5;  // Milliseconds since epoch
  bool is_valid = 6;
}

// Record request
message RecordRequest {
  string record_id = 1;
}

// Record response
message RecordResponse {
  bool success = 1;
  string record_id = 2;
  string error_message = 3;
  int64 timestamp = 4;  // Milliseconds since epoch
}

// List records request
message ListRecordsRequest {
  string trainee_id = 1;
  string instructor_id = 2;
  string course_id = 3;
  string syllabus_id = 4;
  RecordType record_type = 5;
  int64 start_date = 6;  // Milliseconds since epoch
  int64 end_date = 7;  // Milliseconds since epoch
  int32 page = 8;
  int32 page_size = 9;
  string sort_by = 10;
  bool ascending = 11;
}

// List records response
message ListRecordsResponse {
  bool success = 1;
  repeated TrainingRecord records = 2;
  int32 total_count = 3;
  int32 page = 4;
  int32 page_size = 5;
  string error_message = 6;
}

// Signature request
message SignatureRequest {
  string record_id = 1;
  string signer_id = 2;
  string certificate_data = 3;
  bytes signature_data = 4;
  bool is_instructor = 5;
}

// Signature response
message SignatureResponse {
  bool success = 1;
  string record_id = 2;
  string error_message = 3;
  SignatureInfo signature = 4;
}

// Verify request
message VerifyRequest {
  string record_id = 1;
  string signer_id = 2;
}

// Verify response
message VerifyResponse {
  bool success = 1;
  string record_id = 2;
  string error_message = 3;
  bool is_valid = 4;
  SignatureInfo signature = 5;
}

// Compliance request
message ComplianceRequest {
  string trainee_id = 1;
  string regulation_id = 2;
  string certification_type = 3;
}

// Compliance response
message ComplianceResponse {
  bool success = 1;
  bool is_compliant = 2;
  repeated ComplianceItem compliance_items = 3;
  string error_message = 4;
}

// Compliance item
message ComplianceItem {
  string requirement_id = 1;
  string requirement_name = 2;
  string regulation_reference = 3;
  bool is_satisfied = 4;
  int32 required_count = 5;
  int32 completed_count = 6;
  repeated string satisfied_by_records = 7;
  int64 expiration_date = 8;  // Milliseconds since epoch, if applicable
}

// List compliance request
message ListComplianceRequest {
  string regulation_id = 1;
  string certification_type = 2;
}

// List compliance response
message ListComplianceResponse {
  bool success = 1;
  repeated ComplianceRequirement requirements = 2;
  string error_message = 3;
}

// Compliance requirement
message ComplianceRequirement {
  string requirement_id = 1;
  string requirement_name = 2;
  string regulation_id = 3;
  string regulation_name = 4;
  string regulation_reference = 5;
  string description = 6;
  int32 required_count = 7;
  int32 duration_days = 8;  // If time-limited requirement
  repeated string equivalent_requirements = 9;
}

// Regulation mapping request
message RegulationMappingRequest {
  string source_regulation_id = 1;
  string target_regulation_id = 2;
}

// Regulation mapping response
message RegulationMappingResponse {
  bool success = 1;
  repeated RegulationMapping mappings = 2;
  string error_message = 3;
}

// Regulation mapping
message RegulationMapping {
  string source_requirement_id = 1;
  string source_requirement_name = 2;
  string target_requirement_id = 3;
  string target_requirement_name = 4;
  double equivalence_factor = 5;  // 1.0 = full equivalence
  string notes = 6;
}

// Syllabus
message Syllabus {
  string syllabus_id = 1;
  string course_id = 2;
  string title = 3;
  string description = 4;
  string version = 5;
  int64 effective_date = 6;  // Milliseconds since epoch
  int64 expiration_date = 7;  // Milliseconds since epoch, optional
  string status = 8;  // DRAFT, APPROVED, ARCHIVED
  string author_id = 9;
  repeated SyllabusSection sections = 10;
  map<string, string> metadata = 11;
  int64 created_at = 12;  // Milliseconds since epoch
  int64 updated_at = 13;  // Milliseconds since epoch
  SignatureInfo approval_signature = 14;
}

// Syllabus section
message SyllabusSection {
  string section_id = 1;
  string title = 2;
  string description = 3;
  int32 order = 4;
  repeated SyllabusExercise exercises = 5;
}

// Syllabus exercise
message SyllabusExercise {
  string exercise_id = 1;
  string title = 2;
  string description = 3;
  int32 order = 4;
  int32 duration_minutes = 5;
  string exercise_type = 6;  // GROUND, SIMULATOR, FLIGHT, etc.
  repeated string objectives = 7;
  repeated string references = 8;
  repeated string equipment = 9;
  repeated GradingCriteria grading_criteria = 10;
  repeated string prerequisite_exercises = 11;
  map<string, string> metadata = 12;
}

// Grading criteria
message GradingCriteria {
  string criteria_id = 1;
  string name = 2;
  string description = 3;
  repeated GradeDefinition grade_definitions = 4;
  bool is_required = 5;
  map<string, string> regulation_references = 6;
}

// Grade definition
message GradeDefinition {
  int32 grade = 1;  // 1-4 scale
  string description = 2;
  bool is_passing = 3;
}

// Syllabus request
message SyllabusRequest {
  string syllabus_id = 1;
  string version = 2;  // Optional
}

// Syllabus response
message SyllabusResponse {
  bool success = 1;
  string syllabus_id = 2;
  string version = 3;
  string error_message = 4;
}

// List syllabi request
message ListSyllabiRequest {
  string course_id = 1;
  string status = 2;
  int64 effective_date = 3;  // Milliseconds since epoch
  int32 page = 4;
  int32 page_size = 5;
  string sort_by = 6;
  bool ascending = 7;
}

// List syllabi response
message ListSyllabiResponse {
  bool success = 1;
  repeated SyllabusSummary syllabi = 2;
  int32 total_count = 3;
  int32 page = 4;
  int32 page_size = 5;
  string error_message = 6;
}

// Syllabus summary
message SyllabusSummary {
  string syllabus_id = 1;
  string course_id = 2;
  string title = 3;
  string version = 4;
  int64 effective_date = 5;  // Milliseconds since epoch
  int64 expiration_date = 6;  // Milliseconds since epoch, optional
  string status = 7;
  string author_id = 8;
  int64 created_at = 9;  // Milliseconds since epoch
  int64 updated_at = 10;  // Milliseconds since epoch
}

// Syllabus change request
message SyllabusChangeRequest {
  string syllabus_id = 1;
  string from_version = 2;
  string to_version = 3;
}

// Syllabus change response
message SyllabusChangeResponse {
  bool success = 1;
  string syllabus_id = 2;
  string from_version = 3;
  string to_version = 4;
  repeated SyllabusChange changes = 5;
  string error_message = 6;
}

// Syllabus change
message SyllabusChange {
  string change_type = 1;  // ADDED, MODIFIED, REMOVED
  string element_type = 2;  // SECTION, EXERCISE, CRITERIA, etc.
  string element_id = 3;
  string parent_id = 4;  // Optional
  string description = 5;
  map<string, string> old_values = 6;
  map<string, string> new_values = 7;
  string rationale = 8;
  string author_id = 9;
  int64 timestamp = 10;  // Milliseconds since epoch
}
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <optional>
#include "records/record_model.h"
#include "persistence/database_connection.h"

namespace etr {
namespace records {

/**
 * @brief PostgreSQL record repository implementation
 */
class RecordRepository : public IRecordRepository {
public:
    /**
     * @brief Constructor
     * @param db_connection Database connection
     */
    explicit RecordRepository(std::shared_ptr<persistence::DatabaseConnection> db_connection);
    
    /**
     * @brief Destructor
     */
    ~RecordRepository() override;
    
    // IRecordRepository implementation
    std::string createRecord(const TrainingRecord& record) override;
    std::optional<TrainingRecord> getRecord(const std::string& record_id) override;
    bool updateRecord(const TrainingRecord& record) override;
    bool deleteRecord(const std::string& record_id) override;
    std::pair<std::vector<TrainingRecord>, int> listRecords(
        const std::optional<std::string>& trainee_id,
        const std::optional<std::string>& instructor_id,
        const std::optional<std::string>& course_id,
        const std::optional<std::string>& syllabus_id,
        const std::optional<RecordType>& record_type,
        const std::optional<std::chrono::system_clock::time_point>& start_date,
        const std::optional<std::chrono::system_clock::time_point>& end_date,
        int page,
        int page_size,
        const std::string& sort_by,
        bool ascending
    ) override;
    bool logAuditEvent(
        const std::string& record_id, 
        const std::string& action, 
        const std::string& user_id, 
        const std::string& details
    ) override;
    std::vector<nlohmann::json> getAuditLogs(const std::string& record_id) override;

private:
    /**
     * @brief Save record grades
     * @param record_id Record ID
     * @param grades Grades
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveGrades(
        const std::string& record_id, 
        const std::vector<GradeItem>& grades,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get record grades
     * @param record_id Record ID
     * @return Grades
     */
    std::vector<GradeItem> getGrades(const std::string& record_id);
    
    /**
     * @brief Save record attachments
     * @param record_id Record ID
     * @param attachments Attachments
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveAttachments(
        const std::string& record_id, 
        const std::vector<std::string>& attachments,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get record attachments
     * @param record_id Record ID
     * @return Attachments
     */
    std::vector<std::string> getAttachments(const std::string& record_id);
    
    /**
     * @brief Save record metadata
     * @param record_id Record ID
     * @param metadata Metadata
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveMetadata(
        const std::string& record_id, 
        const std::map<std::string, std::string>& metadata,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get record metadata
     * @param record_id Record ID
     * @return Metadata
     */
    std::map<std::string, std::string> getMetadata(const std::string& record_id);
    
    /**
     * @brief Save record signature
     * @param record_id Record ID
     * @param signature Signature
     * @param is_instructor Whether signature is from instructor
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveSignature(
        const std::string& record_id, 
        const SignatureInfo& signature,
        bool is_instructor,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get record signature
     * @param record_id Record ID
     * @param is_instructor Whether to get instructor signature
     * @return Signature or nullopt if not found
     */
    std::optional<SignatureInfo> getSignature(
        const std::string& record_id, 
        bool is_instructor
    );
    
    /**
     * @brief Generate parameters for record query
     * @param trainee_id Trainee ID (optional)
     * @param instructor_id Instructor ID (optional)
     * @param course_id Course ID (optional)
     * @param syllabus_id Syllabus ID (optional)
     * @param record_type Record type (optional)
     * @param start_date Start date (optional)
     * @param end_date End date (optional)
     * @return Pair of (query conditions, parameters)
     */
    std::pair<std::string, std::vector<persistence::PgParam>> generateQueryParams(
        const std::optional<std::string>& trainee_id,
        const std::optional<std::string>& instructor_id,
        const std::optional<std::string>& course_id,
        const std::optional<std::string>& syllabus_id,
        const std::optional<RecordType>& record_type,
        const std::optional<std::chrono::system_clock::time_point>& start_date,
        const std::optional<std::chrono::system_clock::time_point>& end_date
    );
    
    /**
     * @brief Extract record data from result row
     * @param result Result
     * @param row_index Row index
     * @return Training record
     */
    TrainingRecord extractRecordFromRow(const persistence::PgResult& result, int row_index);
    
    /**
     * @brief Generate unique ID
     * @return Unique ID
     */
    std::string generateUniqueId();
    
    std::shared_ptr<persistence::DatabaseConnection> db_connection_;
};

} // namespace records
} // namespace etr
#include "records/record_repository.h"
#include "logging/logger.h"
#include <uuid.h>
#include <chrono>
#include <sstream>

namespace etr {
namespace records {

RecordRepository::RecordRepository(std::shared_ptr<persistence::DatabaseConnection> db_connection)
    : db_connection_(std::move(db_connection)) {
    
    logging::Logger::getInstance().info("RecordRepository initialized");
}

RecordRepository::~RecordRepository() = default;

std::string RecordRepository::createRecord(const TrainingRecord& record) {
    auto transaction = db_connection_->createTransaction();
    
    try {
        // Generate a new ID if not provided
        std::string record_id = record.getRecordId();
        if (record_id.empty()) {
            record_id = generateUniqueId();
        }
        
        // Convert timestamps to database format
        int64_t date = std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getDate().time_since_epoch()).count();
        
        int64_t created_at = std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getCreatedAt().time_since_epoch()).count();
        
        int64_t updated_at = std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getUpdatedAt().time_since_epoch()).count();
        
        // Convert record type to string
        std::string record_type = recordTypeToString(record.getRecordType());
        
        // Insert record into database
        std::string query = R"(
            INSERT INTO etr.training_records(
                record_id, trainee_id, instructor_id, record_type, course_id, syllabus_id,
                exercise_id, date, duration_minutes, location, aircraft_type, comments,
                is_draft, created_at, updated_at
            ) VALUES (
                $1, $2, $3, $4::etr.record_type, $5, $6, $7, TO_TIMESTAMP($8/1000.0),
                $9, $10, $11, $12, $13, TO_TIMESTAMP($14/1000.0), TO_TIMESTAMP($15/1000.0)
            ) RETURNING record_id
        )";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false},
            {"trainee_id", record.getTraineeId(), persistence::PgParamType::TEXT, false},
            {"instructor_id", record.getInstructorId(), persistence::PgParamType::TEXT, false},
            {"record_type", record_type, persistence::PgParamType::TEXT, false},
            {"course_id", record.getCourseId(), persistence::PgParamType::TEXT, false},
            {"syllabus_id", record.getSyllabusId(), persistence::PgParamType::TEXT, false},
            {"exercise_id", record.getExerciseId(), persistence::PgParamType::TEXT, false},
            {"date", std::to_string(date), persistence::PgParamType::BIGINT, false},
            {"duration_minutes", std::to_string(record.getDurationMinutes()), persistence::PgParamType::INTEGER, false},
            {"location", record.getLocation(), persistence::PgParamType::TEXT, false},
            {"aircraft_type", record.getAircraftType(), persistence::PgParamType::TEXT, record.getAircraftType().empty()},
            {"comments", record.getComments(), persistence::PgParamType::TEXT, record.getComments().empty()},
            {"is_draft", record.isDraft() ? "true" : "false", persistence::PgParamType::BOOLEAN, false},
            {"created_at", std::to_string(created_at), persistence::PgParamType::BIGINT, false},
            {"updated_at", std::to_string(updated_at), persistence::PgParamType::BIGINT, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to insert record: {}", result.getErrorMessage());
            transaction.rollback();
            return "";
        }
        
        // Save grades, attachments, metadata, and signatures
        if (!saveGrades(record_id, record.getGrades(), transaction)) {
            logging::Logger::getInstance().error("Failed to save grades for record: {}", record_id);
            transaction.rollback();
            return "";
        }
        
        if (!saveAttachments(record_id, record.getAttachments(), transaction)) {
            logging::Logger::getInstance().error("Failed to save attachments for record: {}", record_id);
            transaction.rollback();
            return "";
        }
        
        if (!saveMetadata(record_id, record.getMetadata(), transaction)) {
            logging::Logger::getInstance().error("Failed to save metadata for record: {}", record_id);
            transaction.rollback();
            return "";
        }
        
        // Save trainee signature if present
        if (record.getTraineeSignature()) {
            if (!saveSignature(record_id, *record.getTraineeSignature(), false, transaction)) {
                logging::Logger::getInstance().error("Failed to save trainee signature for record: {}", record_id);
                transaction.rollback();
                return "";
            }
        }
        
        // Save instructor signature if present
        if (record.getInstructorSignature()) {
            if (!saveSignature(record_id, *record.getInstructorSignature(), true, transaction)) {
                logging::Logger::getInstance().error("Failed to save instructor signature for record: {}", record_id);
                transaction.rollback();
                return "";
            }
        }
        
        // Log audit event
        if (!logAuditEvent(record_id, "create", record.getInstructorId(), "Record created")) {
            logging::Logger::getInstance().error("Failed to log audit event for record: {}", record_id);
            transaction.rollback();
            return "";
        }
        
        // Commit transaction
        if (!transaction.commit()) {
            logging::Logger::getInstance().error("Failed to commit transaction for record: {}", record_id);
            return "";
        }
        
        logging::Logger::getInstance().info("Created record: {}", record_id);
        
        return record_id;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error creating record: {}", e.what());
        transaction.rollback();
        return "";
    }
}

std::optional<TrainingRecord> RecordRepository::getRecord(const std::string& record_id) {
    try {
        // Query the record
        std::string query = R"(
            SELECT record_id, trainee_id, instructor_id, record_type, course_id, syllabus_id,
                exercise_id, date, duration_minutes, location, aircraft_type, comments,
                is_draft, created_at, updated_at
            FROM etr.training_records
            WHERE record_id = $1
        )";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to query record {}: {}", 
                record_id, result.getErrorMessage());
            return std::nullopt;
        }
        
        if (result.getNumRows() == 0) {
            logging::Logger::getInstance().debug("Record not found: {}", record_id);
            return std::nullopt;
        }
        
        // Extract record from result
        TrainingRecord record = extractRecordFromRow(result, 0);
        
        // Load grades
        record.setGrades(getGrades(record_id));
        
        // Load attachments
        record.setAttachments(getAttachments(record_id));
        
        // Load metadata
        record.setMetadata(getMetadata(record_id));
        
        // Load trainee signature
        auto trainee_signature = getSignature(record_id, false);
        if (trainee_signature) {
            record.setTraineeSignature(*trainee_signature);
        }
        
        // Load instructor signature
        auto instructor_signature = getSignature(record_id, true);
        if (instructor_signature) {
            record.setInstructorSignature(*instructor_signature);
        }
        
        logging::Logger::getInstance().debug("Retrieved record: {}", record_id);
        
        return record;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error getting record {}: {}", record_id, e.what());
        return std::nullopt;
    }
}

bool RecordRepository::updateRecord(const TrainingRecord& record) {
    auto transaction = db_connection_->createTransaction();
    
    try {
        // Check if record exists
        std::string check_query = "SELECT 1 FROM etr.training_records WHERE record_id = $1";
        std::vector<persistence::PgParam> check_params = {
            {"record_id", record.getRecordId(), persistence::PgParamType::TEXT, false}
        };
        
        auto check_result = db_connection_->executeQuery(check_query, check_params);
        
        if (check_result.isEmpty() || check_result.hasError() || check_result.getNumRows() == 0) {
            logging::Logger::getInstance().error("Record not found for update: {}", record.getRecordId());
            transaction.rollback();
            return false;
        }
        
        // Convert timestamps to database format
        int64_t date = std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getDate().time_since_epoch()).count();
        
        int64_t updated_at = std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getUpdatedAt().time_since_epoch()).count();
        
        // Convert record type to string
        std::string record_type = recordTypeToString(record.getRecordType());
        
        // Update record in database
        std::string query = R"(
            UPDATE etr.training_records SET
                trainee_id = $2,
                instructor_id = $3,
                record_type = $4::etr.record_type,
                course_id = $5,
                syllabus_id = $6,
                exercise_id = $7,
                date = TO_TIMESTAMP($8/1000.0),
                duration_minutes = $9,
                location = $10,
                aircraft_type = $11,
                comments = $12,
                is_draft = $13,
                updated_at = TO_TIMESTAMP($14/1000.0)
            WHERE record_id = $1
        )";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record.getRecordId(), persistence::PgParamType::TEXT, false},
            {"trainee_id", record.getTraineeId(), persistence::PgParamType::TEXT, false},
            {"instructor_id", record.getInstructorId(), persistence::PgParamType::TEXT, false},
            {"record_type", record_type, persistence::PgParamType::TEXT, false},
            {"course_id", record.getCourseId(), persistence::PgParamType::TEXT, false},
            {"syllabus_id", record.getSyllabusId(), persistence::PgParamType::TEXT, false},
            {"exercise_id", record.getExerciseId(), persistence::PgParamType::TEXT, false},
            {"date", std::to_string(date), persistence::PgParamType::BIGINT, false},
            {"duration_minutes", std::to_string(record.getDurationMinutes()), persistence::PgParamType::INTEGER, false},
            {"location", record.getLocation(), persistence::PgParamType::TEXT, false},
            {"aircraft_type", record.getAircraftType(), persistence::PgParamType::TEXT, record.getAircraftType().empty()},
            {"comments", record.getComments(), persistence::PgParamType::TEXT, record.getComments().empty()},
            {"is_draft", record.isDraft() ? "true" : "false", persistence::PgParamType::BOOLEAN, false},
            {"updated_at", std::to_string(updated_at), persistence::PgParamType::BIGINT, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError() || result.getAffectedRows() == 0) {
            logging::Logger::getInstance().error("Failed to update record: {}", result.getErrorMessage());
            transaction.rollback();
            return false;
        }
        
        // Delete existing related data
        std::string delete_query = "DELETE FROM etr.record_grades WHERE record_id = $1";
        db_connection_->executeQuery(delete_query, {{"record_id", record.getRecordId(), persistence::PgParamType::TEXT, false}});
        
        delete_query = "DELETE FROM etr.record_attachments WHERE record_id = $1";
        db_connection_->executeQuery(delete_query, {{"record_id", record.getRecordId(), persistence::PgParamType::TEXT, false}});
        
        delete_query = "DELETE FROM etr.record_metadata WHERE record_id = $1";
        db_connection_->executeQuery(delete_query, {{"record_id", record.getRecordId(), persistence::PgParamType::TEXT, false}});
        
        // Delete signatures only if they have changed
        if (record.getTraineeSignature()) {
            delete_query = "DELETE FROM etr.record_signatures WHERE record_id = $1 AND is_instructor = false";
            db_connection_->executeQuery(delete_query, {{"record_id", record.getRecordId(), persistence::PgParamType::TEXT, false}});
        }
        
        if (record.getInstructorSignature()) {
            delete_query = "DELETE FROM etr.record_signatures WHERE record_id = $1 AND is_instructor = true";
            db_connection_->executeQuery(delete_query, {{"record_id", record.getRecordId(), persistence::PgParamType::TEXT, false}});
        }
        
        // Save updated related data
        if (!saveGrades(record.getRecordId(), record.getGrades(), transaction)) {
            logging::Logger::getInstance().error("Failed to save grades for record: {}", record.getRecordId());
            transaction.rollback();
            return false;
        }
        
        if (!saveAttachments(record.getRecordId(), record.getAttachments(), transaction)) {
            logging::Logger::getInstance().error("Failed to save attachments for record: {}", record.getRecordId());
            transaction.rollback();
            return false;
        }
        
        if (!saveMetadata(record.getRecordId(), record.getMetadata(), transaction)) {
            logging::Logger::getInstance().error("Failed to save metadata for record: {}", record.getRecordId());
            transaction.rollback();
            return false;
        }
        
        // Save trainee signature if present
        if (record.getTraineeSignature()) {
            if (!saveSignature(record.getRecordId(), *record.getTraineeSignature(), false, transaction)) {
                logging::Logger::getInstance().error("Failed to save trainee signature for record: {}", record.getRecordId());
                transaction.rollback();
                return false;
            }
        }
        
        // Save instructor signature if present
        if (record.getInstructorSignature()) {
            if (!saveSignature(record.getRecordId(), *record.getInstructorSignature(), true, transaction)) {
                logging::Logger::getInstance().error("Failed to save instructor signature for record: {}", record.getRecordId());
                transaction.rollback();
                return false;
            }
        }
        
        // Log audit event
        if (!logAuditEvent(record.getRecordId(), "update", record.getInstructorId(), "Record updated")) {
            logging::Logger::getInstance().error("Failed to log audit event for record: {}", record.getRecordId());
            transaction.rollback();
            return false;
        }
        
        // Commit transaction
        if (!transaction.commit()) {
            logging::Logger::getInstance().error("Failed to commit transaction for record: {}", record.getRecordId());
            return false;
        }
        
        logging::Logger::getInstance().info("Updated record: {}", record.getRecordId());
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error updating record: {}", e.what());
        transaction.rollback();
        return false;
    }
}

bool RecordRepository::deleteRecord(const std::string& record_id) {
    auto transaction = db_connection_->createTransaction();
    
    try {
        // Delete related data first (foreign key constraints will handle this,
        // but we'll do it explicitly for clarity)
        std::string delete_query = "DELETE FROM etr.record_grades WHERE record_id = $1";
        db_connection_->executeQuery(delete_query, {{"record_id", record_id, persistence::PgParamType::TEXT, false}});
        
        delete_query = "DELETE FROM etr.record_attachments WHERE record_id = $1";
        db_connection_->executeQuery(delete_query, {{"record_id", record_id, persistence::PgParamType::TEXT, false}});
        
        delete_query = "DELETE FROM etr.record_metadata WHERE record_id = $1";
        db_connection_->executeQuery(delete_query, {{"record_id", record_id, persistence::PgParamType::TEXT, false}});
        
        delete_query = "DELETE FROM etr.record_signatures WHERE record_id = $1";
        db_connection_->executeQuery(delete_query, {{"record_id", record_id, persistence::PgParamType::TEXT, false}});
        
        // Delete the record itself
        delete_query = "DELETE FROM etr.training_records WHERE record_id = $1";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false}
        };
        
        auto result = db_connection_->executeQuery(delete_query, params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to delete record: {}", result.getErrorMessage());
            transaction.rollback();
            return false;
        }
        
        if (result.getAffectedRows() == 0) {
            logging::Logger::getInstance().debug("Record not found for deletion: {}", record_id);
            transaction.rollback();
            return false;
        }
        
        // Log audit event
        if (!logAuditEvent(record_id, "delete", "system", "Record deleted")) {
            logging::Logger::getInstance().error("Failed to log audit event for record: {}", record_id);
            transaction.rollback();
            return false;
        }
        
        // Commit transaction
        if (!transaction.commit()) {
            logging::Logger::getInstance().error("Failed to commit transaction for record: {}", record_id);
            return false;
        }
        
        logging::Logger::getInstance().info("Deleted record: {}", record_id);
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error deleting record: {}", e.what());
        transaction.rollback();
        return false;
    }
}

std::pair<std::vector<TrainingRecord>, int> RecordRepository::listRecords(
    const std::optional<std::string>& trainee_id,
    const std::optional<std::string>& instructor_id,
    const std::optional<std::string>& course_id,
    const std::optional<std::string>& syllabus_id,
    const std::optional<RecordType>& record_type,
    const std::optional<std::chrono::system_clock::time_point>& start_date,
    const std::optional<std::chrono::system_clock::time_point>& end_date,
    int page,
    int page_size,
    const std::string& sort_by,
    bool ascending
) {
    try {
        // Build query conditions
        auto [conditions, condition_params] = generateQueryParams(
            trainee_id, 
            instructor_id, 
            course_id, 
            syllabus_id, 
            record_type, 
            start_date, 
            end_date
        );
        
        // Validate and sanitize sort column
        std::string sort_column;
        if (sort_by == "date" || sort_by == "created_at" || sort_by == "updated_at") {
            sort_column = sort_by;
        }
        else if (sort_by == "trainee") {
            sort_column = "trainee_id";
        }
        else if (sort_by == "instructor") {
            sort_column = "instructor_id";
        }
        else if (sort_by == "course") {
            sort_column = "course_id";
        }
        else if (sort_by == "syllabus") {
            sort_column = "syllabus_id";
        }
        else if (sort_by == "exercise") {
            sort_column = "exercise_id";
        }
        else if (sort_by == "type") {
            sort_column = "record_type";
        }
        else {
            // Default to date
            sort_column = "date";
        }
        
        // Build sort direction
        std::string sort_direction = ascending ? "ASC" : "DESC";
        
        // Calculate offset
        int offset = (page - 1) * page_size;
        
        // Build the query
        std::string query = R"(
            SELECT record_id, trainee_id, instructor_id, record_type, course_id, syllabus_id,
                exercise_id, date, duration_minutes, location, aircraft_type, comments,
                is_draft, created_at, updated_at
            FROM etr.training_records
        )";
        
        if (!conditions.empty()) {
            query += " WHERE " + conditions;
        }
        
        query += " ORDER BY " + sort_column + " " + sort_direction;
        query += " LIMIT " + std::to_string(page_size) + " OFFSET " + std::to_string(offset);
        
        // Execute query
        auto result = db_connection_->executeQuery(query, condition_params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to list records: {}", result.getErrorMessage());
            return {{}, 0};
        }
        
        // Extract records
        std::vector<TrainingRecord> records;
        for (int i = 0; i < result.getNumRows(); ++i) {
            records.push_back(extractRecordFromRow(result, i));
        }
        
        // Get total count for pagination
        std::string count_query = "SELECT COUNT(*) FROM etr.training_records";
        if (!conditions.empty()) {
            count_query += " WHERE " + conditions;
        }
        
        auto count_result = db_connection_->executeQuery(count_query, condition_params);
        
        int total_count = 0;
        if (!count_result.isEmpty() && !count_result.hasError() && count_result.getNumRows() > 0) {
            total_count = count_result.getInt(0, 0);
        }
        
        logging::Logger::getInstance().debug("Listed {} records (total: {})", records.size(), total_count);
        
        return {records, total_count};
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error listing records: {}", e.what());
        return {{}, 0};
    }
}

bool RecordRepository::logAuditEvent(
    const std::string& record_id, 
    const std::string& action, 
    const std::string& user_id, 
    const std::string& details
) {
    try {
        std::string query = R"(
            INSERT INTO etr.record_audit_log(
                record_id, action, user_id, details, timestamp
            ) VALUES (
                $1, $2, $3, $4, NOW()
            )
        )";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false},
            {"action", action, persistence::PgParamType::TEXT, false},
            {"user_id", user_id, persistence::PgParamType::TEXT, false},
            {"details", details, persistence::PgParamType::TEXT, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to log audit event: {}", result.getErrorMessage());
            return false;
        }
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error logging audit event: {}", e.what());
        return false;
    }
}

std::vector<nlohmann::json> RecordRepository::getAuditLogs(const std::string& record_id) {
    try {
        std::string query = R"(
            SELECT id, record_id, action, user_id, details, timestamp
            FROM etr.record_audit_log
            WHERE record_id = $1
            ORDER BY timestamp DESC
        )";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to get audit logs: {}", result.getErrorMessage());
            return {};
        }
        
        // Convert to JSON
        return result.getAllRowsAsJson();
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error getting audit logs: {}", e.what());
        return {};
    }
}

bool RecordRepository::saveGrades(
    const std::string& record_id, 
    const std::vector<GradeItem>& grades,
    persistence::Transaction& transaction
) {
    try {
        for (const auto& grade : grades) {
            std::string query = R"(
                INSERT INTO etr.record_grades(
                    record_id, criteria_id, criteria_name, grade, comments
                ) VALUES (
                    $1, $2, $3, $4, $5
                )
            )";
            
            std::vector<persistence::PgParam> params = {
                {"record_id", record_id, persistence::PgParamType::TEXT, false},
                {"criteria_id", grade.criteria_id, persistence::PgParamType::TEXT, false},
                {"criteria_name", grade.criteria_name, persistence::PgParamType::TEXT, false},
                {"grade", std::to_string(grade.grade), persistence::PgParamType::INTEGER, false},
                {"comments", grade.comments, persistence::PgParamType::TEXT, grade.comments.empty()}
            };
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                logging::Logger::getInstance().error("Failed to save grade: {}", result.getErrorMessage());
                return false;
            }
        }
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error saving grades: {}", e.what());
        return false;
    }
}

std::vector<GradeItem> RecordRepository::getGrades(const std::string& record_id) {
    try {
        std::string query = R"(
            SELECT criteria_id, criteria_name, grade, comments
            FROM etr.record_grades
            WHERE record_id = $1
        )";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to get grades: {}", result.getErrorMessage());
            return {};
        }
        
        std::vector<GradeItem> grades;
        for (int i = 0; i < result.getNumRows(); ++i) {
            GradeItem grade;
            grade.criteria_id = result.getString(i, "criteria_id");
            grade.criteria_name = result.getString(i, "criteria_name");
            grade.grade = result.getInt(i, "grade");
            grade.comments = result.getString(i, "comments");
            
            grades.push_back(grade);
        }
        
        return grades;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error getting grades: {}", e.what());
        return {};
    }
}

bool RecordRepository::saveAttachments(
    const std::string& record_id, 
    const std::vector<std::string>& attachments,
    persistence::Transaction& transaction
) {
    try {
        for (const auto& attachment : attachments) {
            std::string query = R"(
                INSERT INTO etr.record_attachments(
                    record_id, attachment_path, attachment_name, content_type, size_bytes
                ) VALUES (
                    $1, $2, $3, $4, $5
                )
            )";
            
            // Extract attachment name from path
            std::string attachment_name = attachment;
            auto pos = attachment.find_last_of('/');
            if (pos != std::string::npos) {
                attachment_name = attachment.substr(pos + 1);
            }
            
            // In a real implementation, content type and size would be determined
            // from the actual file. For now, we'll use placeholder values.
            std::string content_type = "application/octet-stream";
            int64_t size_bytes = 0;
            
            std::vector<persistence::PgParam> params = {
                {"record_id", record_id, persistence::PgParamType::TEXT, false},
                {"attachment_path", attachment, persistence::PgParamType::TEXT, false},
                {"attachment_name", attachment_name, persistence::PgParamType::TEXT, false},
                {"content_type", content_type, persistence::PgParamType::TEXT, false},
                {"size_bytes", std::to_string(size_bytes), persistence::PgParamType::BIGINT, false}
            };
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                logging::Logger::getInstance().error("Failed to save attachment: {}", result.getErrorMessage());
                return false;
            }
        }
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error saving attachments: {}", e.what());
        return false;
    }
}

std::vector<std::string> RecordRepository::getAttachments(const std::string& record_id) {
    try {
        std::string query = R"(
            SELECT attachment_path
            FROM etr.record_attachments
            WHERE record_id = $1
        )";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to get attachments: {}", result.getErrorMessage());
            return {};
        }
        
        std::vector<std::string> attachments;
        for (int i = 0; i < result.getNumRows(); ++i) {
            attachments.push_back(result.getString(i, "attachment_path"));
        }
        
        return attachments;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error getting attachments: {}", e.what());
        return {};
    }
}

bool RecordRepository::saveMetadata(
    const std::string& record_id, 
    const std::map<std::string, std::string>& metadata,
    persistence::Transaction& transaction
) {
    try {
        for (const auto& [key, value] : metadata) {
            std::string query = R"(
                INSERT INTO etr.record_metadata(
                    record_id, key, value
                ) VALUES (
                    $1, $2, $3
                )
            )";
            
            std::vector<persistence::PgParam> params = {
                {"record_id", record_id, persistence::PgParamType::TEXT, false},
                {"key", key, persistence::PgParamType::TEXT, false},
                {"value", value, persistence::PgParamType::TEXT, false}
            };
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                logging::Logger::getInstance().error("Failed to save metadata: {}", result.getErrorMessage());
                return false;
            }
        }
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error saving metadata: {}", e.what());
        return false;
    }
}

std::map<std::string, std::string> RecordRepository::getMetadata(const std::string& record_id) {
    try {
        std::string query = R"(
            SELECT key, value
            FROM etr.record_metadata
            WHERE record_id = $1
        )";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to get metadata: {}", result.getErrorMessage());
            return {};
        }
        
        std::map<std::string, std::string> metadata;
        for (int i = 0; i < result.getNumRows(); ++i) {
            metadata[result.getString(i, "key")] = result.getString(i, "value");
        }
        
        return metadata;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error getting metadata: {}", e.what());
        return {};
    }
}

bool RecordRepository::saveSignature(
    const std::string& record_id, 
    const SignatureInfo& signature,
    bool is_instructor,
    persistence::Transaction& transaction
) {
    try {
        std::string query = R"(
            INSERT INTO etr.record_signatures(
                record_id, signer_id, signer_name, certificate_id, signature_data,
                timestamp, is_valid, is_instructor
            ) VALUES (
                $1, $2, $3, $4, $5, TO_TIMESTAMP($6/1000.0), $7, $8
            )
        )";
        
        int64_t timestamp = std::chrono::duration_cast<std::chrono::milliseconds>(
            signature.timestamp.time_since_epoch()).count();
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false},
            {"signer_id", signature.signer_id, persistence::PgParamType::TEXT, false},
            {"signer_name", signature.signer_name, persistence::PgParamType::TEXT, false},
            {"certificate_id", signature.certificate_id, persistence::PgParamType::TEXT, signature.certificate_id.empty()},
            {"signature_data", "", persistence::PgParamType::BYTEA, signature.signature_data.empty()},
            {"timestamp", std::to_string(timestamp), persistence::PgParamType::BIGINT, false},
            {"is_valid", signature.is_valid ? "true" : "false", persistence::PgParamType::BOOLEAN, false},
            {"is_instructor", is_instructor ? "true" : "false", persistence::PgParamType::BOOLEAN, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError()) {
            logging::Logger::getInstance().error("Failed to save signature: {}", result.getErrorMessage());
            return false;
        }
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error saving signature: {}", e.what());
        return false;
    }
}

std::optional<SignatureInfo> RecordRepository::getSignature(
    const std::string& record_id, 
    bool is_instructor
) {
    try {
        std::string query = R"(
            SELECT signer_id, signer_name, certificate_id, signature_data, 
                timestamp, is_valid
            FROM etr.record_signatures
            WHERE record_id = $1 AND is_instructor = $2
        )";
        
        std::vector<persistence::PgParam> params = {
            {"record_id", record_id, persistence::PgParamType::TEXT, false},
            {"is_instructor", is_instructor ? "true" : "false", persistence::PgParamType::BOOLEAN, false}
        };
        
        auto result = db_connection_->executeQuery(query, params);
        
        if (result.isEmpty() || result.hasError() || result.getNumRows() == 0) {
            return std::nullopt;
        }
        
        SignatureInfo signature;
        signature.signer_id = result.getString(0, "signer_id");
        signature.signer_name = result.getString(0, "signer_name");
        signature.certificate_id = result.getString(0, "certificate_id");
        
        // Get signature data as binary
        signature.signature_data = result.getBinary(0, "signature_data");
        
        // Get timestamp
        auto timestamp_opt = result.getTimestamp(0, "timestamp");
        if (timestamp_opt) {
            signature.timestamp = *timestamp_opt;
        } else {
            signature.timestamp = std::chrono::system_clock::now();
        }
        
        signature.is_valid = result.getBool(0, "is_valid");
        
        return signature;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error getting signature: {}", e.what());
        return std::nullopt;
    }
}

std::pair<std::string, std::vector<persistence::PgParam>> RecordRepository::generateQueryParams(
    const std::optional<std::string>& trainee_id,
    const std::optional<std::string>& instructor_id,
    const std::optional<std::string>& course_id,
    const std::optional<std::string>& syllabus_id,
    const std::optional<RecordType>& record_type,
    const std::optional<std::chrono::system_clock::time_point>& start_date,
    const std::optional<std::chrono::system_clock::time_point>& end_date
) {
    std::vector<std::string> conditions;
    std::vector<persistence::PgParam> params;
    
    int param_index = 1;
    
    if (trainee_id) {
        conditions.push_back("trainee_id = $" + std::to_string(param_index));
        params.push_back({"trainee_id", *trainee_id, persistence::PgParamType::TEXT, false});
        param_index++;
    }
    
    if (instructor_id) {
        conditions.push_back("instructor_id = $" + std::to_string(param_index));
        params.push_back({"instructor_id", *instructor_id, persistence::PgParamType::TEXT, false});
        param_index++;
    }
    
    if (course_id) {
        conditions.push_back("course_id = $" + std::to_string(param_index));
        params.push_back({"course_id", *course_id, persistence::PgParamType::TEXT, false});
        param_index++;
    }
    
    if (syllabus_id) {
        conditions.push_back("syllabus_id = $" + std::to_string(param_index));
        params.push_back({"syllabus_id", *syllabus_id, persistence::PgParamType::TEXT, false});
        param_index++;
    }
    
    if (record_type) {
        conditions.push_back("record_type = $" + std::to_string(param_index) + "::etr.record_type");
        params.push_back({"record_type", recordTypeToString(*record_type), persistence::PgParamType::TEXT, false});
        param_index++;
    }
    
    if (start_date) {
        int64_t start = std::chrono::duration_cast<std::chrono::milliseconds>(
            start_date->time_since_epoch()).count();
        conditions.push_back("date >= TO_TIMESTAMP($" + std::to_string(param_index) + "/1000.0)");
        params.push_back({"start_date", std::to_string(start), persistence::PgParamType::BIGINT, false});
        param_index++;
    }
    
    if (end_date) {
        int64_t end = std::chrono::duration_cast<std::chrono::milliseconds>(
            end_date->time_since_epoch()).count();
        conditions.push_back("date <= TO_TIMESTAMP($" + std::to_string(param_index) + "/1000.0)");
        params.push_back({"end_date", std::to_string(end), persistence::PgParamType::BIGINT, false});
        param_index++;
    }
    
    std::string condition_str;
    if (!conditions.empty()) {
        condition_str = conditions[0];
        for (size_t i = 1; i < conditions.size(); ++i) {
            condition_str += " AND " + conditions[i];
        }
    }
    
    return {condition_str, params};
}

TrainingRecord RecordRepository::extractRecordFromRow(const persistence::PgResult& result, int row_index) {
    TrainingRecord record(result.getString(row_index, "record_id"));
    
    record.setTraineeId(result.getString(row_index, "trainee_id"));
    record.setInstructorId(result.getString(row_index, "instructor_id"));
    
    // Convert record type from string
    std::string record_type_str = result.getString(row_index, "record_type");
    record.setRecordType(recordTypeFromString(record_type_str));
    
    record.setCourseId(result.getString(row_index, "course_id"));
    record.setSyllabusId(result.getString(row_index, "syllabus_id"));
    record.setExerciseId(result.getString(row_index, "exercise_id"));
    
    // Get timestamps
    auto date_opt = result.getTimestamp(row_index, "date");
    if (date_opt) {
        record.setDate(*date_opt);
    }
    
    record.setDurationMinutes(result.getInt(row_index, "duration_minutes"));
    record.setLocation(result.getString(row_index, "location"));
    record.setAircraftType(result.getString(row_index, "aircraft_type"));
    record.setComments(result.getString(row_index, "comments"));
    record.setDraft(result.getBool(row_index, "is_draft"));
    
    auto created_at_opt = result.getTimestamp(row_index, "created_at");
    if (created_at_opt) {
        record.setCreatedAt(*created_at_opt);
    }
    
    auto updated_at_opt = result.getTimestamp(row_index, "updated_at");
    if (updated_at_opt) {
        record.setUpdatedAt(*updated_at_opt);
    }
    
    return record;
}

std::string RecordRepository::generateUniqueId() {
    uuids::uuid uuid = uuids::uuid_system_generator{}();
    return uuids::to_string(uuid);
}

} // namespace records
} // namespace etr
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <optional>
#include "records/record_model.h"

namespace etr {
namespace records {

/**
 * @brief Record service interface
 */
class IRecordService {
public:
    virtual ~IRecordService() = default;
    
    /**
     * @brief Create a training record
     * @param record Record to create
     * @return Created record ID or empty string if failed
     */
    virtual std::string createRecord(const TrainingRecord& record) = 0;
    
    /**
     * @brief Get a training record
     * @param record_id Record ID
     * @return Record or nullopt if not found
     */
    virtual std::optional<TrainingRecord> getRecord(const std::string& record_id) = 0;
    
    /**
     * @brief Update a training record
     * @param record Record to update
     * @return True if updated, false if not found
     */
    virtual bool updateRecord(const TrainingRecord& record) = 0;
    
    /**
     * @brief Delete a training record
     * @param record_id Record ID
     * @return True if deleted, false if not found
     */
    virtual bool deleteRecord(const std::string& record_id) = 0;
    
    /**
     * @brief List records matching criteria
     * @param trainee_id Trainee ID (optional)
     * @param instructor_id Instructor ID (optional)
     * @param course_id Course ID (optional)
     * @param syllabus_id Syllabus ID (optional)
     * @param record_type Record type (optional)
     * @param start_date Start date (optional)
     * @param end_date End date (optional)
     * @param page Page number (starting from 1)
     * @param page_size Page size
     * @param sort_by Sort field
     * @param ascending Sort direction
     * @return Pair of records and total count
     */
    virtual std::pair<std::vector<TrainingRecord>, int> listRecords(
        const std::optional<std::string>& trainee_id = std::nullopt,
        const std::optional<std::string>& instructor_id = std::nullopt,
        const std::optional<std::string>& course_id = std::nullopt,
        const std::optional<std::string>& syllabus_id = std::nullopt,
        const std::optional<RecordType>& record_type = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& start_date = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& end_date = std::nullopt,
        int page = 1,
        int page_size = 10,
        const std::string& sort_by = "date",
        bool ascending = false
    ) = 0;
    
    /**
     * @brief Get record audit logs
     * @param record_id Record ID
     * @return Audit logs
     */
    virtual std::vector<nlohmann::json> getAuditLogs(const std::string& record_id) = 0;
    
    /**
     * @brief Get records for trainee and criteria
     * @param trainee_id Trainee ID
     * @param criteria_id Criteria ID
     * @return Records
     */
    virtual std::vector<TrainingRecord> getRecordsForTraineeAndCriteria(
        const std::string& trainee_id,
        const std::string& criteria_id
    ) = 0;
    
    /**
     * @brief Get trainee progress
     * @param trainee_id Trainee ID
     * @param course_id Course ID
     * @return Progress as percentage (0-100)
     */
    virtual double getTraineeProgress(
        const std::string& trainee_id,
        const std::string& course_id
    ) = 0;
    
    /**
     * @brief Add attachment to record
     * @param record_id Record ID
     * @param attachment_path Attachment path
     * @param attachment_name Attachment name
     * @param content_type Content type
     * @param data Attachment data
     * @return True if added successfully
     */
    virtual bool addAttachment(
        const std::string& record_id,
        const std::string& attachment_name,
        const std::string& content_type,
        const std::vector<uint8_t>& data
    ) = 0;
    
    /**
     * @brief Get attachment
     * @param record_id Record ID
     * @param attachment_path Attachment path
     * @return Attachment data or empty vector if not found
     */
    virtual std::vector<uint8_t> getAttachment(
        const std::string& record_id,
        const std::string& attachment_path
    ) = 0;
};

/**
 * @brief Record service implementation
 */
class RecordService : public IRecordService {
public:
    /**
     * @brief Constructor
     * @param repository Record repository
     */
    explicit RecordService(std::shared_ptr<IRecordRepository> repository);
    
    /**
     * @brief Destructor
     */
    ~RecordService() override;
    
    std::string createRecord(const TrainingRecord& record) override;
    
    std::optional<TrainingRecord> getRecord(const std::string& record_id) override;
    
    bool updateRecord(const TrainingRecord& record) override;
    
    bool deleteRecord(const std::string& record_id) override;
    
    std::pair<std::vector<TrainingRecord>, int> listRecords(
        const std::optional<std::string>& trainee_id,
        const std::optional<std::string>& instructor_id,
        const std::optional<std::string>& course_id,
        const std::optional<std::string>& syllabus_id,
        const std::optional<RecordType>& record_type,
        const std::optional<std::chrono::system_clock::time_point>& start_date,
        const std::optional<std::chrono::system_clock::time_point>& end_date,
        int page,
        int page_size,
        const std::string& sort_by,
        bool ascending
    ) override;
    
    std::vector<nlohmann::json> getAuditLogs(const std::string& record_id) override;
    
    std::vector<TrainingRecord> getRecordsForTraineeAndCriteria(
        const std::string& trainee_id,
        const std::string& criteria_id
    ) override;
    
    double getTraineeProgress(
        const std::string& trainee_id,
        const std::string& course_id
    ) override;
    
    bool addAttachment(
        const std::string& record_id,
        const std::string& attachment_name,
        const std::string& content_type,
        const std::vector<uint8_t>& data
    ) override;
    
    std::vector<uint8_t> getAttachment(
        const std::string& record_id,
        const std::string& attachment_path
    ) override;
    
private:
    /**
     * @brief Generate attachment path
     * @param record_id Record ID
     * @param attachment_name Attachment name
     * @return Attachment path
     */
    std::string generateAttachmentPath(
        const std::string& record_id,
        const std::string& attachment_name
    );
    
    /**
     * @brief Validate record
     * @param record Record to validate
     * @return True if valid
     */
    bool validateRecord(const TrainingRecord& record);
    
    std::shared_ptr<IRecordRepository> repository_;
    std::string attachment_base_path_;
};

} // namespace records
} // namespace etr
#include "records/record_service.h"
#include "logging/logger.h"
#include <filesystem>
#include <fstream>
#include <sstream>
#include <uuid.h>

namespace etr {
namespace records {

RecordService::RecordService(std::shared_ptr<IRecordRepository> repository)
    : repository_(std::move(repository)), 
      attachment_base_path_("/app/data/attachments") {
    
    // Create attachments directory if it doesn't exist
    std::filesystem::path attachment_dir(attachment_base_path_);
    if (!std::filesystem::exists(attachment_dir)) {
        std::filesystem::create_directories(attachment_dir);
    }
    
    logging::Logger::getInstance().info("RecordService initialized");
}

RecordService::~RecordService() = default;

std::string RecordService::createRecord(const TrainingRecord& record) {
    // Validate record
    if (!validateRecord(record)) {
        logging::Logger::getInstance().error("Invalid record data");
        return "";
    }
    
    // Set creation and update time if not already set
    TrainingRecord record_copy = record;
    
    auto now = std::chrono::system_clock::now();
    
    if (record_copy.getCreatedAt() == std::chrono::system_clock::time_point()) {
        record_copy.setCreatedAt(now);
    }
    
    if (record_copy.getUpdatedAt() == std::chrono::system_clock::time_point()) {
        record_copy.setUpdatedAt(now);
    }
    
    // Create the record
    std::string record_id = repository_->createRecord(record_copy);
    
    if (!record_id.empty()) {
        logging::Logger::getInstance().info("Created record with ID: {}", record_id);
    } else {
        logging::Logger::getInstance().error("Failed to create record");
    }
    
    return record_id;
}

std::optional<TrainingRecord> RecordService::getRecord(const std::string& record_id) {
    auto record = repository_->getRecord(record_id);
    
    if (record) {
        logging::Logger::getInstance().debug("Retrieved record with ID: {}", record_id);
    } else {
        logging::Logger::getInstance().debug("Record not found with ID: {}", record_id);
    }
    
    return record;
}

bool RecordService::updateRecord(const TrainingRecord& record) {
    // Validate record
    if (!validateRecord(record)) {
        logging::Logger::getInstance().error("Invalid record data");
        return false;
    }
    
    // Get existing record to check permissions
    auto existing_record = repository_->getRecord(record.getRecordId());
    if (!existing_record) {
        logging::Logger::getInstance().error("Record not found with ID: {}", record.getRecordId());
        return false;
    }
    
    // Check if record is already signed
    if (existing_record->isFullySigned() && !record.isDraft()) {
        logging::Logger::getInstance().error("Cannot update signed record: {}", record.getRecordId());
        return false;
    }
    
    // Update the record
    TrainingRecord record_copy = record;
    record_copy.setUpdatedAt(std::chrono::system_clock::now());
    
    bool success = repository_->updateRecord(record_copy);
    
    if (success) {
        logging::Logger::getInstance().info("Updated record with ID: {}", record.getRecordId());
    } else {
        logging::Logger::getInstance().error("Failed to update record with ID: {}", record.getRecordId());
    }
    
    return success;
}

bool RecordService::deleteRecord(const std::string& record_id) {
    // Get existing record to check permissions
    auto existing_record = repository_->getRecord(record_id);
    if (!existing_record) {
        logging::Logger::getInstance().error("Record not found with ID: {}", record_id);
        return false;
    }
    
    // Check if record is already signed
    if (existing_record->isFullySigned() && !existing_record->isDraft()) {
        logging::Logger::getInstance().error("Cannot delete signed record: {}", record_id);
        return false;
    }
    
    // Delete the record
    bool success = repository_->deleteRecord(record_id);
    
    if (success) {
        logging::Logger::getInstance().info("Deleted record with ID: {}", record_id);
        
        // Delete attachments
        for (const auto& attachment : existing_record->getAttachments()) {
            std::string attachment_path = attachment_base_path_ + "/" + attachment;
            
            if (std::filesystem::exists(attachment_path)) {
                try {
                    std::filesystem::remove(attachment_path);
                    logging::Logger::getInstance().debug("Deleted attachment: {}", attachment);
                } 
                catch (const std::exception& e) {
                    logging::Logger::getInstance().error("Failed to delete attachment {}: {}", 
                        attachment, e.what());
                }
            }
        }
    } else {
        logging::Logger::getInstance().error("Failed to delete record with ID: {}", record_id);
    }
    
    return success;
}

std::pair<std::vector<TrainingRecord>, int> RecordService::listRecords(
    const std::optional<std::string>& trainee_id,
    const std::optional<std::string>& instructor_id,
    const std::optional<std::string>& course_id,
    const std::optional<std::string>& syllabus_id,
    const std::optional<RecordType>& record_type,
    const std::optional<std::chrono::system_clock::time_point>& start_date,
    const std::optional<std::chrono::system_clock::time_point>& end_date,
    int page,
    int page_size,
    const std::string& sort_by,
    bool ascending
) {
    // List records
    auto [records, total_count] = repository_->listRecords(
        trainee_id,
        instructor_id,
        course_id,
        syllabus_id,
        record_type,
        start_date,
        end_date,
        page,
        page_size,
        sort_by,
        ascending
    );
    
    logging::Logger::getInstance().debug("Listed {} records out of {} total", 
        records.size(), total_count);
    
    return {records, total_count};
}

std::vector<nlohmann::json> RecordService::getAuditLogs(const std::string& record_id) {
    auto logs = repository_->getAuditLogs(record_id);
    
    logging::Logger::getInstance().debug("Retrieved {} audit logs for record: {}", 
        logs.size(), record_id);
    
    return logs;
}

std::vector<TrainingRecord> RecordService::getRecordsForTraineeAndCriteria(
    const std::string& trainee_id,
    const std::string& criteria_id
) {
    // List records for the trainee
    auto [records, _] = repository_->listRecords(
        trainee_id,
        std::nullopt,
        std::nullopt,
        std::nullopt,
        std::nullopt,
        std::nullopt,
        std::nullopt,
        1,
        1000,  // Fetch a large batch
        "date",
        false
    );
    
    // Filter records that have the specified criteria
    std::vector<TrainingRecord> filtered_records;
    
    for (const auto& record : records) {
        for (const auto& grade : record.getGrades()) {
            if (grade.criteria_id == criteria_id) {
                filtered_records.push_back(record);
                break;
            }
        }
    }
    
    logging::Logger::getInstance().debug("Found {} records for trainee {} and criteria {}", 
        filtered_records.size(), trainee_id, criteria_id);
    
    return filtered_records;
}

double RecordService::getTraineeProgress(
    const std::string& trainee_id,
    const std::string& course_id
) {
    // Get all records for the trainee in the course
    auto [records, _] = repository_->listRecords(
        trainee_id,
        std::nullopt,
        course_id,
        std::nullopt,
        std::nullopt,
        std::nullopt,
        std::nullopt,
        1,
        1000,  // Fetch a large batch
        "date",
        false
    );
    
    // TODO: Get course syllabus and calculate actual progress
    // For now, just return a placeholder progress value
    double progress = 0.0;
    
    if (!records.empty()) {
        // Simple calculation: number of completed exercises / total exercises in syllabus
        // In a real implementation, we would need to get the syllabus structure
        
        // For demo purposes, assume 10 exercises in the syllabus
        int total_exercises = 10;
        
        // Count unique exercise IDs
        std::unordered_set<std::string> completed_exercises;
        for (const auto& record : records) {
            if (!record.isDraft() && record.isFullySigned()) {
                completed_exercises.insert(record.getExerciseId());
            }
        }
        
        progress = static_cast<double>(completed_exercises.size()) / total_exercises * 100.0;
    }
    
    logging::Logger::getInstance().debug("Trainee {} progress in course {}: {:.2f}%", 
        trainee_id, course_id, progress);
    
    return progress;
}

bool RecordService::addAttachment(
    const std::string& record_id,
    const std::string& attachment_name,
    const std::string& content_type,
    const std::vector<uint8_t>& data
) {
    // Get existing record
    auto existing_record = repository_->getRecord(record_id);
    if (!existing_record) {
        logging::Logger::getInstance().error("Record not found with ID: {}", record_id);
        return false;
    }
    
    // Generate a unique attachment path
    std::string attachment_path = generateAttachmentPath(record_id, attachment_name);
    std::string full_path = attachment_base_path_ + "/" + attachment_path;
    
    // Create parent directories if they don't exist
    std::filesystem::path parent_dir = std::filesystem::path(full_path).parent_path();
    if (!std::filesystem::exists(parent_dir)) {
        std::filesystem::create_directories(parent_dir);
    }
    
    // Write attachment data to file
    try {
        std::ofstream file(full_path, std::ios::binary);
        if (!file) {
            logging::Logger::getInstance().error("Failed to create attachment file: {}", full_path);
            return false;
        }
        
        file.write(reinterpret_cast<const char*>(data.data()), data.size());
        file.close();
        
        // Update record with attachment
        auto record_copy = *existing_record;
        auto attachments = record_copy.getAttachments();
        attachments.push_back(attachment_path);
        record_copy.setAttachments(attachments);
        
        // Save updated record
        bool success = repository_->updateRecord(record_copy);
        
        if (success) {
            logging::Logger::getInstance().info("Added attachment {} to record: {}", 
                attachment_name, record_id);
        } else {
            // Clean up the file if record update failed
            std::filesystem::remove(full_path);
            logging::Logger::getInstance().error("Failed to update record with attachment");
            return false;
        }
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error adding attachment: {}", e.what());
        return false;
    }
}

std::vector<uint8_t> RecordService::getAttachment(
    const std::string& record_id,
    const std::string& attachment_path
) {
    // Get existing record
    auto existing_record = repository_->getRecord(record_id);
    if (!existing_record) {
        logging::Logger::getInstance().error("Record not found with ID: {}", record_id);
        return {};
    }
    
    // Check if attachment belongs to the record
    auto attachments = existing_record->getAttachments();
    if (std::find(attachments.begin(), attachments.end(), attachment_path) == attachments.end()) {
        logging::Logger::getInstance().error("Attachment not found for record: {}", record_id);
        return {};
    }
    
    // Read attachment data
    std::string full_path = attachment_base_path_ + "/" + attachment_path;
    
    try {
        if (!std::filesystem::exists(full_path)) {
            logging::Logger::getInstance().error("Attachment file not found: {}", full_path);
            return {};
        }
        
        std::ifstream file(full_path, std::ios::binary | std::ios::ate);
        if (!file) {
            logging::Logger::getInstance().error("Failed to open attachment file: {}", full_path);
            return {};
        }
        
        // Get file size
        std::streamsize size = file.tellg();
        file.seekg(0, std::ios::beg);
        
        // Read file data
        std::vector<uint8_t> data(size);
        if (file.read(reinterpret_cast<char*>(data.data()), size)) {
            logging::Logger::getInstance().debug("Retrieved attachment: {}", attachment_path);
            return data;
        } else {
            logging::Logger::getInstance().error("Failed to read attachment file: {}", full_path);
            return {};
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error reading attachment: {}", e.what());
        return {};
    }
}

std::string RecordService::generateAttachmentPath(
    const std::string& record_id,
    const std::string& attachment_name
) {
    // Generate a unique ID for the attachment
    uuids::uuid uuid = uuids::uuid_system_generator{}();
    std::string uuid_str = uuids::to_string(uuid);
    
    // Extract file extension
    std::string extension;
    auto pos = attachment_name.find_last_of('.');
    if (pos != std::string::npos) {
        extension = attachment_name.substr(pos);
    }
    
    // Create path with record ID and unique name
    return record_id + "/" + uuid_str + extension;
}

bool RecordService::validateRecord(const TrainingRecord& record) {
    // Check required fields
    if (record.getTraineeId().empty()) {
        logging::Logger::getInstance().error("Record validation failed: missing trainee ID");
        return false;
    }
    
    if (record.getInstructorId().empty()) {
        logging::Logger::getInstance().error("Record validation failed: missing instructor ID");
        return false;
    }
    
    if (record.getCourseId().empty()) {
        logging::Logger::getInstance().error("Record validation failed: missing course ID");
        return false;
    }
    
    if (record.getSyllabusId().empty()) {
        logging::Logger::getInstance().error("Record validation failed: missing syllabus ID");
        return false;
    }
    
    if (record.getExerciseId().empty()) {
        logging::Logger::getInstance().error("Record validation failed: missing exercise ID");
        return false;
    }
    
    if (record.getRecordType() == RecordType::UNKNOWN) {
        logging::Logger::getInstance().error("Record validation failed: invalid record type");
        return false;
    }
    
    // Check grade values
    for (const auto& grade : record.getGrades()) {
        if (grade.grade < 1 || grade.grade > 4) {
            logging::Logger::getInstance().error("Record validation failed: invalid grade value");
            return false;
        }
    }
    
    return true;
}

} // namespace records
} // namespace etr
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <chrono>
#include <nlohmann/json.hpp>

namespace etr {
namespace records {

/**
 * @brief Record types
 */
enum class RecordType {
    UNKNOWN,
    TRAINING_SESSION,
    ASSESSMENT,
    CERTIFICATION,
    QUALIFICATION,
    ENDORSEMENT
};

/**
 * @brief Convert RecordType to string
 * @param type Record type
 * @return String representation
 */
std::string recordTypeToString(RecordType type);

/**
 * @brief Convert string to RecordType
 * @param str String representation
 * @return Record type
 */
RecordType recordTypeFromString(const std::string& str);

/**
 * @brief Signature information
 */
struct SignatureInfo {
    std::string signer_id;
    std::string signer_name;
    std::string certificate_id;
    std::vector<uint8_t> signature_data;
    std::chrono::system_clock::time_point timestamp;
    bool is_valid{false};
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Signature info or nullopt if invalid
     */
    static std::optional<SignatureInfo> fromJson(const nlohmann::json& json);
};

/**
 * @brief Grade item
 */
struct GradeItem {
    std::string criteria_id;
    std::string criteria_name;
    int grade;  // 1-4 scale
    std::string comments;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Grade item or nullopt if invalid
     */
    static std::optional<GradeItem> fromJson(const nlohmann::json& json);
};

/**
 * @brief Training record
 */
class TrainingRecord {
public:
    /**
     * @brief Default constructor
     */
    TrainingRecord();
    
    /**
     * @brief Constructor with ID
     * @param id Record ID
     */
    explicit TrainingRecord(const std::string& id);
    
    /**
     * @brief Get record ID
     * @return Record ID
     */
    const std::string& getRecordId() const;
    
    /**
     * @brief Set record ID
     * @param id Record ID
     */
    void setRecordId(const std::string& id);
    
    /**
     * @brief Get trainee ID
     * @return Trainee ID
     */
    const std::string& getTraineeId() const;
    
    /**
     * @brief Set trainee ID
     * @param id Trainee ID
     */
    void setTraineeId(const std::string& id);
    
    /**
     * @brief Get instructor ID
     * @return Instructor ID
     */
    const std::string& getInstructorId() const;
    
    /**
     * @brief Set instructor ID
     * @param id Instructor ID
     */
    void setInstructorId(const std::string& id);
    
    /**
     * @brief Get record type
     * @return Record type
     */
    RecordType getRecordType() const;
    
    /**
     * @brief Set record type
     * @param type Record type
     */
    void setRecordType(RecordType type);
    
    /**
     * @brief Get course ID
     * @return Course ID
     */
    const std::string& getCourseId() const;
    
    /**
     * @brief Set course ID
     * @param id Course ID
     */
    void setCourseId(const std::string& id);
    
    /**
     * @brief Get syllabus ID
     * @return Syllabus ID
     */
    const std::string& getSyllabusId() const;
    
    /**
     * @brief Set syllabus ID
     * @param id Syllabus ID
     */
    void setSyllabusId(const std::string& id);
    
    /**
     * @brief Get exercise ID
     * @return Exercise ID
     */
    const std::string& getExerciseId() const;
    
    /**
     * @brief Set exercise ID
     * @param id Exercise ID
     */
    void setExerciseId(const std::string& id);
    
    /**
     * @brief Get date
     * @return Date
     */
    std::chrono::system_clock::time_point getDate() const;
    
    /**
     * @brief Set date
     * @param date Date
     */
    void setDate(const std::chrono::system_clock::time_point& date);
    
    /**
     * @brief Get duration in minutes
     * @return Duration in minutes
     */
    int getDurationMinutes() const;
    
    /**
     * @brief Set duration in minutes
     * @param minutes Duration in minutes
     */
    void setDurationMinutes(int minutes);
    
    /**
     * @brief Get location
     * @return Location
     */
    const std::string& getLocation() const;
    
    /**
     * @brief Set location
     * @param location Location
     */
    void setLocation(const std::string& location);
    
    /**
     * @brief Get aircraft type
     * @return Aircraft type
     */
    const std::string& getAircraftType() const;
    
    /**
     * @brief Set aircraft type
     * @param type Aircraft type
     */
    void setAircraftType(const std::string& type);
    
    /**
     * @brief Get grades
     * @return Grades
     */
    const std::vector<GradeItem>& getGrades() const;
    
    /**
     * @brief Set grades
     * @param grades Grades
     */
    void setGrades(const std::vector<GradeItem>& grades);
    
    /**
     * @brief Add grade
     * @param grade Grade
     */
    void addGrade(const GradeItem& grade);
    
    /**
     * @brief Get grade by criteria ID
     * @param criteria_id Criteria ID
     * @return Grade or nullopt if not found
     */
    std::optional<GradeItem> getGradeByCriteriaId(const std::string& criteria_id) const;
    
    /**
     * @brief Update grade
     * @param grade Grade
     * @return True if updated, false if not found
     */
    bool updateGrade(const GradeItem& grade);
    
    /**
     * @brief Get attachments
     * @return Attachments
     */
    const std::vector<std::string>& getAttachments() const;
    
    /**
     * @brief Set attachments
     * @param attachments Attachments
     */
    void setAttachments(const std::vector<std::string>& attachments);
    
    /**
     * @brief Add attachment
     * @param attachment Attachment
     */
    void addAttachment(const std::string& attachment);
    
    /**
     * @brief Remove attachment
     * @param attachment Attachment
     * @return True if removed, false if not found
     */
    bool removeAttachment(const std::string& attachment);
    
    /**
     * @brief Get comments
     * @return Comments
     */
    const std::string& getComments() const;
    
    /**
     * @brief Set comments
     * @param comments Comments
     */
    void setComments(const std::string& comments);
    
    /**
     * @brief Get trainee signature
     * @return Trainee signature
     */
    const std::optional<SignatureInfo>& getTraineeSignature() const;
    
    /**
     * @brief Set trainee signature
     * @param signature Trainee signature
     */
    void setTraineeSignature(const SignatureInfo& signature);
    
    /**
     * @brief Get instructor signature
     * @return Instructor signature
     */
    const std::optional<SignatureInfo>& getInstructorSignature() const;
    
    /**
     * @brief Set instructor signature
     * @param signature Instructor signature
     */
    void setInstructorSignature(const SignatureInfo& signature);
    
    /**
     * @brief Check if record is draft
     * @return True if draft
     */
    bool isDraft() const;
    
    /**
     * @brief Set draft status
     * @param is_draft Draft status
     */
    void setDraft(bool is_draft);
    
    /**
     * @brief Get creation time
     * @return Creation time
     */
    std::chrono::system_clock::time_point getCreatedAt() const;
    
    /**
     * @brief Set creation time
     * @param time Creation time
     */
    void setCreatedAt(const std::chrono::system_clock::time_point& time);
    
    /**
     * @brief Get update time
     * @return Update time
     */
    std::chrono::system_clock::time_point getUpdatedAt() const;
    
    /**
     * @brief Set update time
     * @param time Update time
     */
    void setUpdatedAt(const std::chrono::system_clock::time_point& time);
    
    /**
     * @brief Get metadata
     * @return Metadata
     */
    const std::map<std::string, std::string>& getMetadata() const;
    
    /**
     * @brief Set metadata
     * @param metadata Metadata
     */
    void setMetadata(const std::map<std::string, std::string>& metadata);
    
    /**
     * @brief Get metadata value
     * @param key Metadata key
     * @return Metadata value or empty string if not found
     */
    std::string getMetadataValue(const std::string& key) const;
    
    /**
     * @brief Set metadata value
     * @param key Metadata key
     * @param value Metadata value
     */
    void setMetadataValue(const std::string& key, const std::string& value);
    
    /**
     * @brief Check if record is signed by trainee
     * @return True if signed by trainee
     */
    bool isSignedByTrainee() const;
    
    /**
     * @brief Check if record is signed by instructor
     * @return True if signed by instructor
     */
    bool isSignedByInstructor() const;
    
    /**
     * @brief Check if record is fully signed
     * @return True if fully signed
     */
    bool isFullySigned() const;
    
    /**
     * @brief Check if record is valid
     * @return True if valid
     */
    bool isValid() const;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Training record or nullopt if invalid
     */
    static std::optional<TrainingRecord> fromJson(const nlohmann::json& json);
    
    /**
     * @brief Generate audit log entry
     * @param action Action performed
     * @param user_id User ID
     * @param details Additional details
     * @return Audit log entry
     */
    nlohmann::json generateAuditLog(const std::string& action, const std::string& user_id, const std::string& details = "") const;
    
private:
    std::string record_id_;
    std::string trainee_id_;
    std::string instructor_id_;
    RecordType record_type_;
    std::string course_id_;
    std::string syllabus_id_;
    std::string exercise_id_;
    std::chrono::system_clock::time_point date_;
    int duration_minutes_;
    std::string location_;
    std::string aircraft_type_;
    std::vector<GradeItem> grades_;
    std::vector<std::string> attachments_;
    std::string comments_;
    std::optional<SignatureInfo> trainee_signature_;
    std::optional<SignatureInfo> instructor_signature_;
    bool is_draft_;
    std::chrono::system_clock::time_point created_at_;
    std::chrono::system_clock::time_point updated_at_;
    std::map<std::string, std::string> metadata_;
};

/**
 * @brief Record repository interface
 */
class IRecordRepository {
public:
    virtual ~IRecordRepository() = default;
    
    /**
     * @brief Create a record
     * @param record Record to create
     * @return Created record ID or empty string if failed
     */
    virtual std::string createRecord(const TrainingRecord& record) = 0;
    
    /**
     * @brief Get a record by ID
     * @param record_id Record ID
     * @return Record or nullopt if not found
     */
    virtual std::optional<TrainingRecord> getRecord(const std::string& record_id) = 0;
    
    /**
     * @brief Update a record
     * @param record Record to update
     * @return True if updated, false if not found
     */
    virtual bool updateRecord(const TrainingRecord& record) = 0;
    
    /**
     * @brief Delete a record
     * @param record_id Record ID
     * @return True if deleted, false if not found
     */
    virtual bool deleteRecord(const std::string& record_id) = 0;
    
    /**
     * @brief List records matching criteria
     * @param trainee_id Trainee ID (optional)
     * @param instructor_id Instructor ID (optional)
     * @param course_id Course ID (optional)
     * @param syllabus_id Syllabus ID (optional)
     * @param record_type Record type (optional)
     * @param start_date Start date (optional)
     * @param end_date End date (optional)
     * @param page Page number (starting from 1)
     * @param page_size Page size
     * @param sort_by Sort field
     * @param ascending Sort direction
     * @return Pair of records and total count
     */
    virtual std::pair<std::vector<TrainingRecord>, int> listRecords(
        const std::optional<std::string>& trainee_id = std::nullopt,
        const std::optional<std::string>& instructor_id = std::nullopt,
        const std::optional<std::string>& course_id = std::nullopt,
        const std::optional<std::string>& syllabus_id = std::nullopt,
        const std::optional<RecordType>& record_type = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& start_date = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& end_date = std::nullopt,
        int page = 1,
        int page_size = 10,
        const std::string& sort_by = "date",
        bool ascending = false
    ) = 0;
    
    /**
     * @brief Log audit event
     * @param record_id Record ID
     * @param action Action performed
     * @param user_id User ID
     * @param details Additional details
     * @return True if logged successfully
     */
    virtual bool logAuditEvent(
        const std::string& record_id, 
        const std::string& action, 
        const std::string& user_id, 
        const std::string& details
    ) = 0;
    
    /**
     * @brief Get audit logs for a record
     * @param record_id Record ID
     * @return Audit logs
     */
    virtual std::vector<nlohmann::json> getAuditLogs(const std::string& record_id) = 0;
};

} // namespace records
} // namespace etr
#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include "records/record_service.h"
#include <memory>
#include <chrono>

using namespace etr::records;
using namespace testing;

// Mock record repository
class MockRecordRepository : public IRecordRepository {
public:
    MOCK_METHOD(std::string, createRecord, (const TrainingRecord&), (override));
    MOCK_METHOD(std::optional<TrainingRecord>, getRecord, (const std::string&), (override));
    MOCK_METHOD(bool, updateRecord, (const TrainingRecord&), (override));
    MOCK_METHOD(bool, deleteRecord, (const std::string&), (override));
    MOCK_METHOD((std::pair<std::vector<TrainingRecord>, int>), listRecords, 
        (const std::optional<std::string>&, 
         const std::optional<std::string>&, 
         const std::optional<std::string>&, 
         const std::optional<std::string>&, 
         const std::optional<RecordType>&,
         const std::optional<std::chrono::system_clock::time_point>&,
         const std::optional<std::chrono::system_clock::time_point>&,
         int, int, const std::string&, bool), (override));
    MOCK_METHOD(bool, logAuditEvent, 
        (const std::string&, const std::string&, const std::string&, const std::string&), (override));
    MOCK_METHOD(std::vector<nlohmann::json>, getAuditLogs, (const std::string&), (override));
};

class RecordServiceTest : public Test {
protected:
    void SetUp() override {
        // Create mock repository
        mock_repository_ = std::make_shared<MockRecordRepository>();
        
        // Create service with mock repository
        record_service_ = std::make_unique<RecordService>(mock_repository_);
    }
    
    // Helper to create a valid record for testing
    TrainingRecord createValidRecord() {
        TrainingRecord record("test-record-id");
        record.setTraineeId("test-trainee");
        record.setInstructorId("test-instructor");
        record.setRecordType(RecordType::TRAINING_SESSION);
        record.setCourseId("test-course");
        record.setSyllabusId("test-syllabus");
        record.setExerciseId("test-exercise");
        record.setDate(std::chrono::system_clock::now());
        record.setDurationMinutes(60);
        record.setLocation("Test Location");
        
        GradeItem grade;
        grade.criteria_id = "test-criteria";
        grade.criteria_name = "Test Criteria";
        grade.grade = 3;
        grade.comments = "Good performance";
        record.addGrade(grade);
        
        record.setComments("Test comments");
        record.setDraft(true);
        
        return record;
    }
    
    std::shared_ptr<MockRecordRepository> mock_repository_;
    std::unique_ptr<RecordService> record_service_;
};

TEST_F(RecordServiceTest, CreateRecordSuccess) {
    // Setup expectations
    auto record = createValidRecord();
    EXPECT_CALL(*mock_repository_, createRecord(AllOf(
        Field(&TrainingRecord::getTraineeId, "test-trainee"),
        Field(&TrainingRecord::getInstructorId, "test-instructor"),
        Field(&TrainingRecord::getRecordType, RecordType::TRAINING_SESSION)
    ))).WillOnce(Return("test-record-id"));
    
    // Call service method
    std::string result = record_service_->createRecord(record);
    
    // Verify result
    EXPECT_EQ(result, "test-record-id");
}

TEST_F(RecordServiceTest, CreateRecordInvalid) {
    // Create invalid record (missing required fields)
    TrainingRecord record;
    
    // Call service method
    std::string result = record_service_->createRecord(record);
    
    // Verify result
    EXPECT_TRUE(result.empty());
}

TEST_F(RecordServiceTest, GetRecordSuccess) {
    // Setup expectations
    auto record = createValidRecord();
    EXPECT_CALL(*mock_repository_, getRecord("test-record-id"))
        .WillOnce(Return(record));
    
    // Call service method
    auto result = record_service_->getRecord("test-record-id");
    
    // Verify result
    ASSERT_TRUE(result.has_value());
    EXPECT_EQ(result->getRecordId(), "test-record-id");
    EXPECT_EQ(result->getTraineeId(), "test-trainee");
}

TEST_F(RecordServiceTest, GetRecordNotFound) {
    // Setup expectations
    EXPECT_CALL(*mock_repository_, getRecord("nonexistent-id"))
        .WillOnce(Return(std::nullopt));
    
    // Call service method
    auto result = record_service_->getRecord("nonexistent-id");
    
    // Verify result
    EXPECT_FALSE(result.has_value());
}

TEST_F(RecordServiceTest, UpdateRecordSuccess) {
    // Setup expectations
    auto record = createValidRecord();
    EXPECT_CALL(*mock_repository_, getRecord("test-record-id"))
        .WillOnce(Return(record));
    EXPECT_CALL(*mock_repository_, updateRecord(_))
        .WillOnce(Return(true));
    
    // Update record
    record.setComments("Updated comments");
    
    // Call service method
    bool result = record_service_->updateRecord(record);
    
    // Verify result
    EXPECT_TRUE(result);
}

TEST_F(RecordServiceTest, UpdateRecordInvalid) {
    // Create invalid record (missing required fields)
    TrainingRecord record("test-record-id");
    
    // Call service method
    bool result = record_service_->updateRecord(record);
    
    // Verify result
    EXPECT_FALSE(result);
}

TEST_F(RecordServiceTest, UpdateRecordNotFound) {
    // Setup expectations
    auto record = createValidRecord();
    EXPECT_CALL(*mock_repository_, getRecord("test-record-id"))
        .WillOnce(Return(std::nullopt));
    
    // Call service method
    bool result = record_service_->updateRecord(record);
    
    // Verify result
    EXPECT_FALSE(result);
}

TEST_F(RecordServiceTest, DeleteRecordSuccess) {
    // Setup expectations
    auto record = createValidRecord();
    EXPECT_CALL(*mock_repository_, getRecord("test-record-id"))
        .WillOnce(Return(record));
    EXPECT_CALL(*mock_repository_, deleteRecord("test-record-id"))
        .WillOnce(Return(true));
    
    // Call service method
    bool result = record_service_->deleteRecord("test-record-id");
    
    // Verify result
    EXPECT_TRUE(result);
}

TEST_F(RecordServiceTest, DeleteRecordNotFound) {
    // Setup expectations
    EXPECT_CALL(*mock_repository_, getRecord("nonexistent-id"))
        .WillOnce(Return(std::nullopt));
    
    // Call service method
    bool result = record_service_->deleteRecord("nonexistent-id");
    
    // Verify result
    EXPECT_FALSE(result);
}

TEST_F(RecordServiceTest, ListRecordsSuccess) {
    // Setup expectations
    std::vector<TrainingRecord> records = {
        createValidRecord(),
        createValidRecord()
    };
    records[1].setRecordId("test-record-id-2");
    
    EXPECT_CALL(*mock_repository_, listRecords(
        Optional(std::string("test-trainee")),
        Eq(std::nullopt),
        Eq(std::nullopt),
        Eq(std::nullopt),
        Eq(std::nullopt),
        _, _,
        1, 10, "date", false
    )).WillOnce(Return(std::make_pair(records, 2)));
    
    // Call service method
    auto [result_records, count] = record_service_->listRecords(
        "test-trainee",
        std::nullopt,
        std::nullopt,
        std::nullopt,
        std::nullopt,
        std::nullopt,
        std::nullopt,
        1,
        10,
        "date",
        false
    );
    
    // Verify result
    EXPECT_EQ(result_records.size(), 2);
    EXPECT_EQ(count, 2);
}

TEST_F(RecordServiceTest, GetAuditLogsSuccess) {
    // Setup expectations
    std::vector<nlohmann::json> logs = {
        {{"action", "create"}, {"user_id", "test-user"}},
        {{"action", "update"}, {"user_id", "test-user"}}
    };
    
    EXPECT_CALL(*mock_repository_, getAuditLogs("test-record-id"))
        .WillOnce(Return(logs));
    
    // Call service method
    auto result = record_service_->getAuditLogs("test-record-id");
    
    // Verify result
    EXPECT_EQ(result.size(), 2);
}

int main(int argc, char** argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
#pragma once

#include <string>
#include <memory>
#include <functional>
#include <cpprest/http_listener.h>
#include <cpprest/json.h>
#include <cpprest/uri.h>
#include <cpprest/http_client.h>
#include <cpprest/filestream.h>
#include <cpprest/interopstream.h>

#include "records/record_service.h"
#include "signature/digital_signature.h"
#include "compliance/compliance_service.h"
#include "syllabus/syllabus_service.h"

namespace etr {
namespace rest {

/**
 * @brief REST adapter for the ETR service
 */
class RestAdapter {
public:
    /**
     * @brief Constructor
     * @param host Host to bind to
     * @param port Port to bind to
     * @param record_service Record service
     * @param signature_service Signature service
     * @param compliance_service Compliance service
     * @param syllabus_service Syllabus service
     */
    RestAdapter(
        const std::string& host,
        int port,
        std::shared_ptr<records::IRecordService> record_service,
        std::shared_ptr<signature::IDigitalSignatureService> signature_service,
        std::shared_ptr<compliance::IComplianceService> compliance_service,
        std::shared_ptr<syllabus::ISyllabusService> syllabus_service
    );
    
    /**
     * @brief Destructor
     */
    ~RestAdapter();
    
    /**
     * @brief Start the REST server
     * @return True if started successfully
     */
    bool start();
    
    /**
     * @brief Stop the REST server
     */
    void stop();
    
private:
    /**
     * @brief Validate JWT token
     * @param request HTTP request
     * @return User ID or empty string if invalid
     */
    std::string validateToken(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP GET /api/health
     * @param request HTTP request
     */
    void handleHealth(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP OPTIONS requests
     * @param request HTTP request
     */
    void handleOptions(const web::http::http_request& request);
    
    // Records API
    
    /**
     * @brief Handle HTTP GET /api/records
     * @param request HTTP request
     */
    void handleGetRecords(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP GET /api/records/{id}
     * @param request HTTP request
     */
    void handleGetRecord(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP POST /api/records
     * @param request HTTP request
     */
    void handleCreateRecord(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP PUT /api/records/{id}
     * @param request HTTP request
     */
    void handleUpdateRecord(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP DELETE /api/records/{id}
     * @param request HTTP request
     */
    void handleDeleteRecord(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP GET /api/records/{id}/audit
     * @param request HTTP request
     */
    void handleGetRecordAudit(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP POST /api/records/{id}/attachments
     * @param request HTTP request
     */
    void handleAddAttachment(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP GET /api/records/{id}/attachments/{path}
     * @param request HTTP request
     */
    void handleGetAttachment(const web::http::http_request& request);
    
    // Signature API
    
    /**
     * @brief Handle HTTP POST /api/records/{id}/sign
     * @param request HTTP request
     */
    void handleSignRecord(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP GET /api/records/{id}/verify
     * @param request HTTP request
     */
    void handleVerifySignature(const web::http::http_request& request);
    
    // Compliance API
    
    /**
     * @brief Handle HTTP GET /api/compliance/{traineeId}
     * @param request HTTP request
     */
    void handleCheckCompliance(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP GET /api/compliance/requirements
     * @param request HTTP request
     */
    void handleGetRequirements(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP GET /api/compliance/mapping
     * @param request HTTP request
     */
    void handleGetMapping(const web::http::http_request& request);
    
    // Syllabus API
    
    /**
     * @brief Handle HTTP GET /api/syllabi
     * @param request HTTP request
     */
    void handleGetSyllabi(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP GET /api/syllabi/{id}
     * @param request HTTP request
     */
    void handleGetSyllabus(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP POST /api/syllabi
     * @param request HTTP request
     */
    void handleCreateSyllabus(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP PUT /api/syllabi/{id}
     * @param request HTTP request
     */
    void handleUpdateSyllabus(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP DELETE /api/syllabi/{id}
     * @param request HTTP request
     */
    void handleDeleteSyllabus(const web::http::http_request& request);
    
    /**
     * @brief Handle HTTP GET /api/syllabi/{id}/changes
     * @param request HTTP request
     */
    void handleGetSyllabusChanges(const web::http::http_request& request);
    
    std::shared_ptr<records::IRecordService> record_service_;
    std::shared_ptr<signature::IDigitalSignatureService> signature_service_;
    std::shared_ptr<compliance::IComplianceService> compliance_service_;
    std::shared_ptr<syllabus::ISyllabusService> syllabus_service_;
    
    std::unique_ptr<web::http::experimental::listener::http_listener> listener_;
    std::string host_;
    int port_;
    std::string base_url_;
    
    // CORS settings
    std::vector<std::string> allowed_origins_;
    std::vector<std::string> allowed_methods_;
    std::vector<std::string> allowed_headers_;
    bool allow_credentials_;
    int max_age_;
};

} // namespace rest
} // namespace etr
#pragma once

#include <string>
#include <memory>
#include <cpprest/http_listener.h>
#include <cpprest/json.h>
#include <cpprest/uri.h>
#include <cpprest/http_client.h>
#include "records/record_service.h"
#include "signature/digital_signature.h"
#include "compliance/compliance_service.h"
#include "syllabus/syllabus_service.h"
#include "logging/logger.h"

namespace etr {
namespace rest {

/**
 * @brief REST API adapter for ETR service
 */
class RestApiAdapter {
public:
    /**
     * @brief Constructor
     * @param host Host to bind to
     * @param port Port to bind to
     * @param record_service Record service
     * @param signature_service Signature service
     * @param compliance_service Compliance service
     * @param syllabus_service Syllabus service
     */
    RestApiAdapter(
        const std::string& host,
        int port,
        std::shared_ptr<records::IRecordService> record_service,
        std::shared_ptr<signature::IDigitalSignatureService> signature_service,
        std::shared_ptr<compliance::IComplianceService> compliance_service,
        std::shared_ptr<syllabus::ISyllabusService> syllabus_service
    );
    
    /**
     * @brief Destructor
     */
    ~RestApiAdapter();
    
    /**
     * @brief Start the REST API server
     * @return True if started successfully
     */
    bool start();
    
    /**
     * @brief Stop the REST API server
     */
    void stop();
    
private:
    // Record management handlers
    void handleGetRecord(web::http::http_request request);
    void handleCreateRecord(web::http::http_request request);
    void handleUpdateRecord(web::http::http_request request);
    void handleDeleteRecord(web::http::http_request request);
    void handleListRecords(web::http::http_request request);
    
    // Digital signature handlers
    void handleSignRecord(web::http::http_request request);
    void handleVerifySignature(web::http::http_request request);
    
    // Compliance handlers
    void handleCheckCompliance(web::http::http_request request);
    void handleListComplianceRequirements(web::http::http_request request);
    void handleMapRegulations(web::http::http_request request);
    
    // Syllabus handlers
    void handleGetSyllabus(web::http::http_request request);
    void handleCreateSyllabus(web::http::http_request request);
    void handleUpdateSyllabus(web::http::http_request request);
    void handleDeleteSyllabus(web::http::http_request request);
    void handleListSyllabi(web::http::http_request request);
    void handleTrackSyllabusChanges(web::http::http_request request);
    
    // Utility methods
    std::string extractToken(const web::http::http_request& request);
    bool validateToken(const std::string& token);
    std::string extractUserId(const std::string& token);
    
    // Convert between internal models and JSON
    web::json::value recordToJson(const records::TrainingRecord& record);
    records::TrainingRecord jsonToRecord(const web::json::value& json);
    
    web::json::value syllabusToJson(const syllabus::Syllabus& syllabus);
    syllabus::Syllabus jsonToSyllabus(const web::json::value& json);
    
    web::json::value complianceStatusToJson(const compliance::ComplianceStatus& status);
    
    std::string host_;
    int port_;
    std::unique_ptr<web::http::experimental::listener::http_listener> listener_;
    
    std::shared_ptr<records::IRecordService> record_service_;
    std::shared_ptr<signature::IDigitalSignatureService> signature_service_;
    std::shared_ptr<compliance::IComplianceService> compliance_service_;
    std::shared_ptr<syllabus::ISyllabusService> syllabus_service_;
};

} // namespace rest
} // namespace etr
#include "rest/rest_api_adapter.h"
#include <jwt-cpp/jwt.h>
#include <chrono>
#include <regex>

namespace etr {
namespace rest {

RestApiAdapter::RestApiAdapter(
    const std::string& host,
    int port,
    std::shared_ptr<records::IRecordService> record_service,
    std::shared_ptr<signature::IDigitalSignatureService> signature_service,
    std::shared_ptr<compliance::IComplianceService> compliance_service,
    std::shared_ptr<syllabus::ISyllabusService> syllabus_service
) : host_(host),
    port_(port),
    record_service_(std::move(record_service)),
    signature_service_(std::move(signature_service)),
    compliance_service_(std::move(compliance_service)),
    syllabus_service_(std::move(syllabus_service)) {
    
    // Create listener URI
    web::uri_builder uri_builder;
    uri_builder.set_scheme("http");
    uri_builder.set_host(host_);
    uri_builder.set_port(port_);
    
    auto uri = uri_builder.to_uri();
    listener_ = std::make_unique<web::http::experimental::listener::http_listener>(uri);
    
    // Set up request handlers
    
    // Record management endpoints
    listener_->support(web::http::methods::GET, [this](auto request) {
        auto path = web::uri::decode(request.relative_uri().path());
        
        if (std::regex_match(path, std::regex("/api/records/[^/]+"))) {
            handleGetRecord(request);
        } else if (std::regex_match(path, std::regex("/api/records"))) {
            handleListRecords(request);
        } else if (std::regex_match(path, std::regex("/api/compliance/check"))) {
            handleCheckCompliance(request);
        } else if (std::regex_match(path, std::regex("/api/compliance/requirements"))) {
            handleListComplianceRequirements(request);
        } else if (std::regex_match(path, std::regex("/api/syllabi/[^/]+"))) {
            handleGetSyllabus(request);
        } else if (std::regex_match(path, std::regex("/api/syllabi"))) {
            handleListSyllabi(request);
        } else if (std::regex_match(path, std::regex("/api/syllabi/[^/]+/changes"))) {
            handleTrackSyllabusChanges(request);
        } else {
            request.reply(web::http::status_codes::NotFound);
        }
    });
    
    listener_->support(web::http::methods::POST, [this](auto request) {
        auto path = web::uri::decode(request.relative_uri().path());
        
        if (std::regex_match(path, std::regex("/api/records"))) {
            handleCreateRecord(request);
        } else if (std::regex_match(path, std::regex("/api/records/[^/]+/sign"))) {
            handleSignRecord(request);
        } else if (std::regex_match(path, std::regex("/api/records/[^/]+/verify"))) {
            handleVerifySignature(request);
        } else if (std::regex_match(path, std::regex("/api/compliance/map"))) {
            handleMapRegulations(request);
        } else if (std::regex_match(path, std::regex("/api/syllabi"))) {
            handleCreateSyllabus(request);
        } else {
            request.reply(web::http::status_codes::NotFound);
        }
    });
    
    listener_->support(web::http::methods::PUT, [this](auto request) {
        auto path = web::uri::decode(request.relative_uri().path());
        
        if (std::regex_match(path, std::regex("/api/records/[^/]+"))) {
            handleUpdateRecord(request);
        } else if (std::regex_match(path, std::regex("/api/syllabi/[^/]+"))) {
            handleUpdateSyllabus(request);
        } else {
            request.reply(web::http::status_codes::NotFound);
        }
    });
    
    listener_->support(web::http::methods::DEL, [this](auto request) {
        auto path = web::uri::decode(request.relative_uri().path());
        
        if (std::regex_match(path, std::regex("/api/records/[^/]+"))) {
            handleDeleteRecord(request);
        } else if (std::regex_match(path, std::regex("/api/syllabi/[^/]+"))) {
            handleDeleteSyllabus(request);
        } else {
            request.reply(web::http::status_codes::NotFound);
        }
    });
    
    logging::Logger::getInstance().info("REST API adapter initialized at http://{}:{}", host_, port_);
}

RestApiAdapter::~RestApiAdapter() {
    stop();
}

bool RestApiAdapter::start() {
    try {
        listener_->open().wait();
        logging::Logger::getInstance().info("REST API adapter started");
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Failed to start REST API adapter: {}", e.what());
        return false;
    }
}

void RestApiAdapter::stop() {
    try {
        if (listener_) {
            listener_->close().wait();
            logging::Logger::getInstance().info("REST API adapter stopped");
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error stopping REST API adapter: {}", e.what());
    }
}

// Record management handlers

void RestApiAdapter::handleGetRecord(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract record ID from URL
        auto path = web::uri::decode(request.relative_uri().path());
        std::regex record_regex("/api/records/([^/]+)");
        std::smatch matches;
        
        if (std::regex_search(path, matches, record_regex) && matches.size() > 1) {
            std::string record_id = matches[1].str();
            
            // Get record
            auto record = record_service_->getRecord(record_id);
            
            if (record) {
                // Convert to JSON and respond
                auto response_json = recordToJson(*record);
                request.reply(web::http::status_codes::OK, response_json);
            } else {
                request.reply(web::http::status_codes::NotFound, U("Record not found"));
            }
        } else {
            request.reply(web::http::status_codes::BadRequest, U("Invalid record ID"));
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling GET record request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleCreateRecord(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract record from request body
        request.extract_json().then([this, request](web::json::value json) {
            try {
                // Convert JSON to record
                auto record = jsonToRecord(json);
                
                // Create record
                std::string record_id = record_service_->createRecord(record);
                
                if (!record_id.empty()) {
                    // Create response
                    web::json::value response;
                    response[U("success")] = web::json::value::boolean(true);
                    response[U("record_id")] = web::json::value::string(record_id);
                    
                    // Respond
                    request.reply(web::http::status_codes::Created, response);
                } else {
                    request.reply(web::http::status_codes::BadRequest, U("Failed to create record"));
                }
            }
            catch (const std::exception& e) {
                logging::Logger::getInstance().error("Error processing record creation: {}", e.what());
                request.reply(web::http::status_codes::BadRequest, 
                    web::json::value::string(U("Invalid record data: ") + e.what()));
            }
        }).wait();
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling CREATE record request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleUpdateRecord(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract record ID from URL
        auto path = web::uri::decode(request.relative_uri().path());
        std::regex record_regex("/api/records/([^/]+)");
        std::smatch matches;
        
        if (std::regex_search(path, matches, record_regex) && matches.size() > 1) {
            std::string record_id = matches[1].str();
            
            // Extract record from request body
            request.extract_json().then([this, request, record_id](web::json::value json) {
                try {
                    // Convert JSON to record
                    auto record = jsonToRecord(json);
                    
                    // Ensure record ID matches
                    if (record.getRecordId() != record_id) {
                        record.setRecordId(record_id);
                    }
                    
                    // Update record
                    bool success = record_service_->updateRecord(record);
                    
                    if (success) {
                        // Create response
                        web::json::value response;
                        response[U("success")] = web::json::value::boolean(true);
                        response[U("record_id")] = web::json::value::string(record_id);
                        
                        // Respond
                        request.reply(web::http::status_codes::OK, response);
                    } else {
                        request.reply(web::http::status_codes::NotFound, U("Record not found"));
                    }
                }
                catch (const std::exception& e) {
                    logging::Logger::getInstance().error("Error processing record update: {}", e.what());
                    request.reply(web::http::status_codes::BadRequest, 
                        web::json::value::string(U("Invalid record data: ") + e.what()));
                }
            }).wait();
        } else {
            request.reply(web::http::status_codes::BadRequest, U("Invalid record ID"));
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling UPDATE record request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleDeleteRecord(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract record ID from URL
        auto path = web::uri::decode(request.relative_uri().path());
        std::regex record_regex("/api/records/([^/]+)");
        std::smatch matches;
        
        if (std::regex_search(path, matches, record_regex) && matches.size() > 1) {
            std::string record_id = matches[1].str();
            
            // Delete record
            bool success = record_service_->deleteRecord(record_id);
            
            if (success) {
                // Create response
                web::json::value response;
                response[U("success")] = web::json::value::boolean(true);
                response[U("record_id")] = web::json::value::string(record_id);
                
                // Respond
                request.reply(web::http::status_codes::OK, response);
            } else {
                request.reply(web::http::status_codes::NotFound, U("Record not found"));
            }
        } else {
            request.reply(web::http::status_codes::BadRequest, U("Invalid record ID"));
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling DELETE record request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleListRecords(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract query parameters
        auto query_params = request.relative_uri().query();
        auto query_map = web::uri::split_query(query_params);
        
        // Parse parameters
        std::optional<std::string> trainee_id;
        std::optional<std::string> instructor_id;
        std::optional<std::string> course_id;
        std::optional<std::string> syllabus_id;
        std::optional<records::RecordType> record_type;
        std::optional<std::chrono::system_clock::time_point> start_date;
        std::optional<std::chrono::system_clock::time_point> end_date;
        int page = 1;
        int page_size = 10;
        std::string sort_by = "date";
        bool ascending = false;
        
        // Extract parameters from query string
        if (query_map.find(U("trainee_id")) != query_map.end()) {
            trainee_id = utility::conversions::to_utf8string(query_map[U("trainee_id")]);
        }
        
        if (query_map.find(U("instructor_id")) != query_map.end()) {
            instructor_id = utility::conversions::to_utf8string(query_map[U("instructor_id")]);
        }
        
        if (query_map.find(U("course_id")) != query_map.end()) {
            course_id = utility::conversions::to_utf8string(query_map[U("course_id")]);
        }
        
        if (query_map.find(U("syllabus_id")) != query_map.end()) {
            syllabus_id = utility::conversions::to_utf8string(query_map[U("syllabus_id")]);
        }
        
        if (query_map.find(U("record_type")) != query_map.end()) {
            std::string type_str = utility::conversions::to_utf8string(query_map[U("record_type")]);
            int type_value = std::stoi(type_str);
            record_type = static_cast<records::RecordType>(type_value);
        }
        
        if (query_map.find(U("start_date")) != query_map.end()) {
            std::string date_str = utility::conversions::to_utf8string(query_map[U("start_date")]);
            int64_t timestamp = std::stoll(date_str);
            start_date = std::chrono::system_clock::time_point(std::chrono::milliseconds(timestamp));
        }
        
        if (query_map.find(U("end_date")) != query_map.end()) {
            std::string date_str = utility::conversions::to_utf8string(query_map[U("end_date")]);
            int64_t timestamp = std::stoll(date_str);
            end_date = std::chrono::system_clock::time_point(std::chrono::milliseconds(timestamp));
        }
        
        if (query_map.find(U("page")) != query_map.end()) {
            page = std::stoi(utility::conversions::to_utf8string(query_map[U("page")]));
        }
        
        if (query_map.find(U("page_size")) != query_map.end()) {
            page_size = std::stoi(utility::conversions::to_utf8string(query_map[U("page_size")]));
        }
        
        if (query_map.find(U("sort_by")) != query_map.end()) {
            sort_by = utility::conversions::to_utf8string(query_map[U("sort_by")]);
        }
        
        if (query_map.find(U("ascending")) != query_map.end()) {
            std::string asc_str = utility::conversions::to_utf8string(query_map[U("ascending")]);
            ascending = (asc_str == "true" || asc_str == "1");
        }
        
        // List records
        auto [records, total_count] = record_service_->listRecords(
            trainee_id,
            instructor_id,
            course_id,
            syllabus_id,
            record_type,
            start_date,
            end_date,
            page,
            page_size,
            sort_by,
            ascending
        );
        
        // Create response
        web::json::value response;
        response[U("success")] = web::json::value::boolean(true);
        response[U("total_count")] = web::json::value::number(total_count);
        response[U("page")] = web::json::value::number(page);
        response[U("page_size")] = web::json::value::number(page_size);
        
        // Add records to response
        web::json::value records_array = web::json::value::array(records.size());
        for (size_t i = 0; i < records.size(); i++) {
            records_array[i] = recordToJson(records[i]);
        }
        
        response[U("records")] = records_array;
        
        // Respond
        request.reply(web::http::status_codes::OK, response);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling LIST records request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

// Digital signature handlers

void RestApiAdapter::handleSignRecord(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract record ID from URL
        auto path = web::uri::decode(request.relative_uri().path());
        std::regex record_regex("/api/records/([^/]+)/sign");
        std::smatch matches;
        
        if (std::regex_search(path, matches, record_regex) && matches.size() > 1) {
            std::string record_id = matches[1].str();
            
            // Extract signature data from request body
            request.extract_json().then([this, request, record_id](web::json::value json) {
                try {
                    // Get record
                    auto record_opt = record_service_->getRecord(record_id);
                    if (!record_opt) {
                        request.reply(web::http::status_codes::NotFound, U("Record not found"));
                        return;
                    }
                    
                    auto record = *record_opt;
                    
                    // Extract signature parameters
                    std::string signer_id = utility::conversions::to_utf8string(json[U("signer_id")].as_string());
                    std::string certificate_data = utility::conversions::to_utf8string(json[U("certificate_data")].as_string());
                    bool is_instructor = json[U("is_instructor")].as_bool();
                    
                    // Extract signature data
                    auto sig_data_array = json[U("signature_data")].as_array();
                    std::vector<uint8_t> signature_data;
                    for (const auto& val : sig_data_array) {
                        signature_data.push_back(static_cast<uint8_t>(val.as_integer()));
                    }
                    
                    // Sign record
                    auto signature_info = signature_service_->signRecord(
                        record,
                        signer_id,
                        certificate_data,
                        signature_data,
                        is_instructor
                    );
                    
                    if (signature_info) {
                        // Update record
                        bool update_success = record_service_->updateRecord(record);
                        
                        if (update_success) {
                            // Create response
                            web::json::value response;
                            response[U("success")] = web::json::value::boolean(true);
                            response[U("record_id")] = web::json::value::string(record_id);
                            response[U("signer_id")] = web::json::value::string(signer_id);
                            response[U("is_valid")] = web::json::value::boolean(signature_info->is_valid);
                            
                            // Respond
                            request.reply(web::http::status_codes::OK, response);
                        } else {
                            request.reply(web::http::status_codes::InternalError, U("Failed to update record with signature"));
                        }
                    } else {
                        request.reply(web::http::status_codes::BadRequest, U("Failed to sign record"));
                    }
                }
                catch (const std::exception& e) {
                    logging::Logger::getInstance().error("Error processing record signing: {}", e.what());
                    request.reply(web::http::status_codes::BadRequest, 
                        web::json::value::string(U("Invalid signature data: ") + e.what()));
                }
            }).wait();
        } else {
            request.reply(web::http::status_codes::BadRequest, U("Invalid record ID"));
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling SIGN record request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleVerifySignature(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract record ID from URL
        auto path = web::uri::decode(request.relative_uri().path());
        std::regex record_regex("/api/records/([^/]+)/verify");
        std::smatch matches;
        
        if (std::regex_search(path, matches, record_regex) && matches.size() > 1) {
            std::string record_id = matches[1].str();
            
            // Extract signer ID from request body
            request.extract_json().then([this, request, record_id](web::json::value json) {
                try {
                    // Get record
                    auto record_opt = record_service_->getRecord(record_id);
                    if (!record_opt) {
                        request.reply(web::http::status_codes::NotFound, U("Record not found"));
                        return;
                    }
                    
                    std::string signer_id = utility::conversions::to_utf8string(json[U("signer_id")].as_string());
                    
                    // Verify signature
                    auto verification = signature_service_->verifySignature(*record_opt, signer_id);
                    
                    if (verification) {
                        // Create response
                        web::json::value response;
                        response[U("success")] = web::json::value::boolean(true);
                        response[U("record_id")] = web::json::value::string(record_id);
                        response[U("signer_id")] = web::json::value::string(signer_id);
                        response[U("is_valid")] = web::json::value::boolean(verification->first);
                        
                        // Respond
                        request.reply(web::http::status_codes::OK, response);
                    } else {
                        request.reply(web::http::status_codes::BadRequest, U("Signature not found"));
                    }
                }
                catch (const std::exception& e) {
                    logging::Logger::getInstance().error("Error processing signature verification: {}", e.what());
                    request.reply(web::http::status_codes::BadRequest, 
                        web::json::value::string(U("Error verifying signature: ") + e.what()));
                }
            }).wait();
        } else {
            request.reply(web::http::status_codes::BadRequest, U("Invalid record ID"));
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling VERIFY signature request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

// Compliance handlers

void RestApiAdapter::handleCheckCompliance(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract query parameters
        auto query_params = request.relative_uri().query();
        auto query_map = web::uri::split_query(query_params);
        
        if (query_map.find(U("trainee_id")) == query_map.end() ||
            query_map.find(U("regulation_id")) == query_map.end() ||
            query_map.find(U("certification_type")) == query_map.end()) {
            
            request.reply(web::http::status_codes::BadRequest, U("Missing required parameters"));
            return;
        }
        
        std::string trainee_id = utility::conversions::to_utf8string(query_map[U("trainee_id")]);
        std::string regulation_id = utility::conversions::to_utf8string(query_map[U("regulation_id")]);
        std::string certification_type = utility::conversions::to_utf8string(query_map[U("certification_type")]);
        
        // Check compliance
        auto status = compliance_service_->checkCompliance(
            trainee_id,
            regulation_id,
            certification_type
        );
        
        // Create response
        auto response_json = complianceStatusToJson(status);
        
        // Respond
        request.reply(web::http::status_codes::OK, response_json);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling CHECK compliance request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleListComplianceRequirements(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract query parameters
        auto query_params = request.relative_uri().query();
        auto query_map = web::uri::split_query(query_params);
        
        std::optional<std::string> regulation_id;
        std::optional<std::string> certification_type;
        
        if (query_map.find(U("regulation_id")) != query_map.end()) {
            regulation_id = utility::conversions::to_utf8string(query_map[U("regulation_id")]);
        }
        
        if (query_map.find(U("certification_type")) != query_map.end()) {
            certification_type = utility::conversions::to_utf8string(query_map[U("certification_type")]);
        }
        
        // List requirements
        auto requirements = compliance_service_->listRequirements(
            regulation_id,
            certification_type
        );
        
        // Create response
        web::json::value response;
        response[U("success")] = web::json::value::boolean(true);
        
        // Add requirements to response
        web::json::value requirements_array = web::json::value::array(requirements.size());
        for (size_t i = 0; i < requirements.size(); i++) {
            web::json::value req;
            req[U("requirement_id")] = web::json::value::string(requirements[i].requirement_id);
            req[U("requirement_name")] = web::json::value::string(requirements[i].requirement_name);
            req[U("regulation_id")] = web::json::value::string(requirements[i].regulation_id);
            req[U("regulation_name")] = web::json::value::string(requirements[i].regulation_name);
            req[U("regulation_reference")] = web::json::value::string(requirements[i].regulation_reference);
            req[U("description")] = web::json::value::string(requirements[i].description);
            req[U("required_count")] = web::json::value::number(requirements[i].required_count);
            
            if (requirements[i].duration_days) {
                req[U("duration_days")] = web::json::value::number(*requirements[i].duration_days);
            }
            
            requirements_array[i] = req;
        }
        
        response[U("requirements")] = requirements_array;
        
        // Respond
        request.reply(web::http::status_codes::OK, response);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling LIST compliance requirements request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleMapRegulations(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract mapping request from request body
        request.extract_json().then([this, request](web::json::value json) {
            try {
                std::string source_regulation_id = utility::conversions::to_utf8string(json[U("source_regulation_id")].as_string());
                std::string target_regulation_id = utility::conversions::to_utf8string(json[U("target_regulation_id")].as_string());
                
                // Map regulations
                auto mappings = compliance_service_->mapRegulations(
                    source_regulation_id,
                    target_regulation_id
                );
                
                // Create response
                web::json::value response;
                response[U("success")] = web::json::value::boolean(true);
                
                // Add mappings to response
                web::json::value mappings_array = web::json::value::array(mappings.size());
                for (size_t i = 0; i < mappings.size(); i++) {
                    web::json::value mapping;
                    mapping[U("source_requirement_id")] = web::json::value::string(mappings[i].source_requirement_id);
                    mapping[U("source_requirement_name")] = web::json::value::string(mappings[i].source_requirement_name);
                    mapping[U("target_requirement_id")] = web::json::value::string(mappings[i].target_requirement_id);
                    mapping[U("target_requirement_name")] = web::json::value::string(mappings[i].target_requirement_name);
                    mapping[U("equivalence_factor")] = web::json::value::number(mappings[i].equivalence_factor);
                    mapping[U("notes")] = web::json::value::string(mappings[i].notes);
                    
                    mappings_array[i] = mapping;
                }
                
                response[U("mappings")] = mappings_array;
                
                // Respond
                request.reply(web::http::status_codes::OK, response);
            }
            catch (const std::exception& e) {
                logging::Logger::getInstance().error("Error processing regulation mapping: {}", e.what());
                request.reply(web::http::status_codes::BadRequest, 
                    web::json::value::string(U("Invalid mapping request: ") + e.what()));
            }
        }).wait();
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling MAP regulations request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

// Syllabus handlers

void RestApiAdapter::handleGetSyllabus(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract syllabus ID from URL
        auto path = web::uri::decode(request.relative_uri().path());
        std::regex syllabus_regex("/api/syllabi/([^/]+)");
        std::smatch matches;
        
        if (std::regex_search(path, matches, syllabus_regex) && matches.size() > 1) {
            std::string syllabus_id = matches[1].str();
            
            // Extract query parameters
            auto query_params = request.relative_uri().query();
            auto query_map = web::uri::split_query(query_params);
            
            std::optional<std::string> version;
            
            if (query_map.find(U("version")) != query_map.end()) {
                version = utility::conversions::to_utf8string(query_map[U("version")]);
            }
            
            // Get syllabus
            auto syllabus = syllabus_service_->getSyllabus(syllabus_id, version);
            
            if (syllabus) {
                // Convert to JSON and respond
                auto response_json = syllabusToJson(*syllabus);
                request.reply(web::http::status_codes::OK, response_json);
            } else {
                request.reply(web::http::status_codes::NotFound, U("Syllabus not found"));
            }
        } else {
            request.reply(web::http::status_codes::BadRequest, U("Invalid syllabus ID"));
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling GET syllabus request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleCreateSyllabus(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract syllabus from request body
        request.extract_json().then([this, request](web::json::value json) {
            try {
                // Convert JSON to syllabus
                auto syllabus = jsonToSyllabus(json);
                
                // Create syllabus
                std::string syllabus_id = syllabus_service_->createSyllabus(syllabus);
                
                if (!syllabus_id.empty()) {
                    // Create response
                    web::json::value response;
                    response[U("success")] = web::json::value::boolean(true);
                    response[U("syllabus_id")] = web::json::value::string(syllabus_id);
                    response[U("version")] = web::json::value::string(syllabus.getVersion());
                    
                    // Respond
                    request.reply(web::http::status_codes::Created, response);
                } else {
                    request.reply(web::http::status_codes::BadRequest, U("Failed to create syllabus"));
                }
            }
            catch (const std::exception& e) {
                logging::Logger::getInstance().error("Error processing syllabus creation: {}", e.what());
                request.reply(web::http::status_codes::BadRequest, 
                    web::json::value::string(U("Invalid syllabus data: ") + e.what()));
            }
        }).wait();
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling CREATE syllabus request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleUpdateSyllabus(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    std::string user_id = extractUserId(token);
    
    try {
        // Extract syllabus ID from URL
        auto path = web::uri::decode(request.relative_uri().path());
        std::regex syllabus_regex("/api/syllabi/([^/]+)");
        std::smatch matches;
        
        if (std::regex_search(path, matches, syllabus_regex) && matches.size() > 1) {
            std::string syllabus_id = matches[1].str();
            
            // Extract syllabus from request body
            request.extract_json().then([this, request, syllabus_id, user_id](web::json::value json) {
                try {
                    // Convert JSON to syllabus
                    auto syllabus = jsonToSyllabus(json);
                    
                    // Ensure syllabus ID matches
                    if (syllabus.getSyllabusId() != syllabus_id) {
                        syllabus.setSyllabusId(syllabus_id);
                    }
                    
                    // Update syllabus
                    bool success = syllabus_service_->updateSyllabus(syllabus, user_id);
                    
                    if (success) {
                        // Create response
                        web::json::value response;
                        response[U("success")] = web::json::value::boolean(true);
                        response[U("syllabus_id")] = web::json::value::string(syllabus_id);
                        response[U("version")] = web::json::value::string(syllabus.getVersion());
                        
                        // Respond
                        request.reply(web::http::status_codes::OK, response);
                    } else {
                        request.reply(web::http::status_codes::NotFound, U("Syllabus not found or not authorized"));
                    }
                }
                catch (const std::exception& e) {
                    logging::Logger::getInstance().error("Error processing syllabus update: {}", e.what());
                    request.reply(web::http::status_codes::BadRequest, 
                        web::json::value::string(U("Invalid syllabus data: ") + e.what()));
                }
            }).wait();
        } else {
            request.reply(web::http::status_codes::BadRequest, U("Invalid syllabus ID"));
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling UPDATE syllabus request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleDeleteSyllabus(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    std::string user_id = extractUserId(token);
    
    try {
        // Extract syllabus ID from URL
        auto path = web::uri::decode(request.relative_uri().path());
        std::regex syllabus_regex("/api/syllabi/([^/]+)");
        std::smatch matches;
        
        if (std::regex_search(path, matches, syllabus_regex) && matches.size() > 1) {
            std::string syllabus_id = matches[1].str();
            
            // Delete syllabus
            bool success = syllabus_service_->deleteSyllabus(syllabus_id, user_id);
            
            if (success) {
                // Create response
                web::json::value response;
                response[U("success")] = web::json::value::boolean(true);
                response[U("syllabus_id")] = web::json::value::string(syllabus_id);
                
                // Respond
                request.reply(web::http::status_codes::OK, response);
            } else {
                request.reply(web::http::status_codes::NotFound, U("Syllabus not found or not authorized"));
            }
        } else {
            request.reply(web::http::status_codes::BadRequest, U("Invalid syllabus ID"));
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling DELETE syllabus request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleListSyllabi(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract query parameters
        auto query_params = request.relative_uri().query();
        auto query_map = web::uri::split_query(query_params);
        
        // Parse parameters
        std::optional<std::string> course_id;
        std::optional<syllabus::SyllabusStatus> status;
        std::optional<std::chrono::system_clock::time_point> effective_date;
        int page = 1;
        int page_size = 10;
        std::string sort_by = "effective_date";
        bool ascending = false;
        
        // Extract parameters from query string
        if (query_map.find(U("course_id")) != query_map.end()) {
            course_id = utility::conversions::to_utf8string(query_map[U("course_id")]);
        }
        
        if (query_map.find(U("status")) != query_map.end()) {
            std::string status_str = utility::conversions::to_utf8string(query_map[U("status")]);
            int status_value = std::stoi(status_str);
            status = static_cast<syllabus::SyllabusStatus>(status_value);
        }
        
        if (query_map.find(U("effective_date")) != query_map.end()) {
            std::string date_str = utility::conversions::to_utf8string(query_map[U("effective_date")]);
            int64_t timestamp = std::stoll(date_str);
            effective_date = std::chrono::system_clock::time_point(std::chrono::milliseconds(timestamp));
        }
        
        if (query_map.find(U("page")) != query_map.end()) {
            page = std::stoi(utility::conversions::to_utf8string(query_map[U("page")]));
        }
        
        if (query_map.find(U("page_size")) != query_map.end()) {
            page_size = std::stoi(utility::conversions::to_utf8string(query_map[U("page_size")]));
        }
        
        if (query_map.find(U("sort_by")) != query_map.end()) {
            sort_by = utility::conversions::to_utf8string(query_map[U("sort_by")]);
        }
        
        if (query_map.find(U("ascending")) != query_map.end()) {
            std::string asc_str = utility::conversions::to_utf8string(query_map[U("ascending")]);
            ascending = (asc_str == "true" || asc_str == "1");
        }
        
        // List syllabi
        auto [syllabi, total_count] = syllabus_service_->listSyllabi(
            course_id,
            status,
            effective_date,
            page,
            page_size,
            sort_by,
            ascending
        );
        
        // Create response
        web::json::value response;
        response[U("success")] = web::json::value::boolean(true);
        response[U("total_count")] = web::json::value::number(total_count);
        response[U("page")] = web::json::value::number(page);
        response[U("page_size")] = web::json::value::number(page_size);
        
        // Add syllabi to response
        web::json::value syllabi_array = web::json::value::array(syllabi.size());
        for (size_t i = 0; i < syllabi.size(); i++) {
            web::json::value syllabus_json;
            syllabus_json[U("syllabus_id")] = web::json::value::string(syllabi[i].syllabus_id);
            syllabus_json[U("course_id")] = web::json::value::string(syllabi[i].course_id);
            syllabus_json[U("title")] = web::json::value::string(syllabi[i].title);
            syllabus_json[U("version")] = web::json::value::string(syllabi[i].version);
            syllabus_json[U("effective_date")] = web::json::value::number(
                std::chrono::duration_cast<std::chrono::milliseconds>(
                    syllabi[i].effective_date.time_since_epoch()
                ).count()
            );
            
            if (syllabi[i].expiration_date) {
                syllabus_json[U("expiration_date")] = web::json::value::number(
                    std::chrono::duration_cast<std::chrono::milliseconds>(
                        syllabi[i].expiration_date->time_since_epoch()
                    ).count()
                );
            }
            
            syllabus_json[U("status")] = web::json::value::number(static_cast<int>(syllabi[i].status));
            syllabus_json[U("author_id")] = web::json::value::string(syllabi[i].author_id);
            
            syllabi_array[i] = syllabus_json;
        }
        
        response[U("syllabi")] = syllabi_array;
        
        // Respond
        request.reply(web::http::status_codes::OK, response);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling LIST syllabi request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

void RestApiAdapter::handleTrackSyllabusChanges(web::http::http_request request) {
    // Extract token and validate
    std::string token = extractToken(request);
    if (!validateToken(token)) {
        request.reply(web::http::status_codes::Unauthorized, U("Invalid authentication token"));
        return;
    }
    
    try {
        // Extract syllabus ID from URL
        auto path = web::uri::decode(request.relative_uri().path());
        std::regex syllabus_regex("/api/syllabi/([^/]+)/changes");
        std::smatch matches;
        
        if (std::regex_search(path, matches, syllabus_regex) && matches.size() > 1) {
            std::string syllabus_id = matches[1].str();
            
            // Extract query parameters
            auto query_params = request.relative_uri().query();
            auto query_map = web::uri::split_query(query_params);
            
            if (query_map.find(U("from_version")) == query_map.end() || 
                query_map.find(U("to_version")) == query_map.end()) {
                
                request.reply(web::http::status_codes::BadRequest, U("Missing required parameters"));
                return;
            }
            
            std::string from_version = utility::conversions::to_utf8string(query_map[U("from_version")]);
            std::string to_version = utility::conversions::to_utf8string(query_map[U("to_version")]);
            
            // Track changes
            auto changes = syllabus_service_->trackChanges(
                syllabus_id,
                from_version,
                to_version
            );
            
            // Create response
            web::json::value response;
            response[U("success")] = web::json::value::boolean(true);
            response[U("syllabus_id")] = web::json::value::string(syllabus_id);
            response[U("from_version")] = web::json::value::string(from_version);
            response[U("to_version")] = web::json::value::string(to_version);
            
            // Add changes to response
            web::json::value changes_array = web::json::value::array(changes.size());
            for (size_t i = 0; i < changes.size(); i++) {
                web::json::value change;
                change[U("change_type")] = web::json::value::string(
                    syllabus::changeTypeToString(changes[i].change_type)
                );
                change[U("element_type")] = web::json::value::string(
                    syllabus::elementTypeToString(changes[i].element_type)
                );
                change[U("element_id")] = web::json::value::string(changes[i].element_id);
                
                if (changes[i].parent_id) {
                    change[U("parent_id")] = web::json::value::string(*changes[i].parent_id);
                }
                
                change[U("description")] = web::json::value::string(changes[i].description);
                change[U("rationale")] = web::json::value::string(changes[i].rationale);
                change[U("author_id")] = web::json::value::string(changes[i].author_id);
                change[U("timestamp")] = web::json::value::number(
                    std::chrono::duration_cast<std::chrono::milliseconds>(
                        changes[i].timestamp.time_since_epoch()
                    ).count()
                );
                
                // Add old and new values
                web::json::value old_values = web::json::value::object();
                for (const auto& [key, value] : changes[i].old_values) {
                    old_values[utility::conversions::to_string_t(key)] = 
                        web::json::value::string(utility::conversions::to_string_t(value));
                }
                change[U("old_values")] = old_values;
                
                web::json::value new_values = web::json::value::object();
                for (const auto& [key, value] : changes[i].new_values) {
                    new_values[utility::conversions::to_string_t(key)] = 
                        web::json::value::string(utility::conversions::to_string_t(value));
                }
                change[U("new_values")] = new_values;
                
                changes_array[i] = change;
            }
            
            response[U("changes")] = changes_array;
            
            // Respond
            request.reply(web::http::status_codes::OK, response);
        } else {
            request.reply(web::http::status_codes::BadRequest, U("Invalid syllabus ID"));
        }
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error handling TRACK syllabus changes request: {}", e.what());
        request.reply(web::http::status_codes::InternalError, U("Internal server error"));
    }
}

// Utility methods

std::string RestApiAdapter::extractToken(const web::http::http_request& request) {
    // Get Authorization header
    auto headers = request.headers();
    auto auth_iter = headers.find("Authorization");
    
    if (auth_iter != headers.end()) {
        std::string auth_header = auth_iter->second;
        
        // Check for Bearer prefix
        if (auth_header.substr(0, 7) == "Bearer ") {
            return auth_header.substr(7);
        }
    }
    
    return "";
}

bool RestApiAdapter::validateToken(const std::string& token) {
    // For demo purposes, just check if token is not empty
    // In a real implementation, this would validate with the core platform service
    if (token.empty()) {
        return false;
    }
    
    try {
        // Basic JWT validation
        auto decoded = jwt::decode(token);
        
        // Check expiration
        if (decoded.has_expires_at() && decoded.get_expires_at() < std::chrono::system_clock::now()) {
            logging::Logger::getInstance().warn("Token expired");
            return false;
        }
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().warn("Token validation error: {}", e.what());
        return false;
    }
}

std::string RestApiAdapter::extractUserId(const std::string& token) {
    if (token.empty()) {
        return "";
    }
    
    try {
        // Decode JWT to extract user ID
        auto decoded = jwt::decode(token);
        return decoded.get_subject();
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().warn("Error extracting user ID from token: {}", e.what());
        return "";
    }
}

// Conversion methods

web::json::value RestApiAdapter::recordToJson(const records::TrainingRecord& record) {
    web::json::value json;
    
    json[U("record_id")] = web::json::value::string(record.getRecordId());
    json[U("trainee_id")] = web::json::value::string(record.getTraineeId());
    json[U("instructor_id")] = web::json::value::string(record.getInstructorId());
    json[U("record_type")] = web::json::value::number(static_cast<int>(record.getRecordType()));
    json[U("course_id")] = web::json::value::string(record.getCourseId());
    json[U("syllabus_id")] = web::json::value::string(record.getSyllabusId());
    json[U("exercise_id")] = web::json::value::string(record.getExerciseId());
    
    // Set date
    json[U("date")] = web::json::value::number(
        std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getDate().time_since_epoch()
        ).count()
    );
    
    json[U("duration_minutes")] = web::json::value::number(record.getDurationMinutes());
    json[U("location")] = web::json::value::string(record.getLocation());
    json[U("aircraft_type")] = web::json::value::string(record.getAircraftType());
    
    // Set grades
    web::json::value grades_array = web::json::value::array(record.getGrades().size());
    for (size_t i = 0; i < record.getGrades().size(); i++) {
        web::json::value grade;
        grade[U("criteria_id")] = web::json::value::string(record.getGrades()[i].criteria_id);
        grade[U("criteria_name")] = web::json::value::string(record.getGrades()[i].criteria_name);
        grade[U("grade")] = web::json::value::number(record.getGrades()[i].grade);
        grade[U("comments")] = web::json::value::string(record.getGrades()[i].comments);
        
        grades_array[i] = grade;
    }
    
    json[U("grades")] = grades_array;
    
    // Set attachments
    web::json::value attachments_array = web::json::value::array(record.getAttachments().size());
    for (size_t i = 0; i < record.getAttachments().size(); i++) {
        attachments_array[i] = web::json::value::string(record.getAttachments()[i]);
    }
    
    json[U("attachments")] = attachments_array;
    
    json[U("comments")] = web::json::value::string(record.getComments());
    
    // Set signatures
    if (record.getTraineeSignature()) {
        web::json::value trainee_sig;
        trainee_sig[U("signer_id")] = web::json::value::string(record.getTraineeSignature()->signer_id);
        trainee_sig[U("signer_name")] = web::json::value::string(record.getTraineeSignature()->signer_name);
        trainee_sig[U("certificate_id")] = web::json::value::string(record.getTraineeSignature()->certificate_id);
        trainee_sig[U("timestamp")] = web::json::value::number(
            std::chrono::duration_cast<std::chrono::milliseconds>(
                record.getTraineeSignature()->timestamp.time_since_epoch()
            ).count()
        );
        trainee_sig[U("is_valid")] = web::json::value::boolean(record.getTraineeSignature()->is_valid);
        
        json[U("trainee_signature")] = trainee_sig;
    }
    
    if (record.getInstructorSignature()) {
        web::json::value instructor_sig;
        instructor_sig[U("signer_id")] = web::json::value::string(record.getInstructorSignature()->signer_id);
        instructor_sig[U("signer_name")] = web::json::value::string(record.getInstructorSignature()->signer_name);
        instructor_sig[U("certificate_id")] = web::json::value::string(record.getInstructorSignature()->certificate_id);
        instructor_sig[U("timestamp")] = web::json::value::number(
            std::chrono::duration_cast<std::chrono::milliseconds>(
                record.getInstructorSignature()->timestamp.time_since_epoch()
            ).count()
        );
        instructor_sig[U("is_valid")] = web::json::value::boolean(record.getInstructorSignature()->is_valid);
        
        json[U("instructor_signature")] = instructor_sig;
    }
    
    json[U("is_draft")] = web::json::value::boolean(record.isDraft());
    
    // Set timestamps
    json[U("created_at")] = web::json::value::number(
        std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getCreatedAt().time_since_epoch()
        ).count()
    );
    
    json[U("updated_at")] = web::json::value::number(
        std::chrono::duration_cast<std::chrono::milliseconds>(
            record.getUpdatedAt().time_since_epoch()
        ).count()
    );
    
    // Set metadata
    web::json::value metadata = web::json::value::object();
    for (const auto& [key, value] : record.getMetadata()) {
        metadata[utility::conversions::to_string_t(key)] = web::json::value::string(utility::conversions::to_string_t(value));
    }
    
    json[U("metadata")] = metadata;
    
    return json;
}

records::TrainingRecord RestApiAdapter::jsonToRecord(const web::json::value& json) {
    records::TrainingRecord record;
    
    if (json.has_field(U("record_id"))) {
        record.setRecordId(utility::conversions::to_utf8string(json.at(U("record_id")).as_string()));
    }
    
    record.setTraineeId(utility::conversions::to_utf8string(json.at(U("trainee_id")).as_string()));
    record.setInstructorId(utility::conversions::to_utf8string(json.at(U("instructor_id")).as_string()));
    record.setRecordType(static_cast<records::RecordType>(json.at(U("record_type")).as_integer()));
    record.setCourseId(utility::conversions::to_utf8string(json.at(U("course_id")).as_string()));
    record.setSyllabusId(utility::conversions::to_utf8string(json.at(U("syllabus_id")).as_string()));
    record.setExerciseId(utility::conversions::to_utf8string(json.at(U("exercise_id")).as_string()));
    
    // Set date
    record.setDate(std::chrono::system_clock::time_point(
        std::chrono::milliseconds(json.at(U("date")).as_number().to_int64())
    ));
    
    record.setDurationMinutes(json.at(U("duration_minutes")).as_integer());
    record.setLocation(utility::conversions::to_utf8string(json.at(U("location")).as_string()));
    record.setAircraftType(utility::conversions::to_utf8string(json.at(U("aircraft_type")).as_string()));
    
    // Set grades
    std::vector<records::GradeItem> grades;
    for (const auto& grade_json : json.at(U("grades")).as_array()) {
        records::GradeItem grade;
        grade.criteria_id = utility::conversions::to_utf8string(grade_json.at(U("criteria_id")).as_string());
        grade.criteria_name = utility::conversions::to_utf8string(grade_json.at(U("criteria_name")).as_string());
        grade.grade = grade_json.at(U("grade")).as_integer();
        grade.comments = utility::conversions::to_utf8string(grade_json.at(U("comments")).as_string());
        
        grades.push_back(grade);
    }
    
    record.setGrades(grades);
    
    // Set attachments
    std::vector<std::string> attachments;
    for (const auto& attachment : json.at(U("attachments")).as_array()) {
        attachments.push_back(utility::conversions::to_utf8string(attachment.as_string()));
    }
    
    record.setAttachments(attachments);
    
    record.setComments(utility::conversions::to_utf8string(json.at(U("comments")).as_string()));
    
    record.setDraft(json.at(U("is_draft")).as_bool());
    
    // Set metadata
    std::map<std::string, std::string> metadata;
    for (const auto& pair : json.at(U("metadata")).as_object()) {
        metadata[utility::conversions::to_utf8string(pair.first)] = 
            utility::conversions::to_utf8string(pair.second.as_string());
    }
    
    record.setMetadata(metadata);
    
    return record;
}

web::json::value RestApiAdapter::syllabusToJson(const syllabus::Syllabus& syllabus) {
    // Implement conversion from Syllabus to JSON
    // Since Syllabus is complex, I'm providing a simplified implementation
    web::json::value json;
    
    json[U("syllabus_id")] = web::json::value::string(syllabus.getSyllabusId());
    json[U("course_id")] = web::json::value::string(syllabus.getCourseId());
    json[U("title")] = web::json::value::string(syllabus.getTitle());
    json[U("description")] = web::json::value::string(syllabus.getDescription());
    json[U("version")] = web::json::value::string(syllabus.getVersion());
    
    return json;
}

syllabus::Syllabus RestApiAdapter::jsonToSyllabus(const web::json::value& json) {
    // Implement conversion from JSON to Syllabus
    // Since Syllabus is complex, I'm providing a simplified implementation
    syllabus::Syllabus syllabus;
    
    if (json.has_field(U("syllabus_id"))) {
        syllabus.setSyllabusId(utility::conversions::to_utf8string(json.at(U("syllabus_id")).as_string()));
    }
    
    syllabus.setCourseId(utility::conversions::to_utf8string(json.at(U("course_id")).as_string()));
    syllabus.setTitle(utility::conversions::to_utf8string(json.at(U("title")).as_string()));
    syllabus.setDescription(utility::conversions::to_utf8string(json.at(U("description")).as_string()));
    syllabus.setVersion(utility::conversions::to_utf8string(json.at(U("version")).as_string()));
    
    return syllabus;
}

web::json::value RestApiAdapter::complianceStatusToJson(const compliance::ComplianceStatus& status) {
    web::json::value json;
    
    json[U("is_compliant")] = web::json::value::boolean(status.is_compliant);
    
    web::json::value items_array = web::json::value::array(status.compliance_items.size());
    for (size_t i = 0; i < status.compliance_items.size(); i++) {
        web::json::value item;
        item[U("requirement_id")] = web::json::value::string(status.compliance_items[i].requirement_id);
        item[U("requirement_name")] = web::json::value::string(status.compliance_items[i].requirement_name);
        item[U("regulation_reference")] = web::json::value::string(status.compliance_items[i].regulation_reference);
        item[U("is_satisfied")] = web::json::value::boolean(status.compliance_items[i].is_satisfied);
        item[U("required_count")] = web::json::value::number(status.compliance_items[i].required_count);
        item[U("completed_count")] = web::json::value::number(status.compliance_items[i].completed_count);
        
        web::json::value records_array = web::json::value::array(status.compliance_items[i].satisfied_by_records.size());
        for (size_t j = 0; j < status.compliance_items[i].satisfied_by_records.size(); j++) {
            records_array[j] = web::json::value::string(status.compliance_items[i].satisfied_by_records[j]);
        }
        
        item[U("satisfied_by_records")] = records_array;
        
        if (status.compliance_items[i].expiration_date) {
            item[U("expiration_date")] = web::json::value::number(
                std::chrono::duration_cast<std::chrono::milliseconds>(
                    status.compliance_items[i].expiration_date->time_since_epoch()
                ).count()
            );
        }
        
        items_array[i] = item;
    }
    
    json[U("compliance_items")] = items_array;
    
    return json;
}

} // namespace rest
} // namespace etr
#include "rest/rest_adapter.h"
#include "logging/logger.h"
#include <regex>
#include <cpprest/uri_builder.h>

namespace etr {
namespace rest {

RestAdapter::RestAdapter(
    const std::string& host,
    int port,
    std::shared_ptr<service::ETRServiceImpl> service_impl
) : host_(host),
    port_(port),
    service_impl_(service_impl),
    running_(false) {
    
    // Create listener URI
    web::uri_builder uri_builder;
    uri_builder.set_scheme("http");
    uri_builder.set_host(host_);
    uri_builder.set_port(port_);
    
    // Create listener
    listener_ = std::make_unique<web::http::experimental::listener::http_listener>(uri_builder.to_uri());
    
    // Configure listener
    listener_->support(web::http::methods::GET, [this](web::http::http_request request) {
        handleGet(request);
    });
    
    listener_->support(web::http::methods::POST, [this](web::http::http_request request) {
        handlePost(request);
    });
    
    listener_->support(web::http::methods::PUT, [this](web::http::http_request request) {
        handlePut(request);
    });
    
    listener_->support(web::http::methods::DEL, [this](web::http::http_request request) {
        handleDelete(request);
    });
    
    listener_->support(web::http::methods::OPTIONS, [this](web::http::http_request request) {
        web::http::http_response response(web::http::status_codes::OK);
        setCorsHeaders(response);
        request.reply(response);
    });
    
    logging::Logger::getInstance().info("REST adapter created for {}:{}", host_, port_);
}

RestAdapter::~RestAdapter() {
    stop();
}

bool RestAdapter::start() {
    if (running_) {
        logging::Logger::getInstance().warn("REST adapter already running");
        return true;
    }
    
    try {
        listener_->open().wait();
        running_ = true;
        
        logging::Logger::getInstance().info("REST adapter started on {}:{}", host_, port_);
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Failed to start REST adapter: {}", e.what());
        return false;
    }
}

void RestAdapter::stop() {
    if (!running_) {
        return;
    }
    
    try {
        listener_->close().wait();
        running_ = false;
        
        logging::Logger::getInstance().info("REST adapter stopped");
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error stopping REST adapter: {}", e.what());
    }
}

web::http::http_response RestAdapter::handleGet(web::http::http_request request) {
    try {
        const web::uri& uri = request.request_uri();
        const std::string& path = uri.path();
        
        logging::Logger::getInstance().debug("GET request: {}", path);
        
        // Route the request based on the path
        if (std::regex_match(path, std::regex("/api/records/([^/]+)"))) {
            handleGetRecord(request);
            return web::http::http_response();
        }
        else if (std::regex_match(path, std::regex("/api/records"))) {
            handleListRecords(request);
            return web::http::http_response();
        }
        else if (std::regex_match(path, std::regex("/api/syllabi/([^/]+)"))) {
            handleGetSyllabus(request);
            return web::http::http_response();
        }
        else if (std::regex_match(path, std::regex("/api/syllabi"))) {
            handleListSyllabi(request);
            return web::http::http_response();
        }
        else if (std::regex_match(path, std::regex("/api/compliance/requirements"))) {
            handleListComplianceRequirements(request);
            return web::http::http_response();
        }
        // Add more routes as needed
        
        // If no route matches, return 404
        web::http::http_response response(web::http::status_codes::NotFound);
        response.headers().add("Content-Type", "application/json");
        
        web::json::value error_json;
        error_json["error"] = web::json::value::string("Resource not found");
        response.set_body(error_json);
        
        setCorsHeaders(response);
        request.reply(response);
        
        return response;
    }
    catch (const std::exception& e) {
        // Handle unexpected exceptions
        handleInternalError(request, e);
        return web::http::http_response();
    }
}

web::http::http_response RestAdapter::handlePost(web::http::http_request request) {
    try {
        const web::uri& uri = request.request_uri();
        const std::string& path = uri.path();
        
        logging::Logger::getInstance().debug("POST request: {}", path);
        
        // Route the request based on the path
        if (path == "/api/records") {
            handleCreateRecord(request);
            return web::http::http_response();
        }
        else if (path == "/api/records/sign") {
            handleSignRecord(request);
            return web::http::http_response();
        }
        else if (path == "/api/records/verify") {
            handleVerifySignature(request);
            return web::http::http_response();
        }
        else if (path == "/api/syllabi") {
            handleCreateSyllabus(request);
            return web::http::http_response();
        }
        else if (path == "/api/compliance/check") {
            handleCheckCompliance(request);
            return web::http::http_response();
        }
        else if (path == "/api/compliance/map") {
            handleMapRegulations(request);
            return web::http::http_response();
        }
        // Add more routes as needed
        
        // If no route matches, return 404
        web::http::http_response response(web::http::status_codes::NotFound);
        response.headers().add("Content-Type", "application/json");
        
        web::json::value error_json;
        error_json["error"] = web::json::value::string("Resource not found");
        response.set_body(error_json);
        
        setCorsHeaders(response);
        request.reply(response);
        
        return response;
    }
    catch (const std::exception& e) {
        // Handle unexpected exceptions
        handleInternalError(request, e);
        return web::http::http_response();
    }
}

web::http::http_response RestAdapter::handlePut(web::http::http_request request) {
    try {
        const web::uri& uri = request.request_uri();
        const std::string& path = uri.path();
        
        logging::Logger::getInstance().debug("PUT request: {}", path);
        
        // Route the request based on the path
        if (std::regex_match(path, std::regex("/api/records/([^/]+)"))) {
            handleUpdateRecord(request);
            return web::http::http_response();
        }
        else if (std::regex_match(path, std::regex("/api/syllabi/([^/]+)"))) {
            handleUpdateSyllabus(request);
            return web::http::http_response();
        }
        // Add more routes as needed
        
        // If no route matches, return 404
        web::http::http_response response(web::http::status_codes::NotFound);
        response.headers().add("Content-Type", "application/json");
        
        web::json::value error_json;
        error_json["error"] = web::json::value::string("Resource not found");
        response.set_body(error_json);
        
        setCorsHeaders(response);
        request.reply(response);
        
        return response;
    }
    catch (const std::exception& e) {
        // Handle unexpected exceptions
        handleInternalError(request, e);
        return web::http::http_response();
    }
}

web::http::http_response RestAdapter::handleDelete(web::http::http_request request) {
    try {
        const web::uri& uri = request.request_uri();
        const std::string& path = uri.path();
        
        logging::Logger::getInstance().debug("DELETE request: {}", path);
        
        // Route the request based on the path
        if (std::regex_match(path, std::regex("/api/records/([^/]+)"))) {
            handleDeleteRecord(request);
            return web::http::http_response();
        }
        else if (std::regex_match(path, std::regex("/api/syllabi/([^/]+)"))) {
            handleDeleteSyllabus(request);
            return web::http::http_response();
        }
        // Add more routes as needed
        
        // If no route matches, return 404
        web::http::http_response response(web::http::status_codes::NotFound);
        response.headers().add("Content-Type", "application/json");
        
        web::json::value error_json;
        error_json["error"] = web::json::value::string("Resource not found");
        response.set_body(error_json);
        
        setCorsHeaders(response);
        request.reply(response);
        
        return response;
    }
    catch (const std::exception& e) {
        // Handle unexpected exceptions
        handleInternalError(request, e);
        return web::http::http_response();
    }
}

std::string RestAdapter::extractToken(const web::http::http_request& request) {
    // Check for Authorization header
    const web::http::http_headers& headers = request.headers();
    auto it = headers.find("Authorization");
    
    if (it != headers.end()) {
        const std::string& auth_header = it->second;
        
        // Check Bearer prefix
        if (auth_header.substr(0, 7) == "Bearer ") {
            return auth_header.substr(7);
        }
    }
    
    return "";
}

std::map<std::string, std::string> RestAdapter::extractPathParams(
    const web::uri& uri,
    const std::string& path_template
) {
    std::map<std::string, std::string> params;
    
    // Extract parameters from URI path using regular expressions
    std::regex param_regex("\\{([^\\}]+)\\}");
    std::string path_regex_str = path_template;
    
    // Replace {param} with capture groups
    path_regex_str = std::regex_replace(path_regex_str, param_regex, "([^/]+)");
    
    // Extract parameter names
    std::vector<std::string> param_names;
    auto param_begin = std::sregex_iterator(path_template.begin(), path_template.end(), param_regex);
    auto param_end = std::sregex_iterator();
    
    for (auto it = param_begin; it != param_end; ++it) {
        param_names.push_back((*it)[1].str());
    }
    
    // Match the path against the regex
    std::regex path_regex(path_regex_str);
    std::smatch matches;
    
    std::string path = uri.path();
    if (std::regex_match(path, matches, path_regex)) {
        // First match is the full string, skip it
        for (size_t i = 1; i < matches.size() && i - 1 < param_names.size(); ++i) {
            params[param_names[i - 1]] = matches[i].str();
        }
    }
    
    return params;
}

std::unique_ptr<grpc::ClientContext> RestAdapter::createContext(const std::string& token) {
    auto context = std::make_unique<grpc::ClientContext>();
    
    if (!token.empty()) {
        context->AddMetadata("authorization", "Bearer " + token);
    }
    
    return context;
}

void RestAdapter::handleAuthError(
    web::http::http_request& request,
    const std::string& message
) {
    web::http::http_response response(web::http::status_codes::Unauthorized);
    response.headers().add("Content-Type", "application/json");
    
    web::json::value error_json;
    error_json["error"] = web::json::value::string(message);
    response.set_body(error_json);
    
    setCorsHeaders(response);
    request.reply(response);
}

void RestAdapter::handleNotFoundError(
    web::http::http_request& request,
    const std::string& resource
) {
    web::http::http_response response(web::http::status_codes::NotFound);
    response.headers().add("Content-Type", "application/json");
    
    web::json::value error_json;
    error_json["error"] = web::json::value::string(resource + " not found");
    response.set_body(error_json);
    
    setCorsHeaders(response);
    request.reply(response);
}

void RestAdapter::handleInternalError(
    web::http::http_request& request,
    const std::exception& e
) {
    logging::Logger::getInstance().error("Internal server error: {}", e.what());
    
    web::http::http_response response(web::http::status_codes::InternalError);
    response.headers().add("Content-Type", "application/json");
    
    web::json::value error_json;
    error_json["error"] = web::json::value::string("Internal server error");
    response.set_body(error_json);
    
    setCorsHeaders(response);
    request.reply(response);
}

void RestAdapter::setCorsHeaders(web::http::http_response& response) {
    response.headers().add("Access-Control-Allow-Origin", "*");
    response.headers().add("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, OPTIONS");
    response.headers().add("Access-Control-Allow-Headers", "Content-Type, Authorization");
    response.headers().add("Access-Control-Max-Age", "86400");
}

} // namespace rest
} // namespace etr
-- Create schema for ETR service
CREATE SCHEMA IF NOT EXISTS etr;

-- Record types
CREATE TYPE etr.record_type AS ENUM (
    'UNKNOWN',
    'TRAINING_SESSION',
    'ASSESSMENT',
    'CERTIFICATION',
    'QUALIFICATION',
    'ENDORSEMENT'
);

-- Syllabus status
CREATE TYPE etr.syllabus_status AS ENUM (
    'DRAFT',
    'APPROVED',
    'ARCHIVED'
);

-- Change type
CREATE TYPE etr.change_type AS ENUM (
    'ADDED',
    'MODIFIED',
    'REMOVED'
);

-- Element type
CREATE TYPE etr.element_type AS ENUM (
    'SYLLABUS',
    'SECTION',
    'EXERCISE',
    'CRITERIA',
    'OBJECTIVE',
    'REFERENCE',
    'EQUIPMENT',
    'PREREQUISITE',
    'METADATA'
);

-- Users table (minimal, would typically link to core platform service)
CREATE TABLE etr.users (
    user_id TEXT PRIMARY KEY,
    username TEXT NOT NULL,
    role TEXT NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Certificates table
CREATE TABLE etr.certificates (
    certificate_id TEXT PRIMARY KEY,
    user_id TEXT NOT NULL REFERENCES etr.users(user_id),
    subject_name TEXT NOT NULL,
    issuer_name TEXT NOT NULL,
    serial_number TEXT NOT NULL,
    not_before TIMESTAMP WITH TIME ZONE NOT NULL,
    not_after TIMESTAMP WITH TIME ZONE NOT NULL,
    raw_data BYTEA NOT NULL,
    is_valid BOOLEAN NOT NULL DEFAULT TRUE,
    is_revoked BOOLEAN NOT NULL DEFAULT FALSE,
    revocation_reason TEXT,
    revocation_time TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    UNIQUE(user_id, serial_number)
);

-- Training records table
CREATE TABLE etr.training_records (
    record_id TEXT PRIMARY KEY,
    trainee_id TEXT NOT NULL REFERENCES etr.users(user_id),
    instructor_id TEXT NOT NULL REFERENCES etr.users(user_id),
    record_type etr.record_type NOT NULL,
    course_id TEXT NOT NULL,
    syllabus_id TEXT NOT NULL,
    exercise_id TEXT NOT NULL,
    date TIMESTAMP WITH TIME ZONE NOT NULL,
    duration_minutes INTEGER NOT NULL,
    location TEXT NOT NULL,
    aircraft_type TEXT,
    comments TEXT,
    is_draft BOOLEAN NOT NULL DEFAULT TRUE,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Training record grades
CREATE TABLE etr.record_grades (
    record_id TEXT NOT NULL REFERENCES etr.training_records(record_id) ON DELETE CASCADE,
    criteria_id TEXT NOT NULL,
    criteria_name TEXT NOT NULL,
    grade INTEGER NOT NULL,
    comments TEXT,
    PRIMARY KEY (record_id, criteria_id)
);

-- Training record attachments
CREATE TABLE etr.record_attachments (
    record_id TEXT NOT NULL REFERENCES etr.training_records(record_id) ON DELETE CASCADE,
    attachment_path TEXT NOT NULL,
    attachment_name TEXT NOT NULL,
    content_type TEXT NOT NULL,
    size_bytes BIGINT NOT NULL,
    upload_time TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    PRIMARY KEY (record_id, attachment_path)
);

-- Training record metadata
CREATE TABLE etr.record_metadata (
    record_id TEXT NOT NULL REFERENCES etr.training_records(record_id) ON DELETE CASCADE,
    key TEXT NOT NULL,
    value TEXT NOT NULL,
    PRIMARY KEY (record_id, key)
);

-- Record signatures
CREATE TABLE etr.record_signatures (
    record_id TEXT NOT NULL REFERENCES etr.training_records(record_id) ON DELETE CASCADE,
    signer_id TEXT NOT NULL REFERENCES etr.users(user_id),
    signer_name TEXT NOT NULL,
    certificate_id TEXT REFERENCES etr.certificates(certificate_id),
    signature_data BYTEA NOT NULL,
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    is_valid BOOLEAN NOT NULL,
    is_instructor BOOLEAN NOT NULL,
    PRIMARY KEY (record_id, signer_id)
);

-- Training record audit log
CREATE TABLE etr.record_audit_log (
    id SERIAL PRIMARY KEY,
    record_id TEXT NOT NULL REFERENCES etr.training_records(record_id) ON DELETE CASCADE,
    action TEXT NOT NULL,
    user_id TEXT NOT NULL REFERENCES etr.users(user_id),
    details TEXT,
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Compliance requirements
CREATE TABLE etr.compliance_requirements (
    requirement_id TEXT PRIMARY KEY,
    requirement_name TEXT NOT NULL,
    regulation_id TEXT NOT NULL,
    regulation_name TEXT NOT NULL,
    regulation_reference TEXT NOT NULL,
    description TEXT,
    required_count INTEGER NOT NULL,
    duration_days INTEGER,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW()
);

-- Equivalent requirements
CREATE TABLE etr.equivalent_requirements (
    source_requirement_id TEXT NOT NULL REFERENCES etr.compliance_requirements(requirement_id) ON DELETE CASCADE,
    target_requirement_id TEXT NOT NULL REFERENCES etr.compliance_requirements(requirement_id) ON DELETE CASCADE,
    PRIMARY KEY (source_requirement_id, target_requirement_id)
);

-- Regulation mappings
CREATE TABLE etr.regulation_mappings (
    source_requirement_id TEXT NOT NULL REFERENCES etr.compliance_requirements(requirement_id) ON DELETE CASCADE,
    target_requirement_id TEXT NOT NULL REFERENCES etr.compliance_requirements(requirement_id) ON DELETE CASCADE,
    equivalence_factor DOUBLE PRECISION NOT NULL,
    notes TEXT,
    PRIMARY KEY (source_requirement_id, target_requirement_id)
);

-- Trainee compliance status
CREATE TABLE etr.trainee_compliance (
    trainee_id TEXT NOT NULL REFERENCES etr.users(user_id),
    requirement_id TEXT NOT NULL REFERENCES etr.compliance_requirements(requirement_id) ON DELETE CASCADE,
    is_satisfied BOOLEAN NOT NULL DEFAULT FALSE,
    completed_count INTEGER NOT NULL DEFAULT 0,
    expiration_date TIMESTAMP WITH TIME ZONE,
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    PRIMARY KEY (trainee_id, requirement_id)
);

-- Trainee compliance records
CREATE TABLE etr.trainee_compliance_records (
    trainee_id TEXT NOT NULL,
    requirement_id TEXT NOT NULL,
    record_id TEXT NOT NULL REFERENCES etr.training_records(record_id) ON DELETE CASCADE,
    PRIMARY KEY (trainee_id, requirement_id, record_id),
    FOREIGN KEY (trainee_id, requirement_id) REFERENCES etr.trainee_compliance(trainee_id, requirement_id) ON DELETE CASCADE
);

-- Syllabi
CREATE TABLE etr.syllabi (
    syllabus_id TEXT PRIMARY KEY,
    course_id TEXT NOT NULL,
    title TEXT NOT NULL,
    description TEXT,
    version TEXT NOT NULL,
    effective_date TIMESTAMP WITH TIME ZONE NOT NULL,
    expiration_date TIMESTAMP WITH TIME ZONE,
    status etr.syllabus_status NOT NULL,
    author_id TEXT NOT NULL REFERENCES etr.users(user_id),
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    UNIQUE (syllabus_id, version)
);

-- Syllabus metadata
CREATE TABLE etr.syllabus_metadata (
    syllabus_id TEXT NOT NULL,
    version TEXT NOT NULL,
    key TEXT NOT NULL,
    value TEXT NOT NULL,
    PRIMARY KEY (syllabus_id, version, key),
    FOREIGN KEY (syllabus_id, version) REFERENCES etr.syllabi(syllabus_id, version) ON DELETE CASCADE
);

-- Syllabus approval signatures
CREATE TABLE etr.syllabus_signatures (
    syllabus_id TEXT NOT NULL,
    version TEXT NOT NULL,
    signer_id TEXT NOT NULL REFERENCES etr.users(user_id),
    signer_name TEXT NOT NULL,
    certificate_id TEXT REFERENCES etr.certificates(certificate_id),
    signature_data BYTEA NOT NULL,
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    is_valid BOOLEAN NOT NULL,
    PRIMARY KEY (syllabus_id, version),
    FOREIGN KEY (syllabus_id, version) REFERENCES etr.syllabi(syllabus_id, version) ON DELETE CASCADE
);

-- Syllabus sections
CREATE TABLE etr.syllabus_sections (
    section_id TEXT PRIMARY KEY,
    syllabus_id TEXT NOT NULL,
    version TEXT NOT NULL,
    title TEXT NOT NULL,
    description TEXT,
    section_order INTEGER NOT NULL,
    FOREIGN KEY (syllabus_id, version) REFERENCES etr.syllabi(syllabus_id, version) ON DELETE CASCADE
);

-- Syllabus exercises
CREATE TABLE etr.syllabus_exercises (
    exercise_id TEXT PRIMARY KEY,
    section_id TEXT NOT NULL REFERENCES etr.syllabus_sections(section_id) ON DELETE CASCADE,
    title TEXT NOT NULL,
    description TEXT,
    exercise_order INTEGER NOT NULL,
    duration_minutes INTEGER NOT NULL,
    exercise_type TEXT NOT NULL
);

-- Exercise objectives
CREATE TABLE etr.exercise_objectives (
    exercise_id TEXT NOT NULL REFERENCES etr.syllabus_exercises(exercise_id) ON DELETE CASCADE,
    objective TEXT NOT NULL,
    objective_order INTEGER NOT NULL,
    PRIMARY KEY (exercise_id, objective_order)
);

-- Exercise references
CREATE TABLE etr.exercise_references (
    exercise_id TEXT NOT NULL REFERENCES etr.syllabus_exercises(exercise_id) ON DELETE CASCADE,
    reference TEXT NOT NULL,
    reference_order INTEGER NOT NULL,
    PRIMARY KEY (exercise_id, reference_order)
);

-- Exercise equipment
CREATE TABLE etr.exercise_equipment (
    exercise_id TEXT NOT NULL REFERENCES etr.syllabus_exercises(exercise_id) ON DELETE CASCADE,
    equipment TEXT NOT NULL,
    equipment_order INTEGER NOT NULL,
    PRIMARY KEY (exercise_id, equipment_order)
);

-- Exercise prerequisites
CREATE TABLE etr.exercise_prerequisites (
    exercise_id TEXT NOT NULL REFERENCES etr.syllabus_exercises(exercise_id) ON DELETE CASCADE,
    prerequisite_exercise_id TEXT NOT NULL,
    PRIMARY KEY (exercise_id, prerequisite_exercise_id)
);

-- Exercise metadata
CREATE TABLE etr.exercise_metadata (
    exercise_id TEXT NOT NULL REFERENCES etr.syllabus_exercises(exercise_id) ON DELETE CASCADE,
    key TEXT NOT NULL,
    value TEXT NOT NULL,
    PRIMARY KEY (exercise_id, key)
);

-- Grading criteria
CREATE TABLE etr.grading_criteria (
    criteria_id TEXT PRIMARY KEY,
    exercise_id TEXT NOT NULL REFERENCES etr.syllabus_exercises(exercise_id) ON DELETE CASCADE,
    name TEXT NOT NULL,
    description TEXT,
    is_required BOOLEAN NOT NULL DEFAULT TRUE
);

-- Regulation references for criteria
CREATE TABLE etr.criteria_regulations (
    criteria_id TEXT NOT NULL REFERENCES etr.grading_criteria(criteria_id) ON DELETE CASCADE,
    regulation_id TEXT NOT NULL,
    regulation_reference TEXT NOT NULL,
    PRIMARY KEY (criteria_id, regulation_id)
);

-- Grade definitions
CREATE TABLE etr.grade_definitions (
    criteria_id TEXT NOT NULL REFERENCES etr.grading_criteria(criteria_id) ON DELETE CASCADE,
    grade INTEGER NOT NULL,
    description TEXT NOT NULL,
    is_passing BOOLEAN NOT NULL,
    PRIMARY KEY (criteria_id, grade)
);

-- Syllabus changes
CREATE TABLE etr.syllabus_changes (
    id SERIAL PRIMARY KEY,
    syllabus_id TEXT NOT NULL,
    from_version TEXT NOT NULL,
    to_version TEXT NOT NULL,
    change_type etr.change_type NOT NULL,
    element_type etr.element_type NOT NULL,
    element_id TEXT NOT NULL,
    parent_id TEXT,
    description TEXT,
    rationale TEXT,
    author_id TEXT NOT NULL REFERENCES etr.users(user_id),
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT NOW(),
    FOREIGN KEY (syllabus_id) REFERENCES etr.syllabi(syllabus_id) ON DELETE CASCADE
);

-- Old and new values for syllabus changes
CREATE TABLE etr.syllabus_change_values (
    change_id INTEGER NOT NULL REFERENCES etr.syllabus_changes(id) ON DELETE CASCADE,
    key TEXT NOT NULL,
    old_value TEXT,
    new_value TEXT,
    PRIMARY KEY (change_id, key)
);

-- Create indexes for frequently accessed data
CREATE INDEX idx_training_records_trainee ON etr.training_records(trainee_id);
CREATE INDEX idx_training_records_instructor ON etr.training_records(instructor_id);
CREATE INDEX idx_training_records_course ON etr.training_records(course_id);
CREATE INDEX idx_training_records_syllabus ON etr.training_records(syllabus_id);
CREATE INDEX idx_training_records_date ON etr.training_records(date);
CREATE INDEX idx_training_records_type ON etr.training_records(record_type);

CREATE INDEX idx_record_audit_log_record ON etr.record_audit_log(record_id);
CREATE INDEX idx_record_audit_log_user ON etr.record_audit_log(user_id);
CREATE INDEX idx_record_audit_log_timestamp ON etr.record_audit_log(timestamp);

CREATE INDEX idx_compliance_requirements_regulation ON etr.compliance_requirements(regulation_id);

CREATE INDEX idx_trainee_compliance_trainee ON etr.trainee_compliance(trainee_id);
CREATE INDEX idx_trainee_compliance_requirement ON etr.trainee_compliance(requirement_id);
CREATE INDEX idx_trainee_compliance_satisfaction ON etr.trainee_compliance(is_satisfied);

CREATE INDEX idx_syllabi_course ON etr.syllabi(course_id);
CREATE INDEX idx_syllabi_status ON etr.syllabi(status);
CREATE INDEX idx_syllabi_effective_date ON etr.syllabi(effective_date);
CREATE INDEX idx_syllabi_author ON etr.syllabi(author_id);

CREATE INDEX idx_syllabus_sections_syllabus ON etr.syllabus_sections(syllabus_id, version);
CREATE INDEX idx_syllabus_exercises_section ON etr.syllabus_exercises(section_id);

CREATE INDEX idx_syllabus_changes_syllabus ON etr.syllabus_changes(syllabus_id);
CREATE INDEX idx_syllabus_changes_versions ON etr.syllabus_changes(from_version, to_version);
CREATE INDEX idx_syllabus_changes_element ON etr.syllabus_changes(element_type, element_id);
CREATE INDEX idx_syllabus_changes_timestamp ON etr.syllabus_changes(timestamp);

-- Add triggers for updated_at timestamps
CREATE OR REPLACE FUNCTION etr.update_timestamp() 
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_training_records_timestamp
BEFORE UPDATE ON etr.training_records
FOR EACH ROW EXECUTE PROCEDURE etr.update_timestamp();

CREATE TRIGGER update_compliance_requirements_timestamp
BEFORE UPDATE ON etr.compliance_requirements
FOR EACH ROW EXECUTE PROCEDURE etr.update_timestamp();

CREATE TRIGGER update_syllabi_timestamp
BEFORE UPDATE ON etr.syllabi
FOR EACH ROW EXECUTE PROCEDURE etr.update_timestamp();

CREATE TRIGGER update_trainee_compliance_timestamp
BEFORE UPDATE ON etr.trainee_compliance
FOR EACH ROW EXECUTE PROCEDURE etr.update_timestamp();

CREATE TRIGGER update_users_timestamp
BEFORE UPDATE ON etr.users
FOR EACH ROW EXECUTE PROCEDURE etr.update_timestamp();
#include "signature/digital_signature.h"
#include "logging/logger.h"
#include <string>
#include <vector>
#include <fstream>
#include <sstream>

namespace etr {
namespace signature {

X509DigitalSignatureService::X509DigitalSignatureService(
    const std::string& ca_certificate_path,
    const std::string& crl_path
) : ca_certificate_path_(ca_certificate_path),
    crl_path_(crl_path),
    cert_store_(X509_STORE_new(), X509_STORE_free),
    digest_algorithm_(EVP_sha256()) {
    
    // Initialize OpenSSL
    OpenSSL_add_all_algorithms();
    ERR_load_crypto_strings();
    
    // Create certificate store
    if (!cert_store_) {
        logging::Logger::getInstance().error("Failed to create X509 certificate store");
        return;
    }
    
    // Load CA certificate if provided
    if (!ca_certificate_path_.empty()) {
        FILE* ca_file = fopen(ca_certificate_path_.c_str(), "r");
        if (ca_file) {
            X509* ca_cert = PEM_read_X509(ca_file, nullptr, nullptr, nullptr);
            fclose(ca_file);
            
            if (ca_cert) {
                if (X509_STORE_add_cert(cert_store_.get(), ca_cert) != 1) {
                    logging::Logger::getInstance().error("Failed to add CA certificate to store");
                }
                X509_free(ca_cert);
            } else {
                logging::Logger::getInstance().error("Failed to load CA certificate from {}", ca_certificate_path_);
            }
        } else {
            logging::Logger::getInstance().error("Failed to open CA certificate file: {}", ca_certificate_path_);
        }
    }
    
    // Load CRL if provided
    if (!crl_path_.empty()) {
        FILE* crl_file = fopen(crl_path_.c_str(), "r");
        if (crl_file) {
            X509_CRL* crl = PEM_read_X509_CRL(crl_file, nullptr, nullptr, nullptr);
            fclose(crl_file);
            
            if (crl) {
                if (X509_STORE_add_crl(cert_store_.get(), crl) != 1) {
                    logging::Logger::getInstance().error("Failed to add CRL to store");
                }
                X509_CRL_free(crl);
            } else {
                logging::Logger::getInstance().error("Failed to load CRL from {}", crl_path_);
            }
        } else {
            logging::Logger::getInstance().error("Failed to open CRL file: {}", crl_path_);
        }
    }
    
    // Set up verification parameters
    X509_VERIFY_PARAM* param = X509_VERIFY_PARAM_new();
    X509_VERIFY_PARAM_set_flags(param, X509_V_FLAG_CRL_CHECK | X509_V_FLAG_CRL_CHECK_ALL);
    X509_STORE_set1_param(cert_store_.get(), param);
    X509_VERIFY_PARAM_free(param);
    
    logging::Logger::getInstance().info("X509DigitalSignatureService initialized");
}

X509DigitalSignatureService::~X509DigitalSignatureService() {
    // Cleanup OpenSSL
    EVP_cleanup();
    ERR_free_strings();
    
    logging::Logger::getInstance().info("X509DigitalSignatureService shutdown");
}

std::optional<records::SignatureInfo> X509DigitalSignatureService::signRecord(
    records::TrainingRecord& record,
    const std::string& signer_id,
    const std::string& certificate_data,
    const std::vector<uint8_t>& signature_data,
    bool is_instructor
) {
    try {
        // Parse certificate
        auto cert_info = parseCertificate(certificate_data);
        if (!cert_info) {
            logging::Logger::getInstance().error("Failed to parse certificate for signing");
            return std::nullopt;
        }
        
        // Validate certificate
        if (!validateCertificate(certificate_data)) {
            logging::Logger::getInstance().error("Certificate validation failed for signing");
            return std::nullopt;
        }
        
        // Extract user ID from certificate and verify it matches signer_id
        std::string cert_user_id = extractUserIdFromCertificate(certificate_data);
        if (cert_user_id != signer_id) {
            logging::Logger::getInstance().error("Certificate user ID ({}) does not match signer ID ({})",
                cert_user_id, signer_id);
            return std::nullopt;
        }
        
        // Generate signature info
        records::SignatureInfo signature_info;
        signature_info.signer_id = signer_id;
        signature_info.signer_name = cert_info->subject_name;
        signature_info.certificate_id = cert_info->certificate_id;
        signature_info.signature_data = signature_data;
        signature_info.timestamp = std::chrono::system_clock::now();
        
        // Verify signature with certificate
        X509* cert = getX509Certificate(certificate_data);
        if (!cert) {
            logging::Logger::getInstance().error("Failed to get X509 certificate for verification");
            return std::nullopt;
        }
        
        std::vector<uint8_t> digest = generateDigest(record);
        
        // Verify signature
        bool signature_valid = verifySignatureWithCertificate(cert, digest, signature_data);
        X509_free(cert);
        
        if (!signature_valid) {
            logging::Logger::getInstance().error("Signature verification failed");
            return std::nullopt;
        }
        
        signature_info.is_valid = true;
        
        // Add signature to record
        if (is_instructor) {
            record.setInstructorSignature(signature_info);
        } else {
            record.setTraineeSignature(signature_info);
        }
        
        logging::Logger::getInstance().info("Record {} signed by {} ({})",
            record.getRecordId(), signer_id, is_instructor ? "instructor" : "trainee");
        
        return signature_info;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error signing record: {}", e.what());
        return std::nullopt;
    }
}

std::optional<std::pair<bool, records::SignatureInfo>> X509DigitalSignatureService::verifySignature(
    const records::TrainingRecord& record,
    const std::string& signer_id
) {
    try {
        // Get signature based on signer ID
        std::optional<records::SignatureInfo> signature;
        
        if (record.getInstructorSignature() && record.getInstructorSignature()->signer_id == signer_id) {
            signature = record.getInstructorSignature();
        } else if (record.getTraineeSignature() && record.getTraineeSignature()->signer_id == signer_id) {
            signature = record.getTraineeSignature();
        }
        
        if (!signature) {
            logging::Logger::getInstance().error("No signature found for signer: {}", signer_id);
            return std::nullopt;
        }
        
        // Get certificate from repository or other source
        // For this implementation, we'll assume the certificate is embedded in the signature
        // In a real implementation, we would retrieve it from a certificate repository
        
        // Generate digest
        std::vector<uint8_t> digest = generateDigest(record);
        
        // Verify signature
        bool is_valid = signature->is_valid;
        
        logging::Logger::getInstance().info("Signature verification for record {}, signer {}: {}",
            record.getRecordId(), signer_id, is_valid ? "valid" : "invalid");
        
        return std::make_pair(is_valid, *signature);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error verifying signature: {}", e.what());
        return std::nullopt;
    }
}

std::optional<CertificateInfo> X509DigitalSignatureService::parseCertificate(
    const std::string& certificate_data
) {
    try {
        X509* cert = getX509Certificate(certificate_data);
        if (!cert) {
            logging::Logger::getInstance().error("Failed to parse X509 certificate");
            return std::nullopt;
        }
        
        CertificateInfo cert_info;
        
        // Get subject name
        X509_NAME* subject_name = X509_get_subject_name(cert);
        char subject_name_buf[256];
        X509_NAME_oneline(subject_name, subject_name_buf, sizeof(subject_name_buf));
        cert_info.subject_name = subject_name_buf;
        
        // Get issuer name
        X509_NAME* issuer_name = X509_get_issuer_name(cert);
        char issuer_name_buf[256];
        X509_NAME_oneline(issuer_name, issuer_name_buf, sizeof(issuer_name_buf));
        cert_info.issuer_name = issuer_name_buf;
        
        // Get serial number
        ASN1_INTEGER* serial = X509_get_serialNumber(cert);
        BIGNUM* bn = ASN1_INTEGER_to_BN(serial, nullptr);
        char* serial_str = BN_bn2hex(bn);
        cert_info.serial_number = serial_str;
        OPENSSL_free(serial_str);
        BN_free(bn);
        
        // Get validity period
        const ASN1_TIME* not_before = X509_get0_notBefore(cert);
        const ASN1_TIME* not_after = X509_get0_notAfter(cert);
        
        // Convert ASN1_TIME to time_t
        int day, sec;
        ASN1_TIME_diff(&day, &sec, nullptr, not_before);
        std::chrono::system_clock::time_point now = std::chrono::system_clock::now();
        std::chrono::seconds seconds(day * 86400 + sec);
        cert_info.not_before = now + seconds;
        
        ASN1_TIME_diff(&day, &sec, nullptr, not_after);
        cert_info.not_after = now + std::chrono::seconds(day * 86400 + sec);
        
        // Generate certificate ID (thumbprint)
        unsigned char md[EVP_MAX_MD_SIZE];
        unsigned int md_len;
        X509_digest(cert, EVP_sha256(), md, &md_len);
        
        std::stringstream thumbprint;
        for (unsigned int i = 0; i < md_len; i++) {
            thumbprint << std::hex << std::setw(2) << std::setfill('0') << (int)md[i];
        }
        cert_info.certificate_id = thumbprint.str();
        
        // Get raw certificate data
        BIO* bio = BIO_new(BIO_s_mem());
        PEM_write_bio_X509(bio, cert);
        
        char* pem_data;
        long pem_size = BIO_get_mem_data(bio, &pem_data);
        
        cert_info.raw_data.assign(pem_data, pem_data + pem_size);
        
        BIO_free(bio);
        
        // Validate certificate
        cert_info.is_valid = validateCertificate(certificate_data);
        
        X509_free(cert);
        
        logging::Logger::getInstance().debug("Parsed certificate: {}", cert_info.certificate_id);
        
        return cert_info;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing certificate: {}", e.what());
        return std::nullopt;
    }
}

bool X509DigitalSignatureService::validateCertificate(
    const std::string& certificate_data
) {
    try {
        X509* cert = getX509Certificate(certificate_data);
        if (!cert) {
            logging::Logger::getInstance().error("Failed to parse X509 certificate for validation");
            return false;
        }
        
        // Create certificate store context
        X509_STORE_CTX* ctx = X509_STORE_CTX_new();
        if (!ctx) {
            logging::Logger::getInstance().error("Failed to create X509 store context");
            X509_free(cert);
            return false;
        }
        
        if (X509_STORE_CTX_init(ctx, cert_store_.get(), cert, nullptr) != 1) {
            logging::Logger::getInstance().error("Failed to initialize X509 store context");
            X509_STORE_CTX_free(ctx);
            X509_free(cert);
            return false;
        }
        
        // Verify certificate
        int verify_result = X509_verify_cert(ctx);
        
        // Get verification error if any
        if (verify_result != 1) {
            int error = X509_STORE_CTX_get_error(ctx);
            logging::Logger::getInstance().error("Certificate validation failed: {}",
                X509_verify_cert_error_string(error));
        }
        
        X509_STORE_CTX_free(ctx);
        X509_free(cert);
        
        return (verify_result == 1);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error validating certificate: {}", e.what());
        return false;
    }
}

std::string X509DigitalSignatureService::extractUserIdFromCertificate(
    const std::string& certificate_data
) {
    try {
        X509* cert = getX509Certificate(certificate_data);
        if (!cert) {
            logging::Logger::getInstance().error("Failed to parse X509 certificate for user ID extraction");
            return "";
        }
        
        // Get subject name
        X509_NAME* subject_name = X509_get_subject_name(cert);
        
        // Extract Common Name (CN) which often contains the user ID
        int cn_index = X509_NAME_get_index_by_NID(subject_name, NID_commonName, -1);
        if (cn_index < 0) {
            logging::Logger::getInstance().error("No Common Name found in certificate");
            X509_free(cert);
            return "";
        }
        
        X509_NAME_ENTRY* cn_entry = X509_NAME_get_entry(subject_name, cn_index);
        if (!cn_entry) {
            logging::Logger::getInstance().error("Failed to get Common Name entry");
            X509_free(cert);
            return "";
        }
        
        ASN1_STRING* cn_data = X509_NAME_ENTRY_get_data(cn_entry);
        
        // Convert ASN1 string to C string
        const unsigned char* utf8_data;
        int utf8_len = ASN1_STRING_to_UTF8(&utf8_data, cn_data);
        
        std::string user_id;
        if (utf8_len > 0) {
            user_id.assign(reinterpret_cast<const char*>(utf8_data), utf8_len);
            OPENSSL_free((void*)utf8_data);
        }
        
        X509_free(cert);
        
        logging::Logger::getInstance().debug("Extracted user ID from certificate: {}", user_id);
        
        return user_id;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error extracting user ID from certificate: {}", e.what());
        return "";
    }
}

std::vector<uint8_t> X509DigitalSignatureService::generateDigest(
    const records::TrainingRecord& record
) {
    try {
        // Serialize record to JSON
        nlohmann::json record_json = record.toJson();
        
        // Remove existing signatures to create a consistent digest
        if (record_json.contains("trainee_signature")) {
            record_json.erase("trainee_signature");
        }
        
        if (record_json.contains("instructor_signature")) {
            record_json.erase("instructor_signature");
        }
        
        // Convert JSON to string
        std::string record_str = record_json.dump();
        
        // Generate digest
        std::vector<uint8_t> digest(EVP_MAX_MD_SIZE);
        unsigned int digest_len = 0;
        
        EVP_MD_CTX* ctx = EVP_MD_CTX_new();
        EVP_DigestInit_ex(ctx, digest_algorithm_, nullptr);
        EVP_DigestUpdate(ctx, record_str.c_str(), record_str.length());
        EVP_DigestFinal_ex(ctx, digest.data(), &digest_len);
        EVP_MD_CTX_free(ctx);
        
        // Resize digest to actual length
        digest.resize(digest_len);
        
        return digest;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error generating digest: {}", e.what());
        return {};
    }
}

X509* X509DigitalSignatureService::getX509Certificate(const std::string& certificate_data) {
    BIO* bio = BIO_new(BIO_s_mem());
    BIO_puts(bio, certificate_data.c_str());
    
    X509* cert = PEM_read_bio_X509(bio, nullptr, nullptr, nullptr);
    BIO_free(bio);
    
    return cert;
}

bool X509DigitalSignatureService::verifySignatureWithCertificate(
    X509* cert,
    const std::vector<uint8_t>& digest,
    const std::vector<uint8_t>& signature
) {
    if (!cert || digest.empty() || signature.empty()) {
        return false;
    }
    
    EVP_PKEY* pubkey = X509_get_pubkey(cert);
    if (!pubkey) {
        logging::Logger::getInstance().error("Failed to get public key from certificate");
        return false;
    }
    
    EVP_MD_CTX* md_ctx = EVP_MD_CTX_new();
    EVP_PKEY_CTX* pkey_ctx = nullptr;
    
    int result = 0;
    
    EVP_DigestVerifyInit(md_ctx, &pkey_ctx, digest_algorithm_, nullptr, pubkey);
    
    // Skip the digest step since we already have the digest
    // Use EVP_DigestVerify to verify the signature against the digest
    result = EVP_PKEY_verify(pkey_ctx, signature.data(), signature.size(), 
                            digest.data(), digest.size());
    
    EVP_MD_CTX_free(md_ctx);
    EVP_PKEY_free(pubkey);
    
    return (result == 1);
}

bool X509DigitalSignatureService::checkCertificateRevocation(X509* cert) {
    if (!cert) {
        return false;
    }
    
    // In a real implementation, you would check the certificate against a CRL or OCSP
    // For simplicity, we'll assume the certificate is not revoked
    
    return true;
}

// CertificateInfo methods

nlohmann::json CertificateInfo::toJson() const {
    nlohmann::json json;
    json["certificate_id"] = certificate_id;
    json["subject_name"] = subject_name;
    json["issuer_name"] = issuer_name;
    json["serial_number"] = serial_number;
    json["not_before"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        not_before.time_since_epoch()).count();
    json["not_after"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        not_after.time_since_epoch()).count();
    json["is_valid"] = is_valid;
    
    // Convert raw data to base64
    std::stringstream ss;
    for (const auto& byte : raw_data) {
        ss << std::hex << std::setw(2) << std::setfill('0') << (int)byte;
    }
    json["raw_data"] = ss.str();
    
    return json;
}

std::optional<CertificateInfo> CertificateInfo::fromJson(const nlohmann::json& json) {
    try {
        CertificateInfo cert_info;
        
        cert_info.certificate_id = json["certificate_id"];
        cert_info.subject_name = json["subject_name"];
        cert_info.issuer_name = json["issuer_name"];
        cert_info.serial_number = json["serial_number"];
        
        cert_info.not_before = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["not_before"]));
        cert_info.not_after = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["not_after"]));
        
        cert_info.is_valid = json["is_valid"];
        
        // Convert raw data from hex string
        std::string raw_data_hex = json["raw_data"];
        for (size_t i = 0; i < raw_data_hex.length(); i += 2) {
            std::string byte_hex = raw_data_hex.substr(i, 2);
            uint8_t byte = std::stoi(byte_hex, nullptr, 16);
            cert_info.raw_data.push_back(byte);
        }
        
        return cert_info;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing certificate from JSON: {}", e.what());
        return std::nullopt;
    }
}

} // namespace signature
} // namespace etr
#pragma once

#include <string>
#include <vector>
#include <map>
#include <memory>
#include <optional>
#include <chrono>
#include <nlohmann/json.hpp>
#include "records/record_model.h"
#include "signature/digital_signature.h"

namespace etr {
namespace syllabus {

/**
 * @brief Syllabus status
 */
enum class SyllabusStatus {
    DRAFT,
    APPROVED,
    ARCHIVED
};

/**
 * @brief Convert SyllabusStatus to string
 * @param status Syllabus status
 * @return String representation
 */
std::string syllabusStatusToString(SyllabusStatus status);

/**
 * @brief Convert string to SyllabusStatus
 * @param str String representation
 * @return Syllabus status
 */
SyllabusStatus syllabusStatusFromString(const std::string& str);

/**
 * @brief Grade definition
 */
struct GradeDefinition {
    int grade;  // 1-4 scale
    std::string description;
    bool is_passing;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Grade definition or nullopt if invalid
     */
    static std::optional<GradeDefinition> fromJson(const nlohmann::json& json);
};

/**
 * @brief Grading criteria
 */
struct GradingCriteria {
    std::string criteria_id;
    std::string name;
    std::string description;
    std::vector<GradeDefinition> grade_definitions;
    bool is_required;
    std::map<std::string, std::string> regulation_references;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Grading criteria or nullopt if invalid
     */
    static std::optional<GradingCriteria> fromJson(const nlohmann::json& json);
};

/**
 * @brief Syllabus exercise
 */
struct SyllabusExercise {
    std::string exercise_id;
    std::string title;
    std::string description;
    int order;
    int duration_minutes;
    std::string exercise_type;  // GROUND, SIMULATOR, FLIGHT, etc.
    std::vector<std::string> objectives;
    std::vector<std::string> references;
    std::vector<std::string> equipment;
    std::vector<GradingCriteria> grading_criteria;
    std::vector<std::string> prerequisite_exercises;
    std::map<std::string, std::string> metadata;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Syllabus exercise or nullopt if invalid
     */
    static std::optional<SyllabusExercise> fromJson(const nlohmann::json& json);
};

/**
 * @brief Syllabus section
 */
struct SyllabusSection {
    std::string section_id;
    std::string title;
    std::string description;
    int order;
    std::vector<SyllabusExercise> exercises;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Syllabus section or nullopt if invalid
     */
    static std::optional<SyllabusSection> fromJson(const nlohmann::json& json);
};

/**
 * @brief Syllabus
 */
class Syllabus {
public:
    /**
     * @brief Default constructor
     */
    Syllabus();
    
    /**
     * @brief Constructor with ID
     * @param id Syllabus ID
     */
    explicit Syllabus(const std::string& id);
    
    /**
     * @brief Get syllabus ID
     * @return Syllabus ID
     */
    const std::string& getSyllabusId() const;
    
    /**
     * @brief Set syllabus ID
     * @param id Syllabus ID
     */
    void setSyllabusId(const std::string& id);
    
    /**
     * @brief Get course ID
     * @return Course ID
     */
    const std::string& getCourseId() const;
    
    /**
     * @brief Set course ID
     * @param id Course ID
     */
    void setCourseId(const std::string& id);
    
    /**
     * @brief Get title
     * @return Title
     */
    const std::string& getTitle() const;
    
    /**
     * @brief Set title
     * @param title Title
     */
    void setTitle(const std::string& title);
    
    /**
     * @brief Get description
     * @return Description
     */
    const std::string& getDescription() const;
    
    /**
     * @brief Set description
     * @param description Description
     */
    void setDescription(const std::string& description);
    
    /**
     * @brief Get version
     * @return Version
     */
    const std::string& getVersion() const;
    
    /**
     * @brief Set version
     * @param version Version
     */
    void setVersion(const std::string& version);
    
    /**
     * @brief Get effective date
     * @return Effective date
     */
    std::chrono::system_clock::time_point getEffectiveDate() const;
    
    /**
     * @brief Set effective date
     * @param date Effective date
     */
    void setEffectiveDate(const std::chrono::system_clock::time_point& date);
    
    /**
     * @brief Get expiration date
     * @return Expiration date or nullopt if not set
     */
    std::optional<std::chrono::system_clock::time_point> getExpirationDate() const;
    
    /**
     * @brief Set expiration date
     * @param date Expiration date
     */
    void setExpirationDate(const std::chrono::system_clock::time_point& date);
    
    /**
     * @brief Clear expiration date
     */
    void clearExpirationDate();
    
    /**
     * @brief Get status
     * @return Status
     */
    SyllabusStatus getStatus() const;
    
    /**
     * @brief Set status
     * @param status Status
     */
    void setStatus(SyllabusStatus status);
    
    /**
     * @brief Get author ID
     * @return Author ID
     */
    const std::string& getAuthorId() const;
    
    /**
     * @brief Set author ID
     * @param id Author ID
     */
    void setAuthorId(const std::string& id);
    
    /**
     * @brief Get sections
     * @return Sections
     */
    const std::vector<SyllabusSection>& getSections() const;
    
    /**
     * @brief Set sections
     * @param sections Sections
     */
    void setSections(const std::vector<SyllabusSection>& sections);
    
    /**
     * @brief Add section
     * @param section Section
     */
    void addSection(const SyllabusSection& section);
    
    /**
     * @brief Update section
     * @param section Section
     * @return True if updated, false if not found
     */
    bool updateSection(const SyllabusSection& section);
    
    /**
     * @brief Remove section
     * @param section_id Section ID
     * @return True if removed, false if not found
     */
    bool removeSection(const std::string& section_id);
    
    /**
     * @brief Get section by ID
     * @param section_id Section ID
     * @return Section or nullopt if not found
     */
    std::optional<SyllabusSection> getSection(const std::string& section_id) const;
    
    /**
     * @brief Get metadata
     * @return Metadata
     */
    const std::map<std::string, std::string>& getMetadata() const;
    
    /**
     * @brief Set metadata
     * @param metadata Metadata
     */
    void setMetadata(const std::map<std::string, std::string>& metadata);
    
    /**
     * @brief Get metadata value
     * @param key Metadata key
     * @return Metadata value or empty string if not found
     */
    std::string getMetadataValue(const std::string& key) const;
    
    /**
     * @brief Set metadata value
     * @param key Metadata key
     * @param value Metadata value
     */
    void setMetadataValue(const std::string& key, const std::string& value);
    
    /**
     * @brief Get creation time
     * @return Creation time
     */
    std::chrono::system_clock::time_point getCreatedAt() const;
    
    /**
     * @brief Set creation time
     * @param time Creation time
     */
    void setCreatedAt(const std::chrono::system_clock::time_point& time);
    
    /**
     * @brief Get update time
     * @return Update time
     */
    std::chrono::system_clock::time_point getUpdatedAt() const;
    
    /**
     * @brief Set update time
     * @param time Update time
     */
    void setUpdatedAt(const std::chrono::system_clock::time_point& time);
    
    /**
     * @brief Get approval signature
     * @return Approval signature or nullopt if not approved
     */
    const std::optional<records::SignatureInfo>& getApprovalSignature() const;
    
    /**
     * @brief Set approval signature
     * @param signature Approval signature
     */
    void setApprovalSignature(const records::SignatureInfo& signature);
    
    /**
     * @brief Find exercise by ID
     * @param exercise_id Exercise ID
     * @return Pair of (exercise, section_id) or nullopt if not found
     */
    std::optional<std::pair<SyllabusExercise, std::string>> findExercise(const std::string& exercise_id) const;
    
    /**
     * @brief Update exercise
     * @param exercise Exercise
     * @param section_id Section ID
     * @return True if updated, false if not found
     */
    bool updateExercise(const SyllabusExercise& exercise, const std::string& section_id);
    
    /**
     * @brief Add exercise to section
     * @param exercise Exercise
     * @param section_id Section ID
     * @return True if added, false if section not found
     */
    bool addExerciseToSection(const SyllabusExercise& exercise, const std::string& section_id);
    
    /**
     * @brief Remove exercise
     * @param exercise_id Exercise ID
     * @return True if removed, false if not found
     */
    bool removeExercise(const std::string& exercise_id);
    
    /**
     * @brief Check if syllabus is approved
     * @return True if approved
     */
    bool isApproved() const;
    
    /**
     * @brief Check if syllabus is valid
     * @return True if valid
     */
    bool isValid() const;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Syllabus or nullopt if invalid
     */
    static std::optional<Syllabus> fromJson(const nlohmann::json& json);
    
    /**
     * @brief Generate audit log entry
     * @param action Action performed
     * @param user_id User ID
     * @param details Additional details
     * @return Audit log entry
     */
    nlohmann::json generateAuditLog(const std::string& action, const std::string& user_id, const std::string& details = "") const;
    
private:
    std::string syllabus_id_;
    std::string course_id_;
    std::string title_;
    std::string description_;
    std::string version_;
    std::chrono::system_clock::time_point effective_date_;
    std::optional<std::chrono::system_clock::time_point> expiration_date_;
    SyllabusStatus status_;
    std::string author_id_;
    std::vector<SyllabusSection> sections_;
    std::map<std::string, std::string> metadata_;
    std::chrono::system_clock::time_point created_at_;
    std::chrono::system_clock::time_point updated_at_;
    std::optional<records::SignatureInfo> approval_signature_;
};

/**
 * @brief Syllabus change type
 */
enum class ChangeType {
    ADDED,
    MODIFIED,
    REMOVED
};

/**
 * @brief Convert ChangeType to string
 * @param type Change type
 * @return String representation
 */
std::string changeTypeToString(ChangeType type);

/**
 * @brief Convert string to ChangeType
 * @param str String representation
 * @return Change type
 */
ChangeType changeTypeFromString(const std::string& str);

/**
 * @brief Element type
 */
enum class ElementType {
    SYLLABUS,
    SECTION,
    EXERCISE,
    CRITERIA,
    OBJECTIVE,
    REFERENCE,
    EQUIPMENT,
    PREREQUISITE,
    METADATA
};

/**
 * @brief Convert ElementType to string
 * @param type Element type
 * @return String representation
 */
std::string elementTypeToString(ElementType type);

/**
 * @brief Convert string to ElementType
 * @param str String representation
 * @return Element type
 */
ElementType elementTypeFromString(const std::string& str);

/**
 * @brief Syllabus change
 */
struct SyllabusChange {
    ChangeType change_type;
    ElementType element_type;
    std::string element_id;
    std::optional<std::string> parent_id;
    std::string description;
    std::map<std::string, std::string> old_values;
    std::map<std::string, std::string> new_values;
    std::string rationale;
    std::string author_id;
    std::chrono::system_clock::time_point timestamp;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Syllabus change or nullopt if invalid
     */
    static std::optional<SyllabusChange> fromJson(const nlohmann::json& json);
};

/**
 * @brief Syllabus summary
 */
struct SyllabusSummary {
    std::string syllabus_id;
    std::string course_id;
    std::string title;
    std::string version;
    std::chrono::system_clock::time_point effective_date;
    std::optional<std::chrono::system_clock::time_point> expiration_date;
    SyllabusStatus status;
    std::string author_id;
    std::chrono::system_clock::time_point created_at;
    std::chrono::system_clock::time_point updated_at;
    
    /**
     * @brief Convert to JSON
     * @return JSON representation
     */
    nlohmann::json toJson() const;
    
    /**
     * @brief Create from JSON
     * @param json JSON representation
     * @return Syllabus summary or nullopt if invalid
     */
    static std::optional<SyllabusSummary> fromJson(const nlohmann::json& json);
};

/**
 * @brief Syllabus repository interface
 */
class ISyllabusRepository {
public:
    virtual ~ISyllabusRepository() = default;
    
    /**
     * @brief Create a syllabus
     * @param syllabus Syllabus to create
     * @return Created syllabus ID or empty string if failed
     */
    virtual std::string createSyllabus(const Syllabus& syllabus) = 0;
    
    /**
     * @brief Get a syllabus by ID
     * @param syllabus_id Syllabus ID
     * @param version Version (optional)
     * @return Syllabus or nullopt if not found
     */
    virtual std::optional<Syllabus> getSyllabus(
        const std::string& syllabus_id,
        const std::optional<std::string>& version = std::nullopt
    ) = 0;
    
    /**
     * @brief Update a syllabus
     * @param syllabus Syllabus to update
     * @return True if updated, false if not found
     */
    virtual bool updateSyllabus(const Syllabus& syllabus) = 0;
    
    /**
     * @brief Delete a syllabus
     * @param syllabus_id Syllabus ID
     * @return True if deleted, false if not found
     */
    virtual bool deleteSyllabus(const std::string& syllabus_id) = 0;
    
    /**
     * @brief List syllabi matching criteria
     * @param course_id Course ID (optional)
     * @param status Status (optional)
     * @param effective_date Effective date (optional)
     * @param page Page number (starting from 1)
     * @param page_size Page size
     * @param sort_by Sort field
     * @param ascending Sort direction
     * @return Pair of summaries and total count
     */
    virtual std::pair<std::vector<SyllabusSummary>, int> listSyllabi(
        const std::optional<std::string>& course_id = std::nullopt,
        const std::optional<SyllabusStatus>& status = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& effective_date = std::nullopt,
        int page = 1,
        int page_size = 10,
        const std::string& sort_by = "effective_date",
        bool ascending = false
    ) = 0;
    
    /**
     * @brief Track syllabus changes
     * @param syllabus_id Syllabus ID
     * @param from_version From version
     * @param to_version To version
     * @return Syllabus changes
     */
    virtual std::vector<SyllabusChange> trackChanges(
        const std::string& syllabus_id,
        const std::string& from_version,
        const std::string& to_version
    ) = 0;
    
    /**
     * @brief Log syllabus change
     * @param syllabus_id Syllabus ID
     * @param change Syllabus change
     * @return True if logged successfully
     */
    virtual bool logChange(
        const std::string& syllabus_id,
        const SyllabusChange& change
    ) = 0;
    
    /**
     * @brief Get all syllabus versions
     * @param syllabus_id Syllabus ID
     * @return Syllabus versions
     */
    virtual std::vector<std::string> getAllVersions(const std::string& syllabus_id) = 0;
    
    /**
     * @brief Get latest approved syllabus for course
     * @param course_id Course ID
     * @return Syllabus or nullopt if not found
     */
    virtual std::optional<Syllabus> getLatestApprovedSyllabus(const std::string& course_id) = 0;
};

/**
 * @brief Syllabus service interface
 */
class ISyllabusService {
public:
    virtual ~ISyllabusService() = default;
    
    /**
     * @brief Create a syllabus
     * @param syllabus Syllabus to create
     * @return Created syllabus ID or empty string if failed
     */
    virtual std::string createSyllabus(const Syllabus& syllabus) = 0;
    
    /**
     * @brief Get a syllabus
     * @param syllabus_id Syllabus ID
     * @param version Version (optional)
     * @return Syllabus or nullopt if not found
     */
    virtual std::optional<Syllabus> getSyllabus(
        const std::string& syllabus_id,
        const std::optional<std::string>& version = std::nullopt
    ) = 0;
    
    /**
     * @brief Update a syllabus
     * @param syllabus Syllabus to update
     * @param user_id User ID
     * @return True if updated, false if not found or not authorized
     */
    virtual bool updateSyllabus(const Syllabus& syllabus, const std::string& user_id) = 0;
    
    /**
     * @brief Delete a syllabus
     * @param syllabus_id Syllabus ID
     * @param user_id User ID
     * @return True if deleted, false if not found or not authorized
     */
    virtual bool deleteSyllabus(const std::string& syllabus_id, const std::string& user_id) = 0;
    
    /**
     * @brief List syllabi
     * @param course_id Course ID (optional)
     * @param status Status (optional)
     * @param effective_date Effective date (optional)
     * @param page Page number (starting from 1)
     * @param page_size Page size
     * @param sort_by Sort field
     * @param ascending Sort direction
     * @return Pair of summaries and total count
     */
    virtual std::pair<std::vector<SyllabusSummary>, int> listSyllabi(
        const std::optional<std::string>& course_id = std::nullopt,
        const std::optional<SyllabusStatus>& status = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& effective_date = std::nullopt,
        int page = 1,
        int page_size = 10,
        const std::string& sort_by = "effective_date",
        bool ascending = false
    ) = 0;
    
    /**
     * @brief Track syllabus changes
     * @param syllabus_id Syllabus ID
     * @param from_version From version
     * @param to_version To version
     * @return Syllabus changes
     */
    virtual std::vector<SyllabusChange> trackChanges(
        const std::string& syllabus_id,
        const std::string& from_version,
        const std::string& to_version
    ) = 0;
    
    /**
     * @brief Approve syllabus
     * @param syllabus_id Syllabus ID
     * @param approver_id Approver ID
     * @param certificate_data Certificate data
     * @param signature_data Signature data
     * @return True if approved, false if not found or not authorized
     */
    virtual bool approveSyllabus(
        const std::string& syllabus_id,
        const std::string& approver_id,
        const std::string& certificate_data,
        const std::vector<uint8_t>& signature_data
    ) = 0;
    
    /**
     * @brief Archive syllabus
     * @param syllabus_id Syllabus ID
     * @param user_id User ID
     * @return True if archived, false if not found or not authorized
     */
    virtual bool archiveSyllabus(
        const std::string& syllabus_id,
        const std::string& user_id
    ) = 0;
    
    /**
     * @brief Clone syllabus
     * @param syllabus_id Syllabus ID
     * @param new_version New version
     * @param user_id User ID
     * @return New syllabus ID or empty string if failed
     */
    virtual std::string cloneSyllabus(
        const std::string& syllabus_id,
        const std::string& new_version,
        const std::string& user_id
    ) = 0;
    
    /**
     * @brief Import syllabus from JSON
     * @param json_content JSON content
     * @param user_id User ID
     * @return Syllabus ID or empty string if failed
     */
    virtual std::string importSyllabusFromJson(
        const std::string& json_content,
        const std::string& user_id
    ) = 0;
    
    /**
     * @brief Export syllabus to JSON
     * @param syllabus_id Syllabus ID
     * @param version Version (optional)
     * @return JSON content or empty string if failed
     */
    virtual std::string exportSyllabusToJson(
        const std::string& syllabus_id,
        const std::optional<std::string>& version = std::nullopt
    ) = 0;
};

/**
 * @brief Syllabus service implementation
 */
class SyllabusService : public ISyllabusService {
public:
    /**
     * @brief Constructor
     * @param syllabus_repository Syllabus repository
     * @param signature_service Signature service
     */
    SyllabusService(
        std::shared_ptr<ISyllabusRepository> syllabus_repository,
        std::shared_ptr<signature::IDigitalSignatureService> signature_service
    );
    
    /**
     * @brief Destructor
     */
    ~SyllabusService() override;
    
    std::string createSyllabus(const Syllabus& syllabus) override;
    
    std::optional<Syllabus> getSyllabus(
        const std::string& syllabus_id,
        const std::optional<std::string>& version
    ) override;
    
    bool updateSyllabus(const Syllabus& syllabus, const std::string& user_id) override;
    
    bool deleteSyllabus(const std::string& syllabus_id, const std::string& user_id) override;
    
    std::pair<std::vector<SyllabusSummary>, int> listSyllabi(
        const std::optional<std::string>& course_id,
        const std::optional<SyllabusStatus>& status,
        const std::optional<std::chrono::system_clock::time_point>& effective_date,
        int page,
        int page_size,
        const std::string& sort_by,
        bool ascending
    ) override;
    
    std::vector<SyllabusChange> trackChanges(
        const std::string& syllabus_id,
        const std::string& from_version,
        const std::string& to_version
    ) override;
    
    bool approveSyllabus(
        const std::string& syllabus_id,
        const std::string& approver_id,
        const std::string& certificate_data,
        const std::vector<uint8_t>& signature_data
    ) override;
    
    bool archiveSyllabus(
        const std::string& syllabus_id,
        const std::string& user_id
    ) override;
    
    std::string cloneSyllabus(
        const std::string& syllabus_id,
        const std::string& new_version,
        const std::string& user_id
    ) override;
    
    std::string importSyllabusFromJson(
        const std::string& json_content,
        const std::string& user_id
    ) override;
    
    std::string exportSyllabusToJson(
        const std::string& syllabus_id,
        const std::optional<std::string>& version
    ) override;
    
private:
    /**
     * @brief Generate syllabus digest
     * @param syllabus Syllabus
     * @return Digest
     */
    std::vector<uint8_t> generateSyllabusDigest(const Syllabus& syllabus);
    
    /**
     * @brief Check if user is authorized to modify syllabus
     * @param syllabus Syllabus
     * @param user_id User ID
     * @return True if authorized
     */
    bool isAuthorizedToModify(const Syllabus& syllabus, const std::string& user_id);
    
    /**
     * @brief Calculate syllabus changes
     * @param old_syllabus Old syllabus
     * @param new_syllabus New syllabus
     * @param user_id User ID
     * @return Syllabus changes
     */
    std::vector<SyllabusChange> calculateChanges(
        const Syllabus& old_syllabus,
        const Syllabus& new_syllabus,
        const std::string& user_id
    );
    
    std::shared_ptr<ISyllabusRepository> syllabus_repository_;
    std::shared_ptr<signature::IDigitalSignatureService> signature_service_;
};

} // namespace syllabus
} // namespace etr
#include "syllabus/syllabus_service.h"
#include "logging/logger.h"
#include <algorithm>
#include <unordered_set>

namespace etr {
namespace syllabus {

// String conversion functions
std::string syllabusStatusToString(SyllabusStatus status) {
    switch (status) {
        case SyllabusStatus::DRAFT: return "DRAFT";
        case SyllabusStatus::APPROVED: return "APPROVED";
        case SyllabusStatus::ARCHIVED: return "ARCHIVED";
        default: return "UNKNOWN";
    }
}

SyllabusStatus syllabusStatusFromString(const std::string& str) {
    if (str == "DRAFT") return SyllabusStatus::DRAFT;
    if (str == "APPROVED") return SyllabusStatus::APPROVED;
    if (str == "ARCHIVED") return SyllabusStatus::ARCHIVED;
    return SyllabusStatus::DRAFT;  // Default to DRAFT
}

std::string changeTypeToString(ChangeType type) {
    switch (type) {
        case ChangeType::ADDED: return "ADDED";
        case ChangeType::MODIFIED: return "MODIFIED";
        case ChangeType::REMOVED: return "REMOVED";
        default: return "UNKNOWN";
    }
}

ChangeType changeTypeFromString(const std::string& str) {
    if (str == "ADDED") return ChangeType::ADDED;
    if (str == "MODIFIED") return ChangeType::MODIFIED;
    if (str == "REMOVED") return ChangeType::REMOVED;
    return ChangeType::MODIFIED;  // Default to MODIFIED
}

std::string elementTypeToString(ElementType type) {
    switch (type) {
        case ElementType::SYLLABUS: return "SYLLABUS";
        case ElementType::SECTION: return "SECTION";
        case ElementType::EXERCISE: return "EXERCISE";
        case ElementType::CRITERIA: return "CRITERIA";
        case ElementType::OBJECTIVE: return "OBJECTIVE";
        case ElementType::REFERENCE: return "REFERENCE";
        case ElementType::EQUIPMENT: return "EQUIPMENT";
        case ElementType::PREREQUISITE: return "PREREQUISITE";
        case ElementType::METADATA: return "METADATA";
        default: return "UNKNOWN";
    }
}

ElementType elementTypeFromString(const std::string& str) {
    if (str == "SYLLABUS") return ElementType::SYLLABUS;
    if (str == "SECTION") return ElementType::SECTION;
    if (str == "EXERCISE") return ElementType::EXERCISE;
    if (str == "CRITERIA") return ElementType::CRITERIA;
    if (str == "OBJECTIVE") return ElementType::OBJECTIVE;
    if (str == "REFERENCE") return ElementType::REFERENCE;
    if (str == "EQUIPMENT") return ElementType::EQUIPMENT;
    if (str == "PREREQUISITE") return ElementType::PREREQUISITE;
    if (str == "METADATA") return ElementType::METADATA;
    return ElementType::SYLLABUS;  // Default to SYLLABUS
}

// SyllabusService implementation
SyllabusService::SyllabusService(
    std::shared_ptr<ISyllabusRepository> syllabus_repository,
    std::shared_ptr<signature::IDigitalSignatureService> signature_service
) : syllabus_repository_(std::move(syllabus_repository)),
    signature_service_(std::move(signature_service)) {
    
    logging::Logger::getInstance().info("SyllabusService initialized");
}

SyllabusService::~SyllabusService() {
    logging::Logger::getInstance().info("SyllabusService shutdown");
}

std::string SyllabusService::createSyllabus(const Syllabus& syllabus) {
    try {
        // Validate syllabus
        if (!syllabus.isValid()) {
            logging::Logger::getInstance().error("Invalid syllabus data");
            return "";
        }
        
        // Make sure version is unique
        auto existing_syllabus = syllabus_repository_->getSyllabus(
            syllabus.getSyllabusId(),
            syllabus.getVersion()
        );
        
        if (existing_syllabus) {
            logging::Logger::getInstance().error(
                "Syllabus already exists with ID {} and version {}",
                syllabus.getSyllabusId(), syllabus.getVersion()
            );
            return "";
        }
        
        // Set initial status to DRAFT if not specified
        Syllabus syllabus_copy = syllabus;
        if (syllabus_copy.getStatus() == SyllabusStatus::APPROVED && 
            !syllabus_copy.getApprovalSignature()) {
            syllabus_copy.setStatus(SyllabusStatus::DRAFT);
        }
        
        // Create the syllabus
        std::string syllabus_id = syllabus_repository_->createSyllabus(syllabus_copy);
        
        if (!syllabus_id.empty()) {
            logging::Logger::getInstance().info(
                "Created syllabus with ID {} and version {}",
                syllabus_id, syllabus_copy.getVersion()
            );
        } else {
            logging::Logger::getInstance().error("Failed to create syllabus");
        }
        
        return syllabus_id;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error creating syllabus: {}", e.what());
        return "";
    }
}

std::optional<Syllabus> SyllabusService::getSyllabus(
    const std::string& syllabus_id,
    const std::optional<std::string>& version
) {
    try {
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id, version);
        
        if (syllabus) {
            logging::Logger::getInstance().debug(
                "Retrieved syllabus with ID {} and version {}",
                syllabus_id, syllabus->getVersion()
            );
        } else {
            logging::Logger::getInstance().debug(
                "Syllabus not found with ID {} and version {}",
                syllabus_id, version ? *version : "latest"
            );
        }
        
        return syllabus;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error getting syllabus {}, version {}: {}",
            syllabus_id, version ? *version : "latest", e.what()
        );
        return std::nullopt;
    }
}

bool SyllabusService::updateSyllabus(const Syllabus& syllabus, const std::string& user_id) {
    try {
        // Validate syllabus
        if (!syllabus.isValid()) {
            logging::Logger::getInstance().error("Invalid syllabus data");
            return false;
        }
        
        // Get existing syllabus
        auto existing_syllabus = syllabus_repository_->getSyllabus(
            syllabus.getSyllabusId(),
            syllabus.getVersion()
        );
        
        if (!existing_syllabus) {
            logging::Logger::getInstance().error(
                "Syllabus not found with ID {} and version {}",
                syllabus.getSyllabusId(), syllabus.getVersion()
            );
            return false;
        }
        
        // Check authorization
        if (!isAuthorizedToModify(*existing_syllabus, user_id)) {
            logging::Logger::getInstance().error(
                "User {} not authorized to modify syllabus {}",
                user_id, syllabus.getSyllabusId()
            );
            return false;
        }
        
        // Cannot modify APPROVED or ARCHIVED syllabus
        if (existing_syllabus->getStatus() != SyllabusStatus::DRAFT) {
            logging::Logger::getInstance().error(
                "Cannot modify syllabus in {} state",
                syllabusStatusToString(existing_syllabus->getStatus())
            );
            return false;
        }
        
        // Calculate changes
        auto changes = calculateChanges(*existing_syllabus, syllabus, user_id);
        
        // Update the syllabus
        bool success = syllabus_repository_->updateSyllabus(syllabus);
        
        if (success) {
            // Log changes
            for (const auto& change : changes) {
                syllabus_repository_->logChange(syllabus.getSyllabusId(), change);
            }
            
            logging::Logger::getInstance().info(
                "Updated syllabus with ID {} and version {}, {} changes",
                syllabus.getSyllabusId(), syllabus.getVersion(), changes.size()
            );
        } else {
            logging::Logger::getInstance().error(
                "Failed to update syllabus with ID {} and version {}",
                syllabus.getSyllabusId(), syllabus.getVersion()
            );
        }
        
        return success;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error updating syllabus: {}", e.what());
        return false;
    }
}

bool SyllabusService::deleteSyllabus(const std::string& syllabus_id, const std::string& user_id) {
    try {
        // Get existing syllabus
        auto existing_syllabus = syllabus_repository_->getSyllabus(syllabus_id);
        
        if (!existing_syllabus) {
            logging::Logger::getInstance().error("Syllabus not found with ID {}", syllabus_id);
            return false;
        }
        
        // Check authorization
        if (!isAuthorizedToModify(*existing_syllabus, user_id)) {
            logging::Logger::getInstance().error(
                "User {} not authorized to delete syllabus {}",
                user_id, syllabus_id
            );
            return false;
        }
        
        // Cannot delete APPROVED or ARCHIVED syllabus
        if (existing_syllabus->getStatus() != SyllabusStatus::DRAFT) {
            logging::Logger::getInstance().error(
                "Cannot delete syllabus in {} state",
                syllabusStatusToString(existing_syllabus->getStatus())
            );
            return false;
        }
        
        // Delete the syllabus
        bool success = syllabus_repository_->deleteSyllabus(syllabus_id);
        
        if (success) {
            logging::Logger::getInstance().info("Deleted syllabus with ID {}", syllabus_id);
        } else {
            logging::Logger::getInstance().error("Failed to delete syllabus with ID {}", syllabus_id);
        }
        
        return success;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error deleting syllabus: {}", e.what());
        return false;
    }
}

std::pair<std::vector<SyllabusSummary>, int> SyllabusService::listSyllabi(
    const std::optional<std::string>& course_id,
    const std::optional<SyllabusStatus>& status,
    const std::optional<std::chrono::system_clock::time_point>& effective_date,
    int page,
    int page_size,
    const std::string& sort_by,
    bool ascending
) {
    try {
        auto [syllabi, total_count] = syllabus_repository_->listSyllabi(
            course_id,
            status,
            effective_date,
            page,
            page_size,
            sort_by,
            ascending
        );
        
        logging::Logger::getInstance().debug(
            "Listed {} syllabi out of {} total",
            syllabi.size(), total_count
        );
        
        return {syllabi, total_count};
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error listing syllabi: {}", e.what());
        return {{}, 0};
    }
}

std::vector<SyllabusChange> SyllabusService::trackChanges(
    const std::string& syllabus_id,
    const std::string& from_version,
    const std::string& to_version
) {
    try {
        auto changes = syllabus_repository_->trackChanges(
            syllabus_id,
            from_version,
            to_version
        );
        
        logging::Logger::getInstance().debug(
            "Tracked {} changes between versions {} and {} of syllabus {}",
            changes.size(), from_version, to_version, syllabus_id
        );
        
        return changes;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error tracking changes for syllabus {}, versions {} to {}: {}",
            syllabus_id, from_version, to_version, e.what()
        );
        return {};
    }
}

bool SyllabusService::approveSyllabus(
    const std::string& syllabus_id,
    const std::string& approver_id,
    const std::string& certificate_data,
    const std::vector<uint8_t>& signature_data
) {
    try {
        // Get existing syllabus
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id);
        
        if (!syllabus) {
            logging::Logger::getInstance().error("Syllabus not found with ID {}", syllabus_id);
            return false;
        }
        
        // Check if syllabus is in DRAFT state
        if (syllabus->getStatus() != SyllabusStatus::DRAFT) {
            logging::Logger::getInstance().error(
                "Cannot approve syllabus in {} state",
                syllabusStatusToString(syllabus->getStatus())
            );
            return false;
        }
        
        // Validate certificate
        if (!signature_service_->validateCertificate(certificate_data)) {
            logging::Logger::getInstance().error("Invalid certificate for approval");
            return false;
        }
        
        // Extract user ID from certificate and verify it matches approver_id
        std::string cert_user_id = signature_service_->extractUserIdFromCertificate(certificate_data);
        if (cert_user_id != approver_id) {
            logging::Logger::getInstance().error(
                "Certificate user ID ({}) does not match approver ID ({})",
                cert_user_id, approver_id
            );
            return false;
        }
        
        // Generate digest for syllabus
        std::vector<uint8_t> digest = generateSyllabusDigest(*syllabus);
        
        // Verify signature
        auto cert_info = signature_service_->parseCertificate(certificate_data);
        if (!cert_info) {
            logging::Logger::getInstance().error("Failed to parse certificate");
            return false;
        }
        
        // Create signature info
        records::SignatureInfo signature_info;
        signature_info.signer_id = approver_id;
        signature_info.signer_name = cert_info->subject_name;
        signature_info.certificate_id = cert_info->certificate_id;
        signature_info.signature_data = signature_data;
        signature_info.timestamp = std::chrono::system_clock::now();
        signature_info.is_valid = true;
        
        // Update syllabus
        syllabus->setStatus(SyllabusStatus::APPROVED);
        syllabus->setApprovalSignature(signature_info);
        
        // Update the syllabus
        bool success = syllabus_repository_->updateSyllabus(*syllabus);
        
        if (success) {
            logging::Logger::getInstance().info(
                "Approved syllabus with ID {} and version {} by {}",
                syllabus_id, syllabus->getVersion(), approver_id
            );
        } else {
            logging::Logger::getInstance().error(
                "Failed to approve syllabus with ID {} and version {}",
                syllabus_id, syllabus->getVersion()
            );
        }
        
        return success;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error approving syllabus {}: {}",
            syllabus_id, e.what()
        );
        return false;
    }
}

bool SyllabusService::archiveSyllabus(
    const std::string& syllabus_id,
    const std::string& user_id
) {
    try {
        // Get existing syllabus
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id);
        
        if (!syllabus) {
            logging::Logger::getInstance().error("Syllabus not found with ID {}", syllabus_id);
            return false;
        }
        
        // Check authorization
        if (!isAuthorizedToModify(*syllabus, user_id)) {
            logging::Logger::getInstance().error(
                "User {} not authorized to archive syllabus {}",
                user_id, syllabus_id
            );
            return false;
        }
        
        // Can only archive APPROVED syllabus
        if (syllabus->getStatus() != SyllabusStatus::APPROVED) {
            logging::Logger::getInstance().error(
                "Cannot archive syllabus in {} state",
                syllabusStatusToString(syllabus->getStatus())
            );
            return false;
        }
        
        // Update syllabus
        syllabus->setStatus(SyllabusStatus::ARCHIVED);
        
        // Update the syllabus
        bool success = syllabus_repository_->updateSyllabus(*syllabus);
        
        if (success) {
            logging::Logger::getInstance().info(
                "Archived syllabus with ID {} and version {}",
                syllabus_id, syllabus->getVersion()
            );
        } else {
            logging::Logger::getInstance().error(
                "Failed to archive syllabus with ID {} and version {}",
                syllabus_id, syllabus->getVersion()
            );
        }
        
        return success;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error archiving syllabus {}: {}",
            syllabus_id, e.what()
        );
        return false;
    }
}

std::string SyllabusService::cloneSyllabus(
    const std::string& syllabus_id,
    const std::string& new_version,
    const std::string& user_id
) {
    try {
        // Get existing syllabus
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id);
        
        if (!syllabus) {
            logging::Logger::getInstance().error("Syllabus not found with ID {}", syllabus_id);
            return "";
        }
        
        // Create a copy with new version
        Syllabus new_syllabus = *syllabus;
        new_syllabus.setVersion(new_version);
        new_syllabus.setStatus(SyllabusStatus::DRAFT);
        new_syllabus.clearExpirationDate();  // Clear expiration date for new version
        new_syllabus.setAuthorId(user_id);
        
        // Set creation and update times
        auto now = std::chrono::system_clock::now();
        new_syllabus.setCreatedAt(now);
        new_syllabus.setUpdatedAt(now);
        
        // Create the new syllabus
        std::string new_syllabus_id = syllabus_repository_->createSyllabus(new_syllabus);
        
        if (!new_syllabus_id.empty()) {
            logging::Logger::getInstance().info(
                "Cloned syllabus {} from version {} to new version {}",
                syllabus_id, syllabus->getVersion(), new_version
            );
        } else {
            logging::Logger::getInstance().error(
                "Failed to clone syllabus {} to new version {}",
                syllabus_id, new_version
            );
        }
        
        return new_syllabus_id;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error cloning syllabus {}: {}",
            syllabus_id, e.what()
        );
        return "";
    }
}

std::string SyllabusService::importSyllabusFromJson(
    const std::string& json_content,
    const std::string& user_id
) {
    try {
        // Parse JSON
        nlohmann::json json = nlohmann::json::parse(json_content);
        
        // Convert to syllabus
        auto syllabus = Syllabus::fromJson(json);
        
        if (!syllabus) {
            logging::Logger::getInstance().error("Failed to parse syllabus from JSON");
            return "";
        }
        
        // Set author ID to current user
        syllabus->setAuthorId(user_id);
        
        // Set status to DRAFT
        syllabus->setStatus(SyllabusStatus::DRAFT);
        
        // Create the syllabus
        return createSyllabus(*syllabus);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error importing syllabus from JSON: {}", e.what());
        return "";
    }
}

std::string SyllabusService::exportSyllabusToJson(
    const std::string& syllabus_id,
    const std::optional<std::string>& version
) {
    try {
        // Get syllabus
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id, version);
        
        if (!syllabus) {
            logging::Logger::getInstance().error(
                "Syllabus not found with ID {} and version {}",
                syllabus_id, version ? *version : "latest"
            );
            return "";
        }
        
        // Convert to JSON
        nlohmann::json json = syllabus->toJson();
        
        logging::Logger::getInstance().info(
            "Exported syllabus with ID {} and version {} to JSON",
            syllabus_id, syllabus->getVersion()
        );
        
        return json.dump(4);  // Pretty print with 4-space indent
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error(
            "Error exporting syllabus {} to JSON: {}",
            syllabus_id, e.what()
        );
        return "";
    }
}

std::vector<uint8_t> SyllabusService::generateSyllabusDigest(const Syllabus& syllabus) {
    // In a real implementation, this would create a secure hash of the syllabus content
    // For simplicity, we'll just return a dummy digest
    std::vector<uint8_t> digest(32, 0);  // 32-byte zero digest
    
    // Use a proper hash algorithm in a real implementation, e.g.:
    // std::string syllabus_str = syllabus.toJson().dump();
    // SHA256(reinterpret_cast<const unsigned char*>(syllabus_str.c_str()), syllabus_str.length(), digest.data());
    
    return digest;
}

bool SyllabusService::isAuthorizedToModify(const Syllabus& syllabus, const std::string& user_id) {
    // In a real implementation, this would check against a proper authorization system
    // For simplicity, we'll just allow the author and admin users to modify
    return (syllabus.getAuthorId() == user_id || user_id == "admin");
}

std::vector<SyllabusChange> SyllabusService::calculateChanges(
    const Syllabus& old_syllabus,
    const Syllabus& new_syllabus,
    const std::string& user_id
) {
    std::vector<SyllabusChange> changes;
    
    // Check for changes in syllabus properties
    if (old_syllabus.getTitle() != new_syllabus.getTitle() ||
        old_syllabus.getDescription() != new_syllabus.getDescription() ||
        old_syllabus.getEffectiveDate() != new_syllabus.getEffectiveDate() ||
        old_syllabus.getExpirationDate() != new_syllabus.getExpirationDate()) {
        
        SyllabusChange change;
        change.change_type = ChangeType::MODIFIED;
        change.element_type = ElementType::SYLLABUS;
        change.element_id = new_syllabus.getSyllabusId();
        change.description = "Modified syllabus properties";
        change.author_id = user_id;
        change.timestamp = std::chrono::system_clock::now();
        
        // Record old values
        if (old_syllabus.getTitle() != new_syllabus.getTitle()) {
            change.old_values["title"] = old_syllabus.getTitle();
            change.new_values["title"] = new_syllabus.getTitle();
        }
        
        if (old_syllabus.getDescription() != new_syllabus.getDescription()) {
            change.old_values["description"] = old_syllabus.getDescription();
            change.new_values["description"] = new_syllabus.getDescription();
        }
        
        if (old_syllabus.getEffectiveDate() != new_syllabus.getEffectiveDate()) {
            // Format dates as ISO strings
            auto old_time_t = std::chrono::system_clock::to_time_t(old_syllabus.getEffectiveDate());
            auto new_time_t = std::chrono::system_clock::to_time_t(new_syllabus.getEffectiveDate());
            
            std::stringstream old_ss, new_ss;
            old_ss << std::put_time(std::gmtime(&old_time_t), "%Y-%m-%dT%H:%M:%SZ");
            new_ss << std::put_time(std::gmtime(&new_time_t), "%Y-%m-%dT%H:%M:%SZ");
            
            change.old_values["effective_date"] = old_ss.str();
            change.new_values["effective_date"] = new_ss.str();
        }
        
        // Handle optional expiration date
        if (old_syllabus.getExpirationDate() != new_syllabus.getExpirationDate()) {
            if (old_syllabus.getExpirationDate()) {
                auto old_time_t = std::chrono::system_clock::to_time_t(*old_syllabus.getExpirationDate());
                std::stringstream old_ss;
                old_ss << std::put_time(std::gmtime(&old_time_t), "%Y-%m-%dT%H:%M:%SZ");
                change.old_values["expiration_date"] = old_ss.str();
            } else {
                change.old_values["expiration_date"] = "none";
            }
            
            if (new_syllabus.getExpirationDate()) {
                auto new_time_t = std::chrono::system_clock::to_time_t(*new_syllabus.getExpirationDate());
                std::stringstream new_ss;
                new_ss << std::put_time(std::gmtime(&new_time_t), "%Y-%m-%dT%H:%M:%SZ");
                change.new_values["expiration_date"] = new_ss.str();
            } else {
                change.new_values["expiration_date"] = "none";
            }
        }
        
        changes.push_back(change);
    }
    
    // Check for changes in sections
    
    // Get maps of sections by ID for easy lookup
    std::unordered_map<std::string, SyllabusSection> old_sections;
    for (const auto& section : old_syllabus.getSections()) {
        old_sections[section.section_id] = section;
    }
    
    std::unordered_map<std::string, SyllabusSection> new_sections;
    for (const auto& section : new_syllabus.getSections()) {
        new_sections[section.section_id] = section;
    }
    
    // Find sections added in new syllabus
    for (const auto& [section_id, section] : new_sections) {
        if (old_sections.find(section_id) == old_sections.end()) {
            // Section was added
            SyllabusChange change;
            change.change_type = ChangeType::ADDED;
            change.element_type = ElementType::SECTION;
            change.element_id = section_id;
            change.description = "Added section: " + section.title;
            change.author_id = user_id;
            change.timestamp = std::chrono::system_clock::now();
            
            change.new_values["title"] = section.title;
            change.new_values["description"] = section.description;
            change.new_values["order"] = std::to_string(section.order);
            
            changes.push_back(change);
        }
    }
    
    // Find sections removed or modified in old syllabus
    for (const auto& [section_id, old_section] : old_sections) {
        auto it = new_sections.find(section_id);
        if (it == new_sections.end()) {
            // Section was removed
            SyllabusChange change;
            change.change_type = ChangeType::REMOVED;
            change.element_type = ElementType::SECTION;
            change.element_id = section_id;
            change.description = "Removed section: " + old_section.title;
            change.author_id = user_id;
            change.timestamp = std::chrono::system_clock::now();
            
            change.old_values["title"] = old_section.title;
            change.old_values["description"] = old_section.description;
            change.old_values["order"] = std::to_string(old_section.order);
            
            changes.push_back(change);
        } else {
            // Section exists in both, check for modifications
            const auto& new_section = it->second;
            
            if (old_section.title != new_section.title ||
                old_section.description != new_section.description ||
                old_section.order != new_section.order) {
                
                SyllabusChange change;
                change.change_type = ChangeType::MODIFIED;
                change.element_type = ElementType::SECTION;
                change.element_id = section_id;
                change.description = "Modified section: " + new_section.title;
                change.author_id = user_id;
                change.timestamp = std::chrono::system_clock::now();
                
                if (old_section.title != new_section.title) {
                    change.old_values["title"] = old_section.title;
                    change.new_values["title"] = new_section.title;
                }
                
                if (old_section.description != new_section.description) {
                    change.old_values["description"] = old_section.description;
                    change.new_values["description"] = new_section.description;
                }
                
                if (old_section.order != new_section.order) {
                    change.old_values["order"] = std::to_string(old_section.order);
                    change.new_values["order"] = std::to_string(new_section.order);
                }
                
                changes.push_back(change);
            }
            
            // Check for changes in exercises within this section
            
            // Get maps of exercises by ID for easy lookup
            std::unordered_map<std::string, SyllabusExercise> old_exercises;
            for (const auto& exercise : old_section.exercises) {
                old_exercises[exercise.exercise_id] = exercise;
            }
            
            std::unordered_map<std::string, SyllabusExercise> new_exercises;
            for (const auto& exercise : new_section.exercises) {
                new_exercises[exercise.exercise_id] = exercise;
            }
            
            // Find exercises added in new section
            for (const auto& [exercise_id, exercise] : new_exercises) {
                if (old_exercises.find(exercise_id) == old_exercises.end()) {
                    // Exercise was added
                    SyllabusChange change;
                    change.change_type = ChangeType::ADDED;
                    change.element_type = ElementType::EXERCISE;
                    change.element_id = exercise_id;
                    change.parent_id = section_id;
                    change.description = "Added exercise: " + exercise.title;
                    change.author_id = user_id;
                    change.timestamp = std::chrono::system_clock::now();
                    
                    change.new_values["title"] = exercise.title;
                    change.new_values["description"] = exercise.description;
                    change.new_values["order"] = std::to_string(exercise.order);
                    change.new_values["duration_minutes"] = std::to_string(exercise.duration_minutes);
                    change.new_values["exercise_type"] = exercise.exercise_type;
                    
                    changes.push_back(change);
                }
            }
            
            // Find exercises removed or modified in old section
            for (const auto& [exercise_id, old_exercise] : old_exercises) {
                auto it = new_exercises.find(exercise_id);
                if (it == new_exercises.end()) {
                    // Exercise was removed
                    SyllabusChange change;
                    change.change_type = ChangeType::REMOVED;
                    change.element_type = ElementType::EXERCISE;
                    change.element_id = exercise_id;
                    change.parent_id = section_id;
                    change.description = "Removed exercise: " + old_exercise.title;
                    change.author_id = user_id;
                    change.timestamp = std::chrono::system_clock::now();
                    
                    change.old_values["title"] = old_exercise.title;
                    change.old_values["description"] = old_exercise.description;
                    change.old_values["order"] = std::to_string(old_exercise.order);
                    change.old_values["duration_minutes"] = std::to_string(old_exercise.duration_minutes);
                    change.old_values["exercise_type"] = old_exercise.exercise_type;
                    
                    changes.push_back(change);
                } else {
                    // Exercise exists in both, check for modifications
                    const auto& new_exercise = it->second;
                    
                    if (old_exercise.title != new_exercise.title ||
                        old_exercise.description != new_exercise.description ||
                        old_exercise.order != new_exercise.order ||
                        old_exercise.duration_minutes != new_exercise.duration_minutes ||
                        old_exercise.exercise_type != new_exercise.exercise_type) {
                        
                        SyllabusChange change;
                        change.change_type = ChangeType::MODIFIED;
                        change.element_type = ElementType::EXERCISE;
                        change.element_id = exercise_id;
                        change.parent_id = section_id;
                        change.description = "Modified exercise: " + new_exercise.title;
                        change.author_id = user_id;
                        change.timestamp = std::chrono::system_clock::now();
                        
                        if (old_exercise.title != new_exercise.title) {
                            change.old_values["title"] = old_exercise.title;
                            change.new_values["title"] = new_exercise.title;
                        }
                        
                        if (old_exercise.description != new_exercise.description) {
                            change.old_values["description"] = old_exercise.description;
                            change.new_values["description"] = new_exercise.description;
                        }
                        
                        if (old_exercise.order != new_exercise.order) {
                            change.old_values["order"] = std::to_string(old_exercise.order);
                            change.new_values["order"] = std::to_string(new_exercise.order);
                        }
                        
                        if (old_exercise.duration_minutes != new_exercise.duration_minutes) {
                            change.old_values["duration_minutes"] = std::to_string(old_exercise.duration_minutes);
                            change.new_values["duration_minutes"] = std::to_string(new_exercise.duration_minutes);
                        }
                        
                        if (old_exercise.exercise_type != new_exercise.exercise_type) {
                            change.old_values["exercise_type"] = old_exercise.exercise_type;
                            change.new_values["exercise_type"] = new_exercise.exercise_type;
                        }
                        
                        changes.push_back(change);
                    }
                    
                    // Check for changes in objectives
                    std::unordered_set<std::string> old_objectives(
                        old_exercise.objectives.begin(), old_exercise.objectives.end()
                    );
                    std::unordered_set<std::string> new_objectives(
                        new_exercise.objectives.begin(), new_exercise.objectives.end()
                    );
                    
                    // Find added objectives
                    for (const auto& objective : new_objectives) {
                        if (old_objectives.find(objective) == old_objectives.end()) {
                            SyllabusChange change;
                            change.change_type = ChangeType::ADDED;
                            change.element_type = ElementType::OBJECTIVE;
                            change.element_id = exercise_id;
                            change.parent_id = section_id;
                            change.description = "Added objective to exercise: " + new_exercise.title;
                            change.author_id = user_id;
                            change.timestamp = std::chrono::system_clock::now();
                            
                            change.new_values["objective"] = objective;
                            
                            changes.push_back(change);
                        }
                    }
                    
                    // Find removed objectives
                    for (const auto& objective : old_objectives) {
                        if (new_objectives.find(objective) == new_objectives.end()) {
                            SyllabusChange change;
                            change.change_type = ChangeType::REMOVED;
                            change.element_type = ElementType::OBJECTIVE;
                            change.element_id = exercise_id;
                            change.parent_id = section_id;
                            change.description = "Removed objective from exercise: " + new_exercise.title;
                            change.author_id = user_id;
                            change.timestamp = std::chrono::system_clock::now();
                            
                            change.old_values["objective"] = objective;
                            
                            changes.push_back(change);
                        }
                    }
                    
                    // Check for changes in grading criteria
                    // Similar pattern to above - needs implementation for criteria
                }
            }
        }
    }
    
    return changes;
}

// Implementation of SyllabusChange methods

nlohmann::json SyllabusChange::toJson() const {
    nlohmann::json json;
    json["change_type"] = changeTypeToString(change_type);
    json["element_type"] = elementTypeToString(element_type);
    json["element_id"] = element_id;
    
    if (parent_id) {
        json["parent_id"] = *parent_id;
    }
    
    json["description"] = description;
    json["old_values"] = old_values;
    json["new_values"] = new_values;
    json["rationale"] = rationale;
    json["author_id"] = author_id;
    
    // Convert timestamp to milliseconds since epoch
    json["timestamp"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        timestamp.time_since_epoch()
    ).count();
    
    return json;
}

std::optional<SyllabusChange> SyllabusChange::fromJson(const nlohmann::json& json) {
    try {
        SyllabusChange change;
        
        change.change_type = changeTypeFromString(json["change_type"]);
        change.element_type = elementTypeFromString(json["element_type"]);
        change.element_id = json["element_id"];
        
        if (json.contains("parent_id") && !json["parent_id"].is_null()) {
            change.parent_id = json["parent_id"];
        }
        
        change.description = json["description"];
        
        if (json.contains("old_values") && json["old_values"].is_object()) {
            change.old_values = json["old_values"].get<std::map<std::string, std::string>>();
        }
        
        if (json.contains("new_values") && json["new_values"].is_object()) {
            change.new_values = json["new_values"].get<std::map<std::string, std::string>>();
        }
        
        change.rationale = json["rationale"];
        change.author_id = json["author_id"];
        
        // Convert timestamp from milliseconds since epoch
        change.timestamp = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["timestamp"].get<int64_t>())
        );
        
        return change;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus change from JSON: {}", e.what());
        return std::nullopt;
    }
}

// Implementation of SyllabusSummary methods

nlohmann::json SyllabusSummary::toJson() const {
    nlohmann::json json;
    json["syllabus_id"] = syllabus_id;
    json["course_id"] = course_id;
    json["title"] = title;
    json["version"] = version;
    
    // Convert timestamps to milliseconds since epoch
    json["effective_date"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        effective_date.time_since_epoch()
    ).count();
    
    if (expiration_date) {
        json["expiration_date"] = std::chrono::duration_cast<std::chrono::milliseconds>(
            expiration_date->time_since_epoch()
        ).count();
    } else {
        json["expiration_date"] = nullptr;
    }
    
    json["status"] = syllabusStatusToString(status);
    json["author_id"] = author_id;
    
    json["created_at"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        created_at.time_since_epoch()
    ).count();
    
    json["updated_at"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        updated_at.time_since_epoch()
    ).count();
    
    return json;
}

std::optional<SyllabusSummary> SyllabusSummary::fromJson(const nlohmann::json& json) {
    try {
        SyllabusSummary summary;
        
        summary.syllabus_id = json["syllabus_id"];
        summary.course_id = json["course_id"];
        summary.title = json["title"];
        summary.version = json["version"];
        
        // Convert timestamps from milliseconds since epoch
        summary.effective_date = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["effective_date"].get<int64_t>())
        );
        
        if (json.contains("expiration_date") && !json["expiration_date"].is_null()) {
            summary.expiration_date = std::chrono::system_clock::time_point(
                std::chrono::milliseconds(json["expiration_date"].get<int64_t>())
            );
        }
        
        summary.status = syllabusStatusFromString(json["status"]);
        summary.author_id = json["author_id"];
        
        summary.created_at = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["created_at"].get<int64_t>())
        );
        
        summary.updated_at = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["updated_at"].get<int64_t>())
        );
        
        return summary;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus summary from JSON: {}", e.what());
        return std::nullopt;
    }
}

} // namespace syllabus
} // namespace etr
#include "syllabus/syllabus.h"
#include "logging/logger.h"
#include <uuid.h>
#include <algorithm>

namespace etr {
namespace syllabus {

// SyllabusStatus conversion methods
std::string syllabusStatusToString(SyllabusStatus status) {
    switch (status) {
        case SyllabusStatus::DRAFT: return "DRAFT";
        case SyllabusStatus::APPROVED: return "APPROVED";
        case SyllabusStatus::ARCHIVED: return "ARCHIVED";
        default: return "UNKNOWN";
    }
}

SyllabusStatus syllabusStatusFromString(const std::string& str) {
    if (str == "DRAFT") return SyllabusStatus::DRAFT;
    if (str == "APPROVED") return SyllabusStatus::APPROVED;
    if (str == "ARCHIVED") return SyllabusStatus::ARCHIVED;
    return SyllabusStatus::DRAFT; // Default to DRAFT
}

// ChangeType conversion methods
std::string changeTypeToString(ChangeType type) {
    switch (type) {
        case ChangeType::ADDED: return "ADDED";
        case ChangeType::MODIFIED: return "MODIFIED";
        case ChangeType::REMOVED: return "REMOVED";
        default: return "UNKNOWN";
    }
}

ChangeType changeTypeFromString(const std::string& str) {
    if (str == "ADDED") return ChangeType::ADDED;
    if (str == "MODIFIED") return ChangeType::MODIFIED;
    if (str == "REMOVED") return ChangeType::REMOVED;
    return ChangeType::MODIFIED; // Default to MODIFIED
}

// ElementType conversion methods
std::string elementTypeToString(ElementType type) {
    switch (type) {
        case ElementType::SYLLABUS: return "SYLLABUS";
        case ElementType::SECTION: return "SECTION";
        case ElementType::EXERCISE: return "EXERCISE";
        case ElementType::CRITERIA: return "CRITERIA";
        case ElementType::OBJECTIVE: return "OBJECTIVE";
        case ElementType::REFERENCE: return "REFERENCE";
        case ElementType::EQUIPMENT: return "EQUIPMENT";
        case ElementType::PREREQUISITE: return "PREREQUISITE";
        case ElementType::METADATA: return "METADATA";
        default: return "UNKNOWN";
    }
}

ElementType elementTypeFromString(const std::string& str) {
    if (str == "SYLLABUS") return ElementType::SYLLABUS;
    if (str == "SECTION") return ElementType::SECTION;
    if (str == "EXERCISE") return ElementType::EXERCISE;
    if (str == "CRITERIA") return ElementType::CRITERIA;
    if (str == "OBJECTIVE") return ElementType::OBJECTIVE;
    if (str == "REFERENCE") return ElementType::REFERENCE;
    if (str == "EQUIPMENT") return ElementType::EQUIPMENT;
    if (str == "PREREQUISITE") return ElementType::PREREQUISITE;
    if (str == "METADATA") return ElementType::METADATA;
    return ElementType::SYLLABUS; // Default to SYLLABUS
}

// GradeDefinition
nlohmann::json GradeDefinition::toJson() const {
    nlohmann::json json;
    json["grade"] = grade;
    json["description"] = description;
    json["is_passing"] = is_passing;
    return json;
}

std::optional<GradeDefinition> GradeDefinition::fromJson(const nlohmann::json& json) {
    try {
        GradeDefinition definition;
        definition.grade = json["grade"];
        definition.description = json["description"];
        definition.is_passing = json["is_passing"];
        return definition;
    } catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing grade definition from JSON: {}", e.what());
        return std::nullopt;
    }
}

// GradingCriteria
nlohmann::json GradingCriteria::toJson() const {
    nlohmann::json json;
    json["criteria_id"] = criteria_id;
    json["name"] = name;
    json["description"] = description;
    
    json["grade_definitions"] = nlohmann::json::array();
    for (const auto& definition : grade_definitions) {
        json["grade_definitions"].push_back(definition.toJson());
    }
    
    json["is_required"] = is_required;
    
    json["regulation_references"] = nlohmann::json::object();
    for (const auto& [key, value] : regulation_references) {
        json["regulation_references"][key] = value;
    }
    
    return json;
}

std::optional<GradingCriteria> GradingCriteria::fromJson(const nlohmann::json& json) {
    try {
        GradingCriteria criteria;
        criteria.criteria_id = json["criteria_id"];
        criteria.name = json["name"];
        criteria.description = json["description"];
        
        for (const auto& def_json : json["grade_definitions"]) {
            auto definition = GradeDefinition::fromJson(def_json);
            if (definition) {
                criteria.grade_definitions.push_back(*definition);
            }
        }
        
        criteria.is_required = json["is_required"];
        
        for (const auto& [key, value] : json["regulation_references"].items()) {
            criteria.regulation_references[key] = value;
        }
        
        return criteria;
    } catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing grading criteria from JSON: {}", e.what());
        return std::nullopt;
    }
}

// SyllabusExercise
nlohmann::json SyllabusExercise::toJson() const {
    nlohmann::json json;
    json["exercise_id"] = exercise_id;
    json["title"] = title;
    json["description"] = description;
    json["order"] = order;
    json["duration_minutes"] = duration_minutes;
    json["exercise_type"] = exercise_type;
    json["objectives"] = objectives;
    json["references"] = references;
    json["equipment"] = equipment;
    
    json["grading_criteria"] = nlohmann::json::array();
    for (const auto& criteria : grading_criteria) {
        json["grading_criteria"].push_back(criteria.toJson());
    }
    
    json["prerequisite_exercises"] = prerequisite_exercises;
    
    json["metadata"] = nlohmann::json::object();
    for (const auto& [key, value] : metadata) {
        json["metadata"][key] = value;
    }
    
    return json;
}

std::optional<SyllabusExercise> SyllabusExercise::fromJson(const nlohmann::json& json) {
    try {
        SyllabusExercise exercise;
        exercise.exercise_id = json["exercise_id"];
        exercise.title = json["title"];
        exercise.description = json["description"];
        exercise.order = json["order"];
        exercise.duration_minutes = json["duration_minutes"];
        exercise.exercise_type = json["exercise_type"];
        exercise.objectives = json["objectives"].get<std::vector<std::string>>();
        exercise.references = json["references"].get<std::vector<std::string>>();
        exercise.equipment = json["equipment"].get<std::vector<std::string>>();
        
        for (const auto& criteria_json : json["grading_criteria"]) {
            auto criteria = GradingCriteria::fromJson(criteria_json);
            if (criteria) {
                exercise.grading_criteria.push_back(*criteria);
            }
        }
        
        exercise.prerequisite_exercises = json["prerequisite_exercises"].get<std::vector<std::string>>();
        
        for (const auto& [key, value] : json["metadata"].items()) {
            exercise.metadata[key] = value;
        }
        
        return exercise;
    } catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus exercise from JSON: {}", e.what());
        return std::nullopt;
    }
}

// SyllabusSection
nlohmann::json SyllabusSection::toJson() const {
    nlohmann::json json;
    json["section_id"] = section_id;
    json["title"] = title;
    json["description"] = description;
    json["order"] = order;
    
    json["exercises"] = nlohmann::json::array();
    for (const auto& exercise : exercises) {
        json["exercises"].push_back(exercise.toJson());
    }
    
    return json;
}

std::optional<SyllabusSection> SyllabusSection::fromJson(const nlohmann::json& json) {
    try {
        SyllabusSection section;
        section.section_id = json["section_id"];
        section.title = json["title"];
        section.description = json["description"];
        section.order = json["order"];
        
        for (const auto& exercise_json : json["exercises"]) {
            auto exercise = SyllabusExercise::fromJson(exercise_json);
            if (exercise) {
                section.exercises.push_back(*exercise);
            }
        }
        
        return section;
    } catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus section from JSON: {}", e.what());
        return std::nullopt;
    }
}

// Syllabus
Syllabus::Syllabus() {
    // Generate a new ID
    uuids::uuid id = uuids::uuid_system_generator{}();
    syllabus_id_ = uuids::to_string(id);
    
    // Set default values
    status_ = SyllabusStatus::DRAFT;
    created_at_ = std::chrono::system_clock::now();
    updated_at_ = created_at_;
}

Syllabus::Syllabus(const std::string& id) : syllabus_id_(id) {
    // Set default values
    status_ = SyllabusStatus::DRAFT;
    created_at_ = std::chrono::system_clock::now();
    updated_at_ = created_at_;
}

const std::string& Syllabus::getSyllabusId() const {
    return syllabus_id_;
}

void Syllabus::setSyllabusId(const std::string& id) {
    syllabus_id_ = id;
}

const std::string& Syllabus::getCourseId() const {
    return course_id_;
}

void Syllabus::setCourseId(const std::string& id) {
    course_id_ = id;
}

const std::string& Syllabus::getTitle() const {
    return title_;
}

void Syllabus::setTitle(const std::string& title) {
    title_ = title;
}

const std::string& Syllabus::getDescription() const {
    return description_;
}

void Syllabus::setDescription(const std::string& description) {
    description_ = description;
}

const std::string& Syllabus::getVersion() const {
    return version_;
}

void Syllabus::setVersion(const std::string& version) {
    version_ = version;
}

std::chrono::system_clock::time_point Syllabus::getEffectiveDate() const {
    return effective_date_;
}

void Syllabus::setEffectiveDate(const std::chrono::system_clock::time_point& date) {
    effective_date_ = date;
}

std::optional<std::chrono::system_clock::time_point> Syllabus::getExpirationDate() const {
    return expiration_date_;
}

void Syllabus::setExpirationDate(const std::chrono::system_clock::time_point& date) {
    expiration_date_ = date;
}

void Syllabus::clearExpirationDate() {
    expiration_date_ = std::nullopt;
}

SyllabusStatus Syllabus::getStatus() const {
    return status_;
}

void Syllabus::setStatus(SyllabusStatus status) {
    status_ = status;
}

const std::string& Syllabus::getAuthorId() const {
    return author_id_;
}

void Syllabus::setAuthorId(const std::string& id) {
    author_id_ = id;
}

const std::vector<SyllabusSection>& Syllabus::getSections() const {
    return sections_;
}

void Syllabus::setSections(const std::vector<SyllabusSection>& sections) {
    sections_ = sections;
}

void Syllabus::addSection(const SyllabusSection& section) {
    sections_.push_back(section);
    
    // Sort sections by order
    std::sort(sections_.begin(), sections_.end(), 
              [](const SyllabusSection& a, const SyllabusSection& b) {
                  return a.order < b.order;
              });
}

bool Syllabus::updateSection(const SyllabusSection& section) {
    for (auto& existing_section : sections_) {
        if (existing_section.section_id == section.section_id) {
            existing_section = section;
            
            // Sort sections by order
            std::sort(sections_.begin(), sections_.end(), 
                      [](const SyllabusSection& a, const SyllabusSection& b) {
                          return a.order < b.order;
                      });
            
            return true;
        }
    }
    
    return false;
}

bool Syllabus::removeSection(const std::string& section_id) {
    auto it = std::find_if(sections_.begin(), sections_.end(),
                           [&section_id](const SyllabusSection& section) {
                               return section.section_id == section_id;
                           });
    
    if (it != sections_.end()) {
        sections_.erase(it);
        return true;
    }
    
    return false;
}

std::optional<SyllabusSection> Syllabus::getSection(const std::string& section_id) const {
    auto it = std::find_if(sections_.begin(), sections_.end(),
                           [&section_id](const SyllabusSection& section) {
                               return section.section_id == section_id;
                           });
    
    if (it != sections_.end()) {
        return *it;
    }
    
    return std::nullopt;
}

const std::map<std::string, std::string>& Syllabus::getMetadata() const {
    return metadata_;
}

void Syllabus::setMetadata(const std::map<std::string, std::string>& metadata) {
    metadata_ = metadata;
}

std::string Syllabus::getMetadataValue(const std::string& key) const {
    auto it = metadata_.find(key);
    if (it != metadata_.end()) {
        return it->second;
    }
    
    return "";
}

void Syllabus::setMetadataValue(const std::string& key, const std::string& value) {
    metadata_[key] = value;
}

std::chrono::system_clock::time_point Syllabus::getCreatedAt() const {
    return created_at_;
}

void Syllabus::setCreatedAt(const std::chrono::system_clock::time_point& time) {
    created_at_ = time;
}

std::chrono::system_clock::time_point Syllabus::getUpdatedAt() const {
    return updated_at_;
}

void Syllabus::setUpdatedAt(const std::chrono::system_clock::time_point& time) {
    updated_at_ = time;
}

const std::optional<records::SignatureInfo>& Syllabus::getApprovalSignature() const {
    return approval_signature_;
}

void Syllabus::setApprovalSignature(const records::SignatureInfo& signature) {
    approval_signature_ = signature;
}

std::optional<std::pair<SyllabusExercise, std::string>> Syllabus::findExercise(const std::string& exercise_id) const {
    for (const auto& section : sections_) {
        for (const auto& exercise : section.exercises) {
            if (exercise.exercise_id == exercise_id) {
                return std::make_pair(exercise, section.section_id);
            }
        }
    }
    
    return std::nullopt;
}

bool Syllabus::updateExercise(const SyllabusExercise& exercise, const std::string& section_id) {
    for (auto& section : sections_) {
        if (section.section_id == section_id) {
            for (auto& existing_exercise : section.exercises) {
                if (existing_exercise.exercise_id == exercise.exercise_id) {
                    existing_exercise = exercise;
                    
                    // Sort exercises by order
                    std::sort(section.exercises.begin(), section.exercises.end(), 
                              [](const SyllabusExercise& a, const SyllabusExercise& b) {
                                  return a.order < b.order;
                              });
                    
                    return true;
                }
            }
        }
    }
    
    return false;
}

bool Syllabus::addExerciseToSection(const SyllabusExercise& exercise, const std::string& section_id) {
    for (auto& section : sections_) {
        if (section.section_id == section_id) {
            section.exercises.push_back(exercise);
            
            // Sort exercises by order
            std::sort(section.exercises.begin(), section.exercises.end(), 
                      [](const SyllabusExercise& a, const SyllabusExercise& b) {
                          return a.order < b.order;
                      });
            
            return true;
        }
    }
    
    return false;
}

bool Syllabus::removeExercise(const std::string& exercise_id) {
    for (auto& section : sections_) {
        auto it = std::find_if(section.exercises.begin(), section.exercises.end(),
                               [&exercise_id](const SyllabusExercise& exercise) {
                                   return exercise.exercise_id == exercise_id;
                               });
        
        if (it != section.exercises.end()) {
            section.exercises.erase(it);
            return true;
        }
    }
    
    return false;
}

bool Syllabus::isApproved() const {
    return status_ == SyllabusStatus::APPROVED && approval_signature_.has_value();
}

bool Syllabus::isValid() const {
    // Check required fields
    if (course_id_.empty() || title_.empty() || version_.empty() || author_id_.empty()) {
        return false;
    }
    
    // Check if there are sections
    if (sections_.empty()) {
        return false;
    }
    
    // Check if sections have exercises
    for (const auto& section : sections_) {
        if (section.exercises.empty()) {
            return false;
        }
    }
    
    return true;
}

nlohmann::json Syllabus::toJson() const {
    nlohmann::json json;
    json["syllabus_id"] = syllabus_id_;
    json["course_id"] = course_id_;
    json["title"] = title_;
    json["description"] = description_;
    json["version"] = version_;
    
    json["effective_date"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        effective_date_.time_since_epoch()).count();
    
    if (expiration_date_) {
        json["expiration_date"] = std::chrono::duration_cast<std::chrono::milliseconds>(
            expiration_date_->time_since_epoch()).count();
    }
    
    json["status"] = syllabusStatusToString(status_);
    json["author_id"] = author_id_;
    
    json["sections"] = nlohmann::json::array();
    for (const auto& section : sections_) {
        json["sections"].push_back(section.toJson());
    }
    
    json["metadata"] = metadata_;
    
    json["created_at"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        created_at_.time_since_epoch()).count();
    
    json["updated_at"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        updated_at_.time_since_epoch()).count();
    
    if (approval_signature_) {
        json["approval_signature"] = nlohmann::json::object();
        json["approval_signature"]["signer_id"] = approval_signature_->signer_id;
        json["approval_signature"]["signer_name"] = approval_signature_->signer_name;
        json["approval_signature"]["certificate_id"] = approval_signature_->certificate_id;
        
        // Convert signature data to base64
        std::stringstream ss;
        for (const auto& byte : approval_signature_->signature_data) {
            ss << std::hex << std::setw(2) << std::setfill('0') << (int)byte;
        }
        json["approval_signature"]["signature_data"] = ss.str();
        
        json["approval_signature"]["timestamp"] = std::chrono::duration_cast<std::chrono::milliseconds>(
            approval_signature_->timestamp.time_since_epoch()).count();
        
        json["approval_signature"]["is_valid"] = approval_signature_->is_valid;
    }
    
    return json;
}

std::optional<Syllabus> Syllabus::fromJson(const nlohmann::json& json) {
    try {
        Syllabus syllabus;
        
        syllabus.syllabus_id_ = json["syllabus_id"];
        syllabus.course_id_ = json["course_id"];
        syllabus.title_ = json["title"];
        syllabus.description_ = json["description"];
        syllabus.version_ = json["version"];
        
        syllabus.effective_date_ = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["effective_date"].get<int64_t>()));
        
        if (json.contains("expiration_date") && !json["expiration_date"].is_null()) {
            syllabus.expiration_date_ = std::chrono::system_clock::time_point(
                std::chrono::milliseconds(json["expiration_date"].get<int64_t>()));
        }
        
        syllabus.status_ = syllabusStatusFromString(json["status"]);
        syllabus.author_id_ = json["author_id"];
        
        for (const auto& section_json : json["sections"]) {
            auto section = SyllabusSection::fromJson(section_json);
            if (section) {
                syllabus.sections_.push_back(*section);
            }
        }
        
        if (json.contains("metadata") && json["metadata"].is_object()) {
            for (const auto& [key, value] : json["metadata"].items()) {
                syllabus.metadata_[key] = value;
            }
        }
        
        syllabus.created_at_ = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["created_at"].get<int64_t>()));
        
        syllabus.updated_at_ = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["updated_at"].get<int64_t>()));
        
        if (json.contains("approval_signature") && !json["approval_signature"].is_null()) {
            records::SignatureInfo signature;
            signature.signer_id = json["approval_signature"]["signer_id"];
            signature.signer_name = json["approval_signature"]["signer_name"];
            signature.certificate_id = json["approval_signature"]["certificate_id"];
            
            // Convert signature data from hex string
            std::string signature_data_hex = json["approval_signature"]["signature_data"];
            for (size_t i = 0; i < signature_data_hex.length(); i += 2) {
                std::string byte_hex = signature_data_hex.substr(i, 2);
                uint8_t byte = std::stoi(byte_hex, nullptr, 16);
                signature.signature_data.push_back(byte);
            }
            
            signature.timestamp = std::chrono::system_clock::time_point(
                std::chrono::milliseconds(json["approval_signature"]["timestamp"].get<int64_t>()));
            
            signature.is_valid = json["approval_signature"]["is_valid"];
            
            syllabus.approval_signature_ = signature;
        }
        
        return syllabus;
    } catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus from JSON: {}", e.what());
        return std::nullopt;
    }
}

nlohmann::json Syllabus::generateAuditLog(
    const std::string& action,
    const std::string& user_id,
    const std::string& details
) const {
    nlohmann::json log;
    log["syllabus_id"] = syllabus_id_;
    log["version"] = version_;
    log["action"] = action;
    log["user_id"] = user_id;
    log["details"] = details;
    log["timestamp"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        std::chrono::system_clock::now().time_since_epoch()).count();
    
    return log;
}

// SyllabusChange
nlohmann::json SyllabusChange::toJson() const {
    nlohmann::json json;
    json["change_type"] = changeTypeToString(change_type);
    json["element_type"] = elementTypeToString(element_type);
    json["element_id"] = element_id;
    
    if (parent_id) {
        json["parent_id"] = *parent_id;
    }
    
    json["description"] = description;
    json["old_values"] = old_values;
    json["new_values"] = new_values;
    json["rationale"] = rationale;
    json["author_id"] = author_id;
    
    json["timestamp"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        timestamp.time_since_epoch()).count();
    
    return json;
}

std::optional<SyllabusChange> SyllabusChange::fromJson(const nlohmann::json& json) {
    try {
        SyllabusChange change;
        
        change.change_type = changeTypeFromString(json["change_type"]);
        change.element_type = elementTypeFromString(json["element_type"]);
        change.element_id = json["element_id"];
        
        if (json.contains("parent_id") && !json["parent_id"].is_null()) {
            change.parent_id = json["parent_id"];
        }
        
        change.description = json["description"];
        
        for (const auto& [key, value] : json["old_values"].items()) {
            change.old_values[key] = value;
        }
        
        for (const auto& [key, value] : json["new_values"].items()) {
            change.new_values[key] = value;
        }
        
        change.rationale = json["rationale"];
        change.author_id = json["author_id"];
        
        change.timestamp = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["timestamp"].get<int64_t>()));
        
        return change;
    } catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus change from JSON: {}", e.what());
        return std::nullopt;
    }
}

// SyllabusSummary
nlohmann::json SyllabusSummary::toJson() const {
    nlohmann::json json;
    json["syllabus_id"] = syllabus_id;
    json["course_id"] = course_id;
    json["title"] = title;
    json["version"] = version;
    
    json["effective_date"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        effective_date.time_since_epoch()).count();
    
    if (expiration_date) {
        json["expiration_date"] = std::chrono::duration_cast<std::chrono::milliseconds>(
            expiration_date->time_since_epoch()).count();
    }
    
    json["status"] = syllabusStatusToString(status);
    json["author_id"] = author_id;
    
    json["created_at"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        created_at.time_since_epoch()).count();
    
    json["updated_at"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        updated_at.time_since_epoch()).count();
    
    return json;
}

std::optional<SyllabusSummary> SyllabusSummary::fromJson(const nlohmann::json& json) {
    try {
        SyllabusSummary summary;
        
        summary.syllabus_id = json["syllabus_id"];
        summary.course_id = json["course_id"];
        summary.title = json["title"];
        summary.version = json["version"];
        
        summary.effective_date = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["effective_date"].get<int64_t>()));
        
        if (json.contains("expiration_date") && !json["expiration_date"].is_null()) {
            summary.expiration_date = std::chrono::system_clock::time_point(
                std::chrono::milliseconds(json["expiration_date"].get<int64_t>()));
        }
        
        summary.status = syllabusStatusFromString(json["status"]);
        summary.author_id = json["author_id"];
        
        summary.created_at = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["created_at"].get<int64_t>()));
        
        summary.updated_at = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["updated_at"].get<int64_t>()));
        
        return summary;
    } catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus summary from JSON: {}", e.what());
        return std::nullopt;
    }
}

} // namespace syllabus
} // namespace etr
#include "syllabus/syllabus_repository.h"
#include "logging/logger.h"
#include "persistence/database_connection.h"
#include <algorithm>
#include <uuid.h>

namespace etr {
namespace syllabus {

class SyllabusRepository : public ISyllabusRepository {
public:
    explicit SyllabusRepository(std::shared_ptr<persistence::DatabaseConnection> db_connection)
        : db_connection_(std::move(db_connection)) {
        logging::Logger::getInstance().info("SyllabusRepository initialized");
    }
    
    ~SyllabusRepository() override = default;

    std::string createSyllabus(const Syllabus& syllabus) override {
        try {
            auto transaction = db_connection_->createTransaction();
            
            // Generate ID if not provided
            std::string syllabus_id = syllabus.getSyllabusId();
            if (syllabus_id.empty()) {
                syllabus_id = generateUniqueId();
            }
            
            // Insert basic syllabus info
            std::string query = R"(
                INSERT INTO etr.syllabi (
                    syllabus_id, course_id, title, description, version, 
                    effective_date, expiration_date, status, author_id, 
                    created_at, updated_at
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11
                ) RETURNING syllabus_id
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            params.push_back({"course_id", syllabus.getCourseId(), persistence::PgParamType::TEXT, false});
            params.push_back({"title", syllabus.getTitle(), persistence::PgParamType::TEXT, false});
            params.push_back({"description", syllabus.getDescription(), persistence::PgParamType::TEXT, false});
            params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
            
            auto effective_date = std::chrono::duration_cast<std::chrono::milliseconds>(
                syllabus.getEffectiveDate().time_since_epoch()).count();
            params.push_back({"effective_date", std::to_string(effective_date), persistence::PgParamType::TIMESTAMP, false});
            
            if (syllabus.getExpirationDate()) {
                auto expiration_date = std::chrono::duration_cast<std::chrono::milliseconds>(
                    syllabus.getExpirationDate()->time_since_epoch()).count();
                params.push_back({"expiration_date", std::to_string(expiration_date), persistence::PgParamType::TIMESTAMP, false});
            } else {
                params.push_back({"expiration_date", "", persistence::PgParamType::TIMESTAMP, true});
            }
            
            params.push_back({"status", syllabusStatusToString(syllabus.getStatus()), persistence::PgParamType::TEXT, false});
            params.push_back({"author_id", syllabus.getAuthorId(), persistence::PgParamType::TEXT, false});
            
            auto created_at = std::chrono::duration_cast<std::chrono::milliseconds>(
                syllabus.getCreatedAt().time_since_epoch()).count();
            params.push_back({"created_at", std::to_string(created_at), persistence::PgParamType::TIMESTAMP, false});
            
            auto updated_at = std::chrono::duration_cast<std::chrono::milliseconds>(
                syllabus.getUpdatedAt().time_since_epoch()).count();
            params.push_back({"updated_at", std::to_string(updated_at), persistence::PgParamType::TIMESTAMP, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                logging::Logger::getInstance().error("Failed to insert syllabus: {}", result.getErrorMessage());
                transaction.rollback();
                return "";
            }
            
            // Insert syllabus metadata
            for (const auto& [key, value] : syllabus.getMetadata()) {
                std::string metadata_query = R"(
                    INSERT INTO etr.syllabus_metadata (
                        syllabus_id, version, key, value
                    ) VALUES (
                        $1, $2, $3, $4
                    )
                )";
                
                std::vector<persistence::PgParam> metadata_params;
                metadata_params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
                metadata_params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
                metadata_params.push_back({"key", key, persistence::PgParamType::TEXT, false});
                metadata_params.push_back({"value", value, persistence::PgParamType::TEXT, false});
                
                auto metadata_result = db_connection_->executeQuery(metadata_query, metadata_params);
                
                if (metadata_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert syllabus metadata: {}", 
                        metadata_result.getErrorMessage());
                    transaction.rollback();
                    return "";
                }
            }
            
            // Insert signature if available
            if (syllabus.getApprovalSignature()) {
                const auto& signature = *syllabus.getApprovalSignature();
                
                std::string signature_query = R"(
                    INSERT INTO etr.syllabus_signatures (
                        syllabus_id, version, signer_id, signer_name, 
                        certificate_id, signature_data, timestamp, is_valid
                    ) VALUES (
                        $1, $2, $3, $4, $5, $6, $7, $8
                    )
                )";
                
                std::vector<persistence::PgParam> signature_params;
                signature_params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
                signature_params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
                signature_params.push_back({"signer_id", signature.signer_id, persistence::PgParamType::TEXT, false});
                signature_params.push_back({"signer_name", signature.signer_name, persistence::PgParamType::TEXT, false});
                
                if (!signature.certificate_id.empty()) {
                    signature_params.push_back({"certificate_id", signature.certificate_id, persistence::PgParamType::TEXT, false});
                } else {
                    signature_params.push_back({"certificate_id", "", persistence::PgParamType::TEXT, true});
                }
                
                std::string signature_data(reinterpret_cast<const char*>(signature.signature_data.data()), 
                                          signature.signature_data.size());
                signature_params.push_back({"signature_data", signature_data, persistence::PgParamType::BYTEA, false});
                
                auto timestamp = std::chrono::duration_cast<std::chrono::milliseconds>(
                    signature.timestamp.time_since_epoch()).count();
                signature_params.push_back({"timestamp", std::to_string(timestamp), persistence::PgParamType::TIMESTAMP, false});
                
                signature_params.push_back({"is_valid", signature.is_valid ? "true" : "false", persistence::PgParamType::BOOLEAN, false});
                
                auto signature_result = db_connection_->executeQuery(signature_query, signature_params);
                
                if (signature_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert syllabus signature: {}", 
                        signature_result.getErrorMessage());
                    transaction.rollback();
                    return "";
                }
            }
            
            // Insert sections
            for (const auto& section : syllabus.getSections()) {
                if (!insertSection(transaction, syllabus_id, syllabus.getVersion(), section)) {
                    transaction.rollback();
                    return "";
                }
            }
            
            // Commit transaction
            if (!transaction.commit()) {
                logging::Logger::getInstance().error("Failed to commit syllabus transaction");
                return "";
            }
            
            logging::Logger::getInstance().info("Created syllabus: {}, version: {}", 
                syllabus_id, syllabus.getVersion());
            
            return syllabus_id;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error creating syllabus: {}", e.what());
            return "";
        }
    }
    
    std::optional<Syllabus> getSyllabus(
        const std::string& syllabus_id,
        const std::optional<std::string>& version
    ) override {
        try {
            // Get syllabus basic info
            std::string query = R"(
                SELECT 
                    syllabus_id, course_id, title, description, version, 
                    effective_date, expiration_date, status, author_id, 
                    created_at, updated_at
                FROM etr.syllabi
                WHERE syllabus_id = $1
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            
            if (version) {
                query += " AND version = $2";
                params.push_back({"version", *version, persistence::PgParamType::TEXT, false});
            } else {
                // Get latest version if not specified
                query += " ORDER BY effective_date DESC LIMIT 1";
            }
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                if (result.hasError()) {
                    logging::Logger::getInstance().error("Failed to get syllabus: {}", result.getErrorMessage());
                }
                return std::nullopt;
            }
            
            // Extract syllabus info
            Syllabus syllabus(result.getString(0, "syllabus_id"));
            syllabus.setCourseId(result.getString(0, "course_id"));
            syllabus.setTitle(result.getString(0, "title"));
            syllabus.setDescription(result.getString(0, "description"));
            syllabus.setVersion(result.getString(0, "version"));
            
            auto effective_date = result.getTimestamp(0, "effective_date");
            if (effective_date) {
                syllabus.setEffectiveDate(*effective_date);
            }
            
            auto expiration_date = result.getTimestamp(0, "expiration_date");
            if (expiration_date) {
                syllabus.setExpirationDate(*expiration_date);
            }
            
            syllabus.setStatus(syllabusStatusFromString(result.getString(0, "status")));
            syllabus.setAuthorId(result.getString(0, "author_id"));
            
            auto created_at = result.getTimestamp(0, "created_at");
            if (created_at) {
                syllabus.setCreatedAt(*created_at);
            }
            
            auto updated_at = result.getTimestamp(0, "updated_at");
            if (updated_at) {
                syllabus.setUpdatedAt(*updated_at);
            }
            
            // Get syllabus metadata
            std::string metadata_query = R"(
                SELECT key, value
                FROM etr.syllabus_metadata
                WHERE syllabus_id = $1 AND version = $2
            )";
            
            std::vector<persistence::PgParam> metadata_params;
            metadata_params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            metadata_params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
            
            auto metadata_result = db_connection_->executeQuery(metadata_query, metadata_params);
            
            if (!metadata_result.hasError()) {
                std::map<std::string, std::string> metadata;
                
                for (int i = 0; i < metadata_result.getNumRows(); ++i) {
                    std::string key = metadata_result.getString(i, "key");
                    std::string value = metadata_result.getString(i, "value");
                    metadata[key] = value;
                }
                
                syllabus.setMetadata(metadata);
            }
            
            // Get signature if available
            std::string signature_query = R"(
                SELECT 
                    signer_id, signer_name, certificate_id, signature_data, 
                    timestamp, is_valid
                FROM etr.syllabus_signatures
                WHERE syllabus_id = $1 AND version = $2
            )";
            
            std::vector<persistence::PgParam> signature_params;
            signature_params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            signature_params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
            
            auto signature_result = db_connection_->executeQuery(signature_query, signature_params);
            
            if (!signature_result.isEmpty() && !signature_result.hasError()) {
                records::SignatureInfo signature;
                signature.signer_id = signature_result.getString(0, "signer_id");
                signature.signer_name = signature_result.getString(0, "signer_name");
                signature.certificate_id = signature_result.getString(0, "certificate_id");
                
                auto signature_data = signature_result.getBinary(0, "signature_data");
                signature.signature_data = signature_data;
                
                auto timestamp = signature_result.getTimestamp(0, "timestamp");
                if (timestamp) {
                    signature.timestamp = *timestamp;
                }
                
                signature.is_valid = signature_result.getBool(0, "is_valid");
                
                syllabus.setApprovalSignature(signature);
            }
            
            // Get sections
            std::vector<SyllabusSection> sections = getSyllabusSection(syllabus_id, syllabus.getVersion());
            syllabus.setSections(sections);
            
            logging::Logger::getInstance().debug("Retrieved syllabus: {}, version: {}", 
                syllabus_id, syllabus.getVersion());
            
            return syllabus;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting syllabus: {}", e.what());
            return std::nullopt;
        }
    }
    
    bool updateSyllabus(const Syllabus& syllabus) override {
        try {
            // Check if syllabus exists
            auto existing = getSyllabus(syllabus.getSyllabusId(), syllabus.getVersion());
            if (!existing) {
                logging::Logger::getInstance().error("Cannot update non-existent syllabus: {}, version: {}", 
                    syllabus.getSyllabusId(), syllabus.getVersion());
                return false;
            }
            
            auto transaction = db_connection_->createTransaction();
            
            // Update basic syllabus info
            std::string query = R"(
                UPDATE etr.syllabi SET
                    course_id = $1,
                    title = $2,
                    description = $3,
                    effective_date = $4,
                    expiration_date = $5,
                    status = $6,
                    author_id = $7,
                    updated_at = $8
                WHERE syllabus_id = $9 AND version = $10
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"course_id", syllabus.getCourseId(), persistence::PgParamType::TEXT, false});
            params.push_back({"title", syllabus.getTitle(), persistence::PgParamType::TEXT, false});
            params.push_back({"description", syllabus.getDescription(), persistence::PgParamType::TEXT, false});
            
            auto effective_date = std::chrono::duration_cast<std::chrono::milliseconds>(
                syllabus.getEffectiveDate().time_since_epoch()).count();
            params.push_back({"effective_date", std::to_string(effective_date), persistence::PgParamType::TIMESTAMP, false});
            
            if (syllabus.getExpirationDate()) {
                auto expiration_date = std::chrono::duration_cast<std::chrono::milliseconds>(
                    syllabus.getExpirationDate()->time_since_epoch()).count();
                params.push_back({"expiration_date", std::to_string(expiration_date), persistence::PgParamType::TIMESTAMP, false});
            } else {
                params.push_back({"expiration_date", "", persistence::PgParamType::TIMESTAMP, true});
            }
            
            params.push_back({"status", syllabusStatusToString(syllabus.getStatus()), persistence::PgParamType::TEXT, false});
            params.push_back({"author_id", syllabus.getAuthorId(), persistence::PgParamType::TEXT, false});
            
            auto updated_at = std::chrono::duration_cast<std::chrono::milliseconds>(
                syllabus.getUpdatedAt().time_since_epoch()).count();
            params.push_back({"updated_at", std::to_string(updated_at), persistence::PgParamType::TIMESTAMP, false});
            
            params.push_back({"syllabus_id", syllabus.getSyllabusId(), persistence::PgParamType::TEXT, false});
            params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError() || result.getAffectedRows() == 0) {
                logging::Logger::getInstance().error("Failed to update syllabus: {}", 
                    result.hasError() ? result.getErrorMessage() : "No rows affected");
                transaction.rollback();
                return false;
            }
            
            // Update syllabus metadata
            // First delete existing metadata
            std::string delete_metadata_query = R"(
                DELETE FROM etr.syllabus_metadata
                WHERE syllabus_id = $1 AND version = $2
            )";
            
            std::vector<persistence::PgParam> delete_metadata_params;
            delete_metadata_params.push_back({"syllabus_id", syllabus.getSyllabusId(), persistence::PgParamType::TEXT, false});
            delete_metadata_params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
            
            auto delete_metadata_result = db_connection_->executeQuery(delete_metadata_query, delete_metadata_params);
            
            if (delete_metadata_result.hasError()) {
                logging::Logger::getInstance().error("Failed to delete syllabus metadata: {}", 
                    delete_metadata_result.getErrorMessage());
                transaction.rollback();
                return false;
            }
            
            // Then insert new metadata
            for (const auto& [key, value] : syllabus.getMetadata()) {
                std::string metadata_query = R"(
                    INSERT INTO etr.syllabus_metadata (
                        syllabus_id, version, key, value
                    ) VALUES (
                        $1, $2, $3, $4
                    )
                )";
                
                std::vector<persistence::PgParam> metadata_params;
                metadata_params.push_back({"syllabus_id", syllabus.getSyllabusId(), persistence::PgParamType::TEXT, false});
                metadata_params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
                metadata_params.push_back({"key", key, persistence::PgParamType::TEXT, false});
                metadata_params.push_back({"value", value, persistence::PgParamType::TEXT, false});
                
                auto metadata_result = db_connection_->executeQuery(metadata_query, metadata_params);
                
                if (metadata_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert syllabus metadata: {}", 
                        metadata_result.getErrorMessage());
                    transaction.rollback();
                    return false;
                }
            }
            
            // Update signature if available
            if (syllabus.getApprovalSignature()) {
                // First delete existing signature
                std::string delete_signature_query = R"(
                    DELETE FROM etr.syllabus_signatures
                    WHERE syllabus_id = $1 AND version = $2
                )";
                
                std::vector<persistence::PgParam> delete_signature_params;
                delete_signature_params.push_back({"syllabus_id", syllabus.getSyllabusId(), persistence::PgParamType::TEXT, false});
                delete_signature_params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
                
                auto delete_signature_result = db_connection_->executeQuery(delete_signature_query, delete_signature_params);
                
                if (delete_signature_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to delete syllabus signature: {}", 
                        delete_signature_result.getErrorMessage());
                    transaction.rollback();
                    return false;
                }
                
                // Then insert new signature
                const auto& signature = *syllabus.getApprovalSignature();
                
                std::string signature_query = R"(
                    INSERT INTO etr.syllabus_signatures (
                        syllabus_id, version, signer_id, signer_name, 
                        certificate_id, signature_data, timestamp, is_valid
                    ) VALUES (
                        $1, $2, $3, $4, $5, $6, $7, $8
                    )
                )";
                
                std::vector<persistence::PgParam> signature_params;
                signature_params.push_back({"syllabus_id", syllabus.getSyllabusId(), persistence::PgParamType::TEXT, false});
                signature_params.push_back({"version", syllabus.getVersion(), persistence::PgParamType::TEXT, false});
                signature_params.push_back({"signer_id", signature.signer_id, persistence::PgParamType::TEXT, false});
                signature_params.push_back({"signer_name", signature.signer_name, persistence::PgParamType::TEXT, false});
                
                if (!signature.certificate_id.empty()) {
                    signature_params.push_back({"certificate_id", signature.certificate_id, persistence::PgParamType::TEXT, false});
                } else {
                    signature_params.push_back({"certificate_id", "", persistence::PgParamType::TEXT, true});
                }
                
                std::string signature_data(reinterpret_cast<const char*>(signature.signature_data.data()), 
                                          signature.signature_data.size());
                signature_params.push_back({"signature_data", signature_data, persistence::PgParamType::BYTEA, false});
                
                auto timestamp = std::chrono::duration_cast<std::chrono::milliseconds>(
                    signature.timestamp.time_since_epoch()).count();
                signature_params.push_back({"timestamp", std::to_string(timestamp), persistence::PgParamType::TIMESTAMP, false});
                
                signature_params.push_back({"is_valid", signature.is_valid ? "true" : "false", persistence::PgParamType::BOOLEAN, false});
                
                auto signature_result = db_connection_->executeQuery(signature_query, signature_params);
                
                if (signature_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert syllabus signature: {}", 
                        signature_result.getErrorMessage());
                    transaction.rollback();
                    return false;
                }
            }
            
            // Update sections
            // First delete existing sections and all related data (cascade)
            if (!deleteSyllabusSection(transaction, syllabus.getSyllabusId(), syllabus.getVersion())) {
                transaction.rollback();
                return false;
            }
            
            // Then insert new sections
            for (const auto& section : syllabus.getSections()) {
                if (!insertSection(transaction, syllabus.getSyllabusId(), syllabus.getVersion(), section)) {
                    transaction.rollback();
                    return false;
                }
            }
            
            // Commit transaction
            if (!transaction.commit()) {
                logging::Logger::getInstance().error("Failed to commit syllabus update transaction");
                return false;
            }
            
            logging::Logger::getInstance().info("Updated syllabus: {}, version: {}", 
                syllabus.getSyllabusId(), syllabus.getVersion());
            
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error updating syllabus: {}", e.what());
            return false;
        }
    }
    
    bool deleteSyllabus(const std::string& syllabus_id) override {
        try {
            // Delete syllabus and all related data (cascade)
            std::string query = R"(
                DELETE FROM etr.syllabi
                WHERE syllabus_id = $1
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to delete syllabus: {}", result.getErrorMessage());
                return false;
            }
            
            logging::Logger::getInstance().info("Deleted syllabus: {}", syllabus_id);
            
            return result.getAffectedRows() > 0;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error deleting syllabus: {}", e.what());
            return false;
        }
    }
    
    std::pair<std::vector<SyllabusSummary>, int> listSyllabi(
        const std::optional<std::string>& course_id,
        const std::optional<SyllabusStatus>& status,
        const std::optional<std::chrono::system_clock::time_point>& effective_date,
        int page,
        int page_size,
        const std::string& sort_by,
        bool ascending
    ) override {
        try {
            // Build query
            std::string query = R"(
                SELECT 
                    syllabus_id, course_id, title, version, 
                    effective_date, expiration_date, status, author_id, 
                    created_at, updated_at,
                    COUNT(*) OVER() AS total_count
                FROM etr.syllabi
                WHERE 1=1
            )";
            
            std::vector<persistence::PgParam> params;
            int param_index = 1;
            
            if (course_id) {
                query += " AND course_id = $" + std::to_string(param_index++);
                params.push_back({"course_id", *course_id, persistence::PgParamType::TEXT, false});
            }
            
            if (status) {
                query += " AND status = $" + std::to_string(param_index++);
                params.push_back({"status", syllabusStatusToString(*status), persistence::PgParamType::TEXT, false});
            }
            
            if (effective_date) {
                query += " AND effective_date <= $" + std::to_string(param_index++);
                auto effective_date_ms = std::chrono::duration_cast<std::chrono::milliseconds>(
                    effective_date->time_since_epoch()).count();
                params.push_back({"effective_date", std::to_string(effective_date_ms), 
                                  persistence::PgParamType::TIMESTAMP, false});
            }
            
            // Determine sort column
            std::string sort_column;
            if (sort_by == "title") {
                sort_column = "title";
            } else if (sort_by == "version") {
                sort_column = "version";
            } else if (sort_by == "created_at") {
                sort_column = "created_at";
            } else if (sort_by == "updated_at") {
                sort_column = "updated_at";
            } else {
                sort_column = "effective_date";
            }
            
            query += " ORDER BY " + sort_column + (ascending ? " ASC" : " DESC");
            query += " LIMIT $" + std::to_string(param_index++) + " OFFSET $" + std::to_string(param_index++);
            
            params.push_back({"limit", std::to_string(page_size), persistence::PgParamType::INTEGER, false});
            params.push_back({"offset", std::to_string((page - 1) * page_size), persistence::PgParamType::INTEGER, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to list syllabi: {}", result.getErrorMessage());
                return {{}, 0};
            }
            
            std::vector<SyllabusSummary> summaries;
            int total_count = 0;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                SyllabusSummary summary;
                summary.syllabus_id = result.getString(i, "syllabus_id");
                summary.course_id = result.getString(i, "course_id");
                summary.title = result.getString(i, "title");
                summary.version = result.getString(i, "version");
                
                auto effective_date = result.getTimestamp(i, "effective_date");
                if (effective_date) {
                    summary.effective_date = *effective_date;
                }
                
                auto expiration_date = result.getTimestamp(i, "expiration_date");
                if (expiration_date) {
                    summary.expiration_date = *expiration_date;
                }
                
                summary.status = syllabusStatusFromString(result.getString(i, "status"));
                summary.author_id = result.getString(i, "author_id");
                
                auto created_at = result.getTimestamp(i, "created_at");
                if (created_at) {
                    summary.created_at = *created_at;
                }
                
                auto updated_at = result.getTimestamp(i, "updated_at");
                if (updated_at) {
                    summary.updated_at = *updated_at;
                }
                
                summaries.push_back(summary);
                
                // Get total count from first row
                if (i == 0) {
                    total_count = result.getInt(i, "total_count");
                }
            }
            
            logging::Logger::getInstance().debug("Listed {} syllabi (total: {})", summaries.size(), total_count);
            
            return {summaries, total_count};
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error listing syllabi: {}", e.what());
            return {{}, 0};
        }
    }
    
    std::vector<SyllabusChange> trackChanges(
        const std::string& syllabus_id,
        const std::string& from_version,
        const std::string& to_version
    ) override {
        try {
            // Get changes from the database
            std::string query = R"(
                SELECT 
                    id, change_type, element_type, element_id, parent_id,
                    description, rationale, author_id, timestamp
                FROM etr.syllabus_changes
                WHERE syllabus_id = $1 AND from_version = $2 AND to_version = $3
                ORDER BY timestamp ASC
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            params.push_back({"from_version", from_version, persistence::PgParamType::TEXT, false});
            params.push_back({"to_version", to_version, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get syllabus changes: {}", result.getErrorMessage());
                return {};
            }
            
            std::vector<SyllabusChange> changes;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                SyllabusChange change;
                change.change_type = changeTypeFromString(result.getString(i, "change_type"));
                change.element_type = elementTypeFromString(result.getString(i, "element_type"));
                change.element_id = result.getString(i, "element_id");
                
                if (!result.isNull(i, "parent_id")) {
                    change.parent_id = result.getString(i, "parent_id");
                }
                
                change.description = result.getString(i, "description");
                change.rationale = result.getString(i, "rationale");
                change.author_id = result.getString(i, "author_id");
                
                auto timestamp = result.getTimestamp(i, "timestamp");
                if (timestamp) {
                    change.timestamp = *timestamp;
                }
                
                // Get change values
                int change_id = result.getInt(i, "id");
                
                std::string values_query = R"(
                    SELECT key, old_value, new_value
                    FROM etr.syllabus_change_values
                    WHERE change_id = $1
                )";
                
                std::vector<persistence::PgParam> values_params;
                values_params.push_back({"change_id", std::to_string(change_id), persistence::PgParamType::INTEGER, false});
                
                auto values_result = db_connection_->executeQuery(values_query, values_params);
                
                if (!values_result.hasError()) {
                    for (int j = 0; j < values_result.getNumRows(); ++j) {
                        std::string key = values_result.getString(j, "key");
                        
                        if (!values_result.isNull(j, "old_value")) {
                            change.old_values[key] = values_result.getString(j, "old_value");
                        }
                        
                        if (!values_result.isNull(j, "new_value")) {
                            change.new_values[key] = values_result.getString(j, "new_value");
                        }
                    }
                }
                
                changes.push_back(change);
            }
            
            logging::Logger::getInstance().debug("Tracked {} changes between versions {} and {} of syllabus {}", 
                changes.size(), from_version, to_version, syllabus_id);
            
            return changes;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error tracking syllabus changes: {}", e.what());
            return {};
        }
    }
    
    bool logChange(
        const std::string& syllabus_id,
        const SyllabusChange& change
    ) override {
        try {
            auto transaction = db_connection_->createTransaction();
            
            // Insert change
            std::string query = R"(
                INSERT INTO etr.syllabus_changes (
                    syllabus_id, from_version, to_version, change_type, 
                    element_type, element_id, parent_id, description, 
                    rationale, author_id, timestamp
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11
                ) RETURNING id
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            params.push_back({"from_version", change.old_values.at("version"), persistence::PgParamType::TEXT, false});
            params.push_back({"to_version", change.new_values.at("version"), persistence::PgParamType::TEXT, false});
            params.push_back({"change_type", changeTypeToString(change.change_type), persistence::PgParamType::TEXT, false});
            params.push_back({"element_type", elementTypeToString(change.element_type), persistence::PgParamType::TEXT, false});
            params.push_back({"element_id", change.element_id, persistence::PgParamType::TEXT, false});
            
            if (change.parent_id) {
                params.push_back({"parent_id", *change.parent_id, persistence::PgParamType::TEXT, false});
            } else {
                params.push_back({"parent_id", "", persistence::PgParamType::TEXT, true});
            }
            
            params.push_back({"description", change.description, persistence::PgParamType::TEXT, false});
            params.push_back({"rationale", change.rationale, persistence::PgParamType::TEXT, false});
            params.push_back({"author_id", change.author_id, persistence::PgParamType::TEXT, false});
            
            auto timestamp = std::chrono::duration_cast<std::chrono::milliseconds>(
                change.timestamp.time_since_epoch()).count();
            params.push_back({"timestamp", std::to_string(timestamp), persistence::PgParamType::TIMESTAMP, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                logging::Logger::getInstance().error("Failed to insert syllabus change: {}", 
                    result.hasError() ? result.getErrorMessage() : "No rows affected");
                transaction.rollback();
                return false;
            }
            
            int change_id = result.getInt(0, 0);
            
            // Insert change values
            for (const auto& [key, value] : change.old_values) {
                std::string values_query = R"(
                    INSERT INTO etr.syllabus_change_values (
                        change_id, key, old_value, new_value
                    ) VALUES (
                        $1, $2, $3, $4
                    )
                )";
                
                std::vector<persistence::PgParam> values_params;
                values_params.push_back({"change_id", std::to_string(change_id), persistence::PgParamType::INTEGER, false});
                values_params.push_back({"key", key, persistence::PgParamType::TEXT, false});
                values_params.push_back({"old_value", value, persistence::PgParamType::TEXT, false});
                
                std::string new_value;
                if (change.new_values.find(key) != change.new_values.end()) {
                    new_value = change.new_values.at(key);
                    values_params.push_back({"new_value", new_value, persistence::PgParamType::TEXT, false});
                } else {
                    values_params.push_back({"new_value", "", persistence::PgParamType::TEXT, true});
                }
                
                auto values_result = db_connection_->executeQuery(values_query, values_params);
                
                if (values_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert syllabus change value: {}", 
                        values_result.getErrorMessage());
                    transaction.rollback();
                    return false;
                }
            }
            
            // Insert new values that weren't in old values
            for (const auto& [key, value] : change.new_values) {
                if (change.old_values.find(key) == change.old_values.end()) {
                    std::string values_query = R"(
                        INSERT INTO etr.syllabus_change_values (
                            change_id, key, old_value, new_value
                        ) VALUES (
                            $1, $2, $3, $4
                        )
                    )";
                    
                    std::vector<persistence::PgParam> values_params;
                    values_params.push_back({"change_id", std::to_string(change_id), persistence::PgParamType::INTEGER, false});
                    values_params.push_back({"key", key, persistence::PgParamType::TEXT, false});
                    values_params.push_back({"old_value", "", persistence::PgParamType::TEXT, true});
                    values_params.push_back({"new_value", value, persistence::PgParamType::TEXT, false});
                    
                    auto values_result = db_connection_->executeQuery(values_query, values_params);
                    
                    if (values_result.hasError()) {
                        logging::Logger::getInstance().error("Failed to insert syllabus change value: {}", 
                            values_result.getErrorMessage());
                        transaction.rollback();
                        return false;
                    }
                }
            }
            
            // Commit transaction
            if (!transaction.commit()) {
                logging::Logger::getInstance().error("Failed to commit syllabus change transaction");
                return false;
            }
            
            logging::Logger::getInstance().info("Logged change for syllabus {}: {} {} {}", 
                syllabus_id, changeTypeToString(change.change_type), 
                elementTypeToString(change.element_type), change.element_id);
            
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error logging syllabus change: {}", e.what());
            return false;
        }
    }
    
    std::vector<std::string> getAllVersions(const std::string& syllabus_id) override {
        try {
            std::string query = R"(
                SELECT version
                FROM etr.syllabi
                WHERE syllabus_id = $1
                ORDER BY effective_date ASC
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get syllabus versions: {}", result.getErrorMessage());
                return {};
            }
            
            std::vector<std::string> versions;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                versions.push_back(result.getString(i, "version"));
            }
            
            logging::Logger::getInstance().debug("Retrieved {} versions for syllabus {}", versions.size(), syllabus_id);
            
            return versions;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting syllabus versions: {}", e.what());
            return {};
        }
    }
    
    std::optional<Syllabus> getLatestApprovedSyllabus(const std::string& course_id) override {
        try {
            std::string query = R"(
                SELECT syllabus_id, version
                FROM etr.syllabi
                WHERE course_id = $1 AND status = $2
                ORDER BY effective_date DESC
                LIMIT 1
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"course_id", course_id, persistence::PgParamType::TEXT, false});
            params.push_back({"status", syllabusStatusToString(SyllabusStatus::APPROVED), 
                             persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                if (result.hasError()) {
                    logging::Logger::getInstance().error("Failed to get latest approved syllabus: {}", 
                        result.getErrorMessage());
                }
                return std::nullopt;
            }
            
            std::string syllabus_id = result.getString(0, "syllabus_id");
            std::string version = result.getString(0, "version");
            
            return getSyllabus(syllabus_id, version);
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting latest approved syllabus: {}", e.what());
            return std::nullopt;
        }
    }

private:
    bool insertSection(
        persistence::Transaction& transaction,
        const std::string& syllabus_id,
        const std::string& version,
        const SyllabusSection& section
    ) {
        try {
            // Generate section ID if not provided
            std::string section_id = section.section_id;
            if (section_id.empty()) {
                section_id = generateUniqueId();
            }
            
            // Insert section
            std::string query = R"(
                INSERT INTO etr.syllabus_sections (
                    section_id, syllabus_id, version, title, 
                    description, section_order
                ) VALUES (
                    $1, $2, $3, $4, $5, $6
                ) RETURNING section_id
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"section_id", section_id, persistence::PgParamType::TEXT, false});
            params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            params.push_back({"version", version, persistence::PgParamType::TEXT, false});
            params.push_back({"title", section.title, persistence::PgParamType::TEXT, false});
            params.push_back({"description", section.description, persistence::PgParamType::TEXT, false});
            params.push_back({"section_order", std::to_string(section.order), persistence::PgParamType::INTEGER, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                logging::Logger::getInstance().error("Failed to insert syllabus section: {}", 
                    result.hasError() ? result.getErrorMessage() : "No rows affected");
                return false;
            }
            
            // Insert exercises
            for (const auto& exercise : section.exercises) {
                if (!insertExercise(transaction, section_id, exercise)) {
                    return false;
                }
            }
            
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error inserting syllabus section: {}", e.what());
            return false;
        }
    }
    
    bool insertExercise(
        persistence::Transaction& transaction,
        const std::string& section_id,
        const SyllabusExercise& exercise
    ) {
        try {
            // Generate exercise ID if not provided
            std::string exercise_id = exercise.exercise_id;
            if (exercise_id.empty()) {
                exercise_id = generateUniqueId();
            }
            
            // Insert exercise
            std::string query = R"(
                INSERT INTO etr.syllabus_exercises (
                    exercise_id, section_id, title, description, 
                    exercise_order, duration_minutes, exercise_type
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7
                ) RETURNING exercise_id
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
            params.push_back({"section_id", section_id, persistence::PgParamType::TEXT, false});
            params.push_back({"title", exercise.title, persistence::PgParamType::TEXT, false});
            params.push_back({"description", exercise.description, persistence::PgParamType::TEXT, false});
            params.push_back({"exercise_order", std::to_string(exercise.order), persistence::PgParamType::INTEGER, false});
            params.push_back({"duration_minutes", std::to_string(exercise.duration_minutes), 
                             persistence::PgParamType::INTEGER, false});
            params.push_back({"exercise_type", exercise.exercise_type, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                logging::Logger::getInstance().error("Failed to insert syllabus exercise: {}", 
                    result.hasError() ? result.getErrorMessage() : "No rows affected");
                return false;
            }
            
            // Insert objectives
            for (size_t i = 0; i < exercise.objectives.size(); ++i) {
                std::string objective_query = R"(
                    INSERT INTO etr.exercise_objectives (
                        exercise_id, objective, objective_order
                    ) VALUES (
                        $1, $2, $3
                    )
                )";
                
                std::vector<persistence::PgParam> objective_params;
                objective_params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
                objective_params.push_back({"objective", exercise.objectives[i], persistence::PgParamType::TEXT, false});
                objective_params.push_back({"objective_order", std::to_string(i + 1), persistence::PgParamType::INTEGER, false});
                
                auto objective_result = db_connection_->executeQuery(objective_query, objective_params);
                
                if (objective_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert exercise objective: {}", 
                        objective_result.getErrorMessage());
                    return false;
                }
            }
            
            // Insert references
            for (size_t i = 0; i < exercise.references.size(); ++i) {
                std::string reference_query = R"(
                    INSERT INTO etr.exercise_references (
                        exercise_id, reference, reference_order
                    ) VALUES (
                        $1, $2, $3
                    )
                )";
                
                std::vector<persistence::PgParam> reference_params;
                reference_params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
                reference_params.push_back({"reference", exercise.references[i], persistence::PgParamType::TEXT, false});
                reference_params.push_back({"reference_order", std::to_string(i + 1), persistence::PgParamType::INTEGER, false});
                
                auto reference_result = db_connection_->executeQuery(reference_query, reference_params);
                
                if (reference_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert exercise reference: {}", 
                        reference_result.getErrorMessage());
                    return false;
                }
            }
            
            // Insert equipment
            for (size_t i = 0; i < exercise.equipment.size(); ++i) {
                std::string equipment_query = R"(
                    INSERT INTO etr.exercise_equipment (
                        exercise_id, equipment, equipment_order
                    ) VALUES (
                        $1, $2, $3
                    )
                )";
                
                std::vector<persistence::PgParam> equipment_params;
                equipment_params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
                equipment_params.push_back({"equipment", exercise.equipment[i], persistence::PgParamType::TEXT, false});
                equipment_params.push_back({"equipment_order", std::to_string(i + 1), persistence::PgParamType::INTEGER, false});
                
                auto equipment_result = db_connection_->executeQuery(equipment_query, equipment_params);
                
                if (equipment_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert exercise equipment: {}", 
                        equipment_result.getErrorMessage());
                    return false;
                }
            }
            
            // Insert prerequisites
            for (const auto& prerequisite : exercise.prerequisite_exercises) {
                std::string prerequisite_query = R"(
                    INSERT INTO etr.exercise_prerequisites (
                        exercise_id, prerequisite_exercise_id
                    ) VALUES (
                        $1, $2
                    )
                )";
                
                std::vector<persistence::PgParam> prerequisite_params;
                prerequisite_params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
                prerequisite_params.push_back({"prerequisite_exercise_id", prerequisite, 
                                             persistence::PgParamType::TEXT, false});
                
                auto prerequisite_result = db_connection_->executeQuery(prerequisite_query, prerequisite_params);
                
                if (prerequisite_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert exercise prerequisite: {}", 
                        prerequisite_result.getErrorMessage());
                    return false;
                }
            }
            
            // Insert metadata
            for (const auto& [key, value] : exercise.metadata) {
                std::string metadata_query = R"(
                    INSERT INTO etr.exercise_metadata (
                        exercise_id, key, value
                    ) VALUES (
                        $1, $2, $3
                    )
                )";
                
                std::vector<persistence::PgParam> metadata_params;
                metadata_params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
                metadata_params.push_back({"key", key, persistence::PgParamType::TEXT, false});
                metadata_params.push_back({"value", value, persistence::PgParamType::TEXT, false});
                
                auto metadata_result = db_connection_->executeQuery(metadata_query, metadata_params);
                
                if (metadata_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert exercise metadata: {}", 
                        metadata_result.getErrorMessage());
                    return false;
                }
            }
            
            // Insert grading criteria
            for (const auto& criteria : exercise.grading_criteria) {
                if (!insertGradingCriteria(transaction, exercise_id, criteria)) {
                    return false;
                }
            }
            
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error inserting syllabus exercise: {}", e.what());
            return false;
        }
    }
    
    bool insertGradingCriteria(
        persistence::Transaction& transaction,
        const std::string& exercise_id,
        const GradingCriteria& criteria
    ) {
        try {
            // Generate criteria ID if not provided
            std::string criteria_id = criteria.criteria_id;
            if (criteria_id.empty()) {
                criteria_id = generateUniqueId();
            }
            
            // Insert criteria
            std::string query = R"(
                INSERT INTO etr.grading_criteria (
                    criteria_id, exercise_id, name, description, is_required
                ) VALUES (
                    $1, $2, $3, $4, $5
                ) RETURNING criteria_id
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"criteria_id", criteria_id, persistence::PgParamType::TEXT, false});
            params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
            params.push_back({"name", criteria.name, persistence::PgParamType::TEXT, false});
            params.push_back({"description", criteria.description, persistence::PgParamType::TEXT, false});
            params.push_back({"is_required", criteria.is_required ? "true" : "false", 
                             persistence::PgParamType::BOOLEAN, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.isEmpty() || result.hasError()) {
                logging::Logger::getInstance().error("Failed to insert grading criteria: {}", 
                    result.hasError() ? result.getErrorMessage() : "No rows affected");
                return false;
            }
            
            // Insert regulation references
            for (const auto& [regulation_id, reference] : criteria.regulation_references) {
                std::string regulation_query = R"(
                    INSERT INTO etr.criteria_regulations (
                        criteria_id, regulation_id, regulation_reference
                    ) VALUES (
                        $1, $2, $3
                    )
                )";
                
                std::vector<persistence::PgParam> regulation_params;
                regulation_params.push_back({"criteria_id", criteria_id, persistence::PgParamType::TEXT, false});
                regulation_params.push_back({"regulation_id", regulation_id, persistence::PgParamType::TEXT, false});
                regulation_params.push_back({"regulation_reference", reference, persistence::PgParamType::TEXT, false});
                
                auto regulation_result = db_connection_->executeQuery(regulation_query, regulation_params);
                
                if (regulation_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert criteria regulation: {}", 
                        regulation_result.getErrorMessage());
                    return false;
                }
            }
            
            // Insert grade definitions
            for (const auto& grade_def : criteria.grade_definitions) {
                std::string grade_query = R"(
                    INSERT INTO etr.grade_definitions (
                        criteria_id, grade, description, is_passing
                    ) VALUES (
                        $1, $2, $3, $4
                    )
                )";
                
                std::vector<persistence::PgParam> grade_params;
                grade_params.push_back({"criteria_id", criteria_id, persistence::PgParamType::TEXT, false});
                grade_params.push_back({"grade", std::to_string(grade_def.grade), persistence::PgParamType::INTEGER, false});
                grade_params.push_back({"description", grade_def.description, persistence::PgParamType::TEXT, false});
                grade_params.push_back({"is_passing", grade_def.is_passing ? "true" : "false", 
                                      persistence::PgParamType::BOOLEAN, false});
                
                auto grade_result = db_connection_->executeQuery(grade_query, grade_params);
                
                if (grade_result.hasError()) {
                    logging::Logger::getInstance().error("Failed to insert grade definition: {}", 
                        grade_result.getErrorMessage());
                    return false;
                }
            }
            
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error inserting grading criteria: {}", e.what());
            return false;
        }
    }
    
    bool deleteSyllabusSection(
        persistence::Transaction& transaction,
        const std::string& syllabus_id,
        const std::string& version
    ) {
        try {
            std::string query = R"(
                DELETE FROM etr.syllabus_sections
                WHERE syllabus_id = $1 AND version = $2
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            params.push_back({"version", version, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to delete syllabus sections: {}", 
                    result.getErrorMessage());
                return false;
            }
            
            return true;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error deleting syllabus sections: {}", e.what());
            return false;
        }
    }
    
    std::vector<SyllabusSection> getSyllabusSection(
        const std::string& syllabus_id,
        const std::string& version
    ) {
        try {
            std::string query = R"(
                SELECT 
                    section_id, title, description, section_order
                FROM etr.syllabus_sections
                WHERE syllabus_id = $1 AND version = $2
                ORDER BY section_order ASC
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"syllabus_id", syllabus_id, persistence::PgParamType::TEXT, false});
            params.push_back({"version", version, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get syllabus sections: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::vector<SyllabusSection> sections;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                SyllabusSection section;
                section.section_id = result.getString(i, "section_id");
                section.title = result.getString(i, "title");
                section.description = result.getString(i, "description");
                section.order = result.getInt(i, "section_order");
                
                // Get exercises for this section
                section.exercises = getExercises(section.section_id);
                
                sections.push_back(section);
            }
            
            return sections;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting syllabus sections: {}", e.what());
            return {};
        }
    }
    
    std::vector<SyllabusExercise> getExercises(const std::string& section_id) {
        try {
            std::string query = R"(
                SELECT 
                    exercise_id, title, description, exercise_order, 
                    duration_minutes, exercise_type
                FROM etr.syllabus_exercises
                WHERE section_id = $1
                ORDER BY exercise_order ASC
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"section_id", section_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get exercises: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::vector<SyllabusExercise> exercises;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                SyllabusExercise exercise;
                exercise.exercise_id = result.getString(i, "exercise_id");
                exercise.title = result.getString(i, "title");
                exercise.description = result.getString(i, "description");
                exercise.order = result.getInt(i, "exercise_order");
                exercise.duration_minutes = result.getInt(i, "duration_minutes");
                exercise.exercise_type = result.getString(i, "exercise_type");
                
                // Get objectives
                exercise.objectives = getExerciseObjectives(exercise.exercise_id);
                
                // Get references
                exercise.references = getExerciseReferences(exercise.exercise_id);
                
                // Get equipment
                exercise.equipment = getExerciseEquipment(exercise.exercise_id);
                
                // Get prerequisites
                exercise.prerequisite_exercises = getExercisePrerequisites(exercise.exercise_id);
                
                // Get metadata
                exercise.metadata = getExerciseMetadata(exercise.exercise_id);
                
                // Get grading criteria
                exercise.grading_criteria = getGradingCriteria(exercise.exercise_id);
                
                exercises.push_back(exercise);
            }
            
            return exercises;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting exercises: {}", e.what());
            return {};
        }
    }
    
    std::vector<std::string> getExerciseObjectives(const std::string& exercise_id) {
        try {
            std::string query = R"(
                SELECT objective
                FROM etr.exercise_objectives
                WHERE exercise_id = $1
                ORDER BY objective_order ASC
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get exercise objectives: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::vector<std::string> objectives;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                objectives.push_back(result.getString(i, "objective"));
            }
            
            return objectives;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting exercise objectives: {}", e.what());
            return {};
        }
    }
    
    std::vector<std::string> getExerciseReferences(const std::string& exercise_id) {
        try {
            std::string query = R"(
                SELECT reference
                FROM etr.exercise_references
                WHERE exercise_id = $1
                ORDER BY reference_order ASC
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get exercise references: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::vector<std::string> references;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                references.push_back(result.getString(i, "reference"));
            }
            
            return references;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting exercise references: {}", e.what());
            return {};
        }
    }
    
    std::vector<std::string> getExerciseEquipment(const std::string& exercise_id) {
        try {
            std::string query = R"(
                SELECT equipment
                FROM etr.exercise_equipment
                WHERE exercise_id = $1
                ORDER BY equipment_order ASC
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get exercise equipment: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::vector<std::string> equipment;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                equipment.push_back(result.getString(i, "equipment"));
            }
            
            return equipment;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting exercise equipment: {}", e.what());
            return {};
        }
    }
    
    std::vector<std::string> getExercisePrerequisites(const std::string& exercise_id) {
        try {
            std::string query = R"(
                SELECT prerequisite_exercise_id
                FROM etr.exercise_prerequisites
                WHERE exercise_id = $1
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get exercise prerequisites: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::vector<std::string> prerequisites;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                prerequisites.push_back(result.getString(i, "prerequisite_exercise_id"));
            }
            
            return prerequisites;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting exercise prerequisites: {}", e.what());
            return {};
        }
    }
    
    std::map<std::string, std::string> getExerciseMetadata(const std::string& exercise_id) {
        try {
            std::string query = R"(
                SELECT key, value
                FROM etr.exercise_metadata
                WHERE exercise_id = $1
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get exercise metadata: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::map<std::string, std::string> metadata;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                metadata[result.getString(i, "key")] = result.getString(i, "value");
            }
            
            return metadata;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting exercise metadata: {}", e.what());
            return {};
        }
    }
    
    std::vector<GradingCriteria> getGradingCriteria(const std::string& exercise_id) {
        try {
            std::string query = R"(
                SELECT 
                    criteria_id, name, description, is_required
                FROM etr.grading_criteria
                WHERE exercise_id = $1
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"exercise_id", exercise_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get grading criteria: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::vector<GradingCriteria> criteria;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                GradingCriteria criterion;
                criterion.criteria_id = result.getString(i, "criteria_id");
                criterion.name = result.getString(i, "name");
                criterion.description = result.getString(i, "description");
                criterion.is_required = result.getBool(i, "is_required");
                
                // Get regulation references
                criterion.regulation_references = getCriteriaRegulations(criterion.criteria_id);
                
                // Get grade definitions
                criterion.grade_definitions = getGradeDefinitions(criterion.criteria_id);
                
                criteria.push_back(criterion);
            }
            
            return criteria;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting grading criteria: {}", e.what());
            return {};
        }
    }
    
    std::map<std::string, std::string> getCriteriaRegulations(const std::string& criteria_id) {
        try {
            std::string query = R"(
                SELECT regulation_id, regulation_reference
                FROM etr.criteria_regulations
                WHERE criteria_id = $1
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"criteria_id", criteria_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get criteria regulations: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::map<std::string, std::string> regulations;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                regulations[result.getString(i, "regulation_id")] = result.getString(i, "regulation_reference");
            }
            
            return regulations;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting criteria regulations: {}", e.what());
            return {};
        }
    }
    
    std::vector<GradeDefinition> getGradeDefinitions(const std::string& criteria_id) {
        try {
            std::string query = R"(
                SELECT 
                    grade, description, is_passing
                FROM etr.grade_definitions
                WHERE criteria_id = $1
                ORDER BY grade ASC
            )";
            
            std::vector<persistence::PgParam> params;
            params.push_back({"criteria_id", criteria_id, persistence::PgParamType::TEXT, false});
            
            auto result = db_connection_->executeQuery(query, params);
            
            if (result.hasError()) {
                logging::Logger::getInstance().error("Failed to get grade definitions: {}", 
                    result.getErrorMessage());
                return {};
            }
            
            std::vector<GradeDefinition> definitions;
            
            for (int i = 0; i < result.getNumRows(); ++i) {
                GradeDefinition definition;
                definition.grade = result.getInt(i, "grade");
                definition.description = result.getString(i, "description");
                definition.is_passing = result.getBool(i, "is_passing");
                
                definitions.push_back(definition);
            }
            
            return definitions;
        }
        catch (const std::exception& e) {
            logging::Logger::getInstance().error("Error getting grade definitions: {}", e.what());
            return {};
        }
    }
    
    std::string generateUniqueId() {
        uuids::uuid uuid = uuids::uuid_system_generator{}();
        return uuids::to_string(uuid);
    }
    
    std::shared_ptr<persistence::DatabaseConnection> db_connection_;
};

} // namespace syllabus
} // namespace etr
#pragma once

#include "syllabus/syllabus_service.h"
#include "persistence/database_connection.h"
#include <memory>
#include <mutex>

namespace etr {
namespace syllabus {

/**
 * @brief PostgreSQL syllabus repository implementation
 */
class SyllabusRepository : public ISyllabusRepository {
public:
    /**
     * @brief Constructor
     * @param db_connection Database connection
     */
    explicit SyllabusRepository(std::shared_ptr<persistence::DatabaseConnection> db_connection);
    
    /**
     * @brief Destructor
     */
    ~SyllabusRepository() override;
    
    // ISyllabusRepository implementation
    std::string createSyllabus(const Syllabus& syllabus) override;
    std::optional<Syllabus> getSyllabus(
        const std::string& syllabus_id,
        const std::optional<std::string>& version = std::nullopt
    ) override;
    bool updateSyllabus(const Syllabus& syllabus) override;
    bool deleteSyllabus(const std::string& syllabus_id) override;
    std::pair<std::vector<SyllabusSummary>, int> listSyllabi(
        const std::optional<std::string>& course_id,
        const std::optional<SyllabusStatus>& status,
        const std::optional<std::chrono::system_clock::time_point>& effective_date,
        int page,
        int page_size,
        const std::string& sort_by,
        bool ascending
    ) override;
    std::vector<SyllabusChange> trackChanges(
        const std::string& syllabus_id,
        const std::string& from_version,
        const std::string& to_version
    ) override;
    bool logChange(
        const std::string& syllabus_id,
        const SyllabusChange& change
    ) override;
    std::vector<std::string> getAllVersions(const std::string& syllabus_id) override;
    std::optional<Syllabus> getLatestApprovedSyllabus(const std::string& course_id) override;

private:
    /**
     * @brief Save syllabus sections
     * @param syllabus_id Syllabus ID
     * @param version Version
     * @param sections Sections
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveSections(
        const std::string& syllabus_id,
        const std::string& version,
        const std::vector<SyllabusSection>& sections,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get syllabus sections
     * @param syllabus_id Syllabus ID
     * @param version Version
     * @return Sections
     */
    std::vector<SyllabusSection> getSections(
        const std::string& syllabus_id,
        const std::string& version
    );
    
    /**
     * @brief Save exercises for a section
     * @param section_id Section ID
     * @param exercises Exercises
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveExercises(
        const std::string& section_id,
        const std::vector<SyllabusExercise>& exercises,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get exercises for a section
     * @param section_id Section ID
     * @return Exercises
     */
    std::vector<SyllabusExercise> getExercises(const std::string& section_id);
    
    /**
     * @brief Save exercise objectives
     * @param exercise_id Exercise ID
     * @param objectives Objectives
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveObjectives(
        const std::string& exercise_id,
        const std::vector<std::string>& objectives,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get exercise objectives
     * @param exercise_id Exercise ID
     * @return Objectives
     */
    std::vector<std::string> getObjectives(const std::string& exercise_id);
    
    /**
     * @brief Save exercise references
     * @param exercise_id Exercise ID
     * @param references References
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveReferences(
        const std::string& exercise_id,
        const std::vector<std::string>& references,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get exercise references
     * @param exercise_id Exercise ID
     * @return References
     */
    std::vector<std::string> getReferences(const std::string& exercise_id);
    
    /**
     * @brief Save exercise equipment
     * @param exercise_id Exercise ID
     * @param equipment Equipment
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveEquipment(
        const std::string& exercise_id,
        const std::vector<std::string>& equipment,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get exercise equipment
     * @param exercise_id Exercise ID
     * @return Equipment
     */
    std::vector<std::string> getEquipment(const std::string& exercise_id);
    
    /**
     * @brief Save exercise prerequisites
     * @param exercise_id Exercise ID
     * @param prerequisites Prerequisites
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool savePrerequisites(
        const std::string& exercise_id,
        const std::vector<std::string>& prerequisites,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get exercise prerequisites
     * @param exercise_id Exercise ID
     * @return Prerequisites
     */
    std::vector<std::string> getPrerequisites(const std::string& exercise_id);
    
    /**
     * @brief Save exercise metadata
     * @param exercise_id Exercise ID
     * @param metadata Metadata
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveExerciseMetadata(
        const std::string& exercise_id,
        const std::map<std::string, std::string>& metadata,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get exercise metadata
     * @param exercise_id Exercise ID
     * @return Metadata
     */
    std::map<std::string, std::string> getExerciseMetadata(const std::string& exercise_id);
    
    /**
     * @brief Save grading criteria
     * @param exercise_id Exercise ID
     * @param criteria Criteria
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveGradingCriteria(
        const std::string& exercise_id,
        const std::vector<GradingCriteria>& criteria,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get grading criteria
     * @param exercise_id Exercise ID
     * @return Criteria
     */
    std::vector<GradingCriteria> getGradingCriteria(const std::string& exercise_id);
    
    /**
     * @brief Save grade definitions
     * @param criteria_id Criteria ID
     * @param definitions Definitions
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveGradeDefinitions(
        const std::string& criteria_id,
        const std::vector<GradeDefinition>& definitions,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get grade definitions
     * @param criteria_id Criteria ID
     * @return Definitions
     */
    std::vector<GradeDefinition> getGradeDefinitions(const std::string& criteria_id);
    
    /**
     * @brief Save regulation references
     * @param criteria_id Criteria ID
     * @param references References
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveRegulationReferences(
        const std::string& criteria_id,
        const std::map<std::string, std::string>& references,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get regulation references
     * @param criteria_id Criteria ID
     * @return References
     */
    std::map<std::string, std::string> getRegulationReferences(const std::string& criteria_id);
    
    /**
     * @brief Save syllabus metadata
     * @param syllabus_id Syllabus ID
     * @param version Version
     * @param metadata Metadata
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveSyllabusMetadata(
        const std::string& syllabus_id,
        const std::string& version,
        const std::map<std::string, std::string>& metadata,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get syllabus metadata
     * @param syllabus_id Syllabus ID
     * @param version Version
     * @return Metadata
     */
    std::map<std::string, std::string> getSyllabusMetadata(
        const std::string& syllabus_id,
        const std::string& version
    );
    
    /**
     * @brief Save syllabus signature
     * @param syllabus_id Syllabus ID
     * @param version Version
     * @param signature Signature
     * @param transaction Transaction
     * @return True if saved successfully
     */
    bool saveSyllabusSignature(
        const std::string& syllabus_id,
        const std::string& version,
        const records::SignatureInfo& signature,
        persistence::Transaction& transaction
    );
    
    /**
     * @brief Get syllabus signature
     * @param syllabus_id Syllabus ID
     * @param version Version
     * @return Signature or nullopt if not found
     */
    std::optional<records::SignatureInfo> getSyllabusSignature(
        const std::string& syllabus_id,
        const std::string& version
    );
    
    /**
     * @brief Generate query parameters
     * @param course_id Course ID (optional)
     * @param status Status (optional)
     * @param effective_date Effective date (optional)
     * @return Pair of (query conditions, parameters)
     */
    std::pair<std::string, std::vector<persistence::PgParam>> generateQueryParams(
        const std::optional<std::string>& course_id,
        const std::optional<SyllabusStatus>& status,
        const std::optional<std::chrono::system_clock::time_point>& effective_date
    );
    
    /**
     * @brief Generate unique ID
     * @return Unique ID
     */
    std::string generateUniqueId();
    
    std::shared_ptr<persistence::DatabaseConnection> db_connection_;
};

} // namespace syllabus
} // namespace etr
#include "syllabus/syllabus_service.h"
#include "logging/logger.h"
#include <chrono>
#include <algorithm>
#include <sstream>
#include <uuid.h>

namespace etr {
namespace syllabus {

// Utility functions for conversions
std::string syllabusStatusToString(SyllabusStatus status) {
    switch (status) {
        case SyllabusStatus::DRAFT: return "DRAFT";
        case SyllabusStatus::APPROVED: return "APPROVED";
        case SyllabusStatus::ARCHIVED: return "ARCHIVED";
        default: return "UNKNOWN";
    }
}

SyllabusStatus syllabusStatusFromString(const std::string& str) {
    if (str == "DRAFT") return SyllabusStatus::DRAFT;
    if (str == "APPROVED") return SyllabusStatus::APPROVED;
    if (str == "ARCHIVED") return SyllabusStatus::ARCHIVED;
    return SyllabusStatus::DRAFT; // Default to DRAFT
}

std::string changeTypeToString(ChangeType type) {
    switch (type) {
        case ChangeType::ADDED: return "ADDED";
        case ChangeType::MODIFIED: return "MODIFIED";
        case ChangeType::REMOVED: return "REMOVED";
        default: return "UNKNOWN";
    }
}

ChangeType changeTypeFromString(const std::string& str) {
    if (str == "ADDED") return ChangeType::ADDED;
    if (str == "MODIFIED") return ChangeType::MODIFIED;
    if (str == "REMOVED") return ChangeType::REMOVED;
    return ChangeType::MODIFIED; // Default to MODIFIED
}

std::string elementTypeToString(ElementType type) {
    switch (type) {
        case ElementType::SYLLABUS: return "SYLLABUS";
        case ElementType::SECTION: return "SECTION";
        case ElementType::EXERCISE: return "EXERCISE";
        case ElementType::CRITERIA: return "CRITERIA";
        case ElementType::OBJECTIVE: return "OBJECTIVE";
        case ElementType::REFERENCE: return "REFERENCE";
        case ElementType::EQUIPMENT: return "EQUIPMENT";
        case ElementType::PREREQUISITE: return "PREREQUISITE";
        case ElementType::METADATA: return "METADATA";
        default: return "UNKNOWN";
    }
}

ElementType elementTypeFromString(const std::string& str) {
    if (str == "SYLLABUS") return ElementType::SYLLABUS;
    if (str == "SECTION") return ElementType::SECTION;
    if (str == "EXERCISE") return ElementType::EXERCISE;
    if (str == "CRITERIA") return ElementType::CRITERIA;
    if (str == "OBJECTIVE") return ElementType::OBJECTIVE;
    if (str == "REFERENCE") return ElementType::REFERENCE;
    if (str == "EQUIPMENT") return ElementType::EQUIPMENT;
    if (str == "PREREQUISITE") return ElementType::PREREQUISITE;
    if (str == "METADATA") return ElementType::METADATA;
    return ElementType::SYLLABUS; // Default to SYLLABUS
}

// SyllabusService implementation
SyllabusService::SyllabusService(
    std::shared_ptr<ISyllabusRepository> syllabus_repository,
    std::shared_ptr<signature::IDigitalSignatureService> signature_service
) : syllabus_repository_(std::move(syllabus_repository)),
    signature_service_(std::move(signature_service)) {
    
    logging::Logger::getInstance().info("SyllabusService initialized");
}

SyllabusService::~SyllabusService() = default;

std::string SyllabusService::createSyllabus(const Syllabus& syllabus) {
    try {
        // Validate syllabus
        if (syllabus.getTitle().empty() || syllabus.getCourseId().empty() || 
            syllabus.getAuthorId().empty() || syllabus.getVersion().empty()) {
            logging::Logger::getInstance().error("Invalid syllabus data: missing required fields");
            return "";
        }
        
        // Create a copy with appropriate timestamps
        Syllabus copy = syllabus;
        auto now = std::chrono::system_clock::now();
        
        if (copy.getCreatedAt() == std::chrono::system_clock::time_point()) {
            copy.setCreatedAt(now);
        }
        
        if (copy.getUpdatedAt() == std::chrono::system_clock::time_point()) {
            copy.setUpdatedAt(now);
        }
        
        // Ensure status is valid
        if (copy.getStatus() == SyllabusStatus::APPROVED && !copy.getApprovalSignature()) {
            copy.setStatus(SyllabusStatus::DRAFT);
            logging::Logger::getInstance().warn("Syllabus status set to DRAFT because it lacks approval signature");
        }
        
        // Create syllabus in repository
        std::string syllabus_id = syllabus_repository_->createSyllabus(copy);
        
        if (syllabus_id.empty()) {
            logging::Logger::getInstance().error("Failed to create syllabus");
            return "";
        }
        
        logging::Logger::getInstance().info("Created syllabus: {}, version: {}", 
            syllabus_id, copy.getVersion());
        
        return syllabus_id;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error creating syllabus: {}", e.what());
        return "";
    }
}

std::optional<Syllabus> SyllabusService::getSyllabus(
    const std::string& syllabus_id,
    const std::optional<std::string>& version
) {
    try {
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id, version);
        
        if (!syllabus) {
            logging::Logger::getInstance().debug("Syllabus not found: {}, version: {}", 
                syllabus_id, version ? *version : "latest");
            return std::nullopt;
        }
        
        logging::Logger::getInstance().debug("Retrieved syllabus: {}, version: {}", 
            syllabus_id, syllabus->getVersion());
        
        return syllabus;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error getting syllabus: {}", e.what());
        return std::nullopt;
    }
}

bool SyllabusService::updateSyllabus(const Syllabus& syllabus, const std::string& user_id) {
    try {
        // Check if user is authorized to modify syllabus
        if (!isAuthorizedToModify(syllabus, user_id)) {
            logging::Logger::getInstance().error("User {} not authorized to modify syllabus {}", 
                user_id, syllabus.getSyllabusId());
            return false;
        }
        
        // Get existing syllabus to calculate changes
        auto existing = syllabus_repository_->getSyllabus(
            syllabus.getSyllabusId(), syllabus.getVersion());
        
        if (!existing) {
            logging::Logger::getInstance().error("Syllabus not found for update: {}, version: {}", 
                syllabus.getSyllabusId(), syllabus.getVersion());
            return false;
        }
        
        // Create a copy with updated timestamp
        Syllabus copy = syllabus;
        copy.setUpdatedAt(std::chrono::system_clock::now());
        
        // Ensure status is valid
        if (copy.getStatus() == SyllabusStatus::APPROVED && !copy.getApprovalSignature()) {
            copy.setStatus(SyllabusStatus::DRAFT);
            logging::Logger::getInstance().warn("Syllabus status set to DRAFT because it lacks approval signature");
        }
        
        // Calculate changes
        auto changes = calculateChanges(*existing, copy, user_id);
        
        // Update syllabus
        bool success = syllabus_repository_->updateSyllabus(copy);
        
        if (!success) {
            logging::Logger::getInstance().error("Failed to update syllabus: {}, version: {}", 
                syllabus.getSyllabusId(), syllabus.getVersion());
            return false;
        }
        
        // Log changes
        for (const auto& change : changes) {
            syllabus_repository_->logChange(syllabus.getSyllabusId(), change);
        }
        
        logging::Logger::getInstance().info("Updated syllabus: {}, version: {}, with {} changes", 
            syllabus.getSyllabusId(), syllabus.getVersion(), changes.size());
        
        return true;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error updating syllabus: {}", e.what());
        return false;
    }
}

bool SyllabusService::deleteSyllabus(const std::string& syllabus_id, const std::string& user_id) {
    try {
        // Get syllabus to check authorization
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id);
        
        if (!syllabus) {
            logging::Logger::getInstance().error("Syllabus not found for deletion: {}", syllabus_id);
            return false;
        }
        
        // Check if user is authorized to modify syllabus
        if (!isAuthorizedToModify(*syllabus, user_id)) {
            logging::Logger::getInstance().error("User {} not authorized to delete syllabus {}", 
                user_id, syllabus_id);
            return false;
        }
        
        // Check if syllabus is approved
        if (syllabus->getStatus() == SyllabusStatus::APPROVED) {
            logging::Logger::getInstance().error("Cannot delete approved syllabus: {}", syllabus_id);
            return false;
        }
        
        // Delete syllabus
        bool success = syllabus_repository_->deleteSyllabus(syllabus_id);
        
        if (success) {
            logging::Logger::getInstance().info("Deleted syllabus: {}", syllabus_id);
        } else {
            logging::Logger::getInstance().error("Failed to delete syllabus: {}", syllabus_id);
        }
        
        return success;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error deleting syllabus: {}", e.what());
        return false;
    }
}

std::pair<std::vector<SyllabusSummary>, int> SyllabusService::listSyllabi(
    const std::optional<std::string>& course_id,
    const std::optional<SyllabusStatus>& status,
    const std::optional<std::chrono::system_clock::time_point>& effective_date,
    int page,
    int page_size,
    const std::string& sort_by,
    bool ascending
) {
    try {
        auto result = syllabus_repository_->listSyllabi(
            course_id, status, effective_date, page, page_size, sort_by, ascending);
        
        logging::Logger::getInstance().debug("Listed {} syllabi (total: {})", 
            result.first.size(), result.second);
        
        return result;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error listing syllabi: {}", e.what());
        return {{}, 0};
    }
}

std::vector<SyllabusChange> SyllabusService::trackChanges(
    const std::string& syllabus_id,
    const std::string& from_version,
    const std::string& to_version
) {
    try {
        auto changes = syllabus_repository_->trackChanges(syllabus_id, from_version, to_version);
        
        logging::Logger::getInstance().debug("Tracked {} changes between versions {} and {}", 
            changes.size(), from_version, to_version);
        
        return changes;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error tracking syllabus changes: {}", e.what());
        return {};
    }
}

bool SyllabusService::approveSyllabus(
    const std::string& syllabus_id,
    const std::string& approver_id,
    const std::string& certificate_data,
    const std::vector<uint8_t>& signature_data
) {
    try {
        // Get syllabus
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id);
        
        if (!syllabus) {
            logging::Logger::getInstance().error("Syllabus not found for approval: {}", syllabus_id);
            return false;
        }
        
        // Verify certificate
        if (!signature_service_->validateCertificate(certificate_data)) {
            logging::Logger::getInstance().error("Invalid certificate for syllabus approval");
            return false;
        }
        
        // Extract user ID from certificate and verify it matches approver_id
        std::string cert_user_id = signature_service_->extractUserIdFromCertificate(certificate_data);
        if (cert_user_id != approver_id) {
            logging::Logger::getInstance().error("Certificate user ID ({}) does not match approver ID ({})",
                cert_user_id, approver_id);
            return false;
        }
        
        // Parse certificate and get info
        auto cert_info = signature_service_->parseCertificate(certificate_data);
        if (!cert_info) {
            logging::Logger::getInstance().error("Failed to parse certificate for syllabus approval");
            return false;
        }
        
        // Generate signature digest
        std::vector<uint8_t> digest = generateSyllabusDigest(*syllabus);
        
        // Create signature info
        records::SignatureInfo signature;
        signature.signer_id = approver_id;
        signature.signer_name = cert_info->subject_name;
        signature.certificate_id = cert_info->certificate_id;
        signature.signature_data = signature_data;
        signature.timestamp = std::chrono::system_clock::now();
        
        // Verify signature
        X509* cert = X509_new();
        BIO* bio = BIO_new(BIO_s_mem());
        BIO_puts(bio, certificate_data.c_str());
        PEM_read_bio_X509(bio, &cert, nullptr, nullptr);
        BIO_free(bio);
        
        // For simplicity, we'll just set the signature as valid
        // In a real implementation, we would verify the signature against the digest
        signature.is_valid = true;
        
        X509_free(cert);
        
        // Update syllabus with signature and status
        syllabus->setApprovalSignature(signature);
        syllabus->setStatus(SyllabusStatus::APPROVED);
        syllabus->setUpdatedAt(std::chrono::system_clock::now());
        
        // Update syllabus
        bool success = syllabus_repository_->updateSyllabus(*syllabus);
        
        if (success) {
            logging::Logger::getInstance().info("Approved syllabus: {}, version: {}", 
                syllabus_id, syllabus->getVersion());
        } else {
            logging::Logger::getInstance().error("Failed to approve syllabus: {}", syllabus_id);
        }
        
        return success;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error approving syllabus: {}", e.what());
        return false;
    }
}

bool SyllabusService::archiveSyllabus(
    const std::string& syllabus_id,
    const std::string& user_id
) {
    try {
        // Get syllabus
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id);
        
        if (!syllabus) {
            logging::Logger::getInstance().error("Syllabus not found for archiving: {}", syllabus_id);
            return false;
        }
        
        // Check if user is authorized to modify syllabus
        if (!isAuthorizedToModify(*syllabus, user_id)) {
            logging::Logger::getInstance().error("User {} not authorized to archive syllabus {}", 
                user_id, syllabus_id);
            return false;
        }
        
        // Update syllabus status
        syllabus->setStatus(SyllabusStatus::ARCHIVED);
        syllabus->setUpdatedAt(std::chrono::system_clock::now());
        
        // Update syllabus
        bool success = syllabus_repository_->updateSyllabus(*syllabus);
        
        if (success) {
            logging::Logger::getInstance().info("Archived syllabus: {}, version: {}", 
                syllabus_id, syllabus->getVersion());
        } else {
            logging::Logger::getInstance().error("Failed to archive syllabus: {}", syllabus_id);
        }
        
        return success;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error archiving syllabus: {}", e.what());
        return false;
    }
}

std::string SyllabusService::cloneSyllabus(
    const std::string& syllabus_id,
    const std::string& new_version,
    const std::string& user_id
) {
    try {
        // Get source syllabus
        auto source = syllabus_repository_->getSyllabus(syllabus_id);
        
        if (!source) {
            logging::Logger::getInstance().error("Source syllabus not found for cloning: {}", syllabus_id);
            return "";
        }
        
        // Create a copy with new version and timestamps
        Syllabus clone = *source;
        clone.setVersion(new_version);
        clone.setStatus(SyllabusStatus::DRAFT);
        clone.setAuthorId(user_id);
        
        auto now = std::chrono::system_clock::now();
        clone.setCreatedAt(now);
        clone.setUpdatedAt(now);
        
        // Clear approval signature
        clone.setApprovalSignature({});
        
        // Create new syllabus
        std::string new_syllabus_id = syllabus_repository_->createSyllabus(clone);
        
        if (new_syllabus_id.empty()) {
            logging::Logger::getInstance().error("Failed to clone syllabus: {}", syllabus_id);
            return "";
        }
        
        logging::Logger::getInstance().info("Cloned syllabus {} to {} with version {}", 
            syllabus_id, new_syllabus_id, new_version);
        
        return new_syllabus_id;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error cloning syllabus: {}", e.what());
        return "";
    }
}

std::string SyllabusService::importSyllabusFromJson(
    const std::string& json_content,
    const std::string& user_id
) {
    try {
        // Parse JSON
        nlohmann::json json = nlohmann::json::parse(json_content);
        
        // Convert to syllabus
        auto syllabus = Syllabus::fromJson(json);
        
        if (!syllabus) {
            logging::Logger::getInstance().error("Failed to parse syllabus from JSON");
            return "";
        }
        
        // Set author ID and status
        syllabus->setAuthorId(user_id);
        syllabus->setStatus(SyllabusStatus::DRAFT);
        
        // Set timestamps
        auto now = std::chrono::system_clock::now();
        syllabus->setCreatedAt(now);
        syllabus->setUpdatedAt(now);
        
        // Clear approval signature
        syllabus->setApprovalSignature({});
        
        // Create syllabus
        std::string syllabus_id = syllabus_repository_->createSyllabus(*syllabus);
        
        if (syllabus_id.empty()) {
            logging::Logger::getInstance().error("Failed to import syllabus from JSON");
            return "";
        }
        
        logging::Logger::getInstance().info("Imported syllabus from JSON: {}, version: {}", 
            syllabus_id, syllabus->getVersion());
        
        return syllabus_id;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error importing syllabus from JSON: {}", e.what());
        return "";
    }
}

std::string SyllabusService::exportSyllabusToJson(
    const std::string& syllabus_id,
    const std::optional<std::string>& version
) {
    try {
        // Get syllabus
        auto syllabus = syllabus_repository_->getSyllabus(syllabus_id, version);
        
        if (!syllabus) {
            logging::Logger::getInstance().error("Syllabus not found for export: {}, version: {}", 
                syllabus_id, version ? *version : "latest");
            return "";
        }
        
        // Convert to JSON
        nlohmann::json json = syllabus->toJson();
        
        logging::Logger::getInstance().info("Exported syllabus to JSON: {}, version: {}", 
            syllabus_id, syllabus->getVersion());
        
        return json.dump(4);
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error exporting syllabus to JSON: {}", e.what());
        return "";
    }
}

std::vector<uint8_t> SyllabusService::generateSyllabusDigest(const Syllabus& syllabus) {
    try {
        // Create a JSON representation of the syllabus
        nlohmann::json json = syllabus.toJson();
        
        // Remove approval signature to create a consistent digest
        if (json.contains("approval_signature")) {
            json.erase("approval_signature");
        }
        
        // Generate digest
        std::string json_str = json.dump();
        
        // This is a simplified implementation, in a real system we would use cryptographic digest
        std::vector<uint8_t> digest(json_str.begin(), json_str.end());
        
        return digest;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error generating syllabus digest: {}", e.what());
        return {};
    }
}

bool SyllabusService::isAuthorizedToModify(const Syllabus& syllabus, const std::string& user_id) {
    // For simplicity, we'll allow modification if:
    // 1. User is the author
    // 2. Syllabus is in DRAFT state
    
    if (syllabus.getAuthorId() == user_id) {
        return true;
    }
    
    if (syllabus.getStatus() == SyllabusStatus::DRAFT) {
        // In a real implementation, we would check user roles/permissions
        return true;
    }
    
    return false;
}

std::vector<SyllabusChange> SyllabusService::calculateChanges(
    const Syllabus& old_syllabus,
    const Syllabus& new_syllabus,
    const std::string& user_id
) {
    std::vector<SyllabusChange> changes;
    auto now = std::chrono::system_clock::now();
    
    // Check for syllabus-level changes
    if (old_syllabus.getTitle() != new_syllabus.getTitle() ||
        old_syllabus.getDescription() != new_syllabus.getDescription() ||
        old_syllabus.getEffectiveDate() != new_syllabus.getEffectiveDate() ||
        old_syllabus.getExpirationDate() != new_syllabus.getExpirationDate()) {
        
        SyllabusChange change;
        change.change_type = ChangeType::MODIFIED;
        change.element_type = ElementType::SYLLABUS;
        change.element_id = new_syllabus.getSyllabusId();
        change.description = "Modified syllabus properties";
        change.author_id = user_id;
        change.timestamp = now;
        
        if (old_syllabus.getTitle() != new_syllabus.getTitle()) {
            change.old_values["title"] = old_syllabus.getTitle();
            change.new_values["title"] = new_syllabus.getTitle();
        }
        
        if (old_syllabus.getDescription() != new_syllabus.getDescription()) {
            change.old_values["description"] = old_syllabus.getDescription();
            change.new_values["description"] = new_syllabus.getDescription();
        }
        
        if (old_syllabus.getEffectiveDate() != new_syllabus.getEffectiveDate()) {
            change.old_values["effective_date"] = std::to_string(std::chrono::duration_cast<std::chrono::milliseconds>(
                old_syllabus.getEffectiveDate().time_since_epoch()).count());
            change.new_values["effective_date"] = std::to_string(std::chrono::duration_cast<std::chrono::milliseconds>(
                new_syllabus.getEffectiveDate().time_since_epoch()).count());
        }
        
        if (old_syllabus.getExpirationDate() != new_syllabus.getExpirationDate()) {
            if (old_syllabus.getExpirationDate()) {
                change.old_values["expiration_date"] = std::to_string(std::chrono::duration_cast<std::chrono::milliseconds>(
                    old_syllabus.getExpirationDate()->time_since_epoch()).count());
            } else {
                change.old_values["expiration_date"] = "null";
            }
            
            if (new_syllabus.getExpirationDate()) {
                change.new_values["expiration_date"] = std::to_string(std::chrono::duration_cast<std::chrono::milliseconds>(
                    new_syllabus.getExpirationDate()->time_since_epoch()).count());
            } else {
                change.new_values["expiration_date"] = "null";
            }
        }
        
        changes.push_back(change);
    }
    
    // Compare sections
    std::unordered_map<std::string, const SyllabusSection*> old_sections;
    for (const auto& section : old_syllabus.getSections()) {
        old_sections[section.section_id] = &section;
    }
    
    std::unordered_map<std::string, const SyllabusSection*> new_sections;
    for (const auto& section : new_syllabus.getSections()) {
        new_sections[section.section_id] = &section;
    }
    
    // Sections added or modified
    for (const auto& section : new_syllabus.getSections()) {
        auto it = old_sections.find(section.section_id);
        
        if (it == old_sections.end()) {
            // Section added
            SyllabusChange change;
            change.change_type = ChangeType::ADDED;
            change.element_type = ElementType::SECTION;
            change.element_id = section.section_id;
            change.parent_id = new_syllabus.getSyllabusId();
            change.description = "Added section: " + section.title;
            change.author_id = user_id;
            change.timestamp = now;
            
            change.new_values["title"] = section.title;
            change.new_values["description"] = section.description;
            change.new_values["order"] = std::to_string(section.order);
            
            changes.push_back(change);
        } else {
            // Check if section modified
            const auto& old_section = *it->second;
            
            if (old_section.title != section.title ||
                old_section.description != section.description ||
                old_section.order != section.order) {
                
                SyllabusChange change;
                change.change_type = ChangeType::MODIFIED;
                change.element_type = ElementType::SECTION;
                change.element_id = section.section_id;
                change.parent_id = new_syllabus.getSyllabusId();
                change.description = "Modified section: " + section.title;
                change.author_id = user_id;
                change.timestamp = now;
                
                if (old_section.title != section.title) {
                    change.old_values["title"] = old_section.title;
                    change.new_values["title"] = section.title;
                }
                
                if (old_section.description != section.description) {
                    change.old_values["description"] = old_section.description;
                    change.new_values["description"] = section.description;
                }
                
                if (old_section.order != section.order) {
                    change.old_values["order"] = std::to_string(old_section.order);
                    change.new_values["order"] = std::to_string(section.order);
                }
                
                changes.push_back(change);
            }
            
            // Check exercises
            std::unordered_map<std::string, const SyllabusExercise*> old_exercises;
            for (const auto& exercise : old_section.exercises) {
                old_exercises[exercise.exercise_id] = &exercise;
            }
            
            std::unordered_map<std::string, const SyllabusExercise*> new_exercises;
            for (const auto& exercise : section.exercises) {
                new_exercises[exercise.exercise_id] = &exercise;
            }
            
            // Exercises added or modified
            for (const auto& exercise : section.exercises) {
                auto ex_it = old_exercises.find(exercise.exercise_id);
                
                if (ex_it == old_exercises.end()) {
                    // Exercise added
                    SyllabusChange change;
                    change.change_type = ChangeType::ADDED;
                    change.element_type = ElementType::EXERCISE;
                    change.element_id = exercise.exercise_id;
                    change.parent_id = section.section_id;
                    change.description = "Added exercise: " + exercise.title;
                    change.author_id = user_id;
                    change.timestamp = now;
                    
                    change.new_values["title"] = exercise.title;
                    change.new_values["description"] = exercise.description;
                    change.new_values["order"] = std::to_string(exercise.order);
                    change.new_values["duration_minutes"] = std::to_string(exercise.duration_minutes);
                    change.new_values["exercise_type"] = exercise.exercise_type;
                    
                    changes.push_back(change);
                } else {
                    // Check if exercise modified
                    const auto& old_exercise = *ex_it->second;
                    
                    if (old_exercise.title != exercise.title ||
                        old_exercise.description != exercise.description ||
                        old_exercise.order != exercise.order ||
                        old_exercise.duration_minutes != exercise.duration_minutes ||
                        old_exercise.exercise_type != exercise.exercise_type) {
                        
                        SyllabusChange change;
                        change.change_type = ChangeType::MODIFIED;
                        change.element_type = ElementType::EXERCISE;
                        change.element_id = exercise.exercise_id;
                        change.parent_id = section.section_id;
                        change.description = "Modified exercise: " + exercise.title;
                        change.author_id = user_id;
                        change.timestamp = now;
                        
                        if (old_exercise.title != exercise.title) {
                            change.old_values["title"] = old_exercise.title;
                            change.new_values["title"] = exercise.title;
                        }
                        
                        if (old_exercise.description != exercise.description) {
                            change.old_values["description"] = old_exercise.description;
                            change.new_values["description"] = exercise.description;
                        }
                        
                        if (old_exercise.order != exercise.order) {
                            change.old_values["order"] = std::to_string(old_exercise.order);
                            change.new_values["order"] = std::to_string(exercise.order);
                        }
                        
                        if (old_exercise.duration_minutes != exercise.duration_minutes) {
                            change.old_values["duration_minutes"] = std::to_string(old_exercise.duration_minutes);
                            change.new_values["duration_minutes"] = std::to_string(exercise.duration_minutes);
                        }
                        
                        if (old_exercise.exercise_type != exercise.exercise_type) {
                            change.old_values["exercise_type"] = old_exercise.exercise_type;
                            change.new_values["exercise_type"] = exercise.exercise_type;
                        }
                        
                        changes.push_back(change);
                    }
                    
                    // We could continue with more detailed comparison of objectives, criteria, etc.
                    // For brevity, we'll stop here
                }
            }
            
            // Exercises removed
            for (const auto& [ex_id, old_exercise] : old_exercises) {
                if (new_exercises.find(ex_id) == new_exercises.end()) {
                    // Exercise removed
                    SyllabusChange change;
                    change.change_type = ChangeType::REMOVED;
                    change.element_type = ElementType::EXERCISE;
                    change.element_id = ex_id;
                    change.parent_id = section.section_id;
                    change.description = "Removed exercise: " + old_exercise->title;
                    change.author_id = user_id;
                    change.timestamp = now;
                    
                    change.old_values["title"] = old_exercise->title;
                    
                    changes.push_back(change);
                }
            }
        }
    }
    
    // Sections removed
    for (const auto& [sec_id, old_section] : old_sections) {
        if (new_sections.find(sec_id) == new_sections.end()) {
            // Section removed
            SyllabusChange change;
            change.change_type = ChangeType::REMOVED;
            change.element_type = ElementType::SECTION;
            change.element_id = sec_id;
            change.parent_id = new_syllabus.getSyllabusId();
            change.description = "Removed section: " + old_section->title;
            change.author_id = user_id;
            change.timestamp = now;
            
            change.old_values["title"] = old_section->title;
            
            changes.push_back(change);
        }
    }
    
    return changes;
}

// JSON serialization implementations
nlohmann::json GradeDefinition::toJson() const {
    nlohmann::json json;
    json["grade"] = grade;
    json["description"] = description;
    json["is_passing"] = is_passing;
    return json;
}

std::optional<GradeDefinition> GradeDefinition::fromJson(const nlohmann::json& json) {
    try {
        GradeDefinition def;
        def.grade = json["grade"];
        def.description = json["description"];
        def.is_passing = json["is_passing"];
        return def;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing grade definition from JSON: {}", e.what());
        return std::nullopt;
    }
}

nlohmann::json GradingCriteria::toJson() const {
    nlohmann::json json;
    json["criteria_id"] = criteria_id;
    json["name"] = name;
    json["description"] = description;
    json["is_required"] = is_required;
    
    json["grade_definitions"] = nlohmann::json::array();
    for (const auto& def : grade_definitions) {
        json["grade_definitions"].push_back(def.toJson());
    }
    
    json["regulation_references"] = regulation_references;
    
    return json;
}

std::optional<GradingCriteria> GradingCriteria::fromJson(const nlohmann::json& json) {
    try {
        GradingCriteria criteria;
        criteria.criteria_id = json["criteria_id"];
        criteria.name = json["name"];
        criteria.description = json["description"];
        criteria.is_required = json["is_required"];
        
        for (const auto& def_json : json["grade_definitions"]) {
            auto def = GradeDefinition::fromJson(def_json);
            if (def) {
                criteria.grade_definitions.push_back(*def);
            }
        }
        
        criteria.regulation_references = json["regulation_references"].get<std::map<std::string, std::string>>();
        
        return criteria;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing grading criteria from JSON: {}", e.what());
        return std::nullopt;
    }
}

nlohmann::json SyllabusExercise::toJson() const {
    nlohmann::json json;
    json["exercise_id"] = exercise_id;
    json["title"] = title;
    json["description"] = description;
    json["order"] = order;
    json["duration_minutes"] = duration_minutes;
    json["exercise_type"] = exercise_type;
    json["objectives"] = objectives;
    json["references"] = references;
    json["equipment"] = equipment;
    
    json["grading_criteria"] = nlohmann::json::array();
    for (const auto& criteria : grading_criteria) {
        json["grading_criteria"].push_back(criteria.toJson());
    }
    
    json["prerequisite_exercises"] = prerequisite_exercises;
    json["metadata"] = metadata;
    
    return json;
}

std::optional<SyllabusExercise> SyllabusExercise::fromJson(const nlohmann::json& json) {
    try {
        SyllabusExercise exercise;
        exercise.exercise_id = json["exercise_id"];
        exercise.title = json["title"];
        exercise.description = json["description"];
        exercise.order = json["order"];
        exercise.duration_minutes = json["duration_minutes"];
        exercise.exercise_type = json["exercise_type"];
        exercise.objectives = json["objectives"].get<std::vector<std::string>>();
        exercise.references = json["references"].get<std::vector<std::string>>();
        exercise.equipment = json["equipment"].get<std::vector<std::string>>();
        
        for (const auto& criteria_json : json["grading_criteria"]) {
            auto criteria = GradingCriteria::fromJson(criteria_json);
            if (criteria) {
                exercise.grading_criteria.push_back(*criteria);
            }
        }
        
        exercise.prerequisite_exercises = json["prerequisite_exercises"].get<std::vector<std::string>>();
        exercise.metadata = json["metadata"].get<std::map<std::string, std::string>>();
        
        return exercise;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus exercise from JSON: {}", e.what());
        return std::nullopt;
    }
}

nlohmann::json SyllabusSection::toJson() const {
    nlohmann::json json;
    json["section_id"] = section_id;
    json["title"] = title;
    json["description"] = description;
    json["order"] = order;
    
    json["exercises"] = nlohmann::json::array();
    for (const auto& exercise : exercises) {
        json["exercises"].push_back(exercise.toJson());
    }
    
    return json;
}

std::optional<SyllabusSection> SyllabusSection::fromJson(const nlohmann::json& json) {
    try {
        SyllabusSection section;
        section.section_id = json["section_id"];
        section.title = json["title"];
        section.description = json["description"];
        section.order = json["order"];
        
        for (const auto& exercise_json : json["exercises"]) {
            auto exercise = SyllabusExercise::fromJson(exercise_json);
            if (exercise) {
                section.exercises.push_back(*exercise);
            }
        }
        
        return section;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus section from JSON: {}", e.what());
        return std::nullopt;
    }
}

nlohmann::json SyllabusChange::toJson() const {
    nlohmann::json json;
    json["change_type"] = changeTypeToString(change_type);
    json["element_type"] = elementTypeToString(element_type);
    json["element_id"] = element_id;
    
    if (parent_id) {
        json["parent_id"] = *parent_id;
    }
    
    json["description"] = description;
    json["old_values"] = old_values;
    json["new_values"] = new_values;
    json["rationale"] = rationale;
    json["author_id"] = author_id;
    json["timestamp"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        timestamp.time_since_epoch()).count();
    
    return json;
}

std::optional<SyllabusChange> SyllabusChange::fromJson(const nlohmann::json& json) {
    try {
        SyllabusChange change;
        change.change_type = changeTypeFromString(json["change_type"]);
        change.element_type = elementTypeFromString(json["element_type"]);
        change.element_id = json["element_id"];
        
        if (json.contains("parent_id") && !json["parent_id"].is_null()) {
            change.parent_id = json["parent_id"];
        }
        
        change.description = json["description"];
        change.old_values = json["old_values"].get<std::map<std::string, std::string>>();
        change.new_values = json["new_values"].get<std::map<std::string, std::string>>();
        change.rationale = json["rationale"];
        change.author_id = json["author_id"];
        change.timestamp = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["timestamp"].get<int64_t>())
        );
        
        return change;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus change from JSON: {}", e.what());
        return std::nullopt;
    }
}

nlohmann::json SyllabusSummary::toJson() const {
    nlohmann::json json;
    json["syllabus_id"] = syllabus_id;
    json["course_id"] = course_id;
    json["title"] = title;
    json["version"] = version;
    json["effective_date"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        effective_date.time_since_epoch()).count();
    
    if (expiration_date) {
        json["expiration_date"] = std::chrono::duration_cast<std::chrono::milliseconds>(
            expiration_date->time_since_epoch()).count();
    }
    
    json["status"] = syllabusStatusToString(status);
    json["author_id"] = author_id;
    json["created_at"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        created_at.time_since_epoch()).count();
    json["updated_at"] = std::chrono::duration_cast<std::chrono::milliseconds>(
        updated_at.time_since_epoch()).count();
    
    return json;
}

std::optional<SyllabusSummary> SyllabusSummary::fromJson(const nlohmann::json& json) {
    try {
        SyllabusSummary summary;
        summary.syllabus_id = json["syllabus_id"];
        summary.course_id = json["course_id"];
        summary.title = json["title"];
        summary.version = json["version"];
        summary.effective_date = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["effective_date"].get<int64_t>())
        );
        
        if (json.contains("expiration_date") && !json["expiration_date"].is_null()) {
            summary.expiration_date = std::chrono::system_clock::time_point(
                std::chrono::milliseconds(json["expiration_date"].get<int64_t>())
            );
        }
        
        summary.status = syllabusStatusFromString(json["status"]);
        summary.author_id = json["author_id"];
        summary.created_at = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["created_at"].get<int64_t>())
        );
        summary.updated_at = std::chrono::system_clock::time_point(
            std::chrono::milliseconds(json["updated_at"].get<int64_t>())
        );
        
        return summary;
    }
    catch (const std::exception& e) {
        logging::Logger::getInstance().error("Error parsing syllabus summary from JSON: {}", e.what());
        return std::nullopt;
    }
}

} // namespace syllabus
} // namespace etr
cmake_minimum_required(VERSION 3.20)

# Find GTest
find_package(GTest REQUIRED)
include_directories(${GTEST_INCLUDE_DIRS})
include_directories(${CMAKE_SOURCE_DIR}/include)

# Record service tests
add_executable(record_service_test
    record_service_test.cpp
)
target_link_libraries(record_service_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    gmock
    etr_lib
    pthread
)

# Digital signature tests
add_executable(digital_signature_test
    digital_signature_test.cpp
)
target_link_libraries(digital_signature_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    gmock
    etr_lib
    pthread
)

# Compliance tests
add_executable(compliance_test
    compliance_test.cpp
)
target_link_libraries(compliance_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    gmock
    etr_lib
    pthread
)

# Syllabus tests
add_executable(syllabus_test
    syllabus_test.cpp
)
target_link_libraries(syllabus_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    gmock
    etr_lib
    pthread
)

# Database connection tests
add_executable(database_connection_test
    database_connection_test.cpp
)
target_link_libraries(database_connection_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    gmock
    etr_lib
    pthread
)

# Integration tests
add_executable(integration_test
    integration_test.cpp
)
target_link_libraries(integration_test
    PRIVATE
    ${GTEST_BOTH_LIBRARIES}
    gmock
    etr_lib
    pthread
)

# Register tests
include(GoogleTest)
gtest_discover_tests(record_service_test)
gtest_discover_tests(digital_signature_test)
gtest_discover_tests(compliance_test)
gtest_discover_tests(syllabus_test)
gtest_discover_tests(database_connection_test)
gtest_discover_tests(integration_test)

# Add test target that runs all tests
add_custom_target(check
    COMMAND ${CMAKE_CTEST_COMMAND} --output-on-failure
    DEPENDS
        record_service_test
        digital_signature_test
        compliance_test
        syllabus_test
        database_connection_test
        integration_test
)

# Add code coverage target if compiler supports it
option(CODE_COVERAGE "Enable coverage reporting" OFF)
if(CODE_COVERAGE AND CMAKE_CXX_COMPILER_ID MATCHES "GNU|Clang")
    # Add required flags
    target_compile_options(record_service_test PRIVATE --coverage)
    target_link_options(record_service_test PRIVATE --coverage)
    
    target_compile_options(digital_signature_test PRIVATE --coverage)
    target_link_options(digital_signature_test PRIVATE --coverage)
    
    target_compile_options(compliance_test PRIVATE --coverage)
    target_link_options(compliance_test PRIVATE --coverage)
    
    target_compile_options(syllabus_test PRIVATE --coverage)
    target_link_options(syllabus_test PRIVATE --coverage)
    
    target_compile_options(database_connection_test PRIVATE --coverage)
    target_link_options(database_connection_test PRIVATE --coverage)
    
    target_compile_options(integration_test PRIVATE --coverage)
    target_link_options(integration_test PRIVATE --coverage)
    
    # Add coverage report target
    find_program(GCOVR gcovr REQUIRED)
    add_custom_target(coverage
        COMMAND ${GCOVR} --xml-pretty --exclude-unreachable-branches --print-summary
                -r ${CMAKE_SOURCE_DIR} --object-directory=${CMAKE_BINARY_DIR}
                --output=${CMAKE_BINARY_DIR}/coverage.xml
        DEPENDS check
        WORKING_DIRECTORY ${CMAKE_BINARY_DIR}
        COMMENT "Generating coverage report"
    )
endif()
// src/backend/simulator/EventDetector.h
#pragma once

#include <vector>
#include <unordered_map>
#include <memory>
#include <functional>
#include <string>

#include "FlightParameters.h"

namespace PilotTraining {
namespace Simulator {

/**
 * @brief Flight event detector
 * 
 * Detects significant events during flight simulation based on telemetry data.
 * Events include things like takeoffs, landings, stalls, phase changes, etc.
 */
class EventDetector {
public:
    /**
     * @brief Construct a new Event Detector
     * 
     * @param parameters Optional event detection parameters
     */
    explicit EventDetector(const EventDetectionParameters& parameters = EventDetectionParameters());
    
    /**
     * @brief Destroy the Event Detector
     */
    ~EventDetector();
    
    /**
     * @brief Set detection parameters
     * 
     * @param parameters New event detection parameters
     */
    void setParameters(const EventDetectionParameters& parameters);
    
    /**
     * @brief Get current detection parameters
     * 
     * @return EventDetectionParameters Current parameters
     */
    EventDetectionParameters getParameters() const;
    
    /**
     * @brief Detect events in telemetry data
     * 
     * @param data Sequence of flight parameters to analyze
     * @return std::vector<FlightEvent> Detected events
     */
    std::vector<FlightEvent> detectEvents(const std::vector<FlightParameters>& data);
    
    /**
     * @brief Register a custom event detector
     * 
     * @param eventType Type of event to detect
     * @param detector Function that returns true if event is detected
     * @param description Human-readable description
     * @param severity Event severity
     * @return true if successfully registered
     * @return false if eventType already has a detector
     */
    bool registerCustomDetector(
        FlightEventType eventType,
        std::function<bool(const std::vector<FlightParameters>&, FlightEvent&)> detector,
        const std::string& description,
        FlightEventSeverity severity
    );
    
    /**
     * @brief Unregister a custom event detector
     * 
     * @param eventType Type of event to remove detector for
     * @return true if successfully unregistered
     * @return false if eventType has no detector
     */
    bool unregisterCustomDetector(FlightEventType eventType);
    
    /**
     * @brief Enable/disable a specific event detector
     * 
     * @param eventType Type of event
     * @param enabled Whether the detector should be enabled
     * @return true if the detector state was changed
     * @return false if the detector does not exist
     */
    bool setDetectorEnabled(FlightEventType eventType, bool enabled);
    
    /**
     * @brief Check if a specific event detector is enabled
     * 
     * @param eventType Type of event
     * @return true if the detector is enabled
     * @return false if the detector is disabled or does not exist
     */
    bool isDetectorEnabled(FlightEventType eventType) const;

private:
    // Internal detector function type
    using DetectorFunc = std::function<bool(const std::vector<FlightParameters>&, FlightEvent&)>;
    
    // Internal detector configuration
    struct DetectorConfig {
        DetectorFunc detector;
        std::string description;
        FlightEventSeverity severity;
        bool enabled;
    };
    
    // Detection parameters
    EventDetectionParameters _parameters;
    
    // Historical data for state tracking
    FlightPhase _lastPhase;
    bool _wasOnGround;
    bool _wasStalled;
    
    // Map of event type to detector
    std::unordered_map<FlightEventType, DetectorConfig> _detectors;
    
    // Internal detection methods
    void initializeDefaultDetectors();
    
    // Default detector implementations
    bool detectTakeoff(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectLanding(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectStall(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectOverspeed(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectBankAngleExceeded(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectPitchAngleExceeded(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectAltitudeDeviation(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectHeadingDeviation(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectSpeedDeviation(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectGearConfiguration(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectFlapConfiguration(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectSystemFailure(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectPhaseChange(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectNavigationDeviation(const std::vector<FlightParameters>& data, FlightEvent& event);
    bool detectInstructorAction(const std::vector<FlightParameters>& data, FlightEvent& event);
    
    // Helper methods
    FlightEvent createEvent(
        const FlightParameters& params,
        FlightEventType type,
        FlightEventSeverity severity,
        const std::string& description
    );
};

} // namespace Simulator
} // namespace PilotTraining

// src/backend/simulator/EventDetector.cpp
#include "EventDetector.h"
#include "../core/Logger.h"
#include <cmath>
#include <algorithm>

namespace PilotTraining {
namespace Simulator {

EventDetector::EventDetector(const EventDetectionParameters& parameters)
    : _parameters(parameters),
      _lastPhase(FlightPhase::UNKNOWN),
      _wasOnGround(true),
      _wasStalled(false) {
    
    initializeDefaultDetectors();
    Core::Logger::debug("EventDetector initialized");
}

EventDetector::~EventDetector() {
    Core::Logger::debug("EventDetector destroyed");
}

void EventDetector::setParameters(const EventDetectionParameters& parameters) {
    _parameters = parameters;
    Core::Logger::debug("EventDetector parameters updated");
}

EventDetectionParameters EventDetector::getParameters() const {
    return _parameters;
}

std::vector<FlightEvent> EventDetector::detectEvents(const std::vector<FlightParameters>& data) {
    std::vector<FlightEvent> detectedEvents;
    
    if (data.empty()) {
        return detectedEvents;
    }
    
    // Run all enabled detectors
    for (const auto& [eventType, config] : _detectors) {
        if (config.enabled) {
            FlightEvent event;
            if (config.detector(data, event)) {
                detectedEvents.push_back(event);
            }
        }
    }
    
    // Update state for next detection cycle
    const auto& lastParams = data.back();
    _lastPhase = lastParams.phase;
    _wasOnGround = lastParams.onGround;
    _wasStalled = lastParams.stall;
    
    return detectedEvents;
}

bool EventDetector::registerCustomDetector(
    FlightEventType eventType,
    std::function<bool(const std::vector<FlightParameters>&, FlightEvent&)> detector,
    const std::string& description,
    FlightEventSeverity severity) {
    
    // Check if a detector for this event type already exists
    if (_detectors.find(eventType) != _detectors.end()) {
        return false;
    }
    
    // Register the detector
    _detectors[eventType] = {
        detector,
        description,
        severity,
        true // Enabled by default
    };
    
    Core::Logger::debug("Custom detector registered for event type: {}", static_cast<int>(eventType));
    return true;
}

bool EventDetector::unregisterCustomDetector(FlightEventType eventType) {
    // Check if the detector exists
    auto it = _detectors.find(eventType);
    if (it == _detectors.end()) {
        return false;
    }
    
    // Only allow unregistering custom detectors
    if (eventType != FlightEventType::CUSTOM && 
        static_cast<int>(eventType) < static_cast<int>(FlightEventType::CUSTOM)) {
        return false;
    }
    
    // Remove the detector
    _detectors.erase(it);
    
    Core::Logger::debug("Custom detector unregistered for event type: {}", static_cast<int>(eventType));
    return true;
}

bool EventDetector::setDetectorEnabled(FlightEventType eventType, bool enabled) {
    // Check if the detector exists
    auto it = _detectors.find(eventType);
    if (it == _detectors.end()) {
        return false;
    }
    
    // Set enabled state
    it->second.enabled = enabled;
    
    Core::Logger::debug("Detector for event type {} {}", 
        static_cast<int>(eventType), 
        enabled ? "enabled" : "disabled");
    
    return true;
}

bool EventDetector::isDetectorEnabled(FlightEventType eventType) const {
    // Check if the detector exists
    auto it = _detectors.find(eventType);
    if (it == _detectors.end()) {
        return false;
    }
    
    return it->second.enabled;
}

void EventDetector::initializeDefaultDetectors() {
    // Register all default detectors
    _detectors[FlightEventType::TAKEOFF] = {
        [this](const auto& data, auto& event) { return detectTakeoff(data, event); },
        "Aircraft takeoff detected",
        FlightEventSeverity::INFO,
        true
    };
    
    _detectors[FlightEventType::LANDING] = {
        [this](const auto& data, auto& event) { return detectLanding(data, event); },
        "Aircraft landing detected",
        FlightEventSeverity::INFO,
        true
    };
    
    _detectors[FlightEventType::STALL] = {
        [this](const auto& data, auto& event) { return detectStall(data, event); },
        "Aircraft stall detected",
        FlightEventSeverity::WARNING,
        true
    };
    
    _detectors[FlightEventType::OVERSPEED] = {
        [this](const auto& data, auto& event) { return detectOverspeed(data, event); },
        "Aircraft overspeed detected",
        FlightEventSeverity::WARNING,
        true
    };
    
    _detectors[FlightEventType::BANK_ANGLE_EXCEEDED] = {
        [this](const auto& data, auto& event) { return detectBankAngleExceeded(data, event); },
        "Bank angle limit exceeded",
        FlightEventSeverity::CAUTION,
        true
    };
    
    _detectors[FlightEventType::PITCH_ANGLE_EXCEEDED] = {
        [this](const auto& data, auto& event) { return detectPitchAngleExceeded(data, event); },
        "Pitch angle limit exceeded",
        FlightEventSeverity::CAUTION,
        true
    };
    
    _detectors[FlightEventType::ALTITUDE_DEVIATION] = {
        [this](const auto& data, auto& event) { return detectAltitudeDeviation(data, event); },
        "Altitude deviation detected",
        FlightEventSeverity::CAUTION,
        true
    };
    
    _detectors[FlightEventType::HEADING_DEVIATION] = {
        [this](const auto& data, auto& event) { return detectHeadingDeviation(data, event); },
        "Heading deviation detected",
        FlightEventSeverity::CAUTION,
        true
    };
    
    _detectors[FlightEventType::SPEED_DEVIATION] = {
        [this](const auto& data, auto& event) { return detectSpeedDeviation(data, event); },
        "Speed deviation detected",
        FlightEventSeverity::CAUTION,
        true
    };
    
    _detectors[FlightEventType::GEAR_CONFIGURATION] = {
        [this](const auto& data, auto& event) { return detectGearConfiguration(data, event); },
        "Improper gear configuration",
        FlightEventSeverity::WARNING,
        true
    };
    
    _detectors[FlightEventType::FLAP_CONFIGURATION] = {
        [this](const auto& data, auto& event) { return detectFlapConfiguration(data, event); },
        "Improper flap configuration",
        FlightEventSeverity::CAUTION,
        true
    };
    
    _detectors[FlightEventType::SYSTEM_FAILURE] = {
        [this](const auto& data, auto& event) { return detectSystemFailure(data, event); },
        "System failure detected",
        FlightEventSeverity::CRITICAL,
        true
    };
    
    _detectors[FlightEventType::PHASE_CHANGE] = {
        [this](const auto& data, auto& event) { return detectPhaseChange(data, event); },
        "Flight phase change",
        FlightEventSeverity::INFO,
        true
    };
    
    _detectors[FlightEventType::NAVIGATION_DEVIATION] = {
        [this](const auto& data, auto& event) { return detectNavigationDeviation(data, event); },
        "Navigation deviation detected",
        FlightEventSeverity::CAUTION,
        true
    };
    
    _detectors[FlightEventType::INSTRUCTOR_ACTION] = {
        [this](const auto& data, auto& event) { return detectInstructorAction(data, event); },
        "Instructor action detected",
        FlightEventSeverity::INFO,
        true
    };
}

bool EventDetector::detectTakeoff(const std::vector<FlightParameters>& data, FlightEvent& event) {
    // Need at least two data points to detect transition
    if (data.size() < 2) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check for transition from ground to air
    if (_wasOnGround && !current.onGround && current.indicatedAirspeed > 40.0) {
        event = createEvent(
            current,
            FlightEventType::TAKEOFF,
            FlightEventSeverity::INFO,
            "Aircraft takeoff detected"
        );
        
        // Add event-specific data
        event.numericData["speedKnots"] = current.indicatedAirspeed;
        event.numericData["pitchAngle"] = current.pitch;
        event.numericData["headingDegrees"] = current.heading;
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectLanding(const std::vector<FlightParameters>& data, FlightEvent& event) {
    // Need at least two data points to detect transition
    if (data.size() < 2) {
        return false;
    }
    
    const auto& current = data.back();
    const auto& previous = data[data.size() - 2];
    
    // Check for transition from air to ground
    if (!_wasOnGround && current.onGround) {
        event = createEvent(
            current,
            FlightEventType::LANDING,
            FlightEventSeverity::INFO,
            "Aircraft landing detected"
        );
        
        // Calculate touchdown rate (vertical speed at touchdown)
        double touchdownRate = previous.verticalSpeed;
        
        // Add event-specific data
        event.numericData["touchdownRateFPM"] = touchdownRate;
        event.numericData["touchdownSpeedKnots"] = previous.indicatedAirspeed;
        event.numericData["touchdownPitch"] = previous.pitch;
        event.numericData["touchdownRoll"] = previous.roll;
        event.numericData["touchdownHeading"] = previous.heading;
        
        // Assess landing quality
        if (std::abs(touchdownRate) > 600) {
            event.textData["landingQuality"] = "Hard landing";
            event.severity = FlightEventSeverity::CAUTION;
        } else if (std::abs(touchdownRate) > 300) {
            event.textData["landingQuality"] = "Firm landing";
            event.severity = FlightEventSeverity::INFO;
        } else {
            event.textData["landingQuality"] = "Smooth landing";
            event.severity = FlightEventSeverity::INFO;
        }
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectStall(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check for transition to stall state
    if (!_wasStalled && current.stall) {
        event = createEvent(
            current,
            FlightEventType::STALL,
            FlightEventSeverity::WARNING,
            "Aircraft stall detected"
        );
        
        // Add event-specific data
        event.numericData["indicatedAirspeed"] = current.indicatedAirspeed;
        event.numericData["pitchAngle"] = current.pitch;
        event.numericData["bankAngle"] = current.roll;
        event.numericData["altitude"] = current.altitude;
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectOverspeed(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check for overspeed state
    if (current.overspeed) {
        event = createEvent(
            current,
            FlightEventType::OVERSPEED,
            FlightEventSeverity::WARNING,
            "Aircraft overspeed detected"
        );
        
        // Add event-specific data
        event.numericData["indicatedAirspeed"] = current.indicatedAirspeed;
        event.numericData["altitude"] = current.altitude;
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectBankAngleExceeded(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check if bank angle exceeds threshold
    const double bankAngle = std::abs(current.roll);
    if (bankAngle > _parameters.bankAngleThreshold) {
        event = createEvent(
            current,
            FlightEventType::BANK_ANGLE_EXCEEDED,
            FlightEventSeverity::CAUTION,
            "Bank angle limit exceeded"
        );
        
        // Add event-specific data
        event.numericData["bankAngle"] = current.roll;
        event.numericData["threshold"] = _parameters.bankAngleThreshold;
        event.numericData["exceedAmount"] = bankAngle - _parameters.bankAngleThreshold;
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectPitchAngleExceeded(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check if pitch angle exceeds threshold
    const double pitchAngle = std::abs(current.pitch);
    if (pitchAngle > _parameters.pitchAngleThreshold) {
        event = createEvent(
            current,
            FlightEventType::PITCH_ANGLE_EXCEEDED,
            FlightEventSeverity::CAUTION,
            "Pitch angle limit exceeded"
        );
        
        // Add event-specific data
        event.numericData["pitchAngle"] = current.pitch;
        event.numericData["threshold"] = _parameters.pitchAngleThreshold;
        event.numericData["exceedAmount"] = pitchAngle - _parameters.pitchAngleThreshold;
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectAltitudeDeviation(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Skip if autopilot is not engaged or there's no selected altitude
    if (!current.autopilotEngaged || current.selectedAltitude < 1.0) {
        return false;
    }
    
    // Check if altitude deviation exceeds threshold
    const double deviation = std::abs(current.altitude - current.selectedAltitude);
    if (deviation > _parameters.altitudeDeviationThreshold) {
        event = createEvent(
            current,
            FlightEventType::ALTITUDE_DEVIATION,
            FlightEventSeverity::CAUTION,
            "Altitude deviation detected"
        );
        
        // Add event-specific data
        event.numericData["actualAltitude"] = current.altitude;
        event.numericData["selectedAltitude"] = current.selectedAltitude;
        event.numericData["deviation"] = deviation;
        event.numericData["threshold"] = _parameters.altitudeDeviationThreshold;
        
        if (current.altitude > current.selectedAltitude) {
            event.textData["direction"] = "above";
        } else {
            event.textData["direction"] = "below";
        }
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectHeadingDeviation(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Skip if autopilot is not engaged or there's no selected heading
    if (!current.autopilotEngaged || current.selectedHeading < 0.0) {
        return false;
    }
    
    // Calculate heading deviation, accounting for the 0/360 wrap
    double deviation = std::abs(current.heading - current.selectedHeading);
    if (deviation > 180.0) {
        deviation = 360.0 - deviation;
    }
    
    // Check if heading deviation exceeds threshold
    if (deviation > _parameters.headingDeviationThreshold) {
        event = createEvent(
            current,
            FlightEventType::HEADING_DEVIATION,
            FlightEventSeverity::CAUTION,
            "Heading deviation detected"
        );
        
        // Add event-specific data
        event.numericData["actualHeading"] = current.heading;
        event.numericData["selectedHeading"] = current.selectedHeading;
        event.numericData["deviation"] = deviation;
        event.numericData["threshold"] = _parameters.headingDeviationThreshold;
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectSpeedDeviation(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Skip if autopilot is not engaged or there's no selected speed
    if (!current.autopilotEngaged || current.selectedSpeed < 1.0) {
        return false;
    }
    
    // Check if speed deviation exceeds threshold
    const double deviation = std::abs(current.indicatedAirspeed - current.selectedSpeed);
    if (deviation > _parameters.speedDeviationThreshold) {
        event = createEvent(
            current,
            FlightEventType::SPEED_DEVIATION,
            FlightEventSeverity::CAUTION,
            "Speed deviation detected"
        );
        
        // Add event-specific data
        event.numericData["actualSpeed"] = current.indicatedAirspeed;
        event.numericData["selectedSpeed"] = current.selectedSpeed;
        event.numericData["deviation"] = deviation;
        event.numericData["threshold"] = _parameters.speedDeviationThreshold;
        
        if (current.indicatedAirspeed > current.selectedSpeed) {
            event.textData["direction"] = "above";
        } else {
            event.textData["direction"] = "below";
        }
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectGearConfiguration(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check gear configuration against speed thresholds
    for (const auto& [speedThreshold, gearPosition] : _parameters.speedGearThresholds) {
        // Gear should be up above threshold, down below threshold
        if (current.indicatedAirspeed > speedThreshold && current.gearPosition != 0) {
            event = createEvent(
                current,
                FlightEventType::GEAR_CONFIGURATION,
                FlightEventSeverity::WARNING,
                "Gear should be retracted at this speed"
            );
            
            // Add event-specific data
            event.numericData["airspeed"] = current.indicatedAirspeed;
            event.numericData["gearPosition"] = current.gearPosition;
            event.numericData["speedThreshold"] = speedThreshold;
            
            return true;
        } else if (current.indicatedAirspeed < speedThreshold && current.gearPosition != gearPosition) {
            event = createEvent(
                current,
                FlightEventType::GEAR_CONFIGURATION,
                FlightEventSeverity::WARNING,
                "Gear should be extended at this speed"
            );
            
            // Add event-specific data
            event.numericData["airspeed"] = current.indicatedAirspeed;
            event.numericData["gearPosition"] = current.gearPosition;
            event.numericData["speedThreshold"] = speedThreshold;
            
            return true;
        }
    }
    
    return false;
}

bool EventDetector::detectFlapConfiguration(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check flap configuration against speed thresholds
    for (const auto& [speedThreshold, flapPosition] : _parameters.speedFlapThresholds) {
        // Flaps should not exceed position limit at this speed
        if (current.indicatedAirspeed > speedThreshold && current.flapsPosition > flapPosition) {
            event = createEvent(
                current,
                FlightEventType::FLAP_CONFIGURATION,
                FlightEventSeverity::CAUTION,
                "Flap setting too high for current airspeed"
            );
            
            // Add event-specific data
            event.numericData["airspeed"] = current.indicatedAirspeed;
            event.numericData["flapsPosition"] = current.flapsPosition;
            event.numericData["maxFlapsPosition"] = flapPosition;
            event.numericData["speedThreshold"] = speedThreshold;
            
            return true;
        }
    }
    
    return false;
}

bool EventDetector::detectSystemFailure(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check for any system failure
    if (current.failureActive || 
        !current.electricalSystemOk ||
        !current.hydraulicSystemOk ||
        !current.fuelSystemOk ||
        !current.engineSystemOk ||
        !current.avionicsSystemOk) {
        
        event = createEvent(
            current,
            FlightEventType::SYSTEM_FAILURE,
            FlightEventSeverity::CRITICAL,
            "System failure detected"
        );
        
        // Add event-specific data
        event.textData["failures"] = "";
        
        if (!current.electricalSystemOk) {
            event.textData["failures"] += "Electrical system; ";
        }
        if (!current.hydraulicSystemOk) {
            event.textData["failures"] += "Hydraulic system; ";
        }
        if (!current.fuelSystemOk) {
            event.textData["failures"] += "Fuel system; ";
        }
        if (!current.engineSystemOk) {
            event.textData["failures"] += "Engine system; ";
        }
        if (!current.avionicsSystemOk) {
            event.textData["failures"] += "Avionics system; ";
        }
        
        // Add specific failures from aircraft
        if (!current.activeFailures.empty()) {
            for (const auto& failure : current.activeFailures) {
                event.textData["failures"] += failure + "; ";
            }
        }
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectPhaseChange(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check for flight phase change
    if (current.phase != _lastPhase && current.phase != FlightPhase::UNKNOWN) {
        std::string phaseStr;
        
        switch (current.phase) {
            case FlightPhase::PREFLIGHT: phaseStr = "Preflight"; break;
            case FlightPhase::TAXI: phaseStr = "Taxi"; break;
            case FlightPhase::TAKEOFF: phaseStr = "Takeoff"; break;
            case FlightPhase::CLIMB: phaseStr = "Climb"; break;
            case FlightPhase::CRUISE: phaseStr = "Cruise"; break;
            case FlightPhase::DESCENT: phaseStr = "Descent"; break;
            case FlightPhase::APPROACH: phaseStr = "Approach"; break;
            case FlightPhase::LANDING: phaseStr = "Landing"; break;
            case FlightPhase::ROLLOUT: phaseStr = "Rollout"; break;
            case FlightPhase::GO_AROUND: phaseStr = "Go-around"; break;
            default: phaseStr = "Unknown";
        }
        
        event = createEvent(
            current,
            FlightEventType::PHASE_CHANGE,
            FlightEventSeverity::INFO,
            "Flight phase changed to: " + phaseStr
        );
        
        // Add event-specific data
        event.textData["newPhase"] = phaseStr;
        event.numericData["phaseValue"] = static_cast<int>(current.phase);
        
        std::string previousPhaseStr;
        switch (_lastPhase) {
            case FlightPhase::PREFLIGHT: previousPhaseStr = "Preflight"; break;
            case FlightPhase::TAXI: previousPhaseStr = "Taxi"; break;
            case FlightPhase::TAKEOFF: previousPhaseStr = "Takeoff"; break;
            case FlightPhase::CLIMB: previousPhaseStr = "Climb"; break;
            case FlightPhase::CRUISE: previousPhaseStr = "Cruise"; break;
            case FlightPhase::DESCENT: previousPhaseStr = "Descent"; break;
            case FlightPhase::APPROACH: previousPhaseStr = "Approach"; break;
            case FlightPhase::LANDING: previousPhaseStr = "Landing"; break;
            case FlightPhase::ROLLOUT: previousPhaseStr = "Rollout"; break;
            case FlightPhase::GO_AROUND: previousPhaseStr = "Go-around"; break;
            default: previousPhaseStr = "Unknown";
        }
        
        event.textData["previousPhase"] = previousPhaseStr;
        event.numericData["previousPhaseValue"] = static_cast<int>(_lastPhase);
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectNavigationDeviation(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check for ILS approach deviations (glideslope and localizer)
    if (current.phase == FlightPhase::APPROACH && 
        (std::abs(current.glideSlope) > _parameters.glideslopeDeviationThreshold ||
         std::abs(current.localizer) > _parameters.localizerDeviationThreshold)) {
        
        event = createEvent(
            current,
            FlightEventType::NAVIGATION_DEVIATION,
            FlightEventSeverity::CAUTION,
            "Navigation deviation detected"
        );
        
        // Add event-specific data
        event.numericData["glideslopeDeviation"] = current.glideSlope;
        event.numericData["localizerDeviation"] = current.localizer;
        event.numericData["glideslopeThreshold"] = _parameters.glideslopeDeviationThreshold;
        event.numericData["localizerThreshold"] = _parameters.localizerDeviationThreshold;
        
        if (std::abs(current.glideSlope) > _parameters.glideslopeDeviationThreshold) {
            event.textData["deviationType"] = "Glideslope";
            if (current.glideSlope > 0) {
                event.textData["direction"] = "Above glidepath";
            } else {
                event.textData["direction"] = "Below glidepath";
            }
        } else {
            event.textData["deviationType"] = "Localizer";
            if (current.localizer > 0) {
                event.textData["direction"] = "Right of centerline";
            } else {
                event.textData["direction"] = "Left of centerline";
            }
        }
        
        return true;
    }
    
    return false;
}

bool EventDetector::detectInstructorAction(const std::vector<FlightParameters>& data, FlightEvent& event) {
    if (data.empty()) {
        return false;
    }
    
    const auto& current = data.back();
    
    // Check for instructor actions
    if (current.instructorPause || current.instructorReset) {
        event = createEvent(
            current,
            FlightEventType::INSTRUCTOR_ACTION,
            FlightEventSeverity::INFO,
            "Instructor action detected"
        );
        
        // Add event-specific data
        if (current.instructorPause) {
            event.textData["action"] = "Pause";
        } else if (current.instructorReset) {
            event.textData["action"] = "Reset";
        }
        
        return true;
    }
    
    return false;
}

FlightEvent EventDetector::createEvent(
    const FlightParameters& params,
    FlightEventType type,
    FlightEventSeverity severity,
    const std::string& description) {
    
    FlightEvent event;
    event.timestamp = params.timestamp;
    event.sessionId = params.sessionId;
    event.type = type;
    event.severity = severity;
    event.description = description;
    
    // Copy key flight parameters
    event.latitude = params.latitude;
    event.longitude = params.longitude;
    event.altitude = params.altitude;
    event.heading = params.heading;
    event.pitch = params.pitch;
    event.roll = params.roll;
    event.indicatedAirspeed = params.indicatedAirspeed;
    
    return event;
}

} // namespace Simulator
} // namespace PilotTraining

# Expanded Code Generation Prompt for Advanced Pilot Training Platform

## Overall Architecture & Code Organization Instructions

When generating code for the Advanced Pilot Training Platform, follow these organizational principles:

1. **Modular Structure**:
   - Create separate modules for each major subsystem (document processing, syllabus management, assessment, etc.)
   - Use namespaces to isolate functionality and prevent naming conflicts
   - Design clear boundaries between components with well-defined interfaces

2. **Directory Organization**:
   ```
   /src
     /backend
       /core            # Core functionality and shared utilities
       /document        # Document processing pipeline 
       /syllabus        # Syllabus generation and management
       /assessment      # Assessment and grading system
       /users           # User management and authentication
       /api             # API endpoints and controllers
       /compliance      # Regulatory compliance engine
       /simulator       # Simulator integration components
       /analytics       # Performance analytics and reporting
     /frontend
       /components      # Reusable UI components
       /pages           # Page-level components
       /hooks           # Custom React hooks
       /services        # API integration services
       /utils           # Frontend utilities
       /styles          # Global styles and themes
       /assets          # Static assets
   ```

3. **Code Style and Standards**:
   - C++ Backend: Follow Modern C++ (17/20) best practices
   - React Frontend: Use TypeScript with consistent type definitions
   - Use meaningful variable and function names with proper documentation
   - Include unit tests for all components
   - Implement error handling at appropriate levels

## Backend Code Generation - C++ Components

### 1. Core Framework Components

Generate core C++ classes and utilities that will be used throughout the backend:

```cpp
// Example request for code generation:
// Create a ConfigurationManager class that handles application-wide settings with support for:
// - Loading from multiple sources (environment, files, database)
// - Type-safe access to configuration values
// - Change notification and validation
// - Thread safety for concurrent access
```

### 2. Document Processing Pipeline

Generate the C++ classes for the document processing pipeline with these specific capabilities:

```cpp
// Generate a DocumentProcessor abstract base class and concrete implementations for different 
// document types (PDF, DOCX, XLSX, HTML) with:
// - Document parsing and text extraction
// - Structure recognition (headings, sections, tables)
// - Content classification with machine learning integration
// - Document comparison functionality
// - Asynchronous processing with progress tracking
```

### 3. Syllabus Generation Engine

The syllabus generation engine should parse training materials and regulatory documents to extract structured syllabus elements:

```cpp
// Generate a SyllabusGenerator class that:
// - Processes parsed documents to identify training requirements
// - Extracts learning objectives and competency areas
// - Creates structured syllabus components (modules, lessons, exercises)
// - Maps regulatory requirements to training elements
// - Handles template-based generation with customization
```

### 4. Real-time Data Processing 

For the real-time data processing component, generate code that can handle high-frequency simulator data:

```cpp
// Create a SimulatorDataProcessor that:
// - Processes simulator telemetry at 1000Hz
// - Implements lockless concurrent data structures
// - Performs real-time analysis of flight parameters
// - Detects events and anomalies in flight data
// - Provides both real-time and historical data access
```

### 5. API Gateway Implementation

Generate the code for the API gateway that serves as the interface between frontend and backend:

```cpp
// Create a RESTful API implementation using the Drogon framework with:
// - Authentication middleware with JWT support
// - Request validation and sanitization
// - Rate limiting and throttling
// - API versioning support
// - Comprehensive error handling and logging
// - OpenAPI documentation generation
```

### 6. Database Access Layer

Generate the database access layer with proper connection management and query building:

```cpp
// Create a DatabaseManager with:
// - Connection pooling for PostgreSQL
// - Prepared statement caching
// - Transaction management
// - Query builders for common operations
// - Time-series data handling for telemetry
// - Migration system for schema evolution
```

## Frontend Code Generation - React Components

### 1. Component Library Foundation

Generate the base component library that will be used throughout the application:

```typescript
// Create a set of base UI components including:
// - Button, Input, Select with proper accessibility
// - Form components with validation integration
// - Data visualization components (charts, graphs)
// - Navigation components (tabs, pagination)
// - Feedback components (alerts, notifications)
// - Modal and dialog components
```

### 2. Syllabus Builder Interface

Generate the React components for the syllabus builder with drag-and-drop functionality:

```typescript
// Create a SyllabusBuilder component that:
// - Supports drag-and-drop of modules and lessons
// - Provides an intuitive tree-view of the syllabus structure
// - Allows inline editing of syllabus elements
// - Shows regulatory compliance status visually
// - Enables template application and customization
```

### 3. Document Upload and Management

Generate the document upload and management interface:

```typescript
// Create a DocumentManagement component that:
// - Supports drag-and-drop file uploads with progress tracking
// - Handles batch uploads with status tracking
// - Provides document preview capabilities
// - Shows document processing status and results
// - Enables document organization and categorization
```

### 4. Assessment and Grading Interface

Generate the instructor assessment interface with efficient grading workflows:

```typescript
// Create an AssessmentInterface component that:
// - Implements one-click grading on a 1-4 scale
// - Provides competency-based assessment forms
// - Shows performance trends and comparisons
// - Enables digital signature capture
// - Supports offline assessment with synchronization
```

### 5. Analytics Dashboard

Generate the analytics dashboard with customizable views:

```typescript
// Create an AnalyticsDashboard component that:
// - Displays key performance indicators with drill-down
// - Shows training program effectiveness metrics
// - Provides compliance status visualization
// - Enables custom report generation
// - Supports both fleet-wide and individual trainee views
```

## AI Integration Code Generation

### 1. Document Understanding Models

Generate code for document understanding and processing:

```python
# Create document processing pipelines using transformers for:
# - Document classification by type and content
# - Training requirement extraction from text
# - Named entity recognition for aviation-specific terms
# - Relationship extraction between entities
# - Text summarization for document overviews
```

### 2. Training Content Classification

Generate code for classifying and organizing training content:

```python
# Create a content classification system that:
# - Categorizes training material by type and difficulty
# - Identifies learning objectives and outcomes
# - Maps content to competency frameworks
# - Suggests appropriate assessment methods
# - Groups related content for module creation
```

### 3. Performance Prediction Models

Generate code for performance analytics and prediction:

```python
# Create performance prediction models that:
# - Identify early indicators of training challenges
# - Predict checkride outcomes based on training data
# - Model skill decay and recommend refresher timing
# - Benchmark performance against population norms
# - Suggest personalized training interventions
```

## Document Processing Pipeline

Generate comprehensive code for the document processing pipeline which is a core feature:

```cpp
// Create a complete document processing pipeline that:

// 1. Document Ingestion
// - Accepts multiple file formats (PDF, DOCX, XLSX, HTML, PPTX)
// - Validates file integrity and structure
// - Extracts text while preserving layout information
// - Handles OCR for image-based content
// - Processes tables and structured data

// 2. Content Extraction
// - Identifies document structure (headings, sections, paragraphs)
// - Extracts training procedures and requirements
// - Recognizes regulatory references and citations
// - Identifies learning objectives and competencies
// - Detects assessment criteria and standards

// 3. Syllabus Structure Generation
// - Creates program structure based on extracted content
// - Organizes content into logical training phases
// - Sequences elements based on dependencies
// - Allocates time and resources to training elements
// - Maps regulatory requirements to training activities

// 4. Quality Assurance
// - Validates completeness against requirements
// - Identifies potential gaps in training coverage
// - Checks for logical consistency and sequencing
// - Verifies regulatory compliance of generated syllabus
// - Provides confidence scores for extraction quality
```

## Syllabus Customization Features

Generate code for the syllabus customization features which are a key requirement:

```typescript
// Create a SyllabusCustomization component that:

// 1. Visual Editor
// - Drag-and-drop interface for reordering elements
// - Visual indicators for compliance impact of changes
// - Inline editing of exercise details and parameters
// - Template application with customization options
// - Version comparison with highlighted differences

// 2. Compliance Checking
// - Real-time validation against regulatory requirements
// - Visual indicators for compliance status
// - Impact analysis for proposed changes
// - Automatic validation of dependencies
// - Approval workflow for significant modifications

// 3. Content Management
// - Exercise library with searchable categorization
// - Best practice recommendations during editing
// - Content reuse across training programs
// - Bulk modification tools for consistent changes
// - Change history tracking with reversion capability
```

## Specific Implementation Guidelines

When generating code for specific components, follow these guidelines:

1. **Error Handling**:
   ```cpp
   // C++ Backend
   try {
     // Operation that might fail
   } catch (const DatabaseException& e) {
     // Log the error with context
     Logger::error("Database operation failed: {}", e.what());
     // Provide appropriate recovery or fallback
     return Result<T>::failure(ErrorCode::DatabaseError, e.what());
   }
   ```

   ```typescript
   // React Frontend
   try {
     const result = await apiService.fetchData();
     setData(result);
   } catch (error) {
     setError(error.message);
     errorReporting.captureException(error, {
       context: 'Fetching data in ComponentName'
     });
   } finally {
     setLoading(false);
   }
   ```

2. **API Endpoints**:
   ```cpp
   // Controller definition with proper documentation
   /**
    * @api {post} /api/v1/documents Upload a document
    * @apiName UploadDocument
    * @apiGroup Documents
    * @apiVersion 1.0.0
    * 
    * @apiParam {File} document The document file to upload
    * @apiParam {String} type Document type
    * 
    * @apiSuccess {String} id The document ID
    * @apiSuccess {String} status Processing status
    * 
    * @apiError (400) BadRequest Invalid document format
    * @apiError (401) Unauthorized Authentication required
    */
   void uploadDocument(const HttpRequestPtr& req, std::function<void(const HttpResponsePtr&)>&& callback) {
     // Implementation
   }
   ```

3. **Database Operations**:
   ```cpp
   // Repository pattern implementation
   class DocumentRepository {
   public:
     Result<Document> findById(const std::string& id);
     Result<std::vector<Document>> findByOrganization(const std::string& orgId);
     Result<void> save(const Document& document);
     Result<void> update(const Document& document);
     Result<void> remove(const std::string& id);
   
   private:
     DatabaseConnection _connection;
     PreparedStatement _findByIdStmt;
     PreparedStatement _findByOrgStmt;
     PreparedStatement _insertStmt;
     PreparedStatement _updateStmt;
     PreparedStatement _deleteStmt;
   };
   ```

4. **React Components**:
   ```typescript
   // Functional component with TypeScript
   interface DocumentListProps {
     organizationId: string;
     filters?: DocumentFilters;
     onSelect?: (doc: Document) => void;
   }
   
   const DocumentList: React.FC<DocumentListProps> = ({
     organizationId,
     filters = {},
     onSelect
   }) => {
     const [documents, setDocuments] = useState<Document[]>([]);
     const [loading, setLoading] = useState<boolean>(true);
     const [error, setError] = useState<string | null>(null);
     
     useEffect(() => {
       // Fetch documents logic
     }, [organizationId, filters]);
     
     // Component rendering
   };
   ```

## Performance Optimization Guidelines

When generating performance-critical code, especially for the C++ backend, follow these guidelines:

1. **Memory Management**:
   ```cpp
   // Use memory pools for frequent allocations
   class MemoryPool {
   public:
     template<typename T, typename... Args>
     T* allocate(Args&&... args);
     
     template<typename T>
     void deallocate(T* ptr);
     
   private:
     // Implementation details
   };
   
   // Usage
   auto ptr = memoryPool.allocate<SomeObject>(arg1, arg2);
   // Later
   memoryPool.deallocate(ptr);
   ```

2. **Lock-free Data Structures**:
   ```cpp
   // Lock-free queue for high-performance data processing
   template<typename T>
   class LockFreeQueue {
   public:
     bool enqueue(T value);
     bool dequeue(T& result);
     std::size_t size() const;
     
   private:
     // Implementation using atomic operations
   };
   ```

3. **SIMD Optimizations**:
   ```cpp
   // Utilize SIMD intrinsics for data processing
   void processTelemetryData(const float* data, std::size_t count, float* results) {
     // Process data in chunks of 4 using SSE instructions
     for (std::size_t i = 0; i < count; i += 4) {
       // SIMD implementation
     }
     
     // Handle remaining elements
     for (std::size_t i = count - (count % 4); i < count; ++i) {
       // Scalar implementation
     }
   }
   ```

## Testing Requirements

All generated code should include comprehensive tests:

1. **Unit Tests**:
   ```cpp
   // C++ unit test using Google Test
   TEST(DocumentProcessor, ExtractsTextFromPDF) {
     // Arrange
     DocumentProcessor processor;
     auto testFile = TestFiles::getPdfTestFile("sample.pdf");
     
     // Act
     auto result = processor.process(testFile);
     
     // Assert
     ASSERT_TRUE(result.isSuccess());
     EXPECT_FALSE(result.value().extractedText.empty());
     EXPECT_GE(result.value().confidence, 0.8);
   }
   ```

   ```typescript
   // React component test using Jest and Testing Library
   test('renders document list with correct items', async () => {
     // Arrange
     const mockDocuments = [/* test data */];
     apiService.fetchDocuments.mockResolvedValue(mockDocuments);
     
     // Act
     render(<DocumentList organizationId="org-123" />);
     await waitForElementToBeRemoved(() => screen.getByTestId('loading'));
     
     // Assert
     expect(screen.getAllByRole('listitem')).toHaveLength(mockDocuments.length);
   });
   ```

2. **Integration Tests**:
   ```cpp
   // C++ integration test
   TEST_F(DocumentProcessingIntegrationTest, ProcessingPipelineEndToEnd) {
     // Setup test environment
     auto db = TestDatabase::createTemporary();
     auto processor = createProcessorWithDependencies(db);
     
     // Execute complete pipeline
     auto result = processor.processDocument(TestFiles::getSampleTrainingManual());
     
     // Verify results across system boundaries
     ASSERT_TRUE(result.isSuccess());
     auto savedDoc = db->findDocument(result.value().documentId);
     ASSERT_TRUE(savedDoc.isSuccess());
     EXPECT_EQ(savedDoc.value().status, DocumentStatus::Processed);
     // Additional assertions
   }
   ```

## Implementation Priorities

When generating code, prioritize these critical features:

1. **Document Processing Pipeline**: The foundation of AI-driven syllabus generation
2. **Syllabus Builder Interface**: The primary user interface for training customization
3. **Compliance Checking Engine**: Essential for regulatory validation
4. **Assessment System**: Core functionality for trainee evaluation
5. **User Management & Authentication**: Required for secure access

## Specific Feature Implementations

### AI-Powered Syllabus Generation

The AI-powered syllabus generation should handle these steps:

1. **Document Understanding**:
   ```cpp
   // Document understanding pipeline
   class DocumentUnderstandingPipeline {
   public:
     Result<DocumentAnalysis> analyze(const Document& document);
     
   private:
     TextExtractionComponent _textExtractor;
     StructureRecognitionComponent _structureRecognizer;
     EntityExtractionComponent _entityExtractor;
     RelationshipDetectionComponent _relationDetector;
     RegulationMappingComponent _regulationMapper;
   };
   ```

2. **Training Structure Creation**:
   ```cpp
   // Training structure generator
   class TrainingStructureGenerator {
   public:
     Result<SyllabusStructure> generateStructure(
       const std::vector<DocumentAnalysis>& analyses,
       const SyllabusTemplate& baseTemplate,
       const RegulatoryCriteria& criteria
     );
     
   private:
     // Implementation components
   };
   ```

### Custom Exercise Management

For the exercise customization capabilities:

```typescript
// Exercise editor component
interface ExerciseEditorProps {
  exercise: TrainingExercise;
  onChange: (updated: TrainingExercise) => void;
  onValidate: (exercise: TrainingExercise) => Promise<ValidationResult>;
}

const ExerciseEditor: React.FC<ExerciseEditorProps> = ({
  exercise,
  onChange,
  onValidate
}) => {
  // State and handlers
  
  return (
    <div className="exercise-editor">
      {/* Editor components */}
      <ExerciseDetails 
        exercise={exercise} 
        onChange={handleDetailsChange} 
      />
      <LearningObjectives 
        objectives={exercise.objectives}
        onChange={handleObjectivesChange}
      />
      <AssessmentCriteria 
        criteria={exercise.assessmentCriteria}
        onChange={handleCriteriaChange}
      />
      <Resources 
        resources={exercise.resources}
        onChange={handleResourcesChange}
      />
      {/* Compliance indicators */}
      <ComplianceStatus 
        validationResult={validationResult}
        isLoading={validating}
      />
    </div>
  );
};
```

## Conclusion and Final Instructions

When generating code for this Advanced Pilot Training Platform:

1. Focus on creating maintainable, modular code that follows the specified architecture
2. Prioritize the core features: document processing, syllabus management, and compliance checking
3. Ensure all generated code includes proper error handling, logging, and testing
4. Pay special attention to performance optimizations for real-time components
5. Include detailed comments and documentation for all public interfaces
6. Follow security best practices throughout all components
7. Implement proper separation of concerns between frontend and backend
8. Ensure the system supports the full customization flow from document upload through syllabus generation and modification

Generate complete implementations rather than skeleton code, focusing on functional completeness and adherence to requirements. Each component should be able to operate independently while integrating smoothly with the overall system architecture.
# Expanded Code Generation Prompt for Advanced Pilot Training Platform

## Overall Architecture & Code Organization Instructions

When generating code for the Advanced Pilot Training Platform, follow these organizational principles:

1. **Modular Structure**:
   - Create separate modules for each major subsystem (document processing, syllabus management, assessment, etc.)
   - Use namespaces to isolate functionality and prevent naming conflicts
   - Design clear boundaries between components with well-defined interfaces

2. **Directory Organization**:
   ```
   /src
     /backend
       /core            # Core functionality and shared utilities
       /document        # Document processing pipeline 
       /syllabus        # Syllabus generation and management
       /assessment      # Assessment and grading system
       /users           # User management and authentication
       /api             # API endpoints and controllers
       /compliance      # Regulatory compliance engine
       /simulator       # Simulator integration components
       /analytics       # Performance analytics and reporting
     /frontend
       /components      # Reusable UI components
       /pages           # Page-level components
       /hooks           # Custom React hooks
       /services        # API integration services
       /utils           # Frontend utilities
       /styles          # Global styles and themes
       /assets          # Static assets
   ```

3. **Code Style and Standards**:
   - C++ Backend: Follow Modern C++ (17/20) best practices
   - React Frontend: Use TypeScript with consistent type definitions
   - Use meaningful variable and function names with proper documentation
   - Include unit tests for all components
   - Implement error handling at appropriate levels

## Backend Code Generation - C++ Components

### 1. Core Framework Components

Generate core C++ classes and utilities that will be used throughout the backend:

```cpp
// Example request for code generation:
// Create a ConfigurationManager class that handles application-wide settings with support for:
// - Loading from multiple sources (environment, files, database)
// - Type-safe access to configuration values
// - Change notification and validation
// - Thread safety for concurrent access
```

### 2. Document Processing Pipeline

Generate the C++ classes for the document processing pipeline with these specific capabilities:

```cpp
// Generate a DocumentProcessor abstract base class and concrete implementations for different 
// document types (PDF, DOCX, XLSX, HTML) with:
// - Document parsing and text extraction
// - Structure recognition (headings, sections, tables)
// - Content classification with machine learning integration
// - Document comparison functionality
// - Asynchronous processing with progress tracking
```

### 3. Syllabus Generation Engine

The syllabus generation engine should parse training materials and regulatory documents to extract structured syllabus elements:

```cpp
// Generate a SyllabusGenerator class that:
// - Processes parsed documents to identify training requirements
// - Extracts learning objectives and competency areas
// - Creates structured syllabus components (modules, lessons, exercises)
// - Maps regulatory requirements to training elements
// - Handles template-based generation with customization
```

### 4. Real-time Data Processing 

For the real-time data processing component, generate code that can handle high-frequency simulator data:

```cpp
// Create a SimulatorDataProcessor that:
// - Processes simulator telemetry at 1000Hz
// - Implements lockless concurrent data structures
// - Performs real-time analysis of flight parameters
// - Detects events and anomalies in flight data
// - Provides both real-time and historical data access
```

### 5. API Gateway Implementation

Generate the code for the API gateway that serves as the interface between frontend and backend:

```cpp
// Create a RESTful API implementation using the Drogon framework with:
// - Authentication middleware with JWT support
// - Request validation and sanitization
// - Rate limiting and throttling
// - API versioning support
// - Comprehensive error handling and logging
// - OpenAPI documentation generation
```

### 6. Database Access Layer

Generate the database access layer with proper connection management and query building:

```cpp
// Create a DatabaseManager with:
// - Connection pooling for PostgreSQL
// - Prepared statement caching
// - Transaction management
// - Query builders for common operations
// - Time-series data handling for telemetry
// - Migration system for schema evolution
```

## Frontend Code Generation - React Components

### 1. Component Library Foundation

Generate the base component library that will be used throughout the application:

```typescript
// Create a set of base UI components including:
// - Button, Input, Select with proper accessibility
// - Form components with validation integration
// - Data visualization components (charts, graphs)
// - Navigation components (tabs, pagination)
// - Feedback components (alerts, notifications)
// - Modal and dialog components
```

### 2. Syllabus Builder Interface

Generate the React components for the syllabus builder with drag-and-drop functionality:

```typescript
// Create a SyllabusBuilder component that:
// - Supports drag-and-drop of modules and lessons
// - Provides an intuitive tree-view of the syllabus structure
// - Allows inline editing of syllabus elements
// - Shows regulatory compliance status visually
// - Enables template application and customization
```

### 3. Document Upload and Management

Generate the document upload and management interface:

```typescript
// Create a DocumentManagement component that:
// - Supports drag-and-drop file uploads with progress tracking
// - Handles batch uploads with status tracking
// - Provides document preview capabilities
// - Shows document processing status and results
// - Enables document organization and categorization
```

### 4. Assessment and Grading Interface

Generate the instructor assessment interface with efficient grading workflows:

```typescript
// Create an AssessmentInterface component that:
// - Implements one-click grading on a 1-4 scale
// - Provides competency-based assessment forms
// - Shows performance trends and comparisons
// - Enables digital signature capture
// - Supports offline assessment with synchronization
```

### 5. Analytics Dashboard

Generate the analytics dashboard with customizable views:

```typescript
// Create an AnalyticsDashboard component that:
// - Displays key performance indicators with drill-down
// - Shows training program effectiveness metrics
// - Provides compliance status visualization
// - Enables custom report generation
// - Supports both fleet-wide and individual trainee views
```

## AI Integration Code Generation

### 1. Document Understanding Models

Generate code for document understanding and processing:

```python
# Create document processing pipelines using transformers for:
# - Document classification by type and content
# - Training requirement extraction from text
# - Named entity recognition for aviation-specific terms
# - Relationship extraction between entities
# - Text summarization for document overviews
```

### 2. Training Content Classification

Generate code for classifying and organizing training content:

```python
# Create a content classification system that:
# - Categorizes training material by type and difficulty
# - Identifies learning objectives and outcomes
# - Maps content to competency frameworks
# - Suggests appropriate assessment methods
# - Groups related content for module creation
```

### 3. Performance Prediction Models

Generate code for performance analytics and prediction:

```python
# Create performance prediction models that:
# - Identify early indicators of training challenges
# - Predict checkride outcomes based on training data
# - Model skill decay and recommend refresher timing
# - Benchmark performance against population norms
# - Suggest personalized training interventions
```

## Document Processing Pipeline

Generate comprehensive code for the document processing pipeline which is a core feature:

```cpp
// Create a complete document processing pipeline that:

// 1. Document Ingestion
// - Accepts multiple file formats (PDF, DOCX, XLSX, HTML, PPTX)
// - Validates file integrity and structure
// - Extracts text while preserving layout information
// - Handles OCR for image-based content
// - Processes tables and structured data

// 2. Content Extraction
// - Identifies document structure (headings, sections, paragraphs)
// - Extracts training procedures and requirements
// - Recognizes regulatory references and citations
// - Identifies learning objectives and competencies
// - Detects assessment criteria and standards

// 3. Syllabus Structure Generation
// - Creates program structure based on extracted content
// - Organizes content into logical training phases
// - Sequences elements based on dependencies
// - Allocates time and resources to training elements
// - Maps regulatory requirements to training activities

// 4. Quality Assurance
// - Validates completeness against requirements
// - Identifies potential gaps in training coverage
// - Checks for logical consistency and sequencing
// - Verifies regulatory compliance of generated syllabus
// - Provides confidence scores for extraction quality
```

## Syllabus Customization Features

Generate code for the syllabus customization features which are a key requirement:

```typescript
// Create a SyllabusCustomization component that:

// 1. Visual Editor
// - Drag-and-drop interface for reordering elements
// - Visual indicators for compliance impact of changes
// - Inline editing of exercise details and parameters
// - Template application with customization options
// - Version comparison with highlighted differences

// 2. Compliance Checking
// - Real-time validation against regulatory requirements
// - Visual indicators for compliance status
// - Impact analysis for proposed changes
// - Automatic validation of dependencies
// - Approval workflow for significant modifications

// 3. Content Management
// - Exercise library with searchable categorization
// - Best practice recommendations during editing
// - Content reuse across training programs
// - Bulk modification tools for consistent changes
// - Change history tracking with reversion capability
```

## Specific Implementation Guidelines

When generating code for specific components, follow these guidelines:

1. **Error Handling**:
   ```cpp
   // C++ Backend
   try {
     // Operation that might fail
   } catch (const DatabaseException& e) {
     // Log the error with context
     Logger::error("Database operation failed: {}", e.what());
     // Provide appropriate recovery or fallback
     return Result<T>::failure(ErrorCode::DatabaseError, e.what());
   }
   ```

   ```typescript
   // React Frontend
   try {
     const result = await apiService.fetchData();
     setData(result);
   } catch (error) {
     setError(error.message);
     errorReporting.captureException(error, {
       context: 'Fetching data in ComponentName'
     });
   } finally {
     setLoading(false);
   }
   ```

2. **API Endpoints**:
   ```cpp
   // Controller definition with proper documentation
   /**
    * @api {post} /api/v1/documents Upload a document
    * @apiName UploadDocument
    * @apiGroup Documents
    * @apiVersion 1.0.0
    * 
    * @apiParam {File} document The document file to upload
    * @apiParam {String} type Document type
    * 
    * @apiSuccess {String} id The document ID
    * @apiSuccess {String} status Processing status
    * 
    * @apiError (400) BadRequest Invalid document format
    * @apiError (401) Unauthorized Authentication required
    */
   void uploadDocument(const HttpRequestPtr& req, std::function<void(const HttpResponsePtr&)>&& callback) {
     // Implementation
   }
   ```

3. **Database Operations**:
   ```cpp
   // Repository pattern implementation
   class DocumentRepository {
   public:
     Result<Document> findById(const std::string& id);
     Result<std::vector<Document>> findByOrganization(const std::string& orgId);
     Result<void> save(const Document& document);
     Result<void> update(const Document& document);
     Result<void> remove(const std::string& id);
   
   private:
     DatabaseConnection _connection;
     PreparedStatement _findByIdStmt;
     PreparedStatement _findByOrgStmt;
     PreparedStatement _insertStmt;
     PreparedStatement _updateStmt;
     PreparedStatement _deleteStmt;
   };
   ```

4. **React Components**:
   ```typescript
   // Functional component with TypeScript
   interface DocumentListProps {
     organizationId: string;
     filters?: DocumentFilters;
     onSelect?: (doc: Document) => void;
   }
   
   const DocumentList: React.FC<DocumentListProps> = ({
     organizationId,
     filters = {},
     onSelect
   }) => {
     const [documents, setDocuments] = useState<Document[]>([]);
     const [loading, setLoading] = useState<boolean>(true);
     const [error, setError] = useState<string | null>(null);
     
     useEffect(() => {
       // Fetch documents logic
     }, [organizationId, filters]);
     
     // Component rendering
   };
   ```

## Performance Optimization Guidelines

When generating performance-critical code, especially for the C++ backend, follow these guidelines:

1. **Memory Management**:
   ```cpp
   // Use memory pools for frequent allocations
   class MemoryPool {
   public:
     template<typename T, typename... Args>
     T* allocate(Args&&... args);
     
     template<typename T>
     void deallocate(T* ptr);
     
   private:
     // Implementation details
   };
   
   // Usage
   auto ptr = memoryPool.allocate<SomeObject>(arg1, arg2);
   // Later
   memoryPool.deallocate(ptr);
   ```

2. **Lock-free Data Structures**:
   ```cpp
   // Lock-free queue for high-performance data processing
   template<typename T>
   class LockFreeQueue {
   public:
     bool enqueue(T value);
     bool dequeue(T& result);
     std::size_t size() const;
     
   private:
     // Implementation using atomic operations
   };
   ```

3. **SIMD Optimizations**:
   ```cpp
   // Utilize SIMD intrinsics for data processing
   void processTelemetryData(const float* data, std::size_t count, float* results) {
     // Process data in chunks of 4 using SSE instructions
     for (std::size_t i = 0; i < count; i += 4) {
       // SIMD implementation
     }
     
     // Handle remaining elements
     for (std::size_t i = count - (count % 4); i < count; ++i) {
       // Scalar implementation
     }
   }
   ```

## Testing Requirements

All generated code should include comprehensive tests:

1. **Unit Tests**:
   ```cpp
   // C++ unit test using Google Test
   TEST(DocumentProcessor, ExtractsTextFromPDF) {
     // Arrange
     DocumentProcessor processor;
     auto testFile = TestFiles::getPdfTestFile("sample.pdf");
     
     // Act
     auto result = processor.process(testFile);
     
     // Assert
     ASSERT_TRUE(result.isSuccess());
     EXPECT_FALSE(result.value().extractedText.empty());
     EXPECT_GE(result.value().confidence, 0.8);
   }
   ```

   ```typescript
   // React component test using Jest and Testing Library
   test('renders document list with correct items', async () => {
     // Arrange
     const mockDocuments = [/* test data */];
     apiService.fetchDocuments.mockResolvedValue(mockDocuments);
     
     // Act
     render(<DocumentList organizationId="org-123" />);
     await waitForElementToBeRemoved(() => screen.getByTestId('loading'));
     
     // Assert
     expect(screen.getAllByRole('listitem')).toHaveLength(mockDocuments.length);
   });
   ```

2. **Integration Tests**:
   ```cpp
   // C++ integration test
   TEST_F(DocumentProcessingIntegrationTest, ProcessingPipelineEndToEnd) {
     // Setup test environment
     auto db = TestDatabase::createTemporary();
     auto processor = createProcessorWithDependencies(db);
     
     // Execute complete pipeline
     auto result = processor.processDocument(TestFiles::getSampleTrainingManual());
     
     // Verify results across system boundaries
     ASSERT_TRUE(result.isSuccess());
     auto savedDoc = db->findDocument(result.value().documentId);
     ASSERT_TRUE(savedDoc.isSuccess());
     EXPECT_EQ(savedDoc.value().status, DocumentStatus::Processed);
     // Additional assertions
   }
   ```

## Implementation Priorities

When generating code, prioritize these critical features:

1. **Document Processing Pipeline**: The foundation of AI-driven syllabus generation
2. **Syllabus Builder Interface**: The primary user interface for training customization
3. **Compliance Checking Engine**: Essential for regulatory validation
4. **Assessment System**: Core functionality for trainee evaluation
5. **User Management & Authentication**: Required for secure access

## Specific Feature Implementations

### AI-Powered Syllabus Generation

The AI-powered syllabus generation should handle these steps:

1. **Document Understanding**:
   ```cpp
   // Document understanding pipeline
   class DocumentUnderstandingPipeline {
   public:
     Result<DocumentAnalysis> analyze(const Document& document);
     
   private:
     TextExtractionComponent _textExtractor;
     StructureRecognitionComponent _structureRecognizer;
     EntityExtractionComponent _entityExtractor;
     RelationshipDetectionComponent _relationDetector;
     RegulationMappingComponent _regulationMapper;
   };
   ```

2. **Training Structure Creation**:
   ```cpp
   // Training structure generator
   class TrainingStructureGenerator {
   public:
     Result<SyllabusStructure> generateStructure(
       const std::vector<DocumentAnalysis>& analyses,
       const SyllabusTemplate& baseTemplate,
       const RegulatoryCriteria& criteria
     );
     
   private:
     // Implementation components
   };
   ```

### Custom Exercise Management

For the exercise customization capabilities:

```typescript
// Exercise editor component
interface ExerciseEditorProps {
  exercise: TrainingExercise;
  onChange: (updated: TrainingExercise) => void;
  onValidate: (exercise: TrainingExercise) => Promise<ValidationResult>;
}

const ExerciseEditor: React.FC<ExerciseEditorProps> = ({
  exercise,
  onChange,
  onValidate
}) => {
  // State and handlers
  
  return (
    <div className="exercise-editor">
      {/* Editor components */}
      <ExerciseDetails 
        exercise={exercise} 
        onChange={handleDetailsChange} 
      />
      <LearningObjectives 
        objectives={exercise.objectives}
        onChange={handleObjectivesChange}
      />
      <AssessmentCriteria 
        criteria={exercise.assessmentCriteria}
        onChange={handleCriteriaChange}
      />
      <Resources 
        resources={exercise.resources}
        onChange={handleResourcesChange}
      />
      {/* Compliance indicators */}
      <ComplianceStatus 
        validationResult={validationResult}
        isLoading={validating}
      />
    </div>
  );
};
```

## Conclusion and Final Instructions

When generating code for this Advanced Pilot Training Platform:

1. Focus on creating maintainable, modular code that follows the specified architecture
2. Prioritize the core features: document processing, syllabus management, and compliance checking
3. Ensure all generated code includes proper error handling, logging, and testing
4. Pay special attention to performance optimizations for real-time components
5. Include detailed comments and documentation for all public interfaces
6. Follow security best practices throughout all components
7. Implement proper separation of concerns between frontend and backend
8. Ensure the system supports the full customization flow from document upload through syllabus generation and modification

Generate complete implementations rather than skeleton code, focusing on functional completeness and adherence to requirements. Each component should be able to operate independently while integrating smoothly with the overall system architecture.

// src/backend/simulator/FlightParameters.h
#pragma once

#include <string>
#include <vector>
#include <unordered_map>
#include <cstdint>
#include <array>

namespace PilotTraining {
namespace Simulator {

/**
 * @brief Type of aircraft
 */
enum class AircraftType {
    FIXED_WING,
    ROTARY_WING,
    OTHER
};

/**
 * @brief Flight phase
 */
enum class FlightPhase {
    UNKNOWN,
    PREFLIGHT,
    TAXI,
    TAKEOFF,
    CLIMB,
    CRUISE,
    DESCENT,
    APPROACH,
    LANDING,
    ROLLOUT,
    GO_AROUND
};

/**
 * @brief Weather conditions
 */
enum class WeatherConditions {
    VMC,  // Visual Meteorological Conditions
    IMC   // Instrument Meteorological Conditions
};

/**
 * @brief Comprehensive set of flight parameters
 * 
 * This structure contains all telemetry data for a single point in time,
 * including position, attitude, engine parameters, system states, etc.
 */
struct FlightParameters {
    // Timestamp and identification
    int64_t timestamp;       // Microseconds since epoch
    std::string sessionId;   // Training session identifier
    std::string aircraftId;  // Aircraft identifier
    AircraftType aircraftType = AircraftType::FIXED_WING;
    
    // Position and attitude
    double latitude;         // degrees, -90 to 90
    double longitude;        // degrees, -180 to 180
    double altitude;         // feet above mean sea level
    double heading;          // degrees, 0 to 360
    double pitch;            // degrees, -90 to 90
    double roll;             // degrees, -180 to 180
    double groundSpeed;      // knots
    double indicatedAirspeed; // knots
    double trueAirspeed;     // knots
    double verticalSpeed;    // feet per minute
    
    // Engine parameters (supports multi-engine aircraft)
    std::vector<double> engineRpm;       // RPM for each engine
    std::vector<double> enginePower;     // Power setting (%)
    std::vector<double> engineTemp;      // Temperature (C)
    std::vector<double> engineFuelFlow;  // Fuel flow (gallons/hour)
    std::vector<double> engineOilPressure; // Oil pressure (PSI)
    std::vector<double> engineOilTemp;   // Oil temperature (C)
    
    // Control inputs
    double controlPitch;     // Elevator/cyclic position, -1.0 to 1.0
    double controlRoll;      // Aileron/cyclic position, -1.0 to 1.0
    double controlYaw;       // Rudder/pedal position, -1.0 to 1.0
    double controlThrottle;  // Throttle position, 0.0 to 1.0
    double controlCollective; // Collective position (for rotary-wing), 0.0 to 1.0
    double controlFlaps;     // Flap position, 0.0 to 1.0
    double controlGear;      // Landing gear position, 0.0 to 1.0 (0=up, 1=down)
    double controlSpoilers;  // Spoiler/speedbrake position, 0.0 to 1.0
    
    // Navigation and autopilot
    bool autopilotEngaged;        // Is autopilot engaged
    int autopilotMode;            // Autopilot mode
    double selectedAltitude;      // Selected altitude (feet)
    double selectedHeading;       // Selected heading (degrees)
    double selectedSpeed;         // Selected speed (knots)
    double selectedVerticalSpeed; // Selected vertical speed (feet/minute)
    std::array<double, 2> navFrequency; // Navigation radio frequencies
    std::array<double, 2> comFrequency; // Communication radio frequencies
    std::string navMode;          // Navigation mode (e.g., NAV, VOR, ILS, GPS)
    
    // Aircraft configuration
    int flapsPosition;       // Flap position (notches/degrees)
    int gearPosition;        // Gear position (0=up, 1=in transit, 2=down)
    bool spoilersDeployed;   // Are spoilers/speedbrakes deployed
    double fuelRemaining;    // Total fuel remaining (gallons)
    std::vector<double> fuelTankLevels; // Fuel level in each tank (gallons)
    double grossWeight;      // Aircraft gross weight (pounds)
    
    // Environmental conditions
    double outsideAirTemp;   // Outside air temperature (C)
    double windSpeed;        // Wind speed (knots)
    double windDirection;    // Wind direction (degrees)
    double visibility;       // Visibility (statute miles)
    int cloudCeiling;        // Cloud ceiling (feet AGL)
    WeatherConditions weatherConditions = WeatherConditions::VMC;
    
    // Flight state
    FlightPhase phase = FlightPhase::UNKNOWN;
    bool onGround;           // Is the aircraft on the ground
    bool stall;              // Is the aircraft stalled
    bool overspeed;          // Is the aircraft overspeeding
    
    // System states
    bool electricalSystemOk; // Electrical system status
    bool hydraulicSystemOk;  // Hydraulic system status
    bool fuelSystemOk;       // Fuel system status
    bool engineSystemOk;     // Engine system status
    bool avionicsSystemOk;   // Avionics system status
    
    // Flight instructor inputs
    bool instructorPause;    // Has instructor paused the simulation
    bool instructorReset;    // Has instructor reset the simulation
    bool failureActive;      // Is any failure scenario active
    std::vector<std::string> activeFailures; // List of active failures
    
    // Performance metrics
    double glideSlope;       // Glide slope deviation (dots)
    double localizer;        // Localizer deviation (dots)
    double touchdownRate;    // Touchdown rate (feet/minute)
    double touchdownDistance; // Distance from runway threshold at touchdown (feet)
    double touchdownHeading; // Heading at touchdown (degrees)
    double touchdownPitch;   // Pitch at touchdown (degrees)
    double touchdownRoll;    // Roll at touchdown (degrees)
    
    // Additional fields for custom data
    std::unordered_map<std::string, double> customNumericData;
    std::unordered_map<std::string, std::string> customTextData;
    std::unordered_map<std::string, bool> customBoolData;
    
    // Constructors
    FlightParameters() : timestamp(0), latitude(0), longitude(0), altitude(0),
                        heading(0), pitch(0), roll(0), groundSpeed(0),
                        indicatedAirspeed(0), trueAirspeed(0), verticalSpeed(0),
                        controlPitch(0), controlRoll(0), controlYaw(0),
                        controlThrottle(0), controlCollective(0), controlFlaps(0),
                        controlGear(0), controlSpoilers(0), autopilotEngaged(false),
                        autopilotMode(0), selectedAltitude(0), selectedHeading(0),
                        selectedSpeed(0), selectedVerticalSpeed(0), flapsPosition(0),
                        gearPosition(0), spoilersDeployed(false), fuelRemaining(0),
                        grossWeight(0), outsideAirTemp(0), windSpeed(0),
                        windDirection(0), visibility(0), cloudCeiling(0),
                        onGround(true), stall(false), overspeed(false),
                        electricalSystemOk(true), hydraulicSystemOk(true),
                        fuelSystemOk(true), engineSystemOk(true), avionicsSystemOk(true),
                        instructorPause(false), instructorReset(false),
                        failureActive(false), glideSlope(0), localizer(0),
                        touchdownRate(0), touchdownDistance(0), touchdownHeading(0),
                        touchdownPitch(0), touchdownRoll(0) {
        // Initialize radio frequencies
        navFrequency = {0.0, 0.0};
        comFrequency = {0.0, 0.0};
    }
    
    // Simulate default parameters for a Cessna 172 at takeoff
    static FlightParameters createDefaultC172Parameters() {
        FlightParameters params;
        params.timestamp = 0;
        params.sessionId = "default-session";
        params.aircraftId = "C172";
        params.aircraftType = AircraftType::FIXED_WING;
        
        params.latitude = 37.621312;
        params.longitude = -122.378906;
        params.altitude = 10.0;
        params.heading = 270.0;
        params.pitch = 0.0;
        params.roll = 0.0;
        params.groundSpeed = 0.0;
        params.indicatedAirspeed = 0.0;
        params.trueAirspeed = 0.0;
        params.verticalSpeed = 0.0;
        
        // Engine parameters (single engine for C172)
        params.engineRpm = {0.0};
        params.enginePower = {0.0};
        params.engineTemp = {77.0};
        params.engineFuelFlow = {0.0};
        params.engineOilPressure = {78.0};
        params.engineOilTemp = {75.0};
        
        // Control inputs at idle
        params.controlPitch = 0.0;
        params.controlRoll = 0.0;
        params.controlYaw = 0.0;
        params.controlThrottle = 0.0;
        params.controlFlaps = 0.0;
        params.controlGear = 1.0; // Gear down (fixed gear on C172)
        params.controlSpoilers = 0.0;
        
        // Navigation and autopilot
        params.autopilotEngaged = false;
        params.selectedAltitude = 3000.0;
        params.selectedHeading = 270.0;
        params.selectedSpeed = 100.0;
        params.selectedVerticalSpeed = 500.0;
        params.navFrequency = {108.0, 0.0};
        params.comFrequency = {118.1, 0.0};
        params.navMode = "GPS";
        
        // Aircraft configuration
        params.flapsPosition = 0;
        params.gearPosition = 2; // Down (fixed gear)
        params.spoilersDeployed = false;
        params.fuelRemaining = 40.0;
        params.fuelTankLevels = {20.0, 20.0}; // Left and right tanks
        params.grossWeight = 2300.0;
        
        // Environmental conditions
        params.outsideAirTemp = 15.0;
        params.windSpeed = 5.0;
        params.windDirection = 270.0;
        params.visibility = 10.0;
        params.cloudCeiling = 3000;
        params.weatherConditions = WeatherConditions::VMC;
        
        // Flight state
        params.phase = FlightPhase::PREFLIGHT;
        params.onGround = true;
        params.stall = false;
        params.overspeed = false;
        
        // System states
        params.electricalSystemOk = true;
        params.hydraulicSystemOk = true;
        params.fuelSystemOk = true;
        params.engineSystemOk = true;
        params.avionicsSystemOk = true;
        
        // Instructor inputs
        params.instructorPause = false;
        params.instructorReset = false;
        params.failureActive = false;
        
        return params;
    }
};

/**
 * @brief Flight event type
 */
enum class FlightEventType {
    TAKEOFF,
    LANDING,
    STALL,
    OVERSPEED,
    BANK_ANGLE_EXCEEDED,
    PITCH_ANGLE_EXCEEDED,
    ALTITUDE_DEVIATION,
    HEADING_DEVIATION,
    SPEED_DEVIATION,
    GEAR_CONFIGURATION,
    FLAP_CONFIGURATION,
    SYSTEM_FAILURE,
    PHASE_CHANGE,
    NAVIGATION_DEVIATION,
    INSTRUCTOR_ACTION,
    CUSTOM
};

/**
 * @brief Flight event severity
 */
enum class FlightEventSeverity {
    INFO,
    WARNING,
    CAUTION,
    CRITICAL
};

/**
 * @brief Flight event detected during simulation
 */
struct FlightEvent {
    int64_t timestamp;            // Event timestamp (microseconds since epoch)
    std::string sessionId;        // Training session identifier
    FlightEventType type;         // Event type
    FlightEventSeverity severity; // Event severity
    std::string description;      // Human-readable description
    
    // Event-specific data
    std::unordered_map<std::string, double> numericData;
    std::unordered_map<std::string, std::string> textData;
    
    // Snapshot of key flight parameters at event time
    double latitude;
    double longitude;
    double altitude;
    double heading;
    double pitch;
    double roll;
    double indicatedAirspeed;
    
    FlightEvent() : timestamp(0), type(FlightEventType::CUSTOM),
                   severity(FlightEventSeverity::INFO), latitude(0), longitude(0),
                   altitude(0), heading(0), pitch(0), roll(0), indicatedAirspeed(0) {}
};

/**
 * @brief Flight anomaly type
 */
enum class FlightAnomalyType {
    CONTROL_INPUT_ANOMALY,
    INSTRUMENT_ANOMALY,
    NAVIGATION_ANOMALY,
    SYSTEM_ANOMALY,
    TRAJECTORY_ANOMALY,
    PROCEDURE_ANOMALY,
    COMMUNICATION_ANOMALY,
    CUSTOM
};

/**
 * @brief Flight anomaly detected during simulation
 */
struct FlightAnomaly {
    int64_t timestamp;            // Anomaly timestamp (microseconds since epoch)
    std::string sessionId;        // Training session identifier
    FlightAnomalyType type;       // Anomaly type
    double confidence;            // Detection confidence (0.0 to 1.0)
    std::string description;      // Human-readable description
    
    // Anomaly-specific data
    std::unordered_map<std::string, double> parameters;
    std::string expectedBehavior;
    std::string actualBehavior;
    
    // Reference to normal behavior model
    std::string modelReference;
    double deviationScore;
    
    FlightAnomaly() : timestamp(0), type(FlightAnomalyType::CUSTOM),
                     confidence(0.0), deviationScore(0.0) {}
};

/**
 * @brief Parameters for event detection
 */
struct EventDetectionParameters {
    double bankAngleThreshold;    // Maximum bank angle (degrees)
    double pitchAngleThreshold;   // Maximum pitch angle (degrees)
    double altitudeDeviationThreshold; // Maximum altitude deviation (feet)
    double headingDeviationThreshold;  // Maximum heading deviation (degrees)
    double speedDeviationThreshold;    // Maximum speed deviation (knots)
    double vsiThreshold;          // Maximum vertical speed (feet/minute)
    double glideslopeDeviationThreshold; // Maximum glideslope deviation (dots)
    double localizerDeviationThreshold;  // Maximum localizer deviation (dots)
    
    // Gear and flap configuration thresholds
    std::vector<std::pair<double, int>> speedGearThresholds; // Speed/gear position pairs
    std::vector<std::pair<double, int>> speedFlapThresholds; // Speed/flap position pairs
    
    EventDetectionParameters() : bankAngleThreshold(45.0), pitchAngleThreshold(30.0),
                                altitudeDeviationThreshold(200.0), headingDeviationThreshold(10.0),
                                speedDeviationThreshold(10.0), vsiThreshold(1000.0),
                                glideslopeDeviationThreshold(1.0), localizerDeviationThreshold(1.0) {
        // Default gear speed thresholds (knots/position)
        speedGearThresholds = {{140, 0}, {120, 1}}; // Gear up above 140, down below 120
        
        // Default flap speed thresholds (knots/position)
        speedFlapThresholds = {{120, 0}, {100, 1}, {80, 2}}; // Various flap settings
    }
};

/**
 * @brief Parameters for anomaly detection
 */
struct AnomalyDetectionParameters {
    double confidenceThreshold;   // Minimum confidence for detection (0.0 to 1.0)
    double controlInputDeviation; // Anomalous control input deviation threshold
    double trajectoryDeviation;   // Anomalous trajectory deviation threshold
    double systemParameterDeviation; // Anomalous system parameter deviation threshold
    double procedureComplianceThreshold; // Procedure compliance threshold (0.0 to 1.0)
    
    AnomalyDetectionParameters() : confidenceThreshold(0.7), controlInputDeviation(0.5),
                                  trajectoryDeviation(0.5), systemParameterDeviation(0.5),
                                  procedureComplianceThreshold(0.8) {}
};

} // namespace Simulator
} // namespace PilotTraining

import React from 'react';
import { BrowserRouter as Router, Routes, Route, Navigate } from 'react-router-dom';
import { QueryClient, QueryClientProvider } from 'react-query';
import { ReactQueryDevtools } from 'react-query/devtools';

// Layout components
import MainLayout from './layouts/MainLayout';
import AuthLayout from './layouts/AuthLayout';

// Auth pages
import Login from './pages/auth/Login';
import ForgotPassword from './pages/auth/ForgotPassword';
import ResetPassword from './pages/auth/ResetPassword';

// Dashboard pages
import Dashboard from './pages/dashboard/Dashboard';

// Instructor pages
import InstructorDashboard from './pages/instructor/Dashboard';
import TraineeList from './pages/instructor/TraineeList';
import TraineeDetails from './pages/instructor/TraineeDetails';
import Assessment from './pages/instructor/Assessment';
import Debriefing from './pages/instructor/Debriefing';

// Trainee pages
import TraineeDashboard from './pages/trainee/Dashboard';
import TrainingRecords from './pages/trainee/TrainingRecords';
import CourseList from './pages/trainee/CourseList';
import CourseDetails from './pages/trainee/CourseDetails';
import ExerciseDetails from './pages/trainee/ExerciseDetails';

// Admin pages
import AdminDashboard from './pages/admin/Dashboard';
import UserManagement from './pages/admin/UserManagement';
import SyllabusManagement from './pages/admin/SyllabusManagement';
import SyllabusBuilder from './pages/admin/SyllabusBuilder';
import SystemSettings from './pages/admin/SystemSettings';

// Other components
import NotFound from './pages/NotFound';
import ProtectedRoute from './components/auth/ProtectedRoute';
import { useAuthStore } from './stores/authStore';

// Create a client for React Query
const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      refetchOnWindowFocus: false,
      retry: 1,
      staleTime: 5 * 60 * 1000, // 5 minutes
    },
  },
});

const App: React.FC = () => {
  const { isAuthenticated, user } = useAuthStore();

  return (
    <QueryClientProvider client={queryClient}>
      <Router>
        <Routes>
          {/* Auth routes */}
          <Route path="/" element={<AuthLayout />}>
            <Route index element={isAuthenticated ? <Navigate to="/dashboard" /> : <Login />} />
            <Route path="login" element={isAuthenticated ? <Navigate to="/dashboard" /> : <Login />} />
            <Route path="forgot-password" element={<ForgotPassword />} />
            <Route path="reset-password" element={<ResetPassword />} />
          </Route>

          {/* Protected routes */}
          <Route
            path="/"
            element={
              <ProtectedRoute>
                <MainLayout />
              </ProtectedRoute>
            }
          >
            {/* Common dashboard route - redirects based on user role */}
            <Route
              path="dashboard"
              element={
                user?.role === 'admin' ? (
                  <Navigate to="/admin/dashboard" />
                ) : user?.role === 'instructor' ? (
                  <Navigate to="/instructor/dashboard" />
                ) : (
                  <Navigate to="/trainee/dashboard" />
                )
              }
            />

            {/* Admin routes */}
            <Route path="admin">
              <Route
                path="dashboard"
                element={
                  <ProtectedRoute allowedRoles={['admin']}>
                    <AdminDashboard />
                  </ProtectedRoute>
                }
              />
              <Route
                path="users"
                element={
                  <ProtectedRoute allowedRoles={['admin']}>
                    <UserManagement />
                  </ProtectedRoute>
                }
              />
              <Route
                path="syllabi"
                element={
                  <ProtectedRoute allowedRoles={['admin']}>
                    <SyllabusManagement />
                  </ProtectedRoute>
                }
              />
              <Route
                path="syllabi/builder"
                element={
                  <ProtectedRoute allowedRoles={['admin']}>
                    <SyllabusBuilder />
                  </ProtectedRoute>
                }
              />
              <Route
                path="syllabi/builder/:id"
                element={
                  <ProtectedRoute allowedRoles={['admin']}>
                    <SyllabusBuilder />
                  </ProtectedRoute>
                }
              />
              <Route
                path="settings"
                element={
                  <ProtectedRoute allowedRoles={['admin']}>
                    <SystemSettings />
                  </ProtectedRoute>
                }
              />
            </Route>

            {/* Instructor routes */}
            <Route path="instructor">
              <Route
                path="dashboard"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor']}>
                    <InstructorDashboard />
                  </ProtectedRoute>
                }
              />
              <Route
                path="trainees"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor']}>
                    <TraineeList />
                  </ProtectedRoute>
                }
              />
              <Route
                path="trainees/:id"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor']}>
                    <TraineeDetails />
                  </ProtectedRoute>
                }
              />
              <Route
                path="assessment"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor']}>
                    <Assessment />
                  </ProtectedRoute>
                }
              />
              <Route
                path="assessment/:id"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor']}>
                    <Assessment />
                  </ProtectedRoute>
                }
              />
              <Route
                path="debriefing/:id"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor']}>
                    <Debriefing />
                  </ProtectedRoute>
                }
              />
            </Route>

            {/* Trainee routes */}
            <Route path="trainee">
              <Route
                path="dashboard"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor', 'trainee']}>
                    <TraineeDashboard />
                  </ProtectedRoute>
                }
              />
              <Route
                path="records"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor', 'trainee']}>
                    <TrainingRecords />
                  </ProtectedRoute>
                }
              />
              <Route
                path="courses"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor', 'trainee']}>
                    <CourseList />
                  </ProtectedRoute>
                }
              />
              <Route
                path="courses/:id"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor', 'trainee']}>
                    <CourseDetails />
                  </ProtectedRoute>
                }
              />
              <Route
                path="exercises/:id"
                element={
                  <ProtectedRoute allowedRoles={['admin', 'instructor', 'trainee']}>
                    <ExerciseDetails />
                  </ProtectedRoute>
                }
              />
            </Route>
          </Route>

          {/* 404 route */}
          <Route path="*" element={<NotFound />} />
        </Routes>
      </Router>
      <ReactQueryDevtools initialIsOpen={false} position="bottom-right" />
    </QueryClientProvider>
  );
};

export default App;
import create from 'zustand';
import { persist } from 'zustand/middleware';
import { api } from '../services/api';

interface User {
  id: string;
  username: string;
  email: string;
  firstName: string;
  lastName: string;
  role: 'admin' | 'instructor' | 'trainee';
  profileImageUrl?: string;
}

interface AuthState {
  isAuthenticated: boolean;
  user: User | null;
  token: string | null;
  refreshToken: string | null;
  loading: boolean;
  error: string | null;
  login: (username: string, password: string) => Promise<void>;
  logout: () => void;
  refreshAuth: () => Promise<boolean>;
  clearError: () => void;
}

export const useAuthStore = create<AuthState>(
  persist(
    (set, get) => ({
      isAuthenticated: false,
      user: null,
      token: null,
      refreshToken: null,
      loading: false,
      error: null,

      login: async (username: string, password: string) => {
        set({ loading: true, error: null });
        try {
          const response = await api.post('/auth/login', { username, password });
          const { token, refreshToken, user } = response.data;

          // Set token in axios default headers
          api.defaults.headers.common['Authorization'] = `Bearer ${token}`;

          set({
            isAuthenticated: true,
            token,
            refreshToken,
            user,
            loading: false,
          });
        } catch (error: any) {
          set({
            isAuthenticated: false,
            user: null,
            token: null,
            refreshToken: null,
            loading: false,
            error: error.response?.data?.message || 'Login failed',
          });
        }
      },

      logout: () => {
        // Remove token from axios default headers
        delete api.defaults.headers.common['Authorization'];

        set({
          isAuthenticated: false,
          user: null,
          token: null,
          refreshToken: null,
          error: null,
        });
      },

      refreshAuth: async () => {
        const { refreshToken } = get();
        if (!refreshToken) {
          return false;
        }

        try {
          const response = await api.post('/auth/refresh', { refreshToken });
          const { token: newToken, refreshToken: newRefreshToken } = response.data;

          // Set token in axios default headers
          api.defaults.headers.common['Authorization'] = `Bearer ${newToken}`;

          set({
            token: newToken,
            refreshToken: newRefreshToken,
          });
          return true;
        } catch (error) {
          // If refresh fails, log the user out
          get().logout();
          return false;
        }
      },

      clearError: () => {
        set({ error: null });
      },
    }),
    {
      name: 'auth-storage',
      getStorage: () => localStorage,
    }
  )
);
// /frontend/components/collaboration/CollaborationWorkspace.tsx
import React, { useState, useEffect, useContext } from 'react';
import { useRouter } from 'next/router';
import { 
  Box, 
  Grid, 
  Tabs, 
  Tab, 
  Typography, 
  Button, 
  CircularProgress,
  Divider,
  Paper,
  IconButton,
  Tooltip,
  useTheme
} from '@mui/material';
import { 
  Users, 
  MessageSquare, 
  FileText, 
  Clock, 
  Settings, 
  Share2, 
  Bell,
  UserPlus,
  ChevronLeft,
  ChevronRight
} from 'lucide-react';

import WorkspaceMembers from './WorkspaceMembers';
import ChatPanel from './ChatPanel';
import DocumentCollaboration from './DocumentCollaboration';
import ActivityTimeline from './ActivityTimeline';
import WorkspaceSettings from './WorkspaceSettings';
import AuthContext from '../../contexts/AuthContext';
import { useCollaboration } from '../../hooks/useCollaboration';
import { useNotification } from '../../hooks/useNotification';
import InviteUserModal from './InviteUserModal';
import { Workspace, WorkspaceUser } from '../../types/collaboration';

interface CollaborationWorkspaceProps {
  workspaceId: string;
}

const CollaborationWorkspace: React.FC<CollaborationWorkspaceProps> = ({ workspaceId }) => {
  const theme = useTheme();
  const router = useRouter();
  const { user } = useContext(AuthContext);
  const { notify } = useNotification();
  
  const [activeTab, setActiveTab] = useState<number>(0);
  const [sidebarOpen, setSidebarOpen] = useState<boolean>(true);
  const [inviteModalOpen, setInviteModalOpen] = useState<boolean>(false);
  
  const { 
    workspace, 
    members, 
    loading, 
    error, 
    messages, 
    sendMessage,
    documents,
    activities,
    userRole,
    inviteUser,
    removeUser,
    updateUserRole,
    leaveWorkspace
  } = useCollaboration(workspaceId);
  
  useEffect(() => {
    if (error) {
      notify('Error loading workspace', error.message, 'error');
    }
  }, [error, notify]);
  
  const handleTabChange = (event: React.SyntheticEvent, newValue: number) => {
    setActiveTab(newValue);
  };
  
  const handleInviteUser = async (email: string, role: string) => {
    try {
      await inviteUser(email, role);
      notify('User invited', 'Invitation sent successfully', 'success');
      setInviteModalOpen(false);
    } catch (err) {
      notify('Invitation failed', err.message, 'error');
    }
  };
  
  const handleLeaveWorkspace = async () => {
    if (window.confirm('Are you sure you want to leave this workspace?')) {
      try {
        await leaveWorkspace();
        notify('Left workspace', 'You have left the workspace', 'info');
        router.push('/workspaces');
      } catch (err) {
        notify('Error leaving workspace', err.message, 'error');
      }
    }
  };
  
  if (loading) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" minHeight="400px">
        <CircularProgress />
      </Box>
    );
  }
  
  if (!workspace) {
    return (
      <Box p={3}>
        <Typography variant="h5">Workspace not found or you don't have access</Typography>
        <Button 
          variant="contained" 
          color="primary" 
          onClick={() => router.push('/workspaces')}
          sx={{ mt: 2 }}
        >
          Back to Workspaces
        </Button>
      </Box>
    );
  }
  
  const isOwner = workspace.ownerId === user?.id;
  const canInvite = isOwner || userRole === 'ADMIN';
  
  return (
    <Box sx={{ height: 'calc(100vh - 64px)', display: 'flex', overflow: 'hidden' }}>
      {/* Sidebar */}
      <Box
        sx={{
          width: sidebarOpen ? 280 : 0,
          transition: 'width 0.3s ease',
          overflow: 'hidden',
          borderRight: `1px solid ${theme.palette.divider}`,
          display: 'flex',
          flexDirection: 'column',
        }}
      >
        <Box sx={{ p: 2, borderBottom: `1px solid ${theme.palette.divider}` }}>
          <Typography variant="h6" noWrap sx={{ mb: 1 }}>
            {workspace.name}
          </Typography>
          <Typography variant="body2" color="text.secondary" noWrap>
            {workspace.description || 'No description'}
          </Typography>
        </Box>
        
        <Box sx={{ p: 2, borderBottom: `1px solid ${theme.palette.divider}` }}>
          <Typography variant="subtitle2" sx={{ mb: 1 }}>
            Members
          </Typography>
          <Box sx={{ maxHeight: 150, overflowY: 'auto' }}>
            {members.slice(0, 5).map((member: WorkspaceUser) => (
              <Box 
                key={member.userId} 
                sx={{ 
                  display: 'flex', 
                  alignItems: 'center', 
                  mb: 1,
                  '&:last-child': { mb: 0 }
                }}
              >
                <Box
                  sx={{
                    width: 24,
                    height: 24,
                    borderRadius: '50%',
                    bgcolor: 'primary.main',
                    color: 'white',
                    display: 'flex',
                    alignItems: 'center',
                    justifyContent: 'center',
                    fontSize: '0.75rem',
                    mr: 1
                  }}
                >
                  {member.userName?.charAt(0)}
                </Box>
                <Typography variant="body2" noWrap>
                  {member.userName}
                </Typography>
                {member.userId === workspace.ownerId && (
                  <Typography variant="caption" sx={{ ml: 1, color: 'text.secondary' }}>
                    (Owner)
                  </Typography>
                )}
              </Box>
            ))}
            {members.length > 5 && (
              <Typography variant="caption" color="text.secondary">
                +{members.length - 5} more members
              </Typography>
            )}
          </Box>
          {canInvite && (
            <Button
              startIcon={<UserPlus size={16} />}
              variant="outlined"
              size="small"
              fullWidth
              sx={{ mt: 1 }}
              onClick={() => setInviteModalOpen(true)}
            >
              Invite Member
            </Button>
          )}
        </Box>
        
        <Box sx={{ p: 2, borderBottom: `1px solid ${theme.palette.divider}` }}>
          <Typography variant="subtitle2" sx={{ mb: 1 }}>
            Recent Activity
          </Typography>
          <Box sx={{ maxHeight: 150, overflowY: 'auto' }}>
            {activities.slice(0, 3).map((activity) => (
              <Box 
                key={activity.id} 
                sx={{ 
                  display: 'flex', 
                  alignItems: 'center', 
                  mb: 1,
                  '&:last-child': { mb: 0 }
                }}
              >
                <Box
                  sx={{
                    width: 24,
                    height: 24,
                    borderRadius: '50%',
                    bgcolor: 'action.selected',
                    display: 'flex',
                    alignItems: 'center',
                    justifyContent: 'center',
                    mr: 1
                  }}
                >
                  <Clock size={14} />
                </Box>
                <Box>
                  <Typography variant="body2" noWrap>
                    {activity.title}
                  </Typography>
                  <Typography variant="caption" color="text.secondary">
                    {new Date(activity.timestamp).toLocaleTimeString()} by {activity.userName}
                  </Typography>
                </Box>
              </Box>
            ))}
          </Box>
        </Box>
        
        <Box sx={{ mt: 'auto', p: 2, borderTop: `1px solid ${theme.palette.divider}` }}>
          <Button
            variant="outlined"
            color="secondary"
            fullWidth
            onClick={handleLeaveWorkspace}
          >
            Leave Workspace
          </Button>
        </Box>
      </Box>
      
      {/* Toggle sidebar button */}
      <Box 
        sx={{ 
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          borderRight: `1px solid ${theme.palette.divider}`
        }}
      >
        <IconButton onClick={() => setSidebarOpen(!sidebarOpen)}>
          {sidebarOpen ? <ChevronLeft /> : <ChevronRight />}
        </IconButton>
      </Box>
      
      {/* Main content */}
      <Box sx={{ flex: 1, display: 'flex', flexDirection: 'column', overflow: 'hidden' }}>
        <Box sx={{ borderBottom: `1px solid ${theme.palette.divider}` }}>
          <Tabs value={activeTab} onChange={handleTabChange} aria-label="workspace tabs">
            <Tab icon={<MessageSquare size={16} />} label="Chat" />
            <Tab icon={<FileText size={16} />} label="Documents" />
            <Tab icon={<Users size={16} />} label="Members" />
            <Tab icon={<Clock size={16} />} label="Activity" />
            {(isOwner || userRole === 'ADMIN') && (
              <Tab icon={<Settings size={16} />} label="Settings" />
            )}
          </Tabs>
        </Box>
        
        <Box sx={{ flex: 1, overflow: 'auto', p: 2 }}>
          {activeTab === 0 && (
            <ChatPanel 
              messages={messages} 
              onSendMessage={sendMessage} 
              workspace={workspace}
              members={members}
            />
          )}
          {activeTab === 1 && (
            <DocumentCollaboration 
              workspaceId={workspaceId} 
              documents={documents}
              userRole={userRole}
            />
          )}
          {activeTab === 2 && (
            <WorkspaceMembers 
              members={members} 
              workspace={workspace}
              onRemoveUser={removeUser}
              onUpdateRole={updateUserRole}
              userRole={userRole}
              currentUserId={user?.id}
            />
          )}
          {activeTab === 3 && (
            <ActivityTimeline 
              activities={activities} 
              workspaceId={workspaceId}
            />
          )}
          {activeTab === 4 && (isOwner || userRole === 'ADMIN') && (
            <WorkspaceSettings 
              workspace={workspace} 
              workspaceId={workspaceId}
            />
          )}
        </Box>
      </Box>
      
      <InviteUserModal
        open={inviteModalOpen}
        onClose={() => setInviteModalOpen(false)}
        onInvite={handleInviteUser}
      />
    </Box>
  );
};

export default CollaborationWorkspace;

// /frontend/components/collaboration/ChatPanel.tsx
import React, { useState, useRef, useEffect, useContext } from 'react';
import { 
  Box, 
  TextField, 
  IconButton, 
  Typography, 
  Avatar, 
  Paper,
  Chip,
  Menu,
  MenuItem,
  Divider,
  CircularProgress,
  useTheme
} from '@mui/material';
import { 
  Send, 
  Paperclip, 
  Smile, 
  MoreVertical, 
  Copy,
  Trash2,
  Flag 
} from 'lucide-react';
import Picker from 'emoji-picker-react';
import { Message, Workspace, WorkspaceUser } from '../../types/collaboration';
import AuthContext from '../../contexts/AuthContext';
import { formatDistanceToNow } from 'date-fns';

interface ChatPanelProps {
  messages: Message[];
  onSendMessage: (content: string, type?: string) => Promise<void>;
  workspace: Workspace;
  members: WorkspaceUser[];
}

const ChatPanel: React.FC<ChatPanelProps> = ({ 
  messages, 
  onSendMessage, 
  workspace,
  members 
}) => {
  const theme = useTheme();
  const { user } = useContext(AuthContext);
  const [messageInput, setMessageInput] = useState<string>('');
  const [sending, setSending] = useState<boolean>(false);
  const [showEmojiPicker, setShowEmojiPicker] = useState<boolean>(false);
  const [contextMenu, setContextMenu] = useState<{ 
    mouseX: number; 
    mouseY: number; 
    messageId: string | null 
  } | null>(null);
  
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const emojiButtonRef = useRef<HTMLButtonElement>(null);
  
  // Scroll to bottom when messages change
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);
  
  const handleSendMessage = async (e?: React.FormEvent) => {
    if (e) e.preventDefault();
    
    if (messageInput.trim()) {
      setSending(true);
      try {
        await onSendMessage(messageInput);
        setMessageInput('');
      } catch (error) {
        console.error('Failed to send message:', error);
      } finally {
        setSending(false);
      }
    }
  };
  
  const handleFileSelect = () => {
    fileInputRef.current?.click();
  };
  
  const handleFileUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = e.target.files;
    if (!files || files.length === 0) return;
    
    // Handle file upload logic here
    console.log('File selected:', files[0].name);
    
    // Clear the input for future uploads
    e.target.value = '';
  };
  
  const handleEmojiClick = (emojiData: any, event: MouseEvent) => {
    setMessageInput(prev => prev + emojiData.emoji);
    setShowEmojiPicker(false);
  };
  
  const handleContextMenu = (event: React.MouseEvent, messageId: string) => {
    event.preventDefault();
    setContextMenu({
      mouseX: event.clientX - 2,
      mouseY: event.clientY - 4,
      messageId
    });
  };
  
  const handleCloseContextMenu = () => {
    setContextMenu(null);
  };
  
  const handleCopyMessage = () => {
    const message = messages.find(m => m.id === contextMenu?.messageId);
    if (message) {
      navigator.clipboard.writeText(message.content);
    }
    handleCloseContextMenu();
  };
  
  const handleDeleteMessage = () => {
    // Implement delete message logic
    console.log('Delete message:', contextMenu?.messageId);
    handleCloseContextMenu();
  };
  
  const handleReportMessage = () => {
    // Implement report message logic
    console.log('Report message:', contextMenu?.messageId);
    handleCloseContextMenu();
  };
  
  const getMemberName = (userId: string): string => {
    const member = members.find(m => m.userId === userId);
    return member?.userName || 'Unknown User';
  };
  
  const groupMessagesByDate = () => {
    const groups: { [date: string]: Message[] } = {};
    
    messages.forEach(message => {
      const date = new Date(message.timestamp).toLocaleDateString();
      if (!groups[date]) {
        groups[date] = [];
      }
      groups[date].push(message);
    });
    
    return groups;
  };
  
  const messageGroups = groupMessagesByDate();
  
  return (
    <Box 
      sx={{ 
        display: 'flex',
        flexDirection: 'column',
        height: '100%'
      }}
    >
      <Box
        sx={{
          flex: 1,
          overflowY: 'auto',
          display: 'flex',
          flexDirection: 'column',
          gap: 1,
          p: 1
        }}
      >
        {Object.entries(messageGroups).map(([date, messagesGroup]) => (
          <Box key={date}>
            <Box
              sx={{
                display: 'flex',
                justifyContent: 'center',
                mb: 2,
                position: 'relative'
              }}
            >
              <Divider sx={{ width: '100%', position: 'absolute', top: '50%' }} />
              <Chip 
                label={date === new Date().toLocaleDateString() ? 'Today' : date}
                sx={{ zIndex: 1, bgcolor: theme.palette.background.paper }}
              />
            </Box>
            
            {messagesGroup.map((message) => {
              const isCurrentUser = message.senderId === user?.id;
              const senderName = getMemberName(message.senderId);
              
              return (
                <Box
                  key={message.id}
                  sx={{
                    display: 'flex',
                    flexDirection: isCurrentUser ? 'row-reverse' : 'row',
                    mb: 2
                  }}
                  onContextMenu={(e) => handleContextMenu(e, message.id)}
                >
                  <Avatar
                    sx={{
                      width: 36,
                      height: 36,
                      mr: isCurrentUser ? 0 : 1,
                      ml: isCurrentUser ? 1 : 0,
                      bgcolor: isCurrentUser ? 'primary.main' : 'secondary.main'
                    }}
                  >
                    {senderName.charAt(0)}
                  </Avatar>
                  
                  <Box
                    sx={{
                      maxWidth: '70%',
                      display: 'flex',
                      flexDirection: 'column'
                    }}
                  >
                    <Typography
                      variant="caption"
                      sx={{
                        mb: 0.5,
                        textAlign: isCurrentUser ? 'right' : 'left',
                        color: 'text.secondary'
                      }}
                    >
                      {isCurrentUser ? 'You' : senderName}  {formatDistanceToNow(new Date(message.timestamp), { addSuffix: true })}
                    </Typography>
                    
                    <Paper
                      elevation={1}
                      sx={{
                        p: 1.5,
                        borderRadius: 2,
                        bgcolor: isCurrentUser 
                          ? theme.palette.primary.light
                          : theme.palette.action.hover,
                        color: isCurrentUser
                          ? theme.palette.primary.contrastText
                          : theme.palette.text.primary
                      }}
                    >
                      <Typography variant="body1">
                        {message.content}
                      </Typography>
                    </Paper>
                    
                    {message.attachment && (
                      <Paper
                        elevation={1}
                        sx={{
                          p: 1,
                          mt: 1,
                          borderRadius: 1,
                          bgcolor: isCurrentUser 
                            ? theme.palette.primary.light
                            : theme.palette.action.hover,
                          color: isCurrentUser
                            ? theme.palette.primary.contrastText
                            : theme.palette.text.primary,
                          display: 'flex',
                          alignItems: 'center'
                        }}
                      >
                        <Paperclip size={16} />
                        <Typography variant="body2" sx={{ ml: 1 }}>
                          {message.attachment.fileName}
                        </Typography>
                      </Paper>
                    )}
                  </Box>
                </Box>
              );
            })}
          </Box>
        ))}
        
        <div ref={messagesEndRef} />
      </Box>
      
      <Box
        component="form"
        onSubmit={handleSendMessage}
        sx={{
          p: 2,
          borderTop: `1px solid ${theme.palette.divider}`,
          display: 'flex',
          alignItems: 'center',
          gap: 1
        }}
      >
        <IconButton
          onClick={handleFileSelect}
          disabled={sending}
          color="primary"
        >
          <Paperclip size={20} />
        </IconButton>
        
        <Box sx={{ position: 'relative' }}>
          <IconButton
            ref={emojiButtonRef}
            onClick={() => setShowEmojiPicker(!showEmojiPicker)}
            disabled={sending}
            color="primary"
          >
            <Smile size={20} />
          </IconButton>
          
          {showEmojiPicker && (
            <Box
              sx={{
                position: 'absolute',
                bottom: '100%',
                left: 0,
                zIndex: 1
              }}
            >
              <Picker onEmojiClick={handleEmojiClick} />
            </Box>
          )}
        </Box>
        
        <TextField
          fullWidth
          variant="outlined"
          placeholder="Type a message..."
          value={messageInput}
          onChange={(e) => setMessageInput(e.target.value)}
          disabled={sending}
          size="small"
          InputProps={{
            sx: { borderRadius: 4 }
          }}
        />
        
        <IconButton
          type="submit"
          color="primary"
          disabled={!messageInput.trim() || sending}
        >
          {sending ? <CircularProgress size={20} /> : <Send size={20} />}
        </IconButton>
        
        <input
          type="file"
          ref={fileInputRef}
          style={{ display: 'none' }}
          onChange={handleFileUpload}
        />
      </Box>
      
      <Menu
        open={contextMenu !== null}
        onClose={handleCloseContextMenu}
        anchorReference="anchorPosition"
        anchorPosition={
          contextMenu !== null
            ? { top: contextMenu.mouseY, left: contextMenu.mouseX }
            : undefined
        }
      >
        <MenuItem onClick={handleCopyMessage}>
          <Copy size={16} />
          <Typography sx={{ ml: 1 }}>Copy</Typography>
        </MenuItem>
        <MenuItem onClick={handleDeleteMessage}>
          <Trash2 size={16} />
          <Typography sx={{ ml: 1 }}>Delete</Typography>
        </MenuItem>
        <MenuItem onClick={handleReportMessage}>
          <Flag size={16} />
          <Typography sx={{ ml: 1 }}>Report</Typography>
        </MenuItem>
      </Menu>
    </Box>
  );
};

export default ChatPanel;

// /frontend/components/collaboration/DocumentCollaboration.tsx
import React, { useState, useEffect } from 'react';
import { 
  Box, 
  Button, 
  Typography, 
  Grid, 
  Card, 
  CardContent, 
  CardActions,
  IconButton,
  TextField,
  Dialog,
  DialogActions,
  DialogContent,
  DialogTitle,
  CircularProgress,
  Divider,
  Menu,
  MenuItem,
  ListItemIcon,
  ListItemText,
  useTheme
} from '@mui/material';
import { 
  FileText, 
  Upload, 
  Plus, 
  Edit, 
  Trash2, 
  MoreVertical,
  Download,
  Copy,
  Share2,
  Eye,
  Clock,
  Users
} from 'lucide-react';
import { Document, DocumentVersion } from '../../types/collaboration';
import { useDocumentService } from '../../hooks/useDocumentService';
import { useNotification } from '../../hooks/useNotification';
import DocumentViewer from './DocumentViewer';
import VersionHistoryDialog from './VersionHistoryDialog';

interface DocumentCollaborationProps {
  workspaceId: string;
  documents: Document[];
  userRole: string;
}

const DocumentCollaboration: React.FC<DocumentCollaborationProps> = ({ 
  workspaceId, 
  documents,
  userRole
}) => {
  const theme = useTheme();
  const { notify } = useNotification();
  const [uploadDialogOpen, setUploadDialogOpen] = useState<boolean>(false);
  const [newDocName, setNewDocName] = useState<string>('');
  const [selectedFile, setSelectedFile] = useState<File | null>(null);
  const [uploading, setUploading] = useState<boolean>(false);
  const [viewDialogOpen, setViewDialogOpen] = useState<boolean>(false);
  const [versionDialogOpen, setVersionDialogOpen] = useState<boolean>(false);
  const [selectedDocument, setSelectedDocument] = useState<Document | null>(null);
  const [anchorEl, setAnchorEl] = useState<null | HTMLElement>(null);
  const [searchTerm, setSearchTerm] = useState<string>('');
  const [filteredDocuments, setFilteredDocuments] = useState<Document[]>(documents);
  
  const { 
    uploadDocument,
    deleteDocument,
    getVersionHistory,
    downloadDocument,
    revertToVersion
  } = useDocumentService();
  
  useEffect(() => {
    if (searchTerm) {
      const filtered = documents.filter(doc => 
        doc.name.toLowerCase().includes(searchTerm.toLowerCase()) ||
        doc.description?.toLowerCase().includes(searchTerm.toLowerCase())
      );
      setFilteredDocuments(filtered);
    } else {
      setFilteredDocuments(documents);
    }
  }, [searchTerm, documents]);
  
  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
    if (event.target.files && event.target.files[0]) {
      const file = event.target.files[0];
      setSelectedFile(file);
      if (!newDocName) {
        setNewDocName(file.name);
      }
    }
  };
  
  const handleUpload = async () => {
    if (!selectedFile || !newDocName) {
      notify('Error', 'Please select a file and provide a name', 'error');
      return;
    }
    
    setUploading(true);
    try {
      await uploadDocument(workspaceId, selectedFile, newDocName);
      notify('Success', 'Document uploaded successfully', 'success');
      setUploadDialogOpen(false);
      setSelectedFile(null);
      setNewDocName('');
    } catch (error) {
      notify('Error', 'Failed to upload document', 'error');
    } finally {
      setUploading(false);
    }
  };
  
  const handleOpenMenu = (event: React.MouseEvent<HTMLElement>, document: Document) => {
    setAnchorEl(event.currentTarget);
    setSelectedDocument(document);
  };
  
  const handleCloseMenu = () => {
    setAnchorEl(null);
  };
  
  const handleViewDocument = () => {
    handleCloseMenu();
    setViewDialogOpen(true);
  };
  
  const handleViewVersions = async () => {
    handleCloseMenu();
    setVersionDialogOpen(true);
  };
  
  const handleDeleteDocument = async () => {
    if (!selectedDocument) return;
    
    if (window.confirm(`Are you sure you want to delete "${selectedDocument.name}"?`)) {
      try {
        await deleteDocument(workspaceId, selectedDocument.id);
        notify('Success', 'Document deleted successfully', 'success');
      } catch (error) {
        notify('Error', 'Failed to delete document', 'error');
      }
    }
    handleCloseMenu();
  };
  
  const handleDownloadDocument = async () => {
    if (!selectedDocument) return;
    
    try {
      await downloadDocument(workspaceId, selectedDocument.id);
    } catch (error) {
      notify('Error', 'Failed to download document', 'error');
    }
    handleCloseMenu();
  };
  
  const canModifyDocuments = ['OWNER', 'ADMIN', 'EDITOR'].includes(userRole);
  
  return (
    <Box>
      <Box sx={{ mb: 3, display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
        <Typography variant="h5">Documents</Typography>
        <Box sx={{ display: 'flex', gap: 2 }}>
          <TextField
            size="small"
            placeholder="Search documents..."
            value={searchTerm}
            onChange={(e) => setSearchTerm(e.target.value)}
            variant="outlined"
          />
          {canModifyDocuments && (
            <Button 
              variant="contained" 
              color="primary"
              startIcon={<Upload />}
              onClick={() => setUploadDialogOpen(true)}
            >
              Upload Document
            </Button>
          )}
        </Box>
      </Box>
      
      <Grid container spacing={3}>
        {filteredDocuments.length === 0 ? (
          <Grid item xs={12}>
            <Box 
              sx={{ 
                display: 'flex', 
                flexDirection: 'column', 
                alignItems: 'center',
                justifyContent: 'center',
                p: 4,
                border: `1px dashed ${theme.palette.divider}`,
                borderRadius: 1
              }}
            >
              <FileText size={48} color={theme.palette.text.secondary} />
              <Typography variant="h6" sx={{ mt: 2 }}>
                No documents found
              </Typography>
              <Typography variant="body2" color="text.secondary" sx={{ mb: 2 }}>
                {searchTerm 
                  ? 'No documents match your search criteria' 
                  : 'Upload documents to collaborate with your team'}
              </Typography>
              {canModifyDocuments && !searchTerm && (
                <Button
                  variant="outlined"
                  startIcon={<Upload />}
                  onClick={() => setUploadDialogOpen(true)}
                >
                  Upload Document
                </Button>
              )}
            </Box>
          </Grid>
        ) : (
          filteredDocuments.map((doc) => (
            <Grid item xs={12} sm={6} md={4} key={doc.id}>
              <Card 
                elevation={2}
                sx={{ 
                  height: '100%',
                  display: 'flex',
                  flexDirection: 'column',
                  transition: 'transform 0.2s',
                  '&:hover': {
                    transform: 'translateY(-4px)',
                    boxShadow: theme.shadows[4]
                  }
                }}
              >
                <CardContent sx={{ flex: 1 }}>
                  <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'flex-start', mb: 1 }}>
                    <Box sx={{ display: 'flex', alignItems: 'center' }}>
                      <FileText size={24} color={theme.palette.primary.main} />
                      <Typography variant="h6" sx={{ ml: 1, wordBreak: 'break-word' }}>
                        {doc.name}
                      </Typography>
                    </Box>
                    <IconButton 
                      size="small"
                      onClick={(e) => handleOpenMenu(e, doc)}
                    >
                      <MoreVertical size={18} />
                    </IconButton>
                  </Box>
                  
                  <Typography variant="body2" color="text.secondary" sx={{ mb: 2 }}>
                    {doc.description || 'No description'}
                  </Typography>
                  
                  <Box sx={{ display: 'flex', alignItems: 'center', gap: 1, mb: 0.5 }}>
                    <Clock size={14} color={theme.palette.text.secondary} />
                    <Typography variant="caption" color="text.secondary">
                      Last updated: {new Date(doc.updatedAt).toLocaleDateString()}
                    </Typography>
                  </Box>
                  
                  <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
                    <Users size={14} color={theme.palette.text.secondary} />
                    <Typography variant="caption" color="text.secondary">
                      {doc.accessCount} views  {doc.editCount} edits
                    </Typography>
                  </Box>
                </CardContent>
                
                <Divider />
                
                <CardActions sx={{ justifyContent: 'space-between', p: 1 }}>
                  <Button 
                    startIcon={<Eye size={16} />} 
                    size="small"
                    onClick={() => {
                      setSelectedDocument(doc);
                      setViewDialogOpen(true);
                    }}
                  >
                    View
                  </Button>
                  
                  {canModifyDocuments && (
                    <Button 
                      startIcon={<Edit size={16} />} 
                      size="small"
                      onClick={() => {
                        setSelectedDocument(doc);
                        setViewDialogOpen(true);
                      }}
                    >
                      Edit
                    </Button>
                  )}
                </CardActions>
              </Card>
            </Grid>
          ))
        )}
      </Grid>
      
      {/* Upload Dialog */}
      <Dialog
        open={uploadDialogOpen}
        onClose={() => setUploadDialogOpen(false)}
        maxWidth="sm"
        fullWidth
      >
        <DialogTitle>Upload Document</DialogTitle>
        <DialogContent>
          <TextField
            autoFocus
            margin="dense"
            label="Document Name"
            fullWidth
            value={newDocName}
            onChange={(e) => setNewDocName(e.target.value)}
            sx={{ mb: 2 }}
          />
          
          <Box
            sx={{
              border: `1px dashed ${theme.palette.divider}`,
              borderRadius: 1,
              p: 3,
              textAlign: 'center',
              mb: 2
            }}
          >
            {selectedFile ? (
              <Box>
                <Typography variant="body1">{selectedFile.name}</Typography>
                <Typography variant="caption" color="text.secondary">
                  {(selectedFile.size / 1024).toFixed(2)} KB
                </Typography>
                <Box sx={{ mt: 2 }}>
                  <Button 
                    variant="outlined" 
                    size="small"
                    onClick={() => setSelectedFile(null)}
                  >
                    Remove
                  </Button>
                </Box>
              </Box>
            ) : (
              <Box>
                <Upload size={32} color={theme.palette.text.secondary} />
                <Typography variant="body1" sx={{ mt: 1, mb: 1 }}>
                  Drag and drop your file here or click to browse
                </Typography>
                <Button
                  variant="contained"
                  component="label"
                >
                  Choose File
                  <input
                    type="file"
                    hidden
                    onChange={handleFileChange}
                  />
                </Button>
              </Box>
            )}
          </Box>
        </DialogContent>
        <DialogActions>
          <Button onClick={() => setUploadDialogOpen(false)}>Cancel</Button>
          <Button 
            onClick={handleUpload} 
            variant="contained" 
            disabled={!selectedFile || !newDocName || uploading}
          >
            {uploading ? <CircularProgress size={24} /> : 'Upload'}
          </Button>
        </DialogActions>
      </Dialog>
      
      {/* Document Viewer Dialog */}
      {selectedDocument && (
        <DocumentViewer
          open={viewDialogOpen}
          onClose={() => setViewDialogOpen(false)}
          document={selectedDocument}
          workspaceId={workspaceId}
          readOnly={!canModifyDocuments}
        />
      )}
      
      {/* Version History Dialog */}
      {selectedDocument && (
        <VersionHistoryDialog
          open={versionDialogOpen}
          onClose={() => setVersionDialogOpen(false)}
          document={selectedDocument}
          workspaceId={workspaceId}
          readOnly={!canModifyDocuments}
        />
      )}
      
      {/* Document Menu */}
      <Menu
        anchorEl={anchorEl}
        open={Boolean(anchorEl)}
        onClose={handleCloseMenu}
      >
        <MenuItem onClick={handleViewDocument}>
          <ListItemIcon>
            <Eye size={18} />
          </ListItemIcon>
          <ListItemText>View</ListItemText>
        </MenuItem>
        
        {canModifyDocuments && (
          <MenuItem onClick={handleViewDocument}>
            <ListItemIcon>
              <Edit size={18} />
            </ListItemIcon>
            <ListItemText>Edit</ListItemText>
          </MenuItem>
        )}
        
        <MenuItem onClick={handleDownloadDocument}>
          <ListItemIcon>
            <Download size={18} />
          </ListItemIcon>
          <ListItemText>Download</ListItemText>
        </MenuItem>
        
        <MenuItem onClick={handleViewVersions}>
          <ListItemIcon>
            <Clock size={18} />
          </ListItemIcon>
          <ListItemText>Version History</ListItemText>
        </MenuItem>
        
        <MenuItem onClick={handleCloseMenu}>
          <ListItemIcon>
            <Share2 size={18} />
          </ListItemIcon>
          <ListItemText>Share</ListItemText>
        </MenuItem>
        
        {canModifyDocuments && (
          <MenuItem onClick={handleDeleteDocument}>
            <ListItemIcon>
              <Trash2 size={18} color={theme.palette.error.main} />
            </ListItemIcon>
            <ListItemText sx={{ color: theme.palette.error.main }}>
              Delete
            </ListItemText>
          </MenuItem>
        )}
      </Menu>
    </Box>
  );
};

export default DocumentCollaboration;

// /frontend/hooks/useCollaboration.ts
import { useState, useEffect, useContext, useCallback } from 'react';
import AuthContext from '../contexts/AuthContext';
import api from '../services/api';
import { Workspace, WorkspaceUser, Message, Document, Activity } from '../types/collaboration';
import { useSocket } from './useSocket';

export const useCollaboration = (workspaceId: string) => {
  const { user } = useContext(AuthContext);
  const [workspace, setWorkspace] = useState<Workspace | null>(null);
  const [members, setMembers] = useState<WorkspaceUser[]>([]);
  const [userRole, setUserRole] = useState<string>('VIEWER');
  const [messages, setMessages] = useState<Message[]>([]);
  const [documents, setDocuments] = useState<Document[]>([]);
  const [activities, setActivities] = useState<Activity[]>([]);
  const [loading, setLoading] = useState<boolean>(true);
  const [error, setError] = useState<Error | null>(null);
  
  const { socket, connected } = useSocket(`/workspace/${workspaceId}`);
  
  // Fetch workspace data
  const fetchWorkspace = useCallback(async () => {
    try {
      setLoading(true);
      const response = await api.get(`/workspaces/${workspaceId}`);
      setWorkspace(response.data);
      
      // Find current user's role
      if (user) {
        const currentUserMember = response.data.members.find(
          (member: WorkspaceUser) => member.userId === user.id
        );
        if (currentUserMember) {
          setUserRole(currentUserMember.role);
        }
      }
    } catch (err) {
      setError(err as Error);
    }
  }, [workspaceId, user]);
  
  // Fetch workspace members
  const fetchMembers = useCallback(async () => {
    try {
      const response = await api.get(`/workspaces/${workspaceId}/users`);
      setMembers(response.data);
    } catch (err) {
      console.error('Error fetching members:', err);
    }
  }, [workspaceId]);
  
  // Fetch messages
  const fetchMessages = useCallback(async () => {
    try {
      const response = await api.get(`/workspaces/${workspaceId}/messages`);
      setMessages(response.data);
    } catch (err) {
      console.error('Error fetching messages:', err);
    }
  }, [workspaceId]);
  
  // Fetch documents
  const fetchDocuments = useCallback(async () => {
    try {
      const response = await api.get(`/workspaces/${workspaceId}/documents`);
      setDocuments(response.data);
    } catch (err) {
      console.error('Error fetching documents:', err);
    }
  }, [workspaceId]);
  
  // Fetch activities
  const fetchActivities = useCallback(async () => {
    try {
      const response = await api.get(`/workspaces/${workspaceId}/activities`);
      setActivities(response.data);
    } catch (err) {
      console.error('Error fetching activities:', err);
    }
  }, [workspaceId]);
  
  // Initialize data
  useEffect(() => {
    const initData = async () => {
      try {
        await fetchWorkspace();
        await Promise.all([
          fetchMembers(),
          fetchMessages(),
          fetchDocuments(),
          fetchActivities()
        ]);
      } catch (err) {
        console.error('Error initializing data:', err);
      } finally {
        setLoading(false);
      }
    };
    
    initData();
  }, [fetchWorkspace, fetchMembers, fetchMessages, fetchDocuments, fetchActivities]);
  
  // Socket event handlers
  useEffect(() => {
    if (!socket || !connected) return;
    
    // New message event
    socket.on('new_message', (message: Message) => {
      setMessages(prev => [...prev, message]);
      
      // Add to activities
      const activity: Activity = {
        id: message.id,
        type: 'MESSAGE',
        title: 'New message',
        description: message.content.substring(0, 50) + (message.content.length > 50 ? '...' : ''),
        userId: message.senderId,
        userName: members.find(m => m.userId === message.senderId)?.userName || 'Unknown',
        timestamp: message.timestamp,
        resourceId: message.id
      };
      setActivities(prev => [activity, ...prev]);
    });
    
    // User added event
    socket.on('user_added', (data: { userId: string, userName: string, role: string }) => {
      const newMember: WorkspaceUser = {
        userId: data.userId,
        userName: data.userName,
        role: data.role
      };
      
      setMembers(prev => [...prev, newMember]);
      
      // Add to activities
      const activity: Activity = {
        id: Date.now().toString(),
        type: 'USER',
        title: 'User joined',
        description: `${data.userName} joined the workspace`,
        userId: data.userId,
        userName: data.userName,
        timestamp: new Date().toISOString(),
        resourceId: data.userId
      };
      setActivities(prev => [activity, ...prev]);
    });
    
    // User removed event
    socket.on('user_removed', (data: { userId: string }) => {
      setMembers(prev => prev.filter(member => member.userId !== data.userId));
      
      // Add to activities
      const removedMember = members.find(m => m.userId === data.userId);
      if (removedMember) {
        const activity: Activity = {
          id: Date.now().toString(),
          type: 'USER',
          title: 'User removed',
          description: `${removedMember.userName} was removed from the workspace`,
          userId: data.userId,
          userName: removedMember.userName,
          timestamp: new Date().toISOString(),
          resourceId: data.userId
        };
        setActivities(prev => [activity, ...prev]);
      }
    });
    
    // User role updated event
    socket.on('user_role_updated', (data: { userId: string, role: string }) => {
      setMembers(prev => 
        prev.map(member => 
          member.userId === data.userId 
            ? { ...member, role: data.role } 
            : member
        )
      );
      
      // If current user's role updated
      if (user && data.userId === user.id) {
        setUserRole(data.role);
      }
      
      // Add to activities
      const updatedMember = members.find(m => m.userId === data.userId);
      if (updatedMember) {
        const activity: Activity = {
          id: Date.now().toString(),
          type: 'USER',
          title: 'Role updated',
          description: `${updatedMember.userName}'s role changed to ${data.role}`,
          userId: data.userId,
          userName: updatedMember.userName,
          timestamp: new Date().toISOString(),
          resourceId: data.userId
        };
        setActivities(prev => [activity, ...prev]);
      }
    });
    
    // Document updated event
    socket.on('document_updated', (document: Document) => {
      setDocuments(prev => 
        prev.map(doc => 
          doc.id === document.id ? document : doc
        )
      );
      
      // Add to activities
      const activity: Activity = {
        id: Date.now().toString(),
        type: 'DOCUMENT',
        title: 'Document updated',
        description: `${document.name} was updated`,
        userId: document.lastModifiedBy || '',
        userName: members.find(m => m.userId === document.lastModifiedBy)?.userName || 'Unknown',
        timestamp: document.updatedAt,
        resourceId: document.id
      };
      setActivities(prev => [activity, ...prev]);
    });
    
    // New document event
    socket.on('new_document', (document: Document) => {
      setDocuments(prev => [...prev, document]);
      
      // Add to activities
      const activity: Activity = {
        id: Date.now().toString(),
        type: 'DOCUMENT',
        title: 'Document created',
        description: `${document.name} was created`,
        userId: document.createdBy,
        userName: members.find(m => m.userId === document.createdBy)?.userName || 'Unknown',
        timestamp: document.createdAt,
        resourceId: document.id
      };
      setActivities(prev => [activity, ...prev]);
    });
    
    // Document deleted event
    socket.on('document_deleted', (documentId: string) => {
      const deletedDoc = documents.find(doc => doc.id === documentId);
      
      setDocuments(prev => prev.filter(doc => doc.id !== documentId));
      
      // Add to activities
      if (deletedDoc) {
        const activity: Activity = {
          id: Date.now().toString(),
          type: 'DOCUMENT',
          title: 'Document deleted',
          description: `${deletedDoc.name} was deleted`,
          userId: user?.id || '',
          userName: user?.name || 'Unknown',
          timestamp: new Date().toISOString(),
          resourceId: documentId
        };
        setActivities(prev => [activity, ...prev]);
      }
    });
    
    return () => {
      socket.off('new_message');
      socket.off('user_added');
      socket.off('user_removed');
      socket.off('user_role_updated');
      socket.off('document_updated');
      socket.off('new_document');
      socket.off('document_deleted');
    };
  }, [socket, connected, user, members, documents]);
  
  // Send a message
  const sendMessage = async (content: string, type: string = 'TEXT') => {
    if (!user) throw new Error('User not authenticated');
    
    try {
      const response = await api.post(`/workspaces/${workspaceId}/messages`, {
        content,
        type
      });
      
      // Socket will handle updating the UI
      return response.data;
    } catch (error) {
      console.error('Error sending message:', error);
      throw error;
    }
  };
  
  // Invite a user to the workspace
  const inviteUser = async (email: string, role: string) => {
    try {
      const response = await api.post(`/workspaces/${workspaceId}/users`, {
        email,
        role
      });
      return response.data;
    } catch (error) {
      console.error('Error inviting user:', error);
      throw error;
    }
  };
  
  // Remove a user from the workspace
  const removeUser = async (userId: string) => {
    try {
      await api.delete(`/workspaces/${workspaceId}/users/${userId}`);
      // Socket will handle updating the UI
    } catch (error) {
      console.error('Error removing user:', error);
      throw error;
    }
  };
  
  // Update a user's role
  const updateUserRole = async (userId: string, newRole: string) => {
    try {
      await api.put(`/workspaces/${workspaceId}/users/${userId}/role`, {
        role: newRole
      });
      // Socket will handle updating the UI
    } catch (error) {
      console.error('Error updating user role:', error);
      throw error;
    }
  };
  
  // Leave the workspace
  const leaveWorkspace = async () => {
    if (!user) throw new Error('User not authenticated');
    
    try {
      await api.delete(`/workspaces/${workspaceId}/users/${user.id}`);
      return true;
    } catch (error) {
      console.error('Error leaving workspace:', error);
      throw error;
    }
  };
  
  return {
    workspace,
    members,
    loading,
    error,
    messages,
    documents,
    activities,
    userRole,
    sendMessage,
    inviteUser,
    removeUser,
    updateUserRole,
    leaveWorkspace,
    refreshData: () => {
      fetchWorkspace();
      fetchMembers();
      fetchMessages();
      fetchDocuments();
      fetchActivities();
    }
  };
};

// /frontend/components/integration/IntegrationDashboard.tsx
import React, { useState, useEffect } from 'react';
import { 
  Box, 
  Grid, 
  Typography, 
  Card, 
  CardContent, 
  CardHeader, 
  Button, 
  Chip, 
  Divider, 
  List, 
  ListItem, 
  ListItemText, 
  ListItemIcon, 
  ListItemAvatar, 
  Avatar, 
  IconButton, 
  CircularProgress,
  Dialog,
  DialogTitle,
  DialogContent,
  DialogActions,
  Tooltip,
  useTheme
} from '@mui/material';
import { 
  MonitorPlay, 
  Activity, 
  User, 
  Calendar, 
  Plus, 
  AlignLeft, 
  Trash2, 
  RefreshCw, 
  AlertCircle, 
  CheckCircle,
  Settings,
  Link2,
  Link2Off,
  Clock,
  Zap
} from 'lucide-react';
import { useIntegrationService } from '../../hooks/useIntegrationService';
import { Connection, ConnectionHealth } from '../../types/integration';
import SimulatorConnectDialog from './SimulatorConnectDialog';
import BiometricConnectDialog from './BiometricConnectDialog';
import EnterpriseConnectDialog from './EnterpriseConnectDialog';
import CalendarConnectDialog from './CalendarConnectDialog';
import IntegrationSettingsDialog from './IntegrationSettingsDialog';
import StatusIndicator from '../common/StatusIndicator';

const IntegrationDashboard: React.FC = () => {
  const theme = useTheme();
  const [selectedConnection, setSelectedConnection] = useState<Connection | null>(null);
  const [settingsOpen, setSettingsOpen] = useState<boolean>(false);
  const [simulatorDialogOpen, setSimulatorDialogOpen] = useState<boolean>(false);
  const [biometricDialogOpen, setBiometricDialogOpen] = useState<boolean>(false);
  const [enterpriseDialogOpen, setEnterpriseDialogOpen] = useState<boolean>(false);
  const [calendarDialogOpen, setCalendarDialogOpen] = useState<boolean>(false);
  const [confirmDeleteOpen, setConfirmDeleteOpen] = useState<boolean>(false);
  
  const { 
    connections, 
    connectionHealth, 
    loading, 
    error,
    refreshConnections,
    checkConnectionHealth,
    deleteConnection,
    simulators,
    biometricDevices,
    enterpriseSystems,
    calendars,
  } = useIntegrationService();
  
  useEffect(() => {
    refreshConnections();
    
    // Check connection health every minute
    const interval = setInterval(() => {
      checkConnectionHealth();
    }, 60000);
    
    return () => clearInterval(interval);
  }, [refreshConnections, checkConnectionHealth]);
  
  const handleOpenSettings = (connection: Connection) => {
    setSelectedConnection(connection);
    setSettingsOpen(true);
  };
  
  const handleDeleteConnection = async () => {
    if (selectedConnection) {
      await deleteConnection(selectedConnection.id);
      setConfirmDeleteOpen(false);
      setSelectedConnection(null);
    }
  };
  
  const getConnectionTypeName = (type: number): string => {
    switch (type) {
      case 0: return 'Simulator';
      case 1: return 'Biometric Device';
      case 2: return 'Enterprise System';
      case 3: return 'Calendar';
      default: return 'Unknown';
    }
  };
  
  const getConnectionStatusText = (status: number): string => {
    switch (status) {
      case 0: return 'Connected';
      case 1: return 'Disconnected';
      case 2: return 'Connecting';
      case 3: return 'Error';
      default: return 'Unknown';
    }
  };
  
  const getConnectionStatusColor = (status: number): string => {
    switch (status) {
      case 0: return 'success';
      case 1: return 'error';
      case 2: return 'warning';
      case 3: return 'error';
      default: return 'default';
    }
  };
  
  const getConnectionIcon = (type: number) => {
    switch (type) {
      case 0: return <MonitorPlay />;
      case 1: return <Activity />;
      case 2: return <User />;
      case 3: return <Calendar />;
      default: return <Link2 />;
    }
  };
  
  const getConnectionHealth = (connectionId: string): ConnectionHealth | undefined => {
    return connectionHealth.find(health => health.connectionId === connectionId);
  };
  
  const filterConnectionsByType = (type: number): Connection[] => {
    return connections.filter(conn => conn.type === type);
  };
  
  const simulatorConnections = filterConnectionsByType(0);
  const biometricConnections = filterConnectionsByType(1);
  const enterpriseConnections = filterConnectionsByType(2);
  const calendarConnections = filterConnectionsByType(3);
  
  if (loading && connections.length === 0) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" height="400px">
        <CircularProgress />
      </Box>
    );
  }
  
  return (
    <Box>
      <Box sx={{ mb: 3, display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
        <Typography variant="h5">External Integrations</Typography>
        <Box sx={{ display: 'flex', gap: 2 }}>
          <Button 
            variant="outlined" 
            startIcon={<RefreshCw />}
            onClick={refreshConnections}
          >
            Refresh
          </Button>
        </Box>
      </Box>
      
      <Grid container spacing={3}>
        {/* Simulator Integrations */}
        <Grid item xs={12} md={6}>
          <Card elevation={2} sx={{ height: '100%' }}>
            <CardHeader
              title={
                <Box sx={{ display: 'flex', alignItems: 'center' }}>
                  <MonitorPlay size={24} color={theme.palette.primary.main} />
                  <Typography variant="h6" sx={{ ml: 1 }}>Simulator Connections</Typography>
                </Box>
              }
              action={
                <Button
                  startIcon={<Plus />}
                  variant="contained"
                  size="small"
                  onClick={() => setSimulatorDialogOpen(true)}
                >
                  Connect
                </Button>
              }
            />
            <Divider />
            <CardContent sx={{ p: 0 }}>
              {simulatorConnections.length === 0 ? (
                <Box sx={{ p: 3, textAlign: 'center' }}>
                  <Typography color="text.secondary">
                    No simulator connections configured
                  </Typography>
                  <Button
                    startIcon={<Plus />}
                    variant="outlined"
                    size="small"
                    sx={{ mt: 2 }}
                    onClick={() => setSimulatorDialogOpen(true)}
                  >
                    Connect to Simulator
                  </Button>
                </Box>
              ) : (
                <List disablePadding>
                  {simulatorConnections.map((connection) => {
                    const health = getConnectionHealth(connection.id);
                    
                    return (
                      <React.Fragment key={connection.id}>
                        <ListItem
                          secondaryAction={
                            <Box sx={{ display: 'flex', gap: 1 }}>
                              <Tooltip title="Connection Settings">
                                <IconButton edge="end" onClick={() => handleOpenSettings(connection)}>
                                  <Settings size={18} />
                                </IconButton>
                              </Tooltip>
                              <Tooltip title="Delete Connection">
                                <IconButton 
                                  edge="end" 
                                  color="error"
                                  onClick={() => {
                                    setSelectedConnection(connection);
                                    setConfirmDeleteOpen(true);
                                  }}
                                >
                                  <Trash2 size={18} />
                                </IconButton>
                              </Tooltip>
                            </Box>
                          }
                        >
                          <ListItemAvatar>
                            <Avatar sx={{ bgcolor: theme.palette.primary.main }}>
                              <MonitorPlay />
                            </Avatar>
                          </ListItemAvatar>
                          <ListItemText
                            primary={connection.name}
                            secondary={
                              <Box sx={{ display: 'flex', alignItems: 'center', gap: 1, mt: 0.5 }}>
                                <StatusIndicator status={getConnectionStatusColor(connection.status)} />
                                <Typography variant="caption">
                                  {getConnectionStatusText(connection.status)}
                                </Typography>
                                {health && (
                                  <Tooltip title={`Latency: ${health.latencyMs}ms`}>
                                    <Box sx={{ display: 'flex', alignItems: 'center', gap: 0.5 }}>
                                      <Zap size={12} />
                                      <Typography variant="caption">
                                        {health.latencyMs}ms
                                      </Typography>
                                    </Box>
                                  </Tooltip>
                                )}
                              </Box>
                            }
                          />
                        </ListItem>
                        <Divider component="li" />
                      </React.Fragment>
                    );
                  })}
                </List>
              )}
            </CardContent>
          </Card>
        </Grid>
        
        {/* Biometric Device Integrations */}
        <Grid item xs={12} md={6}>
          <Card elevation={2} sx={{ height: '100%' }}>
            <CardHeader
              title={
                <Box sx={{ display: 'flex', alignItems: 'center' }}>
                  <Activity size={24} color={theme.palette.primary.main} />
                  <Typography variant="h6" sx={{ ml: 1 }}>Biometric Devices</Typography>
                </Box>
              }
              action={
                <Button
                  startIcon={<Plus />}
                  variant="contained"
                  size="small"
                  onClick={() => setBiometricDialogOpen(true)}
                >
                  Connect
                </Button>
              }
            />
            <Divider />
            <CardContent sx={{ p: 0 }}>
              {biometricConnections.length === 0 ? (
                <Box sx={{ p: 3, textAlign: 'center' }}>
                  <Typography color="text.secondary">
                    No biometric devices connected
                  </Typography>
                  <Button
                    startIcon={<Plus />}
                    variant="outlined"
                    size="small"
                    sx={{ mt: 2 }}
                    onClick={() => setBiometricDialogOpen(true)}
                  >
                    Connect Biometric Device
                  </Button>
                </Box>
              ) : (
                <List disablePadding>
                  {biometricConnections.map((connection) => {
                    const health = getConnectionHealth(connection.id);
                    
                    return (
                      <React.Fragment key={connection.id}>
                        <ListItem
                          secondaryAction={
                            <Box sx={{ display: 'flex', gap: 1 }}>
                              <Tooltip title="Connection Settings">
                                <IconButton edge="end" onClick={() => handleOpenSettings(connection)}>
                                  <Settings size={18} />
                                </IconButton>
                              </Tooltip>
                              <Tooltip title="Delete Connection">
                                <IconButton 
                                  edge="end" 
                                  color="error"
                                  onClick={() => {
                                    setSelectedConnection(connection);
                                    setConfirmDeleteOpen(true);
                                  }}
                                >
                                  <Trash2 size={18} />
                                </IconButton>
                              </Tooltip>
                            </Box>
                          }
                        >
                          <ListItemAvatar>
                            <Avatar sx={{ bgcolor: theme.palette.secondary.main }}>
                              <Activity />
                            </Avatar>
                          </ListItemAvatar>
                          <ListItemText
                            primary={connection.name}
                            secondary={
                              <Box sx={{ display: 'flex', alignItems: 'center', gap: 1, mt: 0.5 }}>
                                <StatusIndicator status={getConnectionStatusColor(connection.status)} />
                                <Typography variant="caption">
                                  {getConnectionStatusText(connection.status)}
                                </Typography>
                                {health && (
                                  <Tooltip title={`Latency: ${health.latencyMs}ms`}>
                                    <Box sx={{ display: 'flex', alignItems: 'center', gap: 0.5 }}>
                                      <Zap size={12} />
                                      <Typography variant="caption">
                                        {health.latencyMs}ms
                                      </Typography>
                                    </Box>
                                  </Tooltip>
                                )}
                              </Box>
                            }
                          />
                        </ListItem>
                        <Divider component="li" />
                      </React.Fragment>
                    );
                  })}
                </List>
              )}
            </CardContent>
          </Card>
        </Grid>
        
        {/* Enterprise System Integrations */}
        <Grid item xs={12} md={6}>
          <Card elevation={2} sx={{ height: '100%' }}>
            <CardHeader
              title={
                <Box sx={{ display: 'flex', alignItems: 'center' }}>
                  <User size={24} color={theme.palette.primary.main} />
                  <Typography variant="h6" sx={{ ml: 1 }}>Enterprise Systems</Typography>
                </Box>
              }
              action={
                <Button
                  startIcon={<Plus />}
                  variant="contained"
                  size="small"
                  onClick={() => setEnterpriseDialogOpen(true)}
                >
                  Connect
                </Button>
              }
            />
            <Divider />
            <CardContent sx={{ p: 0 }}>
              {enterpriseConnections.length === 0 ? (
                <Box sx={{ p: 3, textAlign: 'center' }}>
                  <Typography color="text.secondary">
                    No enterprise systems connected
                  </Typography>
                  <Button
                    startIcon={<Plus />}
                    variant="outlined"
                    size="small"
                    sx={{ mt: 2 }}
                    onClick={() => setEnterpriseDialogOpen(true)}
                  >
                    Connect Enterprise System
                  </Button>
                </Box>
              ) : (
                <List disablePadding>
                  {enterpriseConnections.map((connection) => {
                    const health = getConnectionHealth(connection.id);
                    
                    return (
                      <React.Fragment key={connection.id}>
                        <ListItem
                          secondaryAction={
                            <Box sx={{ display: 'flex', gap: 1 }}>
                              <Tooltip title="Connection Settings">
                                <IconButton edge="end" onClick={() => handleOpenSettings(connection)}>
                                  <Settings size={18} />
                                </IconButton>
                              </Tooltip>
                              <Tooltip title="Delete Connection">
                                <IconButton 
                                  edge="end" 
                                  color="error"
                                  onClick={() => {
                                    setSelectedConnection(connection);
                                    setConfirmDeleteOpen(true);
                                  }}
                                >
                                  <Trash2 size={18} />
                                </IconButton>
                              </Tooltip>
                            </Box>
                          }
                        >
                          <ListItemAvatar>
                            <Avatar sx={{ bgcolor: theme.palette.success.main }}>
                              <User />
                            </Avatar>
                          </ListItemAvatar>
                          <ListItemText
                            primary={connection.name}
                            secondary={
                              <Box sx={{ display: 'flex', alignItems: 'center', gap: 1, mt: 0.5 }}>
                                <StatusIndicator status={getConnectionStatusColor(connection.status)} />
                                <Typography variant="caption">
                                  {getConnectionStatusText(connection.status)}
                                </Typography>
                                {health && (
                                  <Box sx={{ display: 'flex', alignItems: 'center', gap: 0.5, ml: 1 }}>
                                    <Clock size={12} />
                                    <Typography variant="caption">
                                      Last Sync: {new Date(health.checkedAt).toLocaleTimeString()}
                                    </Typography>
                                  </Box>
                                )}
                              </Box>
                            }
                          />
                        </ListItem>
                        <Divider component="li" />
                      </React.Fragment>
                    );
                  })}
                </List>
              )}
            </CardContent>
          </Card>
        </Grid>
        
        {/* Calendar Integrations */}
        <Grid item xs={12} md={6}>
          <Card elevation={2} sx={{ height: '100%' }}>
            <CardHeader
              title={
                <Box sx={{ display: 'flex', alignItems: 'center' }}>
                  <Calendar size={24} color={theme.palette.primary.main} />
                  <Typography variant="h6" sx={{ ml: 1 }}>Calendar Connections</Typography>
                </Box>
              }
              action={
                <Button
                  startIcon={<Plus />}
                  variant="contained"
                  size="small"
                  onClick={() => setCalendarDialogOpen(true)}
                >
                  Connect
                </Button>
              }
            />
            <Divider />
            <CardContent sx={{ p: 0 }}>
              {calendarConnections.length === 0 ? (
                <Box sx={{ p: 3, textAlign: 'center' }}>
                  <Typography color="text.secondary">
                    No calendar connections configured
                  </Typography>
                  <Button
                    startIcon={<Plus />}
                    variant="outlined"
                    size="small"
                    sx={{ mt: 2 }}
                    onClick={() => setCalendarDialogOpen(true)}
                  >
                    Connect to Calendar
                  </Button>
                </Box>
              ) : (
                <List disablePadding>
                  {calendarConnections.map((connection) => {
                    const health = getConnectionHealth(connection.id);
                    
                    return (
                      <React.Fragment key={connection.id}>
                        <ListItem
                          secondaryAction={
                            <Box sx={{ display: 'flex', gap: 1 }}>
                              <Tooltip title="Connection Settings">
                                <IconButton edge="end" onClick={() => handleOpenSettings(connection)}>
                                  <Settings size={18} />
                                </IconButton>
                              </Tooltip>
                              <Tooltip title="Delete Connection">
                                <IconButton 
                                  edge="end" 
                                  color="error"
                                  onClick={() => {
                                    setSelectedConnection(connection);
                                    setConfirmDeleteOpen(true);
                                  }}
                                >
                                  <Trash2 size={18} />
                                </IconButton>
                              </Tooltip>
                            </Box>
                          }
                        >
                          <ListItemAvatar>
                            <Avatar sx={{ bgcolor: theme.palette.warning.main }}>
                              <Calendar />
                            </Avatar>
                          </ListItemAvatar>
                          <ListItemText
                            primary={connection.name}
                            secondary={
                              <Box sx={{ display: 'flex', alignItems: 'center', gap: 1, mt: 0.5 }}>
                                <StatusIndicator status={getConnectionStatusColor(connection.status)} />
                                <Typography variant="caption">
                                  {getConnectionStatusText(connection.status)}
                                </Typography>
                                {health && (
                                  <Box sx={{ display: 'flex', alignItems: 'center', gap: 0.5, ml: 1 }}>
                                    <Clock size={12} />
                                    <Typography variant="caption">
                                      Last Sync: {new Date(health.checkedAt).toLocaleTimeString()}
                                    </Typography>
                                  </Box>
                                )}
                              </Box>
                            }
                          />
                        </ListItem>
                        <Divider component="li" />
                      </React.Fragment>
                    );
                  })}
                </List>
              )}
            </CardContent>
          </Card>
        </Grid>
      </Grid>
      
      {/* Connection Dialogs */}
      <SimulatorConnectDialog
        open={simulatorDialogOpen}
        onClose={() => setSimulatorDialogOpen(false)}
        onSuccess={() => {
          setSimulatorDialogOpen(false);
          refreshConnections();
        }}
        simulators={simulators}
      />
      
      <BiometricConnectDialog
        open={biometricDialogOpen}
        onClose={() => setBiometricDialogOpen(false)}
        onSuccess={() => {
          setBiometricDialogOpen(false);
          refreshConnections();
        }}
        devices={biometricDevices}
      />
      
      <EnterpriseConnectDialog
        open={enterpriseDialogOpen}
        onClose={() => setEnterpriseDialogOpen(false)}
        onSuccess={() => {
          setEnterpriseDialogOpen(false);
          refreshConnections();
        }}
        systems={enterpriseSystems}
      />
      
      <CalendarConnectDialog
        open={calendarDialogOpen}
        onClose={() => setCalendarDialogOpen(false)}
        onSuccess={() => {
          setCalendarDialogOpen(false);
          refreshConnections();
        }}
        calendarTypes={calendars}
      />
      
      {/* Settings Dialog */}
      {selectedConnection && (
        <IntegrationSettingsDialog
          open={settingsOpen}
          onClose={() => setSettingsOpen(false)}
          connection={selectedConnection}
          onSuccess={() => {
            setSettingsOpen(false);
            refreshConnections();
          }}
        />
      )}
      
      {/* Confirm Delete Dialog */}
      <Dialog
        open={confirmDeleteOpen}
        onClose={() => setConfirmDeleteOpen(false)}
      >
        <DialogTitle>Confirm Delete</DialogTitle>
        <DialogContent>
          <Typography>
            Are you sure you want to delete the connection to "{selectedConnection?.name}"?
            This action cannot be undone.
          </Typography>
        </DialogContent>
        <DialogActions>
          <Button onClick={() => setConfirmDeleteOpen(false)}>Cancel</Button>
          <Button 
            onClick={handleDeleteConnection} 
            color="error"
            variant="contained"
          >
            Delete
          </Button>
        </DialogActions>
      </Dialog>
    </Box>
  );
};

export default IntegrationDashboard;

// /frontend/components/integration/SimulatorConnectDialog.tsx
import React, { useState, useEffect } from 'react';
import { 
  Dialog, 
  DialogTitle, 
  DialogContent, 
  DialogActions, 
  Button, 
  TextField, 
  MenuItem, 
  FormControl, 
  InputLabel, 
  Select, 
  Box, 
  Typography, 
  CircularProgress, 
  Stepper, 
  Step, 
  StepLabel, 
  Divider 
} from '@mui/material';
import { MonitorPlay } from 'lucide-react';
import { Simulator } from '../../types/integration';
import { useIntegrationService } from '../../hooks/useIntegrationService';

interface SimulatorConnectDialogProps {
  open: boolean;
  onClose: () => void;
  onSuccess: () => void;
  simulators: Simulator[];
}

const SimulatorConnectDialog: React.FC<SimulatorConnectDialogProps> = ({ 
  open, 
  onClose, 
  onSuccess,
  simulators
}) => {
  const [activeStep, setActiveStep] = useState(0);
  const [selectedSimulator, setSelectedSimulator] = useState<string>('');
  const [connectionName, setConnectionName] = useState<string>('');
  const [host, setHost] = useState<string>('localhost');
  const [port, setPort] = useState<string>('8080');
  const [username, setUsername] = useState<string>('');
  const [password, setPassword] = useState<string>('');
  const [updateRate, setUpdateRate] = useState<string>('30');
  const [loading, setLoading] = useState<boolean>(false);
  const [error, setError] = useState<string | null>(null);
  
  const { connectToSimulator } = useIntegrationService();
  
  useEffect(() => {
    // Reset state when dialog opens
    if (open) {
      setActiveStep(0);
      setSelectedSimulator('');
      setConnectionName('');
      setHost('localhost');
      setPort('8080');
      setUsername('');
      setPassword('');
      setUpdateRate('30');
      setError(null);
    }
  }, [open]);
  
  const handleNext = () => {
    setActiveStep((prevStep) => prevStep + 1);
  };
  
  const handleBack = () => {
    setActiveStep((prevStep) => prevStep - 1);
  };
  
  const handleSimulatorSelect = (simulatorId: string) => {
    setSelectedSimulator(simulatorId);
    
    // Get default settings for selected simulator
    const simulator = simulators.find(sim => sim.id === simulatorId);
    if (simulator) {
      setConnectionName(simulator.name);
      setPort(simulator.defaultPort.toString());
    }
  };
  
  const handleConnect = async () => {
    setLoading(true);
    setError(null);
    
    try {
      const simulator = simulators.find(sim => sim.id === selectedSimulator);
      if (!simulator) {
        throw new Error('Simulator not found');
      }
      
      const params = {
        name: connectionName,
        host,
        port: parseInt(port),
        username,
        password,
        simulatorType: simulator.type,
        updateFrequencyHz: parseInt(updateRate)
      };
      
      await connectToSimulator(params);
      onSuccess();
    } catch (err) {
      setError((err as Error).message || 'Failed to connect to simulator');
    } finally {
      setLoading(false);
    }
  };
  
  const isStepValid = () => {
    switch (activeStep) {
      case 0:
        return selectedSimulator !== '';
      case 1:
        return (
          connectionName !== '' && 
          host !== '' && 
          port !== '' && 
          !isNaN(parseInt(port)) &&
          parseInt(port) > 0 && 
          parseInt(port) < 65536
        );
      case 2:
        return updateRate !== '' && !isNaN(parseInt(updateRate)) && parseInt(updateRate) > 0;
      default:
        return true;
    }
  };
  
  return (
    <Dialog 
      open={open} 
      onClose={onClose} 
      maxWidth="md" 
      fullWidth
      PaperProps={{ sx: { overflow: 'visible' } }}
    >
      <DialogTitle>
        <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
          <MonitorPlay />
          Connect to Simulator
        </Box>
      </DialogTitle>
      
      <Divider />
      
      <DialogContent>
        <Stepper activeStep={activeStep} sx={{ mb: 4 }}>
          <Step>
            <StepLabel>Select Simulator</StepLabel>
          </Step>
          <Step>
            <StepLabel>Connection Details</StepLabel>
          </Step>
          <Step>
            <StepLabel>Configuration</StepLabel>
          </Step>
        </Stepper>
        
        {activeStep === 0 && (
          <Box>
            <Typography variant="subtitle1" gutterBottom>
              Select a simulator to connect to:
            </Typography>
            
            <Box sx={{ display: 'grid', gridTemplateColumns: '1fr 1fr', gap: 2, mt: 2 }}>
              {simulators.map((simulator) => (
                <Box
                  key={simulator.id}
                  onClick={() => handleSimulatorSelect(simulator.id)}
                  sx={{
                    p: 2,
                    border: '1px solid',
                    borderColor: selectedSimulator === simulator.id ? 'primary.main' : 'divider',
                    borderRadius: 1,
                    cursor: 'pointer',
                    bgcolor: selectedSimulator === simulator.id ? 'primary.lighter' : 'background.paper',
                    transition: 'all 0.2s',
                    '&:hover': {
                      borderColor: 'primary.main',
                      bgcolor: 'primary.lighter'
                    }
                  }}
                >
                  <Box sx={{ display: 'flex', alignItems: 'center', gap: 1 }}>
                    <MonitorPlay size={24} />
                    <Typography variant="h6">{simulator.name}</Typography>
                  </Box>
                  <Typography variant="body2" color="text.secondary" sx={{ mt: 1 }}>
                    {simulator.description}
                  </Typography>
                </Box>
              ))}
            </Box>
          </Box>
        )}
        
        {activeStep === 1 && (
          <Box>
            <Typography variant="subtitle1" gutterBottom>
              Enter connection details:
            </Typography>
            
            <Box sx={{ mt: 2, display: 'flex', flexDirection: 'column', gap: 2 }}>
              <TextField
                label="Connection Name"
                fullWidth
                value={connectionName}
                onChange={(e) => setConnectionName(e.target.value)}
                required
              />
              
              <Box sx={{ display: 'flex', gap: 2 }}>
                <TextField
                  label="Host"
                  fullWidth
                  value={host}
                  onChange={(e) => setHost(e.target.value)}
                  required
                />
                
                <TextField
                  label="Port"
                  fullWidth
                  type="number"
                  value={port}
                  onChange={(e) => setPort(e.target.value)}
                  required
                  inputProps={{ min: 1, max: 65535 }}
                />
              </Box>
              
              <Box sx={{ display: 'flex', gap: 2 }}>
                <TextField
                  label="Username"
                  fullWidth
                  value={username}
                  onChange={(e) => setUsername(e.target.value)}
                />
                
                <TextField
                  label="Password"
                  fullWidth
                  type="password"
                  value={password}
                  onChange={(e) => setPassword(e.target.value)}
                />
              </Box>
            </Box>
          </Box>
        )}
        
        {activeStep === 2 && (
          <Box>
            <Typography variant="subtitle1" gutterBottom>
              Configure simulator settings:
            </Typography>
            
            <Box sx={{ mt: 2, display: 'flex', flexDirection: 'column', gap: 2 }}>
              <FormControl fullWidth>
                <InputLabel id="update-rate-label">Update Rate (Hz)</InputLabel>
                <Select
                  labelId="update-rate-label"
                  value={updateRate}
                  label="Update Rate (Hz)"
                  onChange={(e) => setUpdateRate(e.target.value)}
                >
                  <MenuItem value="10">10 Hz</MenuItem>
                  <MenuItem value="30">30 Hz</MenuItem>
                  <MenuItem value="60">60 Hz</MenuItem>
                  <MenuItem value="120">120 Hz</MenuItem>
                </Select>
              </FormControl>
              
              <Typography variant="body2" color="text.secondary">
                The update rate determines how frequently data is fetched from the simulator.
                Higher rates provide more accurate data but require more network bandwidth.
              </Typography>
              
              {error && (
                <Typography variant="body2" color="error" sx={{ mt: 2 }}>
                  {error}
                </Typography>
              )}
            </Box>
          </Box>
        )}
      </DialogContent>
      
      <DialogActions>
        <Button onClick={onClose}>Cancel</Button>
        {activeStep > 0 && (
          <Button onClick={handleBack}>Back</Button>
        )}
        {activeStep < 2 ? (
          <Button 
            onClick={handleNext} 
            variant="contained" 
            disabled={!isStepValid()}
          >
            Next
          </Button>
        ) : (
          <Button 
            onClick={handleConnect} 
            variant="contained" 
            disabled={!isStepValid() || loading}
          >
            {loading ? <CircularProgress size={24} /> : 'Connect'}
          </Button>
        )}
      </DialogActions>
    </Dialog>
  );
};

export default SimulatorConnectDialog;

// /frontend/hooks/useIntegrationService.ts
import { useState, useCallback, useEffect } from 'react';
import api from '../services/api';
import { 
  Connection, 
  ConnectionHealth, 
  SimulatorConnectionParams,
  BiometricDeviceParams,
  EnterpriseSystemParams,
  CalendarConnectionParams,
  Simulator,
  BiometricDevice,
  EnterpriseSystem,
  Calendar
} from '../types/integration';

export const useIntegrationService = () => {
  const [connections, setConnections] = useState<Connection[]>([]);
  const [connectionHealth, setConnectionHealth] = useState<ConnectionHealth[]>([]);
  const [loading, setLoading] = useState<boolean>(false);
  const [error, setError] = useState<string | null>(null);
  
  // Available integration types
  const [simulators, setSimulators] = useState<Simulator[]>([]);
  const [biometricDevices, setBiometricDevices] = useState<BiometricDevice[]>([]);
  const [enterpriseSystems, setEnterpriseSystems] = useState<EnterpriseSystem[]>([]);
  const [calendars, setCalendars] = useState<Calendar[]>([]);
  
  // Fetch available integration types
  const fetchAvailableIntegrations = useCallback(async () => {
    try {
      const [
        simulatorsResponse,
        biometricDevicesResponse,
        enterpriseSystemsResponse,
        calendarsResponse
      ] = await Promise.all([
        api.get('/integration/simulators/available'),
        api.get('/integration/biometrics/available'),
        api.get('/integration/enterprise/available'),
        api.get('/integration/calendars/available')
      ]);
      
      setSimulators(simulatorsResponse.data);
      setBiometricDevices(biometricDevicesResponse.data);
      setEnterpriseSystems(enterpriseSystemsResponse.data);
      setCalendars(calendarsResponse.data);
    } catch (err) {
      console.error('Failed to fetch available integrations', err);
    }
  }, []);
  
  // Fetch all connections
  const refreshConnections = useCallback(async () => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.get('/integration/connections');
      setConnections(response.data);
      setLoading(false);
    } catch (err) {
      setError('Failed to fetch connections');
      setLoading(false);
      console.error(err);
    }
  }, []);
  
  // Check connection health
  const checkConnectionHealth = useCallback(async () => {
    try {
      const response = await api.get('/integration/connections/health');
      setConnectionHealth(response.data);
    } catch (err) {
      console.error('Failed to check connection health', err);
    }
  }, []);
  
  // Connect to simulator
  const connectToSimulator = useCallback(async (params: SimulatorConnectionParams) => {
    try {
      const response = await api.post('/integration/simulators', params);
      return response.data;
    } catch (err) {
      console.error('Failed to connect to simulator', err);
      throw err;
    }
  }, []);
  
  // Connect to biometric device
  const connectToBiometricDevice = useCallback(async (params: BiometricDeviceParams) => {
    try {
      const response = await api.post('/integration/biometrics', params);
      return response.data;
    } catch (err) {
      console.error('Failed to connect to biometric device', err);
      throw err;
    }
  }, []);
  
  // Connect to enterprise system
  const connectToEnterpriseSystem = useCallback(async (params: EnterpriseSystemParams) => {
    try {
      const response = await api.post('/integration/enterprise', params);
      return response.data;
    } catch (err) {
      console.error('Failed to connect to enterprise system', err);
      throw err;
    }
  }, []);
  
  // Connect to calendar
  const connectToCalendar = useCallback(async (params: CalendarConnectionParams) => {
    try {
      const response = await api.post('/integration/calendars', params);
      return response.data;
    } catch (err) {
      console.error('Failed to connect to calendar', err);
      throw err;
    }
  }, []);
  
  // Delete connection
  const deleteConnection = useCallback(async (connectionId: string) => {
    try {
      await api.delete(`/integration/connections/${connectionId}`);
      // Remove from local state
      setConnections(prevConnections => 
        prevConnections.filter(conn => conn.id !== connectionId)
      );
      return true;
    } catch (err) {
      console.error('Failed to delete connection', err);
      throw err;
    }
  }, []);
  
  // Update connection
  const updateConnection = useCallback(async (connectionId: string, params: any) => {
    try {
      const response = await api.put(`/integration/connections/${connectionId}`, params);
      // Update in local state
      setConnections(prevConnections => 
        prevConnections.map(conn => 
          conn.id === connectionId ? { ...conn, ...response.data } : conn
        )
      );
      return response.data;
    } catch (err) {
      console.error('Failed to update connection', err);
      throw err;
    }
  }, []);
  
  // Start telemetry stream (simulator)
  const startTelemetryStream = useCallback(async (simulatorId: string, params: any) => {
    try {
      const response = await api.post(`/integration/simulators/${simulatorId}/telemetry/start`, params);
      return response.data;
    } catch (err) {
      console.error('Failed to start telemetry stream', err);
      throw err;
    }
  }, []);
  
  // Stop telemetry stream (simulator)
  const stopTelemetryStream = useCallback(async (simulatorId: string) => {
    try {
      await api.post(`/integration/simulators/${simulatorId}/telemetry/stop`);
      return true;
    } catch (err) {
      console.error('Failed to stop telemetry stream', err);
      throw err;
    }
  }, []);
  
  // Initialize
  useEffect(() => {
    fetchAvailableIntegrations();
    refreshConnections();
    checkConnectionHealth();
  }, [fetchAvailableIntegrations, refreshConnections, checkConnectionHealth]);
  
  return {
    connections,
    connectionHealth,
    loading,
    error,
    simulators,
    biometricDevices,
    enterpriseSystems,
    calendars,
    refreshConnections,
    checkConnectionHealth,
    connectToSimulator,
    connectToBiometricDevice,
    connectToEnterpriseSystem,
    connectToCalendar,
    deleteConnection,
    updateConnection,
    startTelemetryStream,
    stopTelemetryStream
  };
};

// /frontend/types/integration.ts
export interface Connection {
  id: string;
  name: string;
  type: number;
  status: number;
  errorMessage: string;
  lastConnected: string;
  createdAt: string;
  connectionParams: any;
}

export interface ConnectionHealth {
  connectionId: string;
  isHealthy: boolean;
  latencyMs: number;
  statusMessage: string;
  checkedAt: string;
}

export interface SimulatorConnectionParams {
  name: string;
  host: string;
  port: number;
  username?: string;
  password?: string;
  simulatorType: string;
  updateFrequencyHz: number;
}

export interface BiometricDeviceParams {
  name: string;
  deviceType: string;
  connectionMethod: string;
  deviceId?: string;
  host?: string;
  port?: number;
  apiKey?: string;
}

export interface EnterpriseSystemParams {
  name: string;
  systemType: string;
  baseUrl: string;
  username?: string;
  password?: string;
  apiKey?: string;
  tenantId?: string;
  syncIntervalMinutes: number;
}

export interface CalendarConnectionParams {
  name: string;
  calendarType: string;
  authMethod: string;
  baseUrl?: string;
  username?: string;
  password?: string;
  apiKey?: string;
  calendarId?: string;
}

export interface Simulator {
  id: string;
  name: string;
  type: string;
  description: string;
  defaultHost: string;
  defaultPort: number;
  supportedFeatures: string[];
}

export interface BiometricDevice {
  id: string;
  name: string;
  type: string;
  description: string;
  connectionMethods: string[];
  dataTypes: string[];
}

export interface EnterpriseSystem {
  id: string;
  name: string;
  type: string;
  description: string;
  features: string[];
}

export interface Calendar {
  id: string;
  name: string;
  type: string;
  description: string;
  authMethods: string[];
}

export interface TelemetryData {
  timestamp: number;
  parameters: Record<string, number>;
}

export interface BiometricData {
  timestamp: number;
  deviceId: string;
  dataType: string;
  value: any;
}

export interface TraineeProfile {
  id: string;
  externalId: string;
  firstName: string;
  lastName: string;
  email: string;
  department: string;
  position: string;
  employeeId: string;
  hireDate: string;
  customAttributes: Record<string, string>;
}

export interface CourseRegistration {
  id: string;
  traineeId: string;
  courseId: string;
  courseName: string;
  registrationDate: string;
  startDate: string;
  endDate: string;
  status: string;
}

export interface CalendarEvent {
  id: string;
  title: string;
  description: string;
  location: string;
  startTime: string;
  endTime: string;
  isAllDay: boolean;
  attendees: string[];
  organizer: string;
  status: string;
}

{
  "name": "training-platform-frontend",
  "version": "0.1.0",
  "private": true,
  "dependencies": {
    "@testing-library/jest-dom": "^5.16.5",
    "@testing-library/react": "^13.4.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.3",
    "@types/react": "^18.0.25",
    "@types/react-dom": "^18.0.9",
    "axios": "^1.2.0",
    "chart.js": "^4.0.1",
    "react": "^18.2.0",
    "react-chartjs-2": "^5.0.1",
    "react-dom": "^18.2.0",
    "react-icons": "^4.7.1",
    "react-query": "^3.39.2",
    "react-router-dom": "^6.4.3",
    "react-scripts": "5.0.1",
    "tailwindcss": "^3.2.4",
    "typescript": "^4.9.3",
    "web-vitals": "^2.1.4",
    "zustand": "^4.1.4"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject",
    "lint": "eslint --ext .js,.jsx,.ts,.tsx src/",
    "format": "prettier --write \"src/**/*.{ts,tsx,js,jsx,json,css,scss,md}\"",
    "prepare": "husky install"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "devDependencies": {
    "@typescript-eslint/eslint-plugin": "^5.45.0",
    "@typescript-eslint/parser": "^5.45.0",
    "autoprefixer": "^10.4.13",
    "eslint": "^8.28.0",
    "eslint-config-prettier": "^8.5.0",
    "eslint-plugin-prettier": "^4.2.1",
    "eslint-plugin-react": "^7.31.11",
    "eslint-plugin-react-hooks": "^4.6.0",
    "husky": "^8.0.2",
    "lint-staged": "^13.0.4",
    "postcss": "^8.4.19",
    "prettier": "^2.8.0"
  },
  "lint-staged": {
    "src/**/*.{js,jsx,ts,tsx}": [
      "eslint --fix",
      "prettier --write"
    ],
    "src/**/*.{json,css,scss,md}": [
      "prettier --write"
    ]
  }
}
// /frontend/components/visualization/KnowledgeMap3D.tsx
import React, { useRef, useEffect, useState } from 'react';
import { Box, CircularProgress, Typography, Button, Slider, Paper, IconButton, Tooltip } from '@mui/material';
import { ZoomIn, ZoomOut, Rotate3d, Home, Download, Share, Settings } from 'lucide-react';
import * as THREE from 'three';
import { OrbitControls } from 'three/examples/jsm/controls/OrbitControls';
import { useKnowledgeMapService } from '../../hooks/useKnowledgeMapService';
import { KnowledgeMap, KnowledgeNode, KnowledgeLink } from '../../types/visualization';
import KnowledgeMapLegend from './KnowledgeMapLegend';
import KnowledgeMapSettings from './KnowledgeMapSettings';

interface KnowledgeMap3DProps {
  syllabusId: string;
  mapId?: string;
}

const KnowledgeMap3D: React.FC<KnowledgeMap3DProps> = ({ syllabusId, mapId }) => {
  const canvasRef = useRef<HTMLDivElement>(null);
  const [loading, setLoading] = useState<boolean>(true);
  const [error, setError] = useState<string | null>(null);
  const [settingsOpen, setSettingsOpen] = useState<boolean>(false);
  const [knowledgeMap, setKnowledgeMap] = useState<KnowledgeMap | null>(null);
  const [zoomLevel, setZoomLevel] = useState<number>(1);
  
  // Three.js objects
  const sceneRef = useRef<THREE.Scene | null>(null);
  const cameraRef = useRef<THREE.PerspectiveCamera | null>(null);
  const rendererRef = useRef<THREE.WebGLRenderer | null>(null);
  const controlsRef = useRef<OrbitControls | null>(null);
  const frameIdRef = useRef<number | null>(null);
  
  // Node references for interaction
  const nodeObjectsRef = useRef<Map<string, THREE.Mesh>>(new Map());
  const [selectedNode, setSelectedNode] = useState<KnowledgeNode | null>(null);
  
  const { getKnowledgeMap, createKnowledgeMap } = useKnowledgeMapService();
  
  useEffect(() => {
    const fetchMap = async () => {
      try {
        setLoading(true);
        let map: KnowledgeMap;
        
        if (mapId) {
          // Load existing map
          map = await getKnowledgeMap(mapId);
        } else {
          // Create new map from syllabus
          map = await createKnowledgeMap(syllabusId);
        }
        
        setKnowledgeMap(map);
        setLoading(false);
      } catch (err) {
        setError('Failed to load knowledge map');
        setLoading(false);
        console.error(err);
      }
    };
    
    fetchMap();
  }, [syllabusId, mapId, getKnowledgeMap, createKnowledgeMap]);
  
  // Initialize Three.js scene
  useEffect(() => {
    if (!canvasRef.current || !knowledgeMap || loading) return;
    
    // Setup scene
    const scene = new THREE.Scene();
    scene.background = new THREE.Color(0xf0f0f0);
    sceneRef.current = scene;
    
    // Setup camera
    const camera = new THREE.PerspectiveCamera(
      75,
      canvasRef.current.clientWidth / canvasRef.current.clientHeight,
      0.1,
      1000
    );
    camera.position.z = 30;
    cameraRef.current = camera;
    
    // Setup renderer
    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(canvasRef.current.clientWidth, canvasRef.current.clientHeight);
    renderer.setPixelRatio(window.devicePixelRatio);
    canvasRef.current.appendChild(renderer.domElement);
    rendererRef.current = renderer;
    
    // Setup controls
    const controls = new OrbitControls(camera, renderer.domElement);
    controls.enableDamping = true;
    controls.dampingFactor = 0.05;
    controlsRef.current = controls;
    
    // Add ambient light
    const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
    scene.add(ambientLight);
    
    // Add directional light
    const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
    directionalLight.position.set(1, 1, 1);
    scene.add(directionalLight);
    
    // Create nodes and links
    createNodesAndLinks();
    
    // Animation loop
    const animate = () => {
      frameIdRef.current = requestAnimationFrame(animate);
      controls.update();
      renderer.render(scene, camera);
    };
    animate();
    
    // Handle resize
    const handleResize = () => {
      if (!canvasRef.current || !camera || !renderer) return;
      
      camera.aspect = canvasRef.current.clientWidth / canvasRef.current.clientHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(canvasRef.current.clientWidth, canvasRef.current.clientHeight);
    };
    
    window.addEventListener('resize', handleResize);
    
    // Cleanup
    return () => {
      if (frameIdRef.current !== null) {
        cancelAnimationFrame(frameIdRef.current);
      }
      window.removeEventListener('resize', handleResize);
      
      if (rendererRef.current && canvasRef.current) {
        canvasRef.current.removeChild(rendererRef.current.domElement);
      }
      
      // Dispose resources
      if (sceneRef.current) {
        sceneRef.current.traverse((object) => {
          if (object instanceof THREE.Mesh) {
            object.geometry.dispose();
            if (object.material instanceof THREE.Material) {
              object.material.dispose();
            } else if (Array.isArray(object.material)) {
              object.material.forEach(material => material.dispose());
            }
          }
        });
      }
    };
  }, [knowledgeMap, loading]);
  
  const createNodesAndLinks = () => {
    if (!sceneRef.current || !knowledgeMap) return;
    
    const scene = sceneRef.current;
    nodeObjectsRef.current.clear();
    
    // Create nodes
    knowledgeMap.nodes.forEach(node => {
      const nodeColor = new THREE.Color(node.color || getNodeColorByType(node.type));
      const geometry = new THREE.SphereGeometry(node.size || 1, 32, 32);
      const material = new THREE.MeshStandardMaterial({
        color: nodeColor,
        roughness: 0.7,
        metalness: 0.3
      });
      
      const mesh = new THREE.Mesh(geometry, material);
      mesh.position.set(
        node.position.x,
        node.position.y,
        node.position.z
      );
      mesh.userData = { nodeId: node.id, type: 'node' };
      scene.add(mesh);
      
      // Add node label
      const canvas = document.createElement('canvas');
      const context = canvas.getContext('2d');
      if (context) {
        canvas.width = 256;
        canvas.height = 128;
        context.fillStyle = '#ffffff';
        context.fillRect(0, 0, canvas.width, canvas.height);
        context.font = '24px Arial';
        context.fillStyle = '#000000';
        context.textAlign = 'center';
        context.fillText(node.label, canvas.width / 2, canvas.height / 2);
        
        const texture = new THREE.CanvasTexture(canvas);
        const spriteMaterial = new THREE.SpriteMaterial({ map: texture });
        const sprite = new THREE.Sprite(spriteMaterial);
        sprite.scale.set(5, 2.5, 1);
        sprite.position.set(
          node.position.x,
          node.position.y + node.size + 1.5,
          node.position.z
        );
        scene.add(sprite);
      }
      
      // Store reference to mesh
      nodeObjectsRef.current.set(node.id, mesh);
    });
    
    // Create links
    knowledgeMap.links.forEach(link => {
      const sourceNode = knowledgeMap.nodes.find(n => n.id === link.sourceNodeId);
      const targetNode = knowledgeMap.nodes.find(n => n.id === link.targetNodeId);
      
      if (sourceNode && targetNode) {
        const start = new THREE.Vector3(
          sourceNode.position.x,
          sourceNode.position.y,
          sourceNode.position.z
        );
        
        const end = new THREE.Vector3(
          targetNode.position.x,
          targetNode.position.y,
          targetNode.position.z
        );
        
        // Create curve for link
        const curve = new THREE.QuadraticBezierCurve3(
          start,
          new THREE.Vector3(
            (start.x + end.x) / 2,
            (start.y + end.y) / 2 + 2,
            (start.z + end.z) / 2
          ),
          end
        );
        
        const points = curve.getPoints(50);
        const geometry = new THREE.BufferGeometry().setFromPoints(points);
        
        const linkColor = new THREE.Color(link.color || '#888888');
        const material = new THREE.LineBasicMaterial({
          color: linkColor,
          linewidth: link.strength || 1
        });
        
        const line = new THREE.Line(geometry, material);
        line.userData = { linkId: link.id, type: 'link' };
        scene.add(line);
      }
    });
    
    // Set up raycaster for interactions
    setupInteractions();
  };
  
  const setupInteractions = () => {
    if (!canvasRef.current || !rendererRef.current || !cameraRef.current) return;
    
    const raycaster = new THREE.Raycaster();
    const mouse = new THREE.Vector2();
    
    const onMouseMove = (event: MouseEvent) => {
      // Calculate mouse position in normalized device coordinates
      const rect = rendererRef.current!.domElement.getBoundingClientRect();
      mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
      mouse.y = -((event.clientY - rect.top) / rect.height) * 2 + 1;
      
      // Update the raycaster
      raycaster.setFromCamera(mouse, cameraRef.current!);
      
      // Find intersections with nodes
      const intersects = raycaster.intersectObjects(
        Array.from(nodeObjectsRef.current.values())
      );
      
      if (intersects.length > 0) {
        const intersectedObject = intersects[0].object as THREE.Mesh;
        document.body.style.cursor = 'pointer';
        
        // Highlight node
        if (intersectedObject.material instanceof THREE.MeshStandardMaterial) {
          intersectedObject.material.emissive.set(0x333333);
        }
      } else {
        document.body.style.cursor = 'auto';
        
        // Reset all node materials
        nodeObjectsRef.current.forEach(nodeMesh => {
          if (nodeMesh.material instanceof THREE.MeshStandardMaterial) {
            nodeMesh.material.emissive.set(0x000000);
          }
        });
      }
    };
    
    const onClick = (event: MouseEvent) => {
      // Calculate mouse position in normalized device coordinates
      const rect = rendererRef.current!.domElement.getBoundingClientRect();
      mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
      mouse.y = -((event.clientY - rect.top) / rect.height) * 2 + 1;
      
      // Update the raycaster
      raycaster.setFromCamera(mouse, cameraRef.current!);
      
      // Find intersections with nodes
      const intersects = raycaster.intersectObjects(
        Array.from(nodeObjectsRef.current.values())
      );
      
      if (intersects.length > 0) {
        const intersectedObject = intersects[0].object as THREE.Mesh;
        const nodeId = intersectedObject.userData.nodeId;
        
        if (nodeId) {
          const node = knowledgeMap?.nodes.find(n => n.id === nodeId) || null;
          setSelectedNode(node);
        }
      } else {
        setSelectedNode(null);
      }
    };
    
    rendererRef.current.domElement.addEventListener('mousemove', onMouseMove);
    rendererRef.current.domElement.addEventListener('click', onClick);
    
    return () => {
      rendererRef.current?.domElement.removeEventListener('mousemove', onMouseMove);
      rendererRef.current?.domElement.removeEventListener('click', onClick);
    };
  };
  
  const handleZoomChange = (event: Event, newValue: number | number[]) => {
    if (typeof newValue === 'number') {
      setZoomLevel(newValue);
      
      if (cameraRef.current) {
        // Scale camera position based on zoom level
        const direction = new THREE.Vector3().subVectors(
          cameraRef.current.position,
          new THREE.Vector3(0, 0, 0)
        ).normalize();
        
        const distance = 30 / newValue;
        cameraRef.current.position.copy(direction.multiplyScalar(distance));
        cameraRef.current.updateProjectionMatrix();
      }
    }
  };
  
  const handleResetView = () => {
    if (cameraRef.current && controlsRef.current) {
      cameraRef.current.position.set(0, 0, 30);
      cameraRef.current.lookAt(0, 0, 0);
      controlsRef.current.reset();
      setZoomLevel(1);
    }
  };
  
  const handleExportMap = () => {
    if (!knowledgeMap) return;
    
    // Serialize the knowledge map to JSON
    const jsonStr = JSON.stringify(knowledgeMap, null, 2);
    const blob = new Blob([jsonStr], { type: 'application/json' });
    const url = URL.createObjectURL(blob);
    
    // Create a download link
    const a = document.createElement('a');
    a.href = url;
    a.download = `knowledge-map-${knowledgeMap.id}.json`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
  };
  
  // Helper function to get color based on node type
  const getNodeColorByType = (type: number): string => {
    switch (type) {
      case 0: // OBJECTIVE
        return '#4285F4'; // Blue
      case 1: // COMPETENCY
        return '#EA4335'; // Red
      case 2: // TOPIC
        return '#34A853'; // Green
      case 3: // PROCEDURE
        return '#FBBC05'; // Yellow
      case 4: // REGULATION
        return '#9C27B0'; // Purple
      case 5: // AIRCRAFT_SYSTEM
        return '#FF9800'; // Orange
      default:
        return '#9E9E9E'; // Grey
    }
  };
  
  // Helper function to get type name
  const getNodeTypeName = (type: number): string => {
    switch (type) {
      case 0: return 'Objective';
      case 1: return 'Competency';
      case 2: return 'Topic';
      case 3: return 'Procedure';
      case 4: return 'Regulation';
      case 5: return 'Aircraft System';
      default: return 'Unknown';
    }
  };
  
  if (loading) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" height="500px">
        <CircularProgress />
      </Box>
    );
  }
  
  if (error) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" height="500px">
        <Typography color="error">{error}</Typography>
      </Box>
    );
  }
  
  return (
    <Box sx={{ position: 'relative', height: '700px', width: '100%' }}>
      {/* Controls Panel */}
      <Paper
        elevation={3}
        sx={{
          position: 'absolute',
          top: 16,
          left: 16,
          zIndex: 10,
          p: 2,
          borderRadius: 2
        }}
      >
        <Box sx={{ display: 'flex', flexDirection: 'column', gap: 2 }}>
          <Tooltip title="Zoom In">
            <IconButton onClick={() => setZoomLevel(prev => Math.min(prev + 0.1, 2))}>
              <ZoomIn />
            </IconButton>
          </Tooltip>
          
          <Slider
            orientation="vertical"
            min={0.5}
            max={2}
            step={0.1}
            value={zoomLevel}
            onChange={handleZoomChange}
            sx={{ height: 100 }}
          />
          
          <Tooltip title="Zoom Out">
            <IconButton onClick={() => setZoomLevel(prev => Math.max(prev - 0.1, 0.5))}>
              <ZoomOut />
            </IconButton>
          </Tooltip>
          
          <Divider sx={{ my: 1 }} />
          
          <Tooltip title="Reset View">
            <IconButton onClick={handleResetView}>
              <Home />
            </IconButton>
          </Tooltip>
          
          <Tooltip title="Rotate Mode">
            <IconButton>
              <Rotate3d />
            </IconButton>
          </Tooltip>
          
          <Divider sx={{ my: 1 }} />
          
          <Tooltip title="Download Map">
            <IconButton onClick={handleExportMap}>
              <Download />
            </IconButton>
          </Tooltip>
          
          <Tooltip title="Share Map">
            <IconButton>
              <Share />
            </IconButton>
          </Tooltip>
          
          <Tooltip title="Map Settings">
            <IconButton onClick={() => setSettingsOpen(true)}>
              <Settings />
            </IconButton>
          </Tooltip>
        </Box>
      </Paper>
      
      {/* Legend */}
      <Box 
        sx={{ 
          position: 'absolute', 
          top: 16, 
          right: 16, 
          zIndex: 10 
        }}
      >
        <KnowledgeMapLegend />
      </Box>
      
      {/* Node Info Panel */}
      {selectedNode && (
        <Paper
          elevation={3}
          sx={{
            position: 'absolute',
            bottom: 16,
            left: 16,
            zIndex: 10,
            p: 2,
            borderRadius: 2,
            maxWidth: 300
          }}
        >
          <Typography variant="h6" gutterBottom>
            {selectedNode.label}
          </Typography>
          
          <Typography variant="body2" color="text.secondary" gutterBottom>
            Type: {getNodeTypeName(selectedNode.type)}
          </Typography>
          
          <Typography variant="body2">
            {selectedNode.description || 'No description available.'}
          </Typography>
          
          <Box sx={{ mt: 2 }}>
            <Button variant="outlined" size="small">
              View Details
            </Button>
          </Box>
        </Paper>
      )}
      
      {/* 3D Canvas */}
      <Box 
        ref={canvasRef} 
        sx={{ 
          width: '100%', 
          height: '100%', 
          borderRadius: 2,
          overflow: 'hidden',
          bgcolor: '#f0f0f0'
        }}
      />
      
      {/* Settings Dialog */}
      <KnowledgeMapSettings
        open={settingsOpen}
        onClose={() => setSettingsOpen(false)}
        knowledgeMap={knowledgeMap}
        onApplySettings={(updatedMap) => {
          setKnowledgeMap(updatedMap);
          // Re-create nodes and links with new settings
          if (sceneRef.current) {
            // Clear existing scene
            while (sceneRef.current.children.length > 0) {
              const object = sceneRef.current.children[0];
              sceneRef.current.remove(object);
            }
            
            // Add lights again
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
            sceneRef.current.add(ambientLight);
            
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(1, 1, 1);
            sceneRef.current.add(directionalLight);
            
            // Recreate nodes and links
            createNodesAndLinks();
          }
        }}
      />
    </Box>
  );
};

export default KnowledgeMap3D;

// /frontend/components/visualization/PerformanceDashboard.tsx
import React, { useState, useEffect } from 'react';
import { 
  Box, 
  Grid, 
  Paper, 
  Typography, 
  CircularProgress,
  Button,
  Card,
  CardContent,
  CardHeader,
  Divider,
  FormControl,
  InputLabel,
  Select,
  MenuItem,
  SelectChangeEvent,
  Tabs,
  Tab,
  IconButton,
  useTheme,
} from '@mui/material';
import { 
  BarChart,
  LineChart,
  Line,
  Bar,
  XAxis,
  YAxis,
  CartesianGrid,
  Tooltip,
  Legend,
  ResponsiveContainer,
  RadarChart,
  PolarGrid,
  PolarAngleAxis,
  PolarRadiusAxis,
  Radar,
} from 'recharts';
import { 
  Download,
  Calendar,
  Users,
  Filter,
  Maximize2,
  Settings,
} from 'lucide-react';
import { usePerformanceData } from '../../hooks/usePerformanceData';
import { Performance, CompetencyScore } from '../../types/visualization';
import CompetencyRadarChart from './CompetencyRadarChart';
import PerformanceTrend from './PerformanceTrend';
import AssessmentBreakdown from './AssessmentBreakdown';

interface PerformanceDashboardProps {
  traineeId?: string;
  groupId?: string;
  courseId?: string;
}

const PerformanceDashboard: React.FC<PerformanceDashboardProps> = ({ 
  traineeId,
  groupId,
  courseId 
}) => {
  const theme = useTheme();
  const [timeRange, setTimeRange] = useState<string>('month');
  const [selectedMetric, setSelectedMetric] = useState<string>('overall');
  const [tabValue, setTabValue] = useState<number>(0);
  
  const { 
    performanceData, 
    competencyScores,
    assessmentData,
    loading, 
    error,
    fetchPerformanceData,
    fetchCompetencyScores,
    fetchAssessmentData
  } = usePerformanceData();
  
  useEffect(() => {
    if (traineeId) {
      fetchPerformanceData(traineeId, timeRange);
      fetchCompetencyScores(traineeId);
      fetchAssessmentData(traineeId, timeRange);
    } else if (groupId) {
      // Fetch group performance data
    }
  }, [traineeId, groupId, timeRange, fetchPerformanceData, fetchCompetencyScores, fetchAssessmentData]);
  
  const handleTimeRangeChange = (event: SelectChangeEvent) => {
    setTimeRange(event.target.value);
  };
  
  const handleMetricChange = (event: SelectChangeEvent) => {
    setSelectedMetric(event.target.value);
  };
  
  const handleTabChange = (event: React.SyntheticEvent, newValue: number) => {
    setTabValue(newValue);
  };
  
  if (loading) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" height="500px">
        <CircularProgress />
      </Box>
    );
  }
  
  if (error) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" height="500px">
        <Typography color="error">{error}</Typography>
      </Box>
    );
  }
  
  // Calculate summary metrics
  const calculateAverage = (data: Performance[]) => {
    if (data.length === 0) return 0;
    return data.reduce((sum, item) => sum + item.score, 0) / data.length;
  };
  
  const averageScore = calculateAverage(performanceData);
  const latestScore = performanceData.length > 0 ? performanceData[performanceData.length - 1].score : 0;
  const scoreChange = performanceData.length > 1 
    ? latestScore - performanceData[performanceData.length - 2].score
    : 0;
  
  const competencyNames = {
    technicalKnowledge: 'Technical Knowledge',
    procedureExecution: 'Procedure Execution',
    situationalAwareness: 'Situational Awareness',
    decisionMaking: 'Decision Making',
    communication: 'Communication',
    workload: 'Workload Management',
    teamwork: 'Teamwork'
  };
  
  // Transform competency data for radar chart
  const competencyRadarData = competencyScores.map(item => ({
    subject: competencyNames[item.competency as keyof typeof competencyNames] || item.competency,
    value: item.score,
    fullMark: 100
  }));
  
  // Prepare assessment breakdown data
  const assessmentCounts = assessmentData.reduce((acc: {[key: string]: number}, assessment) => {
    const result = assessment.result;
    acc[result] = (acc[result] || 0) + 1;
    return acc;
  }, {});
  
  const assessmentBreakdownData = [
    { name: 'Excellent', value: assessmentCounts['Excellent'] || 0, color: '#4CAF50' },
    { name: 'Good', value: assessmentCounts['Good'] || 0, color: '#2196F3' },
    { name: 'Satisfactory', value: assessmentCounts['Satisfactory'] || 0, color: '#FFC107' },
    { name: 'Needs Improvement', value: assessmentCounts['Needs Improvement'] || 0, color: '#FF5722' },
    { name: 'Unsatisfactory', value: assessmentCounts['Unsatisfactory'] || 0, color: '#F44336' }
  ];
  
  return (
    <Box>
      <Box sx={{ mb: 3, display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
        <Typography variant="h5">Performance Dashboard</Typography>
        <Box sx={{ display: 'flex', gap: 2 }}>
          <FormControl variant="outlined" size="small" sx={{ minWidth: 120 }}>
            <InputLabel>Time Range</InputLabel>
            <Select
              value={timeRange}
              onChange={handleTimeRangeChange}
              label="Time Range"
            >
              <MenuItem value="week">Past Week</MenuItem>
              <MenuItem value="month">Past Month</MenuItem>
              <MenuItem value="quarter">Past Quarter</MenuItem>
              <MenuItem value="year">Past Year</MenuItem>
              <MenuItem value="all">All Time</MenuItem>
            </Select>
          </FormControl>
          
          <Button 
            variant="outlined" 
            startIcon={<Download />}
            onClick={() => {/* Export functionality */}}
          >
            Export
          </Button>
        </Box>
      </Box>
      
      {/* Summary Cards */}
      <Grid container spacing={3} sx={{ mb: 3 }}>
        <Grid item xs={12} md={4}>
          <Paper
            elevation={2}
            sx={{
              p: 2,
              borderRadius: 2,
              height: '100%',
              background: `linear-gradient(135deg, ${theme.palette.primary.light}, ${theme.palette.primary.main})`,
              color: 'white'
            }}
          >
            <Typography variant="h6" gutterBottom>Overall Performance</Typography>
            <Typography variant="h3" sx={{ mb: 1 }}>{averageScore.toFixed(1)}%</Typography>
            <Box sx={{ display: 'flex', alignItems: 'center' }}>
              <Typography variant="body2">
                {scoreChange >= 0 ? '+' : ''}{scoreChange.toFixed(1)}% from previous period
              </Typography>
            </Box>
          </Paper>
        </Grid>
        
        <Grid item xs={12} md={4}>
          <Paper
            elevation={2}
            sx={{
              p: 2,
              borderRadius: 2,
              height: '100%'
            }}
          >
            <Typography variant="h6" gutterBottom>Total Assessments</Typography>
            <Typography variant="h3" sx={{ mb: 1 }}>{assessmentData.length}</Typography>
            <Typography variant="body2" color="text.secondary">
              {assessmentData.filter(a => a.result === 'Excellent' || a.result === 'Good').length} passed ({
                assessmentData.length > 0 
                  ? Math.round(assessmentData.filter(a => a.result === 'Excellent' || a.result === 'Good').length / assessmentData.length * 100)
                  : 0
              }%)
            </Typography>
          </Paper>
        </Grid>
        
        <Grid item xs={12} md={4}>
          <Paper
            elevation={2}
            sx={{
              p: 2,
              borderRadius: 2,
              height: '100%'
            }}
          >
            <Typography variant="h6" gutterBottom>Top Competency</Typography>
            {competencyScores.length > 0 ? (
              <>
                <Typography variant="h3" sx={{ mb: 1 }}>
                  {
                    competencyNames[
                      competencyScores.reduce((max, item) => 
                        item.score > max.score ? item : max
                      ).competency as keyof typeof competencyNames
                    ] || 'None'
                  }
                </Typography>
                <Typography variant="body2" color="text.secondary">
                  Score: {
                    competencyScores.reduce((max, item) => 
                      item.score > max.score ? item : max
                    ).score.toFixed(1)
                  }%
                </Typography>
              </>
            ) : (
              <Typography variant="body1">No competency data available</Typography>
            )}
          </Paper>
        </Grid>
      </Grid>
      
      {/* Tabs for different views */}
      <Box sx={{ borderBottom: 1, borderColor: 'divider', mb: 3 }}>
        <Tabs value={tabValue} onChange={handleTabChange} aria-label="dashboard tabs">
          <Tab label="Overview" />
          <Tab label="Competencies" />
          <Tab label="Assessments" />
          <Tab label="Trends" />
        </Tabs>
      </Box>
      
      {/* Tab Panels */}
      {tabValue === 0 && (
        <Grid container spacing={3}>
          {/* Performance Trend */}
          <Grid item xs={12} md={8}>
            <Paper
              elevation={2}
              sx={{
                p: 2,
                borderRadius: 2,
                height: '100%'
              }}
            >
              <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', mb: 2 }}>
                <Typography variant="h6">Performance Trend</Typography>
                <IconButton size="small">
                  <Maximize2 size={16} />
                </IconButton>
              </Box>
              
              <ResponsiveContainer width="100%" height={300}>
                <LineChart data={performanceData}>
                  <CartesianGrid strokeDasharray="3 3" />
                  <XAxis dataKey="date" />
                  <YAxis domain={[0, 100]} />
                  <Tooltip />
                  <Legend />
                  <Line
                    type="monotone"
                    dataKey="score"
                    stroke={theme.palette.primary.main}
                    activeDot={{ r: 8 }}
                    name="Overall Score"
                  />
                </LineChart>
              </ResponsiveContainer>
            </Paper>
          </Grid>
          
          {/* Competency Radar */}
          <Grid item xs={12} md={4}>
            <Paper
              elevation={2}
              sx={{
                p: 2,
                borderRadius: 2,
                height: '100%'
              }}
            >
              <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', mb: 2 }}>
                <Typography variant="h6">Competency Breakdown</Typography>
                <IconButton size="small">
                  <Maximize2 size={16} />
                </IconButton>
              </Box>
              
              <ResponsiveContainer width="100%" height={300}>
                <RadarChart outerRadius={90} data={competencyRadarData}>
                  <PolarGrid />
                  <PolarAngleAxis dataKey="subject" />
                  <PolarRadiusAxis domain={[0, 100]} />
                  <Radar
                    name="Competency Score"
                    dataKey="value"
                    stroke={theme.palette.primary.main}
                    fill={theme.palette.primary.main}
                    fillOpacity={0.6}
                  />
                </RadarChart>
              </ResponsiveContainer>
            </Paper>
          </Grid>
          
          {/* Assessment Results */}
          <Grid item xs={12} md={6}>
            <Paper
              elevation={2}
              sx={{
                p: 2,
                borderRadius: 2,
                height: '100%'
              }}
            >
              <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', mb: 2 }}>
                <Typography variant="h6">Assessment Results</Typography>
                <IconButton size="small">
                  <Maximize2 size={16} />
                </IconButton>
              </Box>
              
              <ResponsiveContainer width="100%" height={300}>
                <BarChart data={assessmentBreakdownData}>
                  <CartesianGrid strokeDasharray="3 3" />
                  <XAxis dataKey="name" />
                  <YAxis />
                  <Tooltip />
                  <Legend />
                  <Bar dataKey="value" name="Count">
                    {assessmentBreakdownData.map((entry, index) => (
                      <Cell key={`cell-${index}`} fill={entry.color} />
                    ))}
                  </Bar>
                </BarChart>
              </ResponsiveContainer>
            </Paper>
          </Grid>
          
          {/* Recent Assessments */}
          <Grid item xs={12} md={6}>
            <Paper
              elevation={2}
              sx={{
                p: 2,
                borderRadius: 2,
                height: '100%'
              }}
            >
              <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', mb: 2 }}>
                <Typography variant="h6">Recent Assessments</Typography>
                <Button size="small">View All</Button>
              </Box>
              
              {assessmentData.slice(0, 5).map((assessment, index) => (
                <Box key={index} sx={{ mb: 2 }}>
                  <Box sx={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center' }}>
                    <Box>
                      <Typography variant="body1">{assessment.title}</Typography>
                      <Typography variant="caption" color="text.secondary">
                        {assessment.date}  {assessment.instructor}
                      </Typography>
                    </Box>
                    <Typography
                      variant="body2"
                      sx={{
                        px: 1,
                        py: 0.5,
                        borderRadius: 1,
                        bgcolor: 
                          assessment.result === 'Excellent' ? 'success.light' :
                          assessment.result === 'Good' ? 'info.light' :
                          assessment.result === 'Satisfactory' ? 'warning.light' :
                          'error.light',
                        color: 
                          assessment.result === 'Excellent' ? 'success.dark' :
                          assessment.result === 'Good' ? 'info.dark' :
                          assessment.result === 'Satisfactory' ? 'warning.dark' :
                          'error.dark',
                      }}
                    >
                      {assessment.result}
                    </Typography>
                  </Box>
                  
                  {index < assessmentData.slice(0, 5).length - 1 && (
                    <Divider sx={{ mt: 2 }} />
                  )}
                </Box>
              ))}
            </Paper>
          </Grid>
        </Grid>
      )}
      
      {tabValue === 1 && (
        <CompetencyRadarChart competencyScores={competencyScores} />
      )}
      
      {tabValue === 2 && (
        <AssessmentBreakdown assessmentData={assessmentData} />
      )}
      
      {tabValue === 3 && (
        <PerformanceTrend performanceData={performanceData} />
      )}
    </Box>
  );
};

export default PerformanceDashboard;

// /frontend/hooks/useKnowledgeMapService.ts
import { useState, useCallback } from 'react';
import api from '../services/api';
import { KnowledgeMap } from '../types/visualization';

export const useKnowledgeMapService = () => {
  const [loading, setLoading] = useState<boolean>(false);
  const [error, setError] = useState<string | null>(null);
  
  const getKnowledgeMap = useCallback(async (mapId: string): Promise<KnowledgeMap> => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.get(`/visualization/knowledge-maps/${mapId}`);
      setLoading(false);
      return response.data;
    } catch (err) {
      setLoading(false);
      setError('Failed to fetch knowledge map');
      throw err;
    }
  }, []);
  
  const createKnowledgeMap = useCallback(async (syllabusId: string): Promise<KnowledgeMap> => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.post('/visualization/knowledge-maps', { syllabusId });
      setLoading(false);
      return response.data;
    } catch (err) {
      setLoading(false);
      setError('Failed to create knowledge map');
      throw err;
    }
  }, []);
  
  const updateKnowledgeMap = useCallback(async (mapId: string, data: Partial<KnowledgeMap>): Promise<KnowledgeMap> => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.put(`/visualization/knowledge-maps/${mapId}`, data);
      setLoading(false);
      return response.data;
    } catch (err) {
      setLoading(false);
      setError('Failed to update knowledge map');
      throw err;
    }
  }, []);
  
  const deleteKnowledgeMap = useCallback(async (mapId: string): Promise<boolean> => {
    setLoading(true);
    setError(null);
    
    try {
      await api.delete(`/visualization/knowledge-maps/${mapId}`);
      setLoading(false);
      return true;
    } catch (err) {
      setLoading(false);
      setError('Failed to delete knowledge map');
      throw err;
    }
  }, []);
  
  const exportKnowledgeMapToGltf = useCallback(async (mapId: string): Promise<Blob> => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.get(`/visualization/knowledge-maps/${mapId}/export/gltf`, {
        responseType: 'blob',
      });
      setLoading(false);
      return response.data;
    } catch (err) {
      setLoading(false);
      setError('Failed to export knowledge map');
      throw err;
    }
  }, []);
  
  const getUserKnowledgeMaps = useCallback(async (userId: string): Promise<KnowledgeMap[]> => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.get(`/visualization/knowledge-maps/user/${userId}`);
      setLoading(false);
      return response.data;
    } catch (err) {
      setLoading(false);
      setError('Failed to fetch user knowledge maps');
      throw err;
    }
  }, []);
  
  return {
    loading,
    error,
    getKnowledgeMap,
    createKnowledgeMap,
    updateKnowledgeMap,
    deleteKnowledgeMap,
    exportKnowledgeMapToGltf,
    getUserKnowledgeMaps,
  };
};

// /frontend/hooks/usePerformanceData.ts
import { useState, useCallback } from 'react';
import api from '../services/api';
import { Performance, CompetencyScore, Assessment } from '../types/visualization';

export const usePerformanceData = () => {
  const [performanceData, setPerformanceData] = useState<Performance[]>([]);
  const [competencyScores, setCompetencyScores] = useState<CompetencyScore[]>([]);
  const [assessmentData, setAssessmentData] = useState<Assessment[]>([]);
  const [loading, setLoading] = useState<boolean>(false);
  const [error, setError] = useState<string | null>(null);
  
  const fetchPerformanceData = useCallback(async (traineeId: string, timeRange: string = 'month') => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.get(`/analytics/performance/${traineeId}`, {
        params: { timeRange }
      });
      setPerformanceData(response.data);
      setLoading(false);
    } catch (err) {
      setError('Failed to fetch performance data');
      setLoading(false);
      console.error(err);
    }
  }, []);
  
  const fetchCompetencyScores = useCallback(async (traineeId: string) => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.get(`/analytics/competencies/${traineeId}`);
      setCompetencyScores(response.data);
      setLoading(false);
    } catch (err) {
      setError('Failed to fetch competency scores');
      setLoading(false);
      console.error(err);
    }
  }, []);
  
  const fetchAssessmentData = useCallback(async (traineeId: string, timeRange: string = 'month') => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.get(`/assessment/trainee/${traineeId}`, {
        params: { timeRange }
      });
      setAssessmentData(response.data);
      setLoading(false);
    } catch (err) {
      setError('Failed to fetch assessment data');
      setLoading(false);
      console.error(err);
    }
  }, []);
  
  const fetchGroupPerformance = useCallback(async (groupId: string, timeRange: string = 'month') => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.get(`/analytics/group-performance/${groupId}`, {
        params: { timeRange }
      });
      setPerformanceData(response.data);
      setLoading(false);
    } catch (err) {
      setError('Failed to fetch group performance data');
      setLoading(false);
      console.error(err);
    }
  }, []);
  
  const fetchGroupCompetencies = useCallback(async (groupId: string) => {
    setLoading(true);
    setError(null);
    
    try {
      const response = await api.get(`/analytics/group-competencies/${groupId}`);
      setCompetencyScores(response.data);
      setLoading(false);
    } catch (err) {
      setError('Failed to fetch group competency data');
      setLoading(false);
      console.error(err);
    }
  }, []);
  
  return {
    performanceData,
    competencyScores,
    assessmentData,
    loading,
    error,
    fetchPerformanceData,
    fetchCompetencyScores,
    fetchAssessmentData,
    fetchGroupPerformance,
    fetchGroupCompetencies
  };
};

// /frontend/types/visualization.ts
export interface Vector3 {
  x: number;
  y: number;
  z: number;
}

export interface KnowledgeNode {
  id: string;
  label: string;
  description?: string;
  type: number;
  position: Vector3;
  size: number;
  color: string;
  metadata?: Record<string, string>;
}

export interface KnowledgeLink {
  id: string;
  sourceNodeId: string;
  targetNodeId: string;
  label?: string;
  strength: number;
  color: string;
}

export interface KnowledgeMap {
  id: string;
  name: string;
  description?: string;
  creatorId: string;
  syllabusId: string;
  createdAt: string;
  updatedAt: string;
  nodes: KnowledgeNode[];
  links: KnowledgeLink[];
}

export interface Performance {
  id: string;
  traineeId: string;
  date: string;
  score: number;
  assessmentId?: string;
  assessmentTitle?: string;
  metadata?: Record<string, any>;
}

export interface CompetencyScore {
  id: string;
  traineeId: string;
  competency: string;
  score: number;
  lastUpdated: string;
}

export interface Assessment {
  id: string;
  traineeId: string;
  title: string;
  date: string;
  instructor: string;
  score: number;
  result: string;
  competencyBreakdown?: Record<string, number>;
  notes?: string;
}

export interface SimulationScene {
  id: string;
  name: string;
  description?: string;
  aircraftType: string;
  weather: string;
  timeOfDay: string;
  airport?: string;
  runway?: string;
  scenarios?: string[];
}

export interface ARContent {
  id: string;
  name: string;
  type: string;
  modelUrl: string;
  texturesUrl?: string;
  annotations?: Record<string, string>;
}

#include <drogon/drogon.h>
#include <json/json.h>
#include <string>
#include <vector>
#include <map>
#include <memory>
#include <mutex>
#include "gamification_repository.h"
#include "achievement_manager.h"
#include "leaderboard_service.h"

namespace atp {
namespace gamification {

class GamificationSystemAPI : public drogon::HttpController<GamificationSystemAPI> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(GamificationSystemAPI::getAchievements, "/api/gamification/achievements/{userId}", drogon::Get);
    ADD_METHOD_TO(GamificationSystemAPI::unlockAchievement, "/api/gamification/achievements/{userId}/unlock", drogon::Post);
    ADD_METHOD_TO(GamificationSystemAPI::getLeaderboard, "/api/gamification/leaderboard", drogon::Get);
    ADD_METHOD_TO(GamificationSystemAPI::getTrainingChallenges, "/api/gamification/challenges/{userId}", drogon::Get);
    ADD_METHOD_TO(GamificationSystemAPI::updateChallengeProgress, "/api/gamification/challenges/{userId}/progress", drogon::Post);
    ADD_METHOD_TO(GamificationSystemAPI::getSkillTree, "/api/gamification/skill-tree/{userId}", drogon::Get);
    ADD_METHOD_TO(GamificationSystemAPI::progressSkill, "/api/gamification/skill-tree/{userId}/progress", drogon::Post);
    ADD_METHOD_TO(GamificationSystemAPI::getStreaks, "/api/gamification/streaks/{userId}", drogon::Get);
    ADD_METHOD_TO(GamificationSystemAPI::updateStreak, "/api/gamification/streaks/{userId}/update", drogon::Post);
    ADD_METHOD_TO(GamificationSystemAPI::getRewards, "/api/gamification/rewards/{userId}", drogon::Get);
    ADD_METHOD_TO(GamificationSystemAPI::redeemReward, "/api/gamification/rewards/{userId}/redeem", drogon::Post);
    METHOD_LIST_END

    GamificationSystemAPI();

    void getAchievements(const drogon::HttpRequestPtr& req, 
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& userId);
    
    void unlockAchievement(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                          const std::string& userId);
    
    void getLeaderboard(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getTrainingChallenges(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                             const std::string& userId);
    
    void updateChallengeProgress(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                               const std::string& userId);
    
    void getSkillTree(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& userId);
    
    void progressSkill(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                      const std::string& userId);
    
    void getStreaks(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                   const std::string& userId);
    
    void updateStreak(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& userId);
    
    void getRewards(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                   const std::string& userId);
    
    void redeemReward(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& userId);

private:
    std::shared_ptr<GamificationRepository> gamificationRepo_;
    std::shared_ptr<AchievementManager> achievementManager_;
    std::shared_ptr<LeaderboardService> leaderboardService_;
    
    // Helper methods
    Json::Value generateAchievementProgress(const std::string& userId);
    Json::Value generatePersonalizedChallenges(const std::string& userId);
    bool validateAchievementUnlock(const std::string& userId, const std::string& achievementId);
    Json::Value applyAchievementRewards(const std::string& userId, const std::string& achievementId);
    Json::Value normalizeLeaderboardScores(const std::vector<Json::Value>& rawScores);
    Json::Value buildSkillTreeData(const std::string& userId);
    bool validateSkillProgression(const std::string& userId, const std::string& skillId);
    Json::Value calculateStreakRewards(const std::string& userId, int streakLength);
};

GamificationSystemAPI::GamificationSystemAPI() {
    // Initialize components
    gamificationRepo_ = std::make_shared<GamificationRepository>();
    achievementManager_ = std::make_shared<AchievementManager>();
    leaderboardService_ = std::make_shared<LeaderboardService>();
}

void GamificationSystemAPI::getAchievements(const drogon::HttpRequestPtr& req, 
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                      const std::string& userId) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string category = params.find("category") != params.end() ? params["category"] : "all";
        bool includeHidden = params.find("include_hidden") != params.end() && params["include_hidden"] == "true";
        
        // Get achievements for user
        Json::Value achievements = gamificationRepo_->getUserAchievements(userId, category, includeHidden);
        
        // Generate achievement progress
        Json::Value progress = generateAchievementProgress(userId);
        
        // Prepare response
        Json::Value result;
        result["user_id"] = userId;
        result["achievements"] = achievements;
        result["progress"] = progress;
        
        // Add achievement stats
        Json::Value stats;
        stats["total_earned"] = gamificationRepo_->getEarnedAchievementCount(userId);
        stats["total_available"] = gamificationRepo_->getTotalAchievementCount(category);
        stats["completion_percentage"] = (stats["total_earned"].asInt() * 100.0) / stats["total_available"].asInt();
        
        result["stats"] = stats;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::unlockAchievement(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& userId) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract achievement ID
        std::string achievementId = (*json)["achievement_id"].asString();
        
        // Validate achievement can be unlocked
        if (!validateAchievementUnlock(userId, achievementId)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Achievement requirements not met";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Unlock achievement
        bool success = achievementManager_->unlockAchievement(userId, achievementId);
        
        if (!success) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Failed to unlock achievement";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k500InternalServerError);
            callback(resp);
            return;
        }
        
        // Apply achievement rewards
        Json::Value rewards = applyAchievementRewards(userId, achievementId);
        
        // Get achievement details
        Json::Value achievement = gamificationRepo_->getAchievementDetails(achievementId);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["user_id"] = userId;
        result["achievement"] = achievement;
        result["rewards"] = rewards;
        result["unlocked_at"] = drogon::utils::getFormattedDate();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::getLeaderboard(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string category = params.find("category") != params.end() ? params["category"] : "overall";
        std::string timeFrame = params.find("time_frame") != params.end() ? params["time_frame"] : "all_time";
        int limit = params.find("limit") != params.end() ? std::stoi(params["limit"]) : 10;
        
        // Get leaderboard data
        std::vector<Json::Value> rawLeaderboard = leaderboardService_->getLeaderboard(category, timeFrame, limit);
        
        // Normalize scores for fair comparison
        Json::Value normalizedLeaderboard = normalizeLeaderboardScores(rawLeaderboard);
        
        // Prepare response
        Json::Value result;
        result["category"] = category;
        result["time_frame"] = timeFrame;
        result["generated_at"] = drogon::utils::getFormattedDate();
        result["entries"] = normalizedLeaderboard;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::getTrainingChallenges(const drogon::HttpRequestPtr& req,
                           std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                           const std::string& userId) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string category = params.find("category") != params.end() ? params["category"] : "all";
        std::string status = params.find("status") != params.end() ? params["status"] : "active";
        
        // Get active challenges
        Json::Value challenges = gamificationRepo_->getUserChallenges(userId, category, status);
        
        // Generate personalized challenges if needed
        if (challenges.size() < 3 && status == "active") {
            Json::Value personalizedChallenges = generatePersonalizedChallenges(userId);
            
            // Add personalized challenges to the list
            for (const auto& challenge : personalizedChallenges) {
                challenges.append(challenge);
            }
            
            // Save personalized challenges
            for (const auto& challenge : personalizedChallenges) {
                gamificationRepo_->saveUserChallenge(userId, challenge);
            }
        }
        
        // Prepare response
        Json::Value result;
        result["user_id"] = userId;
        result["category"] = category;
        result["status"] = status;
        result["challenges"] = challenges;
        
        // Add challenge stats
        Json::Value stats;
        stats["active_count"] = gamificationRepo_->getUserChallengeCount(userId, "active");
        stats["completed_count"] = gamificationRepo_->getUserChallengeCount(userId, "completed");
        stats["success_rate"] = gamificationRepo_->getUserChallengeSuccessRate(userId);
        
        result["stats"] = stats;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::updateChallengeProgress(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                             const std::string& userId) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract challenge ID and progress
        std::string challengeId = (*json)["challenge_id"].asString();
        int progressValue = (*json)["progress"].asInt();
        
        // Get current challenge
        Json::Value challenge = gamificationRepo_->getUserChallenge(userId, challengeId);
        
        if (challenge.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Challenge not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Update progress
        int currentProgress = challenge["current_progress"].asInt();
        int targetProgress = challenge["target_progress"].asInt();
        
        // Calculate new progress
        int newProgress = currentProgress + progressValue;
        if (newProgress > targetProgress) {
            newProgress = targetProgress;
        }
        
        challenge["current_progress"] = newProgress;
        
        // Check if challenge is completed
        bool isCompleted = (newProgress >= targetProgress);
        
        if (isCompleted) {
            challenge["status"] = "completed";
            challenge["completed_at"] = drogon::utils::getFormattedDate();
            
            // Apply rewards
            Json::Value rewards;
            rewards["experience_points"] = challenge["reward_xp"];
            rewards["points"] = challenge["reward_points"];
            
            // Apply rewards to user
            gamificationRepo_->applyUserRewards(userId, rewards);
        }
        
        // Save updated challenge
        gamificationRepo_->updateUserChallenge(userId, challengeId, challenge);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["user_id"] = userId;
        result["challenge_id"] = challengeId;
        result["previous_progress"] = currentProgress;
        result["current_progress"] = newProgress;
        result["target_progress"] = targetProgress;
        result["is_completed"] = isCompleted;
        
        if (isCompleted) {
            result["rewards"] = Json::Value(Json::objectValue);
            result["rewards"]["experience_points"] = challenge["reward_xp"];
            result["rewards"]["points"] = challenge["reward_points"];
        }
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::getSkillTree(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                   const std::string& userId) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string category = params.find("category") != params.end() ? params["category"] : "all";
        
        // Build skill tree data
        Json::Value skillTree = buildSkillTreeData(userId);
        
        // Filter by category if specified
        if (category != "all") {
            Json::Value filteredSkillTree(Json::arrayValue);
            
            for (const auto& skill : skillTree) {
                if (skill["category"].asString() == category) {
                    filteredSkillTree.append(skill);
                }
            }
            
            skillTree = filteredSkillTree;
        }
        
        // Get user's level and experience
        Json::Value userProfile = gamificationRepo_->getUserProfile(userId);
        
        // Prepare response
        Json::Value result;
        result["user_id"] = userId;
        result["level"] = userProfile["level"];
        result["experience"] = userProfile["experience"];
        result["skill_tree"] = skillTree;
        
        // Add skill stats
        Json::Value stats;
        stats["unlocked_skills"] = gamificationRepo_->getUserUnlockedSkillCount(userId);
        stats["total_skills"] = gamificationRepo_->getTotalSkillCount(category);
        stats["mastery_percentage"] = (stats["unlocked_skills"].asInt() * 100.0) / stats["total_skills"].asInt();
        
        result["stats"] = stats;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::progressSkill(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                    const std::string& userId) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract skill ID and progress action
        std::string skillId = (*json)["skill_id"].asString();
        std::string action = (*json)["action"].asString();
        
        // Validate skill progression
        if (!validateSkillProgression(userId, skillId)) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Skill prerequisites not met or already mastered";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Get skill details
        Json::Value skill = gamificationRepo_->getSkillDetails(skillId);
        
        // Get user's current progress on this skill
        Json::Value userSkill = gamificationRepo_->getUserSkillProgress(userId, skillId);
        
        int currentLevel = 0;
        if (!userSkill.isNull()) {
            currentLevel = userSkill["level"].asInt();
        }
        
        int maxLevel = skill["max_level"].asInt();
        
        // Calculate new level based on action
        int newLevel = currentLevel;
        
        if (action == "increase") {
            newLevel = currentLevel + 1;
            if (newLevel > maxLevel) {
                newLevel = maxLevel;
            }
        }
        else if (action == "master") {
            newLevel = maxLevel;
        }
        
        // Update skill progress
        userSkill["level"] = newLevel;
        userSkill["updated_at"] = drogon::utils::getFormattedDate();
        
        if (newLevel == maxLevel && currentLevel < maxLevel) {
            userSkill["mastered"] = true;
            userSkill["mastered_at"] = drogon::utils::getFormattedDate();
            
            // Apply mastery rewards
            int masteryXp = skill["mastery_xp"].asInt();
            
            // Update user's experience
            Json::Value userProfile = gamificationRepo_->getUserProfile(userId);
            int currentXp = userProfile["experience"].asInt();
            int newXp = currentXp + masteryXp;
            
            userProfile["experience"] = newXp;
            
            // Check for level up
            int currentLevel = userProfile["level"].asInt();
            int xpForNextLevel = (currentLevel + 1) * 1000; // Simple level calculation
            
            if (newXp >= xpForNextLevel) {
                userProfile["level"] = currentLevel + 1;
            }
            
            // Save updated profile
            gamificationRepo_->updateUserProfile(userId, userProfile);
        }
        
        // Save updated skill progress
        gamificationRepo_->updateUserSkillProgress(userId, skillId, userSkill);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["user_id"] = userId;
        result["skill_id"] = skillId;
        result["skill_name"] = skill["name"];
        result["previous_level"] = currentLevel;
        result["current_level"] = newLevel;
        result["max_level"] = maxLevel;
        
        if (newLevel == maxLevel && currentLevel < maxLevel) {
            result["mastered"] = true;
            result["rewards"] = Json::Value(Json::objectValue);
            result["rewards"]["experience_points"] = skill["mastery_xp"];
            
            if (userProfile["level"].asInt() > currentLevel) {
                result["level_up"] = true;
                result["new_level"] = userProfile["level"];
            }
        }
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::getStreaks(const drogon::HttpRequestPtr& req,
                 std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                 const std::string& userId) {
    try {
        // Get user's streak information
        Json::Value streakData = gamificationRepo_->getUserStreaks(userId);
        
        // Prepare response
        Json::Value result;
        result["user_id"] = userId;
        result["current_streak"] = streakData["current_streak"];
        result["longest_streak"] = streakData["longest_streak"];
        result["last_activity_date"] = streakData["last_activity_date"];
        result["streak_history"] = streakData["streak_history"];
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::updateStreak(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                   const std::string& userId) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract activity information
        std::string activityType = (*json)["activity_type"].asString();
        std::string activityDate = (*json).get("activity_date", drogon::utils::getFormattedDate()).asString();
        
        // Get user's current streak information
        Json::Value streakData = gamificationRepo_->getUserStreaks(userId);
        
        int currentStreak = streakData["current_streak"].asInt();
        int longestStreak = streakData["longest_streak"].asInt();
        std::string lastActivityDate = streakData["last_activity_date"].asString();
        
        // Check if this is a new day compared to last activity
        bool isNewDay = (lastActivityDate != activityDate);
        
        // Calculate new streak
        int newStreak = currentStreak;
        
        if (isNewDay) {
            // Check if this is a consecutive day
            // In a real implementation, proper date comparison would be done
            bool isConsecutiveDay = true; // Simplified for this example
            
            if (isConsecutiveDay) {
                newStreak = currentStreak + 1;
                
                // Update longest streak if needed
                if (newStreak > longestStreak) {
                    longestStreak = newStreak;
                }
            }
            else {
                // Streak broken
                newStreak = 1;
            }
        }
        
        // Update streak data
        streakData["current_streak"] = newStreak;
        streakData["longest_streak"] = longestStreak;
        streakData["last_activity_date"] = activityDate;
        
        // Add to history
        Json::Value historyEntry;
        historyEntry["date"] = activityDate;
        historyEntry["activity_type"] = activityType;
        
        streakData["streak_history"].append(historyEntry);
        
        // Save updated streak data
        gamificationRepo_->updateUserStreaks(userId, streakData);
        
        // Calculate streak rewards if streak increased
        Json::Value rewards;
        
        if (newStreak > currentStreak) {
            rewards = calculateStreakRewards(userId, newStreak);
            
            // Apply rewards to user
            gamificationRepo_->applyUserRewards(userId, rewards);
        }
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["user_id"] = userId;
        result["previous_streak"] = currentStreak;
        result["current_streak"] = newStreak;
        result["longest_streak"] = longestStreak;
        
        if (!rewards.isNull()) {
            result["rewards"] = rewards;
        }
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::getRewards(const drogon::HttpRequestPtr& req,
                 std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                 const std::string& userId) {
    try {
        // Extract query parameters
        auto params = req->getParameters();
        std::string status = params.find("status") != params.end() ? params["status"] : "available";
        
        // Get user rewards
        Json::Value rewards = gamificationRepo_->getUserRewards(userId, status);
        
        // Get user points
        Json::Value userProfile = gamificationRepo_->getUserProfile(userId);
        
        // Prepare response
        Json::Value result;
        result["user_id"] = userId;
        result["points"] = userProfile["points"];
        result["rewards"] = rewards;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void GamificationSystemAPI::redeemReward(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                   const std::string& userId) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract reward ID
        std::string rewardId = (*json)["reward_id"].asString();
        
        // Get reward details
        Json::Value reward = gamificationRepo_->getRewardDetails(rewardId);
        
        if (reward.isNull()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Reward not found";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Get user profile to check points
        Json::Value userProfile = gamificationRepo_->getUserProfile(userId);
        int userPoints = userProfile["points"].asInt();
        int rewardCost = reward["cost"].asInt();
        
        if (userPoints < rewardCost) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Insufficient points";
            error["user_points"] = userPoints;
            error["reward_cost"] = rewardCost;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Deduct points
        userProfile["points"] = userPoints - rewardCost;
        gamificationRepo_->updateUserProfile(userId, userProfile);
        
        // Record reward redemption
        Json::Value redemption;
        redemption["user_id"] = userId;
        redemption["reward_id"] = rewardId;
        redemption["redeemed_at"] = drogon::utils::getFormattedDate();
        redemption["cost"] = rewardCost;
        redemption["status"] = "pending";
        
        std::string redemptionId = gamificationRepo_->recordRewardRedemption(redemption);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["user_id"] = userId;
        result["reward_id"] = rewardId;
        result["reward_name"] = reward["name"];
        result["redemption_id"] = redemptionId;
        result["cost"] = rewardCost;
        result["previous_points"] = userPoints;
        result["current_points"] = userProfile["points"];
        result["redemption_status"] = "pending";
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

// Helper methods
Json::Value GamificationSystemAPI::generateAchievementProgress(const std::string& userId) {
    // In a real implementation, this would calculate actual progress for each achievement
    // For this example, we'll return mock progress data
    
    Json::Value progress(Json::objectValue);
    
    // Get user's in-progress achievements
    std::vector<Json::Value> inProgressAchievements = gamificationRepo_->getUserInProgressAchievements(userId);
    
    for (const auto& achievement : inProgressAchievements) {
        std::string achievementId = achievement["id"].asString();
        int currentProgress = achievement["current_progress"].asInt();
        int targetProgress = achievement["target_progress"].asInt();
        
        Json::Value achievementProgress;
        achievementProgress["current"] = currentProgress;
        achievementProgress["target"] = targetProgress;
        achievementProgress["percentage"] = (currentProgress * 100.0) / targetProgress;
        
        progress[achievementId] = achievementProgress;
    }
    
    return progress;
}

Json::Value GamificationSystemAPI::generatePersonalizedChallenges(const std::string& userId) {
    // In a real implementation, this would analyze user data to generate tailored challenges
    // For this example, we'll return mock challenges
    
    Json::Value challenges(Json::arrayValue);
    
    // Get user profile to personalize challenges
    Json::Value userProfile = gamificationRepo_->getUserProfile(userId);
    int userLevel = userProfile["level"].asInt();
    
    // Challenge 1: Training sessions
    Json::Value challenge1;
    challenge1["id"] = "ch-" + userId + "-" + std::to_string(std::rand());
    challenge1["type"] = "training";
    challenge1["title"] = "Consistent Training";
    challenge1["description"] = "Complete 5 training sessions within the next 7 days";
    challenge1["current_progress"] = 0;
    challenge1["target_progress"] = 5;
    challenge1["reward_xp"] = 150 + (userLevel * 10); // Scale with user level
    challenge1["reward_points"] = 100;
    challenge1["status"] = "active";
    challenge1["expires_at"] = ""; // Would be calculated based on current date + 7 days
    
    challenges.append(challenge1);
    
    // Challenge 2: Perfect score
    Json::Value challenge2;
    challenge2["id"] = "ch-" + userId + "-" + std::to_string(std::rand());
    challenge2["type"] = "performance";
    challenge2["title"] = "Perfect Execution";
    challenge2["description"] = "Achieve a perfect score on any assessment";
    challenge2["current_progress"] = 0;
    challenge2["target_progress"] = 1;
    challenge2["reward_xp"] = 200 + (userLevel * 15);
    challenge2["reward_points"] = 150;
    challenge2["status"] = "active";
    
    challenges.append(challenge2);
    
    // Challenge 3: Skill development
    Json::Value challenge3;
    challenge3["id"] = "ch-" + userId + "-" + std::to_string(std::rand());
    challenge3["type"] = "skill";
    challenge3["title"] = "Skill Mastery";
    challenge3["description"] = "Master 2 new skills in your skill tree";
    challenge3["current_progress"] = 0;
    challenge3["target_progress"] = 2;
    challenge3["reward_xp"] = 180 + (userLevel * 12);
    challenge3["reward_points"] = 120;
    challenge3["status"] = "active";
    
    challenges.append(challenge3);
    
    return challenges;
}

bool GamificationSystemAPI::validateAchievementUnlock(const std::string& userId, const std::string& achievementId) {
    // Get achievement details
    Json::Value achievement = gamificationRepo_->getAchievementDetails(achievementId);
    
    if (achievement.isNull()) {
        return false;
    }
    
    // Check if already unlocked
    bool isUnlocked = gamificationRepo_->isAchievementUnlocked(userId, achievementId);
    
    if (isUnlocked) {
        return false;
    }
    
    // Check prerequisites
    if (achievement.isMember("prerequisites") && achievement["prerequisites"].isArray()) {
        for (const auto& prereq : achievement["prerequisites"]) {
            std::string prereqId = prereq.asString();
            
            if (!gamificationRepo_->isAchievementUnlocked(userId, prereqId)) {
                return false;
            }
        }
    }
    
    // Check requirements based on achievement type
    std::string achievementType = achievement["type"].asString();
    
    if (achievementType == "progress") {
        // Progress-based achievement
        int currentProgress = achievement.isMember("current_progress") ? 
                            achievement["current_progress"].asInt() : 0;
        int targetProgress = achievement["target_progress"].asInt();
        
        return currentProgress >= targetProgress;
    }
    else if (achievementType == "milestone") {
        // Milestone achievement - validate based on user stats
        std::string milestoneType = achievement["milestone_type"].asString();
        int milestoneValue = achievement["milestone_value"].asInt();
        
        if (milestoneType == "training_count") {
            int userTrainingCount = gamificationRepo_->getUserTrainingCount(userId);
            return userTrainingCount >= milestoneValue;
        }
        else if (milestoneType == "perfect_score_count") {
            int userPerfectScoreCount = gamificationRepo_->getUserPerfectScoreCount(userId);
            return userPerfectScoreCount >= milestoneValue;
        }
        // Add more milestone types as needed
    }
    
    // For other achievement types or if no validation is needed
    return true;
}

Json::Value GamificationSystemAPI::applyAchievementRewards(const std::string& userId, const std::string& achievementId) {
    // Get achievement details to determine rewards
    Json::Value achievement = gamificationRepo_->getAchievementDetails(achievementId);
    
    Json::Value rewards(Json::objectValue);
    
    // Experience points
    int xpReward = achievement.get("reward_xp", 0).asInt();
    rewards["experience_points"] = xpReward;
    
    // Points
    int pointsReward = achievement.get("reward_points", 0).asInt();
    rewards["points"] = pointsReward;
    
    // Unlock badges if applicable
    if (achievement.isMember("reward_badges") && achievement["reward_badges"].isArray()) {
        Json::Value badges(Json::arrayValue);
        
        for (const auto& badgeId : achievement["reward_badges"]) {
            // Unlock badge for user
            achievementManager_->unlockBadge(userId, badgeId.asString());
            
            // Add badge details to response
            Json::Value badge = gamificationRepo_->getBadgeDetails(badgeId.asString());
            badges.append(badge);
        }
        
        rewards["badges"] = badges;
    }
    
    // Apply experience and points to user profile
    Json::Value userProfile = gamificationRepo_->getUserProfile(userId);
    
    int currentXp = userProfile["experience"].asInt();
    int currentPoints = userProfile["points"].asInt();
    int currentLevel = userProfile["level"].asInt();
    
    int newXp = currentXp + xpReward;
    int newPoints = currentPoints + pointsReward;
    
    userProfile["experience"] = newXp;
    userProfile["points"] = newPoints;
    
    // Check for level up
    int xpForNextLevel = (currentLevel + 1) * 1000; // Simple level calculation
    
    if (newXp >= xpForNextLevel) {
        int newLevel = currentLevel + 1;
        userProfile["level"] = newLevel;
        rewards["level_up"] = true;
        rewards["new_level"] = newLevel;
    }
    
    // Save updated profile
    gamificationRepo_->updateUserProfile(userId, userProfile);
    
    return rewards;
}

Json::Value GamificationSystemAPI::normalizeLeaderboardScores(const std::vector<Json::Value>& rawScores) {
    // In a real implementation, this would normalize scores based on various factors
    // For this example, we'll just convert the vector to a Json::Value array
    
    Json::Value normalizedScores(Json::arrayValue);
    
    for (const auto& score : rawScores) {
        normalizedScores.append(score);
    }
    
    return normalizedScores;
}

Json::Value GamificationSystemAPI::buildSkillTreeData(const std::string& userId) {
    // Get all skills
    std::vector<Json::Value> allSkills = gamificationRepo_->getAllSkills();
    
    // Get user's skill progress
    std::map<std::string, Json::Value> userSkillProgress = gamificationRepo_->getUserSkillProgressMap(userId);
    
    // Build skill tree with user progress
    Json::Value skillTree(Json::arrayValue);
    
    for (const auto& skill : allSkills) {
        Json::Value skillNode = skill;
        std::string skillId = skill["id"].asString();
        
        // Add user progress
        if (userSkillProgress.find(skillId) != userSkillProgress.end()) {
            skillNode["user_level"] = userSkillProgress[skillId]["level"];
            skillNode["mastered"] = userSkillProgress[skillId]["mastered"];
            
            if (userSkillProgress[skillId]["mastered"].asBool()) {
                skillNode["mastered_at"] = userSkillProgress[skillId]["mastered_at"];
            }
        }
        else {
            skillNode["user_level"] = 0;
            skillNode["mastered"] = false;
        }
        
        // Add unlock status
        skillNode["unlocked"] = isSkillUnlocked(userId, skill);
        
        skillTree.append(skillNode);
    }
    
    return skillTree;
}

bool GamificationSystemAPI::isSkillUnlocked(const std::string& userId, const Json::Value& skill) {
    // Check prerequisites
    if (skill.isMember("prerequisites") && skill["prerequisites"].isArray()) {
        for (const auto& prereq : skill["prerequisites"]) {
            std::string prereqId = prereq.asString();
            
            // Check if prerequisite skill is mastered
            Json::Value userSkill = gamificationRepo_->getUserSkillProgress(userId, prereqId);
            
            if (userSkill.isNull() || !userSkill["mastered"].asBool()) {
                return false;
            }
        }
    }
    
    // Check level requirement
    if (skill.isMember("level_requirement")) {
        int levelReq = skill["level_requirement"].asInt();
        
        Json::Value userProfile = gamificationRepo_->getUserProfile(userId);
        int userLevel = userProfile["level"].asInt();
        
        if (userLevel < levelReq) {
            return false;
        }
    }
    
    return true;
}

bool GamificationSystemAPI::validateSkillProgression(const std::string& userId, const std::string& skillId) {
    // Get skill details
    Json::Value skill = gamificationRepo_->getSkillDetails(skillId);
    
    if (skill.isNull()) {
        return false;
    }
    
    // Check if skill is unlocked
    if (!isSkillUnlocked(userId, skill)) {
        return false;
    }
    
    // Get user's current progress on this skill
    Json::Value userSkill = gamificationRepo_->getUserSkillProgress(userId, skillId);
    
    // Check if already mastered
    if (!userSkill.isNull() && userSkill["mastered"].asBool()) {
        return false;
    }
    
    return true;
}

Json::Value GamificationSystemAPI::calculateStreakRewards(const std::string& userId, int streakLength) {
    Json::Value rewards(Json::objectValue);
    
    // Calculate rewards based on streak length
    int xpReward = 0;
    int pointsReward = 0;
    
    // Example reward scale
    if (streakLength >= 365) {
        // 1 year streak
        xpReward = 1000;
        pointsReward = 500;
    }
    else if (streakLength >= 180) {
        // 6 month streak
        xpReward = 500;
        pointsReward = 250;
    }
    else if (streakLength >= 90) {
        // 3 month streak
        xpReward = 300;
        pointsReward = 150;
    }
    else if (streakLength >= 30) {
        // 1 month streak
        xpReward = 200;
        pointsReward = 100;
    }
    else if (streakLength >= 7) {
        // 1 week streak
        xpReward = 50;
        pointsReward = 25;
    }
    else {
        // Daily streaks (1-6 days)
        xpReward = 10 * streakLength;
        pointsReward = 5 * streakLength;
    }
    
    rewards["experience_points"] = xpReward;
    rewards["points"] = pointsReward;
    
    // Special milestones might unlock badges
    if (streakLength == 7 || streakLength == 30 || streakLength == 90 || 
        streakLength == 180 || streakLength == 365) {
        
        std::string badgeId = "streak-" + std::to_string(streakLength);
        achievementManager_->unlockBadge(userId, badgeId);
        
        Json::Value badge = gamificationRepo_->getBadgeDetails(badgeId);
        
        Json::Value badges(Json::arrayValue);
        badges.append(badge);
        
        rewards["badges"] = badges;
    }
    
    return rewards;
}

} // namespace gamification
} // namespace atp

// Main application setup
int main() {
    // Configure Drogon app
    drogon::app().setLogPath("./")
                 .setLogLevel(trantor::Logger::kInfo)
                 .addListener("0.0.0.0", 8086)
                 .setThreadNum(16)
                 .run();
    
    return 0;
}

{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "gnetId": null,
  "graphTooltip": 0,
  "id": 1,
  "links": [],
  "panels": [
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "custom": {}
        },
        "overrides": []
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 0,
        "y": 0
      },
      "hiddenSeries": false,
      "id": 2,
      "legend": {
        "avg": false,
        "current": false,
        "max": false,
        "min": false,
        "show": true,
        "total": false,
        "values": false
      },
      "lines": true,
      "linewidth": 1,
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "percentage": false,
      "pluginVersion": "7.3.7",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "sum(rate(http_requests_total[5m])) by (job)",
          "interval": "",
          "legendFormat": "{{job}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeFrom": null,
      "timeRegions": [],
      "timeShift": null,
      "title": "HTTP Request Rate (by Service)",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "buckets": null,
        "mode": "time",
        "name": null,
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "short",
          "label": "Requests/sec",
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        },
        {
          "format": "short",
          "label": null,
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        }
      ],
      "yaxis": {
        "align": false,
        "alignLevel": null
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "custom": {}
        },
        "overrides": []
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 9,
        "w": 12,
        "x": 12,
        "y": 0
      },
      "hiddenSeries": false,
      "id": 3,
      "legend": {
        "avg": false,
        "current": false,
        "max": false,
        "min": false,
        "show": true,
        "total": false,
        "values": false
      },
      "lines": true,
      "linewidth": 1,
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "percentage": false,
      "pluginVersion": "7.3.7",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (job, le))",
          "interval": "",
          "legendFormat": "{{job}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeFrom": null,
      "timeRegions": [],
      "timeShift": null,
      "title": "HTTP Request Duration (95th Percentile)",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "buckets": null,
        "mode": "time",
        "name": null,
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "s",
          "label": "Duration",
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        },
        {
          "format": "short",
          "label": null,
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        }
      ],
      "yaxis": {
        "align": false,
        "alignLevel": null
      }
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "custom": {
            "align": null,
            "filterable": false
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 9
      },
      "id": 4,
      "options": {
        "showHeader": true
      },
      "pluginVersion": "7.3.7",
      "targets": [
        {
          "expr": "sum(active_connections) by (job)",
          "instant": true,
          "interval": "",
          "legendFormat": "{{job}}",
          "refId": "A"
        }
      ],
      "timeFrom": null,
      "timeShift": null,
      "title": "Active Connections by Service",
      "type": "table"
    },
    {
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "custom": {},
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 80
              }
            ]
          }
        },
        "overrides": []
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 9
      },
      "id": 5,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "mean"
          ],
          "fields": "",
          "values": false
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "pluginVersion": "7.3.7",
      "targets": [
        {
          "expr": "sum(rate(http_response_status{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m])) * 100",
          "interval": "",
          "legendFormat": "",
          "refId": "A"
        }
      ],
      "timeFrom": null,
      "timeShift": null,
      "title": "Error Rate (%)",
      "type": "gauge"
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "custom": {}
        },
        "overrides": []
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 17
      },
      "hiddenSeries": false,
      "id": 6,
      "legend": {
        "avg": false,
        "current": false,
        "max": false,
        "min": false,
        "show": true,
        "total": false,
        "values": false
      },
      "lines": true,
      "linewidth": 1,
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "percentage": false,
      "pluginVersion": "7.3.7",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "rate(etr_record_operations_total{status=\"success\"}[5m])",
          "interval": "",
          "legendFormat": "{{operation}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeFrom": null,
      "timeRegions": [],
      "timeShift": null,
      "title": "ETR Record Operations",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "buckets": null,
        "mode": "time",
        "name": null,
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "ops",
          "label": "Operations/sec",
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        },
        {
          "format": "short",
          "label": null,
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        }
      ],
      "yaxis": {
        "align": false,
        "alignLevel": null
      }
    },
    {
      "aliasColors": {},
      "bars": false,
      "dashLength": 10,
      "dashes": false,
      "datasource": "Prometheus",
      "fieldConfig": {
        "defaults": {
          "custom": {}
        },
        "overrides": []
      },
      "fill": 1,
      "fillGradient": 0,
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 17
      },
      "hiddenSeries": false,
      "id": 7,
      "legend": {
        "avg": false,
        "current": false,
        "max": false,
        "min": false,
        "show": true,
        "total": false,
        "values": false
      },
      "lines": true,
      "linewidth": 1,
      "nullPointMode": "null",
      "options": {
        "alertThreshold": true
      },
      "percentage": false,
      "pluginVersion": "7.3.7",
      "pointradius": 2,
      "points": false,
      "renderer": "flot",
      "seriesOverrides": [],
      "spaceLength": 10,
      "stack": false,
      "steppedLine": false,
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(etr_request_duration_seconds_bucket[5m])) by (method, le))",
          "interval": "",
          "legendFormat": "{{method}}",
          "refId": "A"
        }
      ],
      "thresholds": [],
      "timeFrom": null,
      "timeRegions": [],
      "timeShift": null,
      "title": "ETR Request Duration (95th Percentile)",
      "tooltip": {
        "shared": true,
        "sort": 0,
        "value_type": "individual"
      },
      "type": "graph",
      "xaxis": {
        "buckets": null,
        "mode": "time",
        "name": null,
        "show": true,
        "values": []
      },
      "yaxes": [
        {
          "format": "s",
          "label": "Duration",
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        },
        {
          "format": "short",
          "label": null,
          "logBase": 1,
          "max": null,
          "min": null,
          "show": true
        }
      ],
      "yaxis": {
        "align": false,
        "alignLevel": null
      }
    }
  ],
  "refresh": "10s",
  "schemaVersion": 26,
  "style": "dark",
  "tags": [],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timepicker": {},
  "timezone": "",
  "title": "Advanced Pilot Training Platform",
  "uid": "pilot-training-platform",
  "version": 1
}
# Advanced Pilot Training Platform - Implementation Roadmap & Integration Guide

## 1. Implementation Phases

### Phase 1: Core Infrastructure (Weeks 1-4)
- [x] Core Platform Service - Authentication/Authorization
- [x] Core Platform Service - Service Discovery
- [x] Core Platform Service - Configuration Management
- [x] Data Acquisition Service - Basic Framework
- [x] ETR Service - Basic Framework
- [x] Database Schema Design and Implementation
- [x] Docker Configuration

### Phase 2: Service Implementation (Weeks 5-12)
- [x] ETR Service - Records Management
- [x] ETR Service - Digital Signatures
- [x] ETR Service - Compliance Tracking
- [x] ETR Service - Syllabus Management 
- [ ] Data Acquisition Service - Device Connectors
- [ ] Data Acquisition Service - Data Fusion
- [ ] AI Analytics Service - Model Framework
- [ ] AI Analytics Service - Inference Engine
- [ ] Document Service - Storage & Retrieval
- [ ] Document Service - Parsing & Extraction

### Phase 3: Advanced Features (Weeks 13-20)
- [ ] AI Syllabus Generator Service
- [ ] Assessment Service
- [ ] API Gateway Integration
- [ ] Frontend Applications
- [ ] Performance Optimization
- [ ] Security Hardening

### Phase 4: Integration & Testing (Weeks 21-24)
- [ ] End-to-End Testing
- [ ] Load Testing
- [ ] Security Auditing
- [ ] Monitoring & Alerting Setup
- [ ] Documentation Finalization

## 2. Integration Guidelines

### Service Communication Patterns

#### Synchronous Service Calls
For direct service-to-service communication, use gRPC:

```cpp
// Client-side example (calling another service)
auto channel = grpc::CreateChannel("service-name:port", 
                                  grpc::InsecureChannelCredentials());
auto stub = OtherService::NewStub(channel);

// Create request
ServiceRequest request;
request.set_field("value");

// Call method
ServiceResponse response;
grpc::ClientContext context;
grpc::Status status = stub->Method(&context, request, &response);

if (status.ok()) {
    // Process response
} else {
    // Handle error
}
```

#### Authentication Integration
All services should validate tokens with the Core Platform Service:

```cpp
// Token validation example
bool validateToken(const std::string& token) {
    auto channel = grpc::CreateChannel("core-platform-service:50051", 
                                      grpc::InsecureChannelCredentials());
    auto stub = AuthService::NewStub(channel);
    
    TokenValidationRequest request;
    request.set_token(token);
    
    TokenValidationResponse response;
    grpc::ClientContext context;
    grpc::Status status = stub->ValidateToken(&context, request, &response);
    
    return status.ok() && response.valid();
}
```

### Database Integration

Each service should use its own schema but connect to the shared PostgreSQL database:

```cpp
// Database connection example
auto db_connection = std::make_shared<persistence::DatabaseConnection>(
    getEnvOrDefault("DB_HOST", "postgres"),
    std::stoi(getEnvOrDefault("DB_PORT", "5432")),
    getEnvOrDefault("DB_NAME", "training_platform"),
    getEnvOrDefault("DB_USER", "postgres"),
    getEnvOrDefault("DB_PASSWORD", "postgres")
);

// Use schema qualification in queries
auto result = db_connection->executeQuery(
    "SELECT * FROM your_service_schema.your_table WHERE id = $1",
    {persistence::PgParam{"id", id, persistence::PgParamType::TEXT, false}}
);
```

### Metrics Integration

All services should expose Prometheus metrics:

```cpp
// Metrics initialization
metrics::MetricsService::getInstance().initialize(
    "your-service-name",
    true,  // expose_http
    "0.0.0.0",  // http_address
    9100,  // http_port
    false  // push_gateway
);

// Create metrics
auto& request_counter = metrics::MetricsService::getInstance().createCounter(
    "requests_total",
    "Total number of requests",
    {{"service", "your-service-name"}}
);

// Use metrics
request_counter.Increment();
```

### Logging Integration

Use the centralized logging framework:

```cpp
// Initialize logger
logging::Logger::getInstance().initialize(
    "your-service-name",
    logging::LogLevel::INFO,
    "logs/your-service.log"
);

// Use logger
logging::Logger::getInstance().info("Service started on port {}", port);
logging::Logger::getInstance().error("Error: {}", error_message);
```

## 3. API Integration Examples

### AI Analytics Integration with ETR Service

The AI Analytics Service provides performance assessment for training records:

```cpp
// In ETR Service - Requesting performance assessment
auto channel = grpc::CreateChannel("ai-analytics-service:50054", 
                                  grpc::InsecureChannelCredentials());
auto stub = AIAnalyticsService::NewStub(channel);

PerformanceAssessmentRequest request;
request.set_record_id(record_id);
request.set_trainee_id(trainee_id);
// Add more fields as needed

PerformanceAssessmentResponse response;
grpc::ClientContext context;
grpc::Status status = stub->AssessPerformance(&context, request, &response);

if (status.ok()) {
    // Process assessment results
    float score = response.overall_score();
    // Update record with AI assessment
}
```

### Document Service Integration with Syllabus Generator

The Syllabus Generator uses documents from the Document Service:

```cpp
// In Syllabus Generator - Retrieving documents
auto channel = grpc::CreateChannel("document-service:50055", 
                                  grpc::InsecureChannelCredentials());
auto stub = DocumentService::NewStub(channel);

GetDocumentRequest request;
request.set_document_id(document_id);

GetDocumentResponse response;
grpc::ClientContext context;
grpc::Status status = stub->GetDocument(&context, request, &response);

if (status.ok()) {
    // Process document content
    const std::string& content = response.content();
    // Extract training requirements from document
}
```

### Assessment Service Integration with ETR Service

The Assessment Service provides grades that are stored in training records:

```cpp
// In ETR Service - Updating record with assessment
auto record = getRecord(record_id);

// Add grades from assessment
for (const auto& criterion : assessment.criteria()) {
    records::GradeItem grade;
    grade.criteria_id = criterion.criteria_id();
    grade.criteria_name = criterion.name();
    grade.grade = criterion.grade();
    grade.comments = criterion.comments();
    
    record.addGrade(grade);
}

// Update record
updateRecord(record);
```

## 4. Frontend Integration

### REST API Access via API Gateway

Frontend applications connect to the API Gateway:

```typescript
// Authentication example
async function login(username: string, password: string): Promise<string> {
  const response = await fetch('http://api-gateway:8080/auth/login', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ username, password })
  });
  
  if (!response.ok) {
    throw new Error('Authentication failed');
  }
  
  const data = await response.json();
  return data.token;
}

// Accessing ETR service via gateway
async function getTrainingRecord(recordId: string): Promise<any> {
  const token = localStorage.getItem('token');
  
  const response = await fetch(`http://api-gateway:8080/etr/records/${recordId}`, {
    headers: { 
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    }
  });
  
  if (!response.ok) {
    throw new Error('Failed to fetch record');
  }
  
  return response.json();
}
```

### Real-time Data Visualization

For streaming data visualization:

```typescript
// Using WebSocket for real-time data
function connectToDataStream(sessionId: string): WebSocket {
  const token = localStorage.getItem('token');
  
  const ws = new WebSocket(`ws://api-gateway:8080/data-acquisition/stream/${sessionId}`);
  
  ws.onopen = () => {
    // Send authentication
    ws.send(JSON.stringify({ token }));
  };
  
  ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    // Update visualization with new data point
    updateChart(data);
  };
  
  return ws;
}
```

## 5. Testing Strategies

### Unit Testing

Each component should have comprehensive unit tests:

```cpp
// Example unit test for Record Service
TEST_F(RecordServiceTest, CreateRecordSuccess) {
  // Arrange
  auto record = createValidRecord();
  EXPECT_CALL(*mock_repository_, createRecord(_))
      .WillOnce(Return("test-record-id"));
  
  // Act
  std::string result = record_service_->createRecord(record);
  
  // Assert
  EXPECT_EQ(result, "test-record-id");
}
```

### Integration Testing

Test service interactions:

```cpp
// Example integration test
TEST_F(IntegrationTest, RecordCreationTriggerComplianceCheck) {
  // Create record
  auto record = createValidRecord();
  auto record_id = record_service_->createRecord(record);
  
  // Verify compliance check was triggered
  auto events = event_listener_->getEvents();
  bool found_compliance_event = false;
  
  for (const auto& event : events) {
    if (event.type == "compliance.check" && 
        event.data["record_id"] == record_id) {
      found_compliance_event = true;
      break;
    }
  }
  
  EXPECT_TRUE(found_compliance_event);
}
```

### End-to-End Testing

Test complete workflows across all services:

```cpp
// Example E2E test script
// This would typically be implemented in a testing framework
// that can interact with the system through its external APIs

// 1. Authenticate user
auto token = authenticateUser("instructor", "password");

// 2. Create training record
auto record_id = createTrainingRecord(token, trainee_id, ...);

// 3. Sign record
signRecord(token, record_id);

// 4. Verify record in database
auto record = getTrainingRecord(token, record_id);
EXPECT_TRUE(record.is_signed);

// 5. Check compliance status
auto compliance = getComplianceStatus(token, trainee_id);
// Verify compliance contains the new record
```

## 6. Performance Considerations

### Optimizing gRPC Communication

- Use streaming for large data transfers
- Implement connection pooling
- Consider using bidirectional streams for real-time data

### Database Performance

- Use appropriate indexes
- Implement query optimization
- Consider caching frequently accessed data
- Use connection pooling

### Real-time Processing

- Minimize data copying
- Use lock-free algorithms where possible
- Consider using memory-mapped files for large datasets
- Implement batched processing where appropriate
// src/backend/core/KnowledgeGraphEngine.h
#pragma once

#include <memory>
#include <string>
#include <vector>
#include <unordered_map>
#include <optional>
#include <functional>
#include <future>
#include <set>

#include "Result.h"
#include "Logger.h"
#include "ConfigurationManager.h"
#include "../document/DocumentProcessor.h"

namespace PilotTraining {
namespace Core {

// Forward declarations
class NLPProcessor;
class GraphDatabase;

/**
 * Enum representing relationship types in the knowledge graph
 */
enum class RelationshipType {
  HIERARCHICAL,  // Parent-child, contains, part of
  SEQUENTIAL,    // Precedes, follows
  CAUSAL,        // Causes, affects, influences
  TEMPORAL,      // Before, after, during
  ASSOCIATIVE,   // Related to, similar to
  REGULATORY,    // Regulated by, complies with
  TRAINING,      // Trains for, teaches, assesses
  CUSTOM         // User-defined relationship
};

/**
 * Struct representing a node in the knowledge graph
 */
struct KnowledgeNode {
  std::string id;
  std::string label;
  std::string type;
  std::unordered_map<std::string, std::string> properties;
  float confidence;
  std::optional<std::string> sourceDocumentId;
  std::optional<std::string> sourceLocation; // e.g., "page 5, paragraph 2"
  std::vector<std::string> tags;
  
  // Advanced features
  std::optional<std::string> summary;
  std::unordered_map<std::string, float> sentiment;
  std::optional<std::string> createdBy;
  std::optional<std::string> lastModifiedBy;
  std::string createdAt;
  std::string lastModifiedAt;
};

/**
 * Struct representing a relationship between nodes in the knowledge graph
 */
struct KnowledgeRelationship {
  std::string id;
  std::string sourceNodeId;
  std::string targetNodeId;
  RelationshipType type;
  std::string label;
  std::unordered_map<std::string, std::string> properties;
  float strength;
  float confidence;
  std::optional<std::string> sourceDocumentId;
  
  // Advanced features
  std::optional<std::string> bidirectional;
  std::optional<std::string> temporal; // e.g., "before", "after", "during"
  std::optional<std::string> createdBy;
  std::optional<std::string> lastModifiedBy;
  std::string createdAt;
  std::string lastModifiedAt;
};

/**
 * Struct representing a subgraph (a portion of the knowledge graph)
 */
struct KnowledgeSubgraph {
  std::vector<KnowledgeNode> nodes;
  std::vector<KnowledgeRelationship> relationships;
  std::unordered_map<std::string, std::string> metadata;
};

/**
 * Struct for knowledge graph query parameters
 */
struct KnowledgeGraphQuery {
  struct NodeFilter {
    std::optional<std::string> type;
    std::optional<std::vector<std::string>> labels;
    std::optional<std::vector<std::string>> tags;
    std::optional<std::vector<std::string>> sourceDocumentIds;
    std::optional<float> minConfidence;
    std::unordered_map<std::string, std::string> propertyFilters;
  };
  
  struct RelationshipFilter {
    std::optional<std::vector<RelationshipType>> types;
    std::optional<std::vector<std::string>> labels;
    std::optional<float> minStrength;
    std::optional<float> minConfidence;
    std::unordered_map<std::string, std::string> propertyFilters;
  };
  
  std::optional<NodeFilter> nodeFilter;
  std::optional<RelationshipFilter> relationshipFilter;
  std::optional<std::string> startNodeId;
  std::optional<int> maxDepth;
  std::optional<int> maxResults;
  bool includeProperties = true;
};

/**
 * Struct for natural language query parameters
 */
struct NaturalLanguageQuery {
  std::string query;
  std::optional<std::string> context;
  std::optional<std::string> language;
  std::optional<int> maxResults;
  std::optional<float> minConfidence;
};

/**
 * Interface for the Knowledge Graph Engine
 */
class IKnowledgeGraphEngine {
public:
  virtual ~IKnowledgeGraphEngine() = default;
  
  /**
   * Create a node in the knowledge graph
   * 
   * @param node Node to create
   * @return Result containing the created node ID or error
   */
  virtual Result<std::string> createNode(const KnowledgeNode& node) = 0;
  
  /**
   * Create a relationship between nodes in the knowledge graph
   * 
   * @param relationship Relationship to create
   * @return Result containing the created relationship ID or error
   */
  virtual Result<std::string> createRelationship(const KnowledgeRelationship& relationship) = 0;
  
  /**
   * Update a node in the knowledge graph
   * 
   * @param nodeId ID of the node to update
   * @param node Updated node data
   * @return Result indicating success or error
   */
  virtual Result<void> updateNode(const std::string& nodeId, const KnowledgeNode& node) = 0;
  
  /**
   * Update a relationship in the knowledge graph
   * 
   * @param relationshipId ID of the relationship to update
   * @param relationship Updated relationship data
   * @return Result indicating success or error
   */
  virtual Result<void> updateRelationship(
    const std::string& relationshipId, 
    const KnowledgeRelationship& relationship
  ) = 0;
  
  /**
   * Delete a node from the knowledge graph
   * 
   * @param nodeId ID of the node to delete
   * @return Result indicating success or error
   */
  virtual Result<void> deleteNode(const std::string& nodeId) = 0;
  
  /**
   * Delete a relationship from the knowledge graph
   * 
   * @param relationshipId ID of the relationship to delete
   * @return Result indicating success or error
   */
  virtual Result<void> deleteRelationship(const std::string& relationshipId) = 0;
  
  /**
   * Get a node from the knowledge graph
   * 
   * @param nodeId ID of the node to retrieve
   * @return Result containing the node or error
   */
  virtual Result<KnowledgeNode> getNode(const std::string& nodeId) = 0;
  
  /**
   * Get a relationship from the knowledge graph
   * 
   * @param relationshipId ID of the relationship to retrieve
   * @return Result containing the relationship or error
   */
  virtual Result<KnowledgeRelationship> getRelationship(const std::string& relationshipId) = 0;
  
  /**
   * Query the knowledge graph
   * 
   * @param query Query parameters
   * @return Result containing a subgraph of the knowledge graph or error
   */
  virtual Result<KnowledgeSubgraph> query(const KnowledgeGraphQuery& query) = 0;
  
  /**
   * Process a document to extract knowledge and build the graph
   * 
   * @param processingResult Result from document processing
   * @return Result containing the number of nodes and relationships created or error
   */
  virtual Result<std::pair<int, int>> processDocument(
    const Document::ProcessingResult& processingResult
  ) = 0;
  
  /**
   * Process a document asynchronously to extract knowledge and build the graph
   * 
   * @param processingResult Result from document processing
   * @return Future result containing the number of nodes and relationships created or error
   */
  virtual std::future<Result<std::pair<int, int>>> processDocumentAsync(
    const Document::ProcessingResult& processingResult
  ) = 0;
  
  /**
   * Query the knowledge graph using natural language
   * 
   * @param query Natural language query
   * @return Result containing a subgraph of the knowledge graph or error
   */
  virtual Result<KnowledgeSubgraph> naturalLanguageQuery(const NaturalLanguageQuery& query) = 0;
  
  /**
   * Merge two subgraphs
   * 
   * @param subgraph1 First subgraph
   * @param subgraph2 Second subgraph
   * @param mergeStrategy Strategy for resolving conflicts
   * @return Result containing the merged subgraph or error
   */
  virtual Result<KnowledgeSubgraph> mergeSubgraphs(
    const KnowledgeSubgraph& subgraph1,
    const KnowledgeSubgraph& subgraph2,
    const std::string& mergeStrategy = "prefer_higher_confidence"
  ) = 0;
  
  /**
   * Calculate the semantic similarity between two nodes
   * 
   * @param nodeId1 ID of the first node
   * @param nodeId2 ID of the second node
   * @return Result containing the similarity score (0.0 to 1.0) or error
   */
  virtual Result<float> calculateNodeSimilarity(
    const std::string& nodeId1,
    const std::string& nodeId2
  ) = 0;
  
  /**
   * Find the shortest path between two nodes
   * 
   * @param sourceNodeId ID of the source node
   * @param targetNodeId ID of the target node
   * @param maxDepth Maximum path length to consider
   * @return Result containing a subgraph representing the path or error
   */
  virtual Result<KnowledgeSubgraph> findShortestPath(
    const std::string& sourceNodeId,
    const std::string& targetNodeId,
    int maxDepth = 5
  ) = 0;
  
  /**
   * Detect communities in the knowledge graph
   * 
   * @param algorithm Community detection algorithm to use
   * @param parameters Algorithm-specific parameters
   * @return Result containing a map of community IDs to node IDs or error
   */
  virtual Result<std::unordered_map<std::string, std::vector<std::string>>> detectCommunities(
    const std::string& algorithm = "louvain",
    const std::unordered_map<std::string, std::string>& parameters = {}
  ) = 0;
  
  /**
   * Export the knowledge graph to a specified format
   * 
   * @param format Export format (e.g., "json", "graphml", "cypher")
   * @param filePath Path to save the exported graph
   * @param query Optional query to filter the exported graph
   * @return Result indicating success or error
   */
  virtual Result<void> exportGraph(
    const std::string& format,
    const std::string& filePath,
    const std::optional<KnowledgeGraphQuery>& query = std::nullopt
  ) = 0;
  
  /**
   * Import a knowledge graph from a file
   * 
   * @param format Import format (e.g., "json", "graphml", "cypher")
   * @param filePath Path to the file to import
   * @param mergeStrategy Strategy for resolving conflicts with existing data
   * @return Result containing the number of nodes and relationships imported or error
   */
  virtual Result<std::pair<int, int>> importGraph(
    const std::string& format,
    const std::string& filePath,
    const std::string& mergeStrategy = "prefer_higher_confidence"
  ) = 0;
};

/**
 * Implementation of the Knowledge Graph Engine
 */
class KnowledgeGraphEngine : public IKnowledgeGraphEngine {
public:
  explicit KnowledgeGraphEngine(
    std::shared_ptr<ConfigurationManager> configManager,
    std::shared_ptr<NLPProcessor> nlpProcessor,
    std::shared_ptr<GraphDatabase> graphDatabase
  );
  
  ~KnowledgeGraphEngine() override;
  
  Result<std::string> createNode(const KnowledgeNode& node) override;
  Result<std::string> createRelationship(const KnowledgeRelationship& relationship) override;
  Result<void> updateNode(const std::string& nodeId, const KnowledgeNode& node) override;
  Result<void> updateRelationship(
    const std::string& relationshipId, 
    const KnowledgeRelationship& relationship
  ) override;
  Result<void> deleteNode(const std::string& nodeId) override;
  Result<void> deleteRelationship(const std::string& relationshipId) override;
  Result<KnowledgeNode> getNode(const std::string& nodeId) override;
  Result<KnowledgeRelationship> getRelationship(const std::string& relationshipId) override;
  Result<KnowledgeSubgraph> query(const KnowledgeGraphQuery& query) override;
  Result<std::pair<int, int>> processDocument(
    const Document::ProcessingResult& processingResult
  ) override;
  std::future<Result<std::pair<int, int>>> processDocumentAsync(
    const Document::ProcessingResult& processingResult
  ) override;
  Result<KnowledgeSubgraph> naturalLanguageQuery(const NaturalLanguageQuery& query) override;
  Result<KnowledgeSubgraph> mergeSubgraphs(
    const KnowledgeSubgraph& subgraph1,
    const KnowledgeSubgraph& subgraph2,
    const std::string& mergeStrategy
  ) override;
  Result<float> calculateNodeSimilarity(
    const std::string& nodeId1,
    const std::string& nodeId2
  ) override;
  Result<KnowledgeSubgraph> findShortestPath(
    const std::string& sourceNodeId,
    const std::string& targetNodeId,
    int maxDepth
  ) override;
  Result<std::unordered_map<std::string, std::vector<std::string>>> detectCommunities(
    const std::string& algorithm,
    const std::unordered_map<std::string, std::string>& parameters
  ) override;
  Result<void> exportGraph(
    const std::string& format,
    const std::string& filePath,
    const std::optional<KnowledgeGraphQuery>& query
  ) override;
  Result<std::pair<int, int>> importGraph(
    const std::string& format,
    const std::string& filePath,
    const std::string& mergeStrategy
  ) override;
  
private:
  // Helper methods for document processing
  Result<std::vector<KnowledgeNode>> extractNodes(const Document::ProcessingResult& processingResult);
  Result<std::vector<KnowledgeRelationship>> extractRelationships(
    const Document::ProcessingResult& processingResult,
    const std::vector<KnowledgeNode>& nodes
  );
  
  // Helper methods for NLP processing
  Result<std::vector<std::pair<std::string, std::string>>> extractEntities(const std::string& text);
  Result<std::vector<std::tuple<std::string, std::string, RelationshipType>>> extractRelations(
    const std::string& text
  );
  
  // Helper methods for graph operations
  Result<KnowledgeSubgraph> executeQuery(const std::string& queryString);
  Result<std::string> generateNodeId(const KnowledgeNode& node);
  Result<std::string> generateRelationshipId(const KnowledgeRelationship& relationship);
  
  std::shared_ptr<ConfigurationManager> _configManager;
  std::shared_ptr<NLPProcessor> _nlpProcessor;
  std::shared_ptr<GraphDatabase> _graphDatabase;
  
  // Cache frequently accessed nodes and relationships
  std::unordered_map<std::string, KnowledgeNode> _nodeCache;
  std::unordered_map<std::string, KnowledgeRelationship> _relationshipCache;
  std::set<std::string> _processedDocuments;
  
  // Configuration values
  bool _enableNodeCaching;
  bool _enableRelationshipCaching;
  int _maxCacheSize;
  float _minConfidenceThreshold;
  std::string _defaultLanguage;
};

/**
 * Factory for creating knowledge graph engines
 */
class KnowledgeGraphEngineFactory {
public:
  explicit KnowledgeGraphEngineFactory(std::shared_ptr<ConfigurationManager> configManager);
  
  /**
   * Create a knowledge graph engine
   * 
   * @param engineType Type of engine to create
   * @return Shared pointer to knowledge graph engine
   */
  std::shared_ptr<IKnowledgeGraphEngine> createEngine(const std::string& engineType = "default");
  
private:
  std::shared_ptr<ConfigurationManager> _configManager;
  std::shared_ptr<NLPProcessor> _nlpProcessor;
  std::unordered_map<std::string, std::weak_ptr<IKnowledgeGraphEngine>> _engineInstances;
};

} // namespace Core
} // namespace PilotTraining

// src/backend/core/KnowledgeGraphEngine.cpp
#include "KnowledgeGraphEngine.h"
#include "NLPProcessor.h"
#include "GraphDatabase.h"

#include <chrono>
#include <algorithm>
#include <random>
#include <sstream>
#include <fstream>
#include <set>
#include <queue>
#include <unordered_set>

namespace PilotTraining {
namespace Core {

KnowledgeGraphEngine::KnowledgeGraphEngine(
    std::shared_ptr<ConfigurationManager> configManager,
    std::shared_ptr<NLPProcessor> nlpProcessor,
    std::shared_ptr<GraphDatabase> graphDatabase)
    : _configManager(std::move(configManager)),
      _nlpProcessor(std::move(nlpProcessor)),
      _graphDatabase(std::move(graphDatabase)) {
    
    // Load configuration values
    _enableNodeCaching = _configManager->getBool("knowledgeGraph.enableNodeCaching").value_or(true);
    _enableRelationshipCaching = _configManager->getBool("knowledgeGraph.enableRelationshipCaching").value_or(true);
    _maxCacheSize = _configManager->getInt("knowledgeGraph.maxCacheSize").value_or(1000);
    _minConfidenceThreshold = _configManager->getDouble("knowledgeGraph.minConfidenceThreshold").value_or(0.5);
    _defaultLanguage = _configManager->getString("knowledgeGraph.defaultLanguage").value_or("en");
    
    Logger::info("Knowledge Graph Engine initialized with cache size: {}", _maxCacheSize);
}

KnowledgeGraphEngine::~KnowledgeGraphEngine() = default;

Result<std::string> KnowledgeGraphEngine::createNode(const KnowledgeNode& node) {
    try {
        // Generate ID if not provided
        std::string nodeId = node.id.empty() ? generateNodeId(node).getValue() : node.id;
        
        // Check confidence threshold
        if (node.confidence < _minConfidenceThreshold) {
            Logger::warn("Node confidence {} below threshold {}, creating anyway", 
                node.confidence, _minConfidenceThreshold);
        }
        
        // Create node in database
        auto result = _graphDatabase->createNode(nodeId, node.label, node.type, node.properties);
        if (!result.isSuccess()) {
            return Result<std::string>::failure(result.getError().code, result.getError().message);
        }
        
        // Add to cache if enabled
        if (_enableNodeCaching) {
            if (_nodeCache.size() >= _maxCacheSize) {
                // Simple eviction strategy: remove a random entry
                auto it = _nodeCache.begin();
                std::advance(it, std::rand() % _nodeCache.size());
                _nodeCache.erase(it);
            }
            
            KnowledgeNode cachedNode = node;
            cachedNode.id = nodeId;
            _nodeCache[nodeId] = cachedNode;
        }
        
        return Result<std::string>::success(nodeId);
    } catch (const std::exception& e) {
        Logger::error("Error creating node: {}", e.what());
        return Result<std::string>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<std::string> KnowledgeGraphEngine::createRelationship(const KnowledgeRelationship& relationship) {
    try {
        // Check if source and target nodes exist
        auto sourceNodeResult = getNode(relationship.sourceNodeId);
        auto targetNodeResult = getNode(relationship.targetNodeId);
        
        if (!sourceNodeResult.isSuccess()) {
            return Result<std::string>::failure(ErrorCode::NodeNotFound, 
                "Source node not found: " + relationship.sourceNodeId);
        }
        
        if (!targetNodeResult.isSuccess()) {
            return Result<std::string>::failure(ErrorCode::NodeNotFound, 
                "Target node not found: " + relationship.targetNodeId);
        }
        
        // Generate ID if not provided
        std::string relId = relationship.id.empty() ? 
            generateRelationshipId(relationship).getValue() : relationship.id;
        
        // Check confidence threshold
        if (relationship.confidence < _minConfidenceThreshold) {
            Logger::warn("Relationship confidence {} below threshold {}, creating anyway", 
                relationship.confidence, _minConfidenceThreshold);
        }
        
        // Convert RelationshipType to string
        std::string typeStr;
        switch (relationship.type) {
            case RelationshipType::HIERARCHICAL: typeStr = "HIERARCHICAL"; break;
            case RelationshipType::SEQUENTIAL: typeStr = "SEQUENTIAL"; break;
            case RelationshipType::CAUSAL: typeStr = "CAUSAL"; break;
            case RelationshipType::TEMPORAL: typeStr = "TEMPORAL"; break;
            case RelationshipType::ASSOCIATIVE: typeStr = "ASSOCIATIVE"; break;
            case RelationshipType::REGULATORY: typeStr = "REGULATORY"; break;
            case RelationshipType::TRAINING: typeStr = "TRAINING"; break;
            case RelationshipType::CUSTOM: typeStr = "CUSTOM"; break;
            default: typeStr = "UNKNOWN";
        }
        
        // Create relationship in database
        auto result = _graphDatabase->createRelationship(
            relId, 
            relationship.sourceNodeId, 
            relationship.targetNodeId, 
            typeStr, 
            relationship.label, 
            relationship.properties
        );
        
        if (!result.isSuccess()) {
            return Result<std::string>::failure(result.getError().code, result.getError().message);
        }
        
        // Add to cache if enabled
        if (_enableRelationshipCaching) {
            if (_relationshipCache.size() >= _maxCacheSize) {
                // Simple eviction strategy: remove a random entry
                auto it = _relationshipCache.begin();
                std::advance(it, std::rand() % _relationshipCache.size());
                _relationshipCache.erase(it);
            }
            
            KnowledgeRelationship cachedRel = relationship;
            cachedRel.id = relId;
            _relationshipCache[relId] = cachedRel;
        }
        
        return Result<std::string>::success(relId);
    } catch (const std::exception& e) {
        Logger::error("Error creating relationship: {}", e.what());
        return Result<std::string>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<void> KnowledgeGraphEngine::updateNode(const std::string& nodeId, const KnowledgeNode& node) {
    try {
        // Check if node exists
        auto existingNodeResult = getNode(nodeId);
        if (!existingNodeResult.isSuccess()) {
            return Result<void>::failure(ErrorCode::NodeNotFound, "Node not found: " + nodeId);
        }
        
        // Update node in database
        auto result = _graphDatabase->updateNode(nodeId, node.label, node.type, node.properties);
        if (!result.isSuccess()) {
            return Result<void>::failure(result.getError().code, result.getError().message);
        }
        
        // Update cache if enabled
        if (_enableNodeCaching && _nodeCache.find(nodeId) != _nodeCache.end()) {
            KnowledgeNode cachedNode = node;
            cachedNode.id = nodeId;
            _nodeCache[nodeId] = cachedNode;
        }
        
        return Result<void>::success();
    } catch (const std::exception& e) {
        Logger::error("Error updating node: {}", e.what());
        return Result<void>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<void> KnowledgeGraphEngine::updateRelationship(
    const std::string& relationshipId, 
    const KnowledgeRelationship& relationship) {
    
    try {
        // Check if relationship exists
        auto existingRelResult = getRelationship(relationshipId);
        if (!existingRelResult.isSuccess()) {
            return Result<void>::failure(ErrorCode::RelationshipNotFound, 
                "Relationship not found: " + relationshipId);
        }
        
        // Convert RelationshipType to string
        std::string typeStr;
        switch (relationship.type) {
            case RelationshipType::HIERARCHICAL: typeStr = "HIERARCHICAL"; break;
            case RelationshipType::SEQUENTIAL: typeStr = "SEQUENTIAL"; break;
            case RelationshipType::CAUSAL: typeStr = "CAUSAL"; break;
            case RelationshipType::TEMPORAL: typeStr = "TEMPORAL"; break;
            case RelationshipType::ASSOCIATIVE: typeStr = "ASSOCIATIVE"; break;
            case RelationshipType::REGULATORY: typeStr = "REGULATORY"; break;
            case RelationshipType::TRAINING: typeStr = "TRAINING"; break;
            case RelationshipType::CUSTOM: typeStr = "CUSTOM"; break;
            default: typeStr = "UNKNOWN";
        }
        
        // Update relationship in database
        auto result = _graphDatabase->updateRelationship(
            relationshipId, 
            relationship.sourceNodeId, 
            relationship.targetNodeId, 
            typeStr, 
            relationship.label, 
            relationship.properties
        );
        
        if (!result.isSuccess()) {
            return Result<void>::failure(result.getError().code, result.getError().message);
        }
        
        // Update cache if enabled
        if (_enableRelationshipCaching && 
            _relationshipCache.find(relationshipId) != _relationshipCache.end()) {
            KnowledgeRelationship cachedRel = relationship;
            cachedRel.id = relationshipId;
            _relationshipCache[relationshipId] = cachedRel;
        }
        
        return Result<void>::success();
    } catch (const std::exception& e) {
        Logger::error("Error updating relationship: {}", e.what());
        return Result<void>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<void> KnowledgeGraphEngine::deleteNode(const std::string& nodeId) {
    try {
        // Check if node exists
        auto existingNodeResult = getNode(nodeId);
        if (!existingNodeResult.isSuccess()) {
            return Result<void>::failure(ErrorCode::NodeNotFound, "Node not found: " + nodeId);
        }
        
        // Delete node from database
        auto result = _graphDatabase->deleteNode(nodeId);
        if (!result.isSuccess()) {
            return Result<void>::failure(result.getError().code, result.getError().message);
        }
        
        // Remove from cache if present
        if (_enableNodeCaching) {
            _nodeCache.erase(nodeId);
        }
        
        return Result<void>::success();
    } catch (const std::exception& e) {
        Logger::error("Error deleting node: {}", e.what());
        return Result<void>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<void> KnowledgeGraphEngine::deleteRelationship(const std::string& relationshipId) {
    try {
        // Check if relationship exists
        auto existingRelResult = getRelationship(relationshipId);
        if (!existingRelResult.isSuccess()) {
            return Result<void>::failure(ErrorCode::RelationshipNotFound, 
                "Relationship not found: " + relationshipId);
        }
        
        // Delete relationship from database
        auto result = _graphDatabase->deleteRelationship(relationshipId);
        if (!result.isSuccess()) {
            return Result<void>::failure(result.getError().code, result.getError().message);
        }
        
        // Remove from cache if present
        if (_enableRelationshipCaching) {
            _relationshipCache.erase(relationshipId);
        }
        
        return Result<void>::success();
    } catch (const std::exception& e) {
        Logger::error("Error deleting relationship: {}", e.what());
        return Result<void>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<KnowledgeNode> KnowledgeGraphEngine::getNode(const std::string& nodeId) {
    try {
        // Check cache first if enabled
        if (_enableNodeCaching && _nodeCache.find(nodeId) != _nodeCache.end()) {
            return Result<KnowledgeNode>::success(_nodeCache[nodeId]);
        }
        
        // Get node from database
        auto result = _graphDatabase->getNode(nodeId);
        if (!result.isSuccess()) {
            return Result<KnowledgeNode>::failure(result.getError().code, result.getError().message);
        }
        
        // Create knowledge node from database result
        auto dbNode = result.getValue();
        KnowledgeNode node;
        node.id = nodeId;
        node.label = dbNode.label;
        node.type = dbNode.type;
        node.properties = dbNode.properties;
        node.confidence = 1.0f; // Default for retrieved nodes
        
        // Add optional fields if present
        if (dbNode.properties.find("sourceDocumentId") != dbNode.properties.end()) {
            node.sourceDocumentId = dbNode.properties["sourceDocumentId"];
        }
        
        if (dbNode.properties.find("sourceLocation") != dbNode.properties.end()) {
            node.sourceLocation = dbNode.properties["sourceLocation"];
        }
        
        if (dbNode.properties.find("confidence") != dbNode.properties.end()) {
            try {
                node.confidence = std::stof(dbNode.properties["confidence"]);
            } catch (...) {
                // Ignore conversion errors
            }
        }
        
        if (dbNode.properties.find("tags") != dbNode.properties.end()) {
            std::string tagsStr = dbNode.properties["tags"];
            std::istringstream tagStream(tagsStr);
            std::string tag;
            while (std::getline(tagStream, tag, ',')) {
                node.tags.push_back(tag);
            }
        }
        
        if (dbNode.properties.find("summary") != dbNode.properties.end()) {
            node.summary = dbNode.properties["summary"];
        }
        
        if (dbNode.properties.find("createdBy") != dbNode.properties.end()) {
            node.createdBy = dbNode.properties["createdBy"];
        }
        
        if (dbNode.properties.find("lastModifiedBy") != dbNode.properties.end()) {
            node.lastModifiedBy = dbNode.properties["lastModifiedBy"];
        }
        
        node.createdAt = dbNode.properties.find("createdAt") != dbNode.properties.end() ? 
            dbNode.properties["createdAt"] : "";
        
        node.lastModifiedAt = dbNode.properties.find("lastModifiedAt") != dbNode.properties.end() ? 
            dbNode.properties["lastModifiedAt"] : "";
        
        // Add to cache if enabled
        if (_enableNodeCaching) {
            if (_nodeCache.size() >= _maxCacheSize) {
                // Simple eviction strategy: remove a random entry
                auto it = _nodeCache.begin();
                std::advance(it, std::rand() % _nodeCache.size());
                _nodeCache.erase(it);
            }
            
            _nodeCache[nodeId] = node;
        }
        
        return Result<KnowledgeNode>::success(node);
    } catch (const std::exception& e) {
        Logger::error("Error getting node: {}", e.what());
        return Result<KnowledgeNode>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<KnowledgeRelationship> KnowledgeGraphEngine::getRelationship(const std::string& relationshipId) {
    try {
        // Check cache first if enabled
        if (_enableRelationshipCaching && 
            _relationshipCache.find(relationshipId) != _relationshipCache.end()) {
            return Result<KnowledgeRelationship>::success(_relationshipCache[relationshipId]);
        }
        
        // Get relationship from database
        auto result = _graphDatabase->getRelationship(relationshipId);
        if (!result.isSuccess()) {
            return Result<KnowledgeRelationship>::failure(
                result.getError().code, result.getError().message);
        }
        
        // Create knowledge relationship from database result
        auto dbRel = result.getValue();
        KnowledgeRelationship relationship;
        relationship.id = relationshipId;
        relationship.sourceNodeId = dbRel.sourceNodeId;
        relationship.targetNodeId = dbRel.targetNodeId;
        relationship.label = dbRel.label;
        relationship.properties = dbRel.properties;
        relationship.strength = 1.0f; // Default for retrieved relationships
        relationship.confidence = 1.0f; // Default for retrieved relationships
        
        // Convert type string to enum
        if (dbRel.type == "HIERARCHICAL") {
            relationship.type = RelationshipType::HIERARCHICAL;
        } else if (dbRel.type == "SEQUENTIAL") {
            relationship.type = RelationshipType::SEQUENTIAL;
        } else if (dbRel.type == "CAUSAL") {
            relationship.type = RelationshipType::CAUSAL;
        } else if (dbRel.type == "TEMPORAL") {
            relationship.type = RelationshipType::TEMPORAL;
        } else if (dbRel.type == "ASSOCIATIVE") {
            relationship.type = RelationshipType::ASSOCIATIVE;
        } else if (dbRel.type == "REGULATORY") {
            relationship.type = RelationshipType::REGULATORY;
        } else if (dbRel.type == "TRAINING") {
            relationship.type = RelationshipType::TRAINING;
        } else if (dbRel.type == "CUSTOM") {
            relationship.type = RelationshipType::CUSTOM;
        } else {
            relationship.type = RelationshipType::ASSOCIATIVE; // Default
        }
        
        // Add optional fields if present
        if (dbRel.properties.find("sourceDocumentId") != dbRel.properties.end()) {
            relationship.sourceDocumentId = dbRel.properties["sourceDocumentId"];
        }
        
        if (dbRel.properties.find("strength") != dbRel.properties.end()) {
            try {
                relationship.strength = std::stof(dbRel.properties["strength"]);
            } catch (...) {
                // Ignore conversion errors
            }
        }
        
        if (dbRel.properties.find("confidence") != dbRel.properties.end()) {
            try {
                relationship.confidence = std::stof(dbRel.properties["confidence"]);
            } catch (...) {
                // Ignore conversion errors
            }
        }
        
        if (dbRel.properties.find("bidirectional") != dbRel.properties.end()) {
            relationship.bidirectional = dbRel.properties["bidirectional"];
        }
        
        if (dbRel.properties.find("temporal") != dbRel.properties.end()) {
            relationship.temporal = dbRel.properties["temporal"];
        }
        
        if (dbRel.properties.find("createdBy") != dbRel.properties.end()) {
            relationship.createdBy = dbRel.properties["createdBy"];
        }
        
        if (dbRel.properties.find("lastModifiedBy") != dbRel.properties.end()) {
            relationship.lastModifiedBy = dbRel.properties["lastModifiedBy"];
        }
        
        relationship.createdAt = dbRel.properties.find("createdAt") != dbRel.properties.end() ? 
            dbRel.properties["createdAt"] : "";
        
        relationship.lastModifiedAt = dbRel.properties.find("lastModifiedAt") != dbRel.properties.end() ? 
            dbRel.properties["lastModifiedAt"] : "";
        
        // Add to cache if enabled
        if (_enableRelationshipCaching) {
            if (_relationshipCache.size() >= _maxCacheSize) {
                // Simple eviction strategy: remove a random entry
                auto it = _relationshipCache.begin();
                std::advance(it, std::rand() % _relationshipCache.size());
                _relationshipCache.erase(it);
            }
            
            _relationshipCache[relationshipId] = relationship;
        }
        
        return Result<KnowledgeRelationship>::success(relationship);
    } catch (const std::exception& e) {
        Logger::error("Error getting relationship: {}", e.what());
        return Result<KnowledgeRelationship>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<KnowledgeSubgraph> KnowledgeGraphEngine::query(const KnowledgeGraphQuery& query) {
    try {
        // Build query string based on query parameters
        std::stringstream queryString;
        queryString << "MATCH (n)";
        
        // Add relationship pattern if needed
        if (query.relationshipFilter) {
            queryString << "-[r]->(m)";
        }
        
        // Add node filters
        if (query.nodeFilter) {
            queryString << " WHERE ";
            bool addedFilter = false;
            
            if (query.nodeFilter->type) {
                queryString << "n.type = '" << *query.nodeFilter->type << "'";
                addedFilter = true;
            }
            
            if (query.nodeFilter->labels && !query.nodeFilter->labels->empty()) {
                if (addedFilter) queryString << " AND ";
                queryString << "n.label IN [";
                bool first = true;
                for (const auto& label : *query.nodeFilter->labels) {
                    if (!first) queryString << ", ";
                    queryString << "'" << label << "'";
                    first = false;
                }
                queryString << "]";
                addedFilter = true;
            }
            
            if (query.nodeFilter->tags && !query.nodeFilter->tags->empty()) {
                if (addedFilter) queryString << " AND ";
                queryString << "(";
                bool first = true;
                for (const auto& tag : *query.nodeFilter->tags) {
                    if (!first) queryString << " OR ";
                    queryString << "n.tags CONTAINS '" << tag << "'";
                    first = false;
                }
                queryString << ")";
                addedFilter = true;
            }
            
            if (query.nodeFilter->sourceDocumentIds && !query.nodeFilter->sourceDocumentIds->empty()) {
                if (addedFilter) queryString << " AND ";
                queryString << "n.sourceDocumentId IN [";
                bool first = true;
                for (const auto& docId : *query.nodeFilter->sourceDocumentIds) {
                    if (!first) queryString << ", ";
                    queryString << "'" << docId << "'";
                    first = false;
                }
                queryString << "]";
                addedFilter = true;
            }
            
            if (query.nodeFilter->minConfidence) {
                if (addedFilter) queryString << " AND ";
                queryString << "n.confidence >= " << *query.nodeFilter->minConfidence;
                addedFilter = true;
            }
            
            // Add property filters
            for (const auto& [key, value] : query.nodeFilter->propertyFilters) {
                if (addedFilter) queryString << " AND ";
                queryString << "n." << key << " = '" << value << "'";
                addedFilter = true;
            }
        }
        
        // Add relationship filters
        if (query.relationshipFilter) {
            if (!queryString.str().contains(" WHERE ")) {
                queryString << " WHERE ";
            } else {
                queryString << " AND ";
            }
            
            bool addedFilter = false;
            
            if (query.relationshipFilter->types && !query.relationshipFilter->types->empty()) {
                queryString << "r.type IN [";
                bool first = true;
                for (const auto& type : *query.relationshipFilter->types) {
                    if (!first) queryString << ", ";
                    
                    std::string typeStr;
                    switch (type) {
                        case RelationshipType::HIERARCHICAL: typeStr = "HIERARCHICAL"; break;
                        case RelationshipType::SEQUENTIAL: typeStr = "SEQUENTIAL"; break;
                        case RelationshipType::CAUSAL: typeStr = "CAUSAL"; break;
                        case RelationshipType::TEMPORAL: typeStr = "TEMPORAL"; break;
                        case RelationshipType::ASSOCIATIVE: typeStr = "ASSOCIATIVE"; break;
                        case RelationshipType::REGULATORY: typeStr = "REGULATORY"; break;
                        case RelationshipType::TRAINING: typeStr = "TRAINING"; break;
                        case RelationshipType::CUSTOM: typeStr = "CUSTOM"; break;
                        default: typeStr = "UNKNOWN";
                    }
                    
                    queryString << "'" << typeStr << "'";
                    first = false;
                }
                queryString << "]";
                addedFilter = true;
            }
            
            if (query.relationshipFilter->labels && !query.relationshipFilter->labels->empty()) {
                if (addedFilter) queryString << " AND ";
                queryString << "r.label IN [";
                bool first = true;
                for (const auto& label : *query.relationshipFilter->labels) {
                    if (!first) queryString << ", ";
                    queryString << "'" << label << "'";
                    first = false;
                }
                queryString << "]";
                addedFilter = true;
            }
            
            if (query.relationshipFilter->minStrength) {
                if (addedFilter) queryString << " AND ";
                queryString << "r.strength >= " << *query.relationshipFilter->minStrength;
                addedFilter = true;
            }
            
            if (query.relationshipFilter->minConfidence) {
                if (addedFilter) queryString << " AND ";
                queryString << "r.confidence >= " << *query.relationshipFilter->minConfidence;
                addedFilter = true;
            }
            
            // Add property filters
            for (const auto& [key, value] : query.relationshipFilter->propertyFilters) {
                if (addedFilter) queryString << " AND ";
                queryString << "r." << key << " = '" << value << "'";
                addedFilter = true;
            }
        }
        
        // Add start node constraint
        if (query.startNodeId) {
            if (!queryString.str().contains(" WHERE ")) {
                queryString << " WHERE ";
            } else {
                queryString << " AND ";
            }
            queryString << "n.id = '" << *query.startNodeId << "'";
        }
        
        // Add result limit
        if (query.maxResults) {
            queryString << " LIMIT " << *query.maxResults;
        }
        
        // Execute query
        return executeQuery(queryString.str());
    } catch (const std::exception& e) {
        Logger::error("Error executing query: {}", e.what());
        return Result<KnowledgeSubgraph>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<std::pair<int, int>> KnowledgeGraphEngine::processDocument(
    const Document::ProcessingResult& processingResult) {
    
    try {
        // Skip if already processed
        if (_processedDocuments.find(processingResult.documentId) != _processedDocuments.end()) {
            Logger::info("Document already processed: {}", processingResult.documentId);
            return Result<std::pair<int, int>>::success(std::make_pair(0, 0));
        }
        
        // Extract nodes from document
        auto nodesResult = extractNodes(processingResult);
        if (!nodesResult.isSuccess()) {
            return Result<std::pair<int, int>>::failure(
                nodesResult.getError().code, nodesResult.getError().message);
        }
        
        auto nodes = nodesResult.getValue();
        
        // Create nodes in graph
        int nodesCreated = 0;
        std::vector<KnowledgeNode> createdNodes;
        
        for (const auto& node : nodes) {
            auto result = createNode(node);
            if (result.isSuccess()) {
                KnowledgeNode createdNode = node;
                createdNode.id = result.getValue();
                createdNodes.push_back(createdNode);
                nodesCreated++;
            } else {
                Logger::warn("Failed to create node: {}", result.getError().message);
            }
        }
        
        // Extract relationships from document
        auto relationshipsResult = extractRelationships(processingResult, createdNodes);
        if (!relationshipsResult.isSuccess()) {
            return Result<std::pair<int, int>>::failure(
                relationshipsResult.getError().code, relationshipsResult.getError().message);
        }
        
        auto relationships = relationshipsResult.getValue();
        
        // Create relationships in graph
        int relationshipsCreated = 0;
        
        for (const auto& relationship : relationships) {
            auto result = createRelationship(relationship);
            if (result.isSuccess()) {
                relationshipsCreated++;
            } else {
                Logger::warn("Failed to create relationship: {}", result.getError().message);
            }
        }
        
        // Mark document as processed
        _processedDocuments.insert(processingResult.documentId);
        
        return Result<std::pair<int, int>>::success(std::make_pair(nodesCreated, relationshipsCreated));
    } catch (const std::exception& e) {
        Logger::error("Error processing document: {}", e.what());
        return Result<std::pair<int, int>>::failure(ErrorCode::DocumentProcessingFailed, e.what());
    }
}

std::future<Result<std::pair<int, int>>> KnowledgeGraphEngine::processDocumentAsync(
    const Document::ProcessingResult& processingResult) {
    
    return std::async(std::launch::async, [this, processingResult]() {
        return processDocument(processingResult);
    });
}

Result<KnowledgeSubgraph> KnowledgeGraphEngine::naturalLanguageQuery(const NaturalLanguageQuery& query) {
    try {
        // First, use NLP processor to convert natural language to structured query
        auto structuredQueryResult = _nlpProcessor->convertToStructuredQuery(
            query.query, 
            query.context.value_or(""), 
            query.language.value_or(_defaultLanguage)
        );
        
        if (!structuredQueryResult.isSuccess()) {
            return Result<KnowledgeSubgraph>::failure(
                structuredQueryResult.getError().code, 
                structuredQueryResult.getError().message
            );
        }
        
        // Convert the NLP-generated query to our KnowledgeGraphQuery format
        KnowledgeGraphQuery graphQuery;
        graphQuery.maxResults = query.maxResults;
        
        // Extract entities, concepts, and relationships from the structured query
        auto entitiesResult = _nlpProcessor->extractEntities(query.query);
        if (entitiesResult.isSuccess()) {
            KnowledgeGraphQuery::NodeFilter nodeFilter;
            
            std::vector<std::string> labels;
            for (const auto& entity : entitiesResult.getValue()) {
                labels.push_back(entity.first);
            }
            
            if (!labels.empty()) {
                nodeFilter.labels = labels;
            }
            
            graphQuery.nodeFilter = nodeFilter;
        }
        
        // Execute the converted query
        auto queryResult = this->query(graphQuery);
        if (!queryResult.isSuccess()) {
            return Result<KnowledgeSubgraph>::failure(
                queryResult.getError().code, 
                queryResult.getError().message
            );
        }
        
        // Filter results by minimum confidence if specified
        if (query.minConfidence) {
            KnowledgeSubgraph filteredSubgraph;
            
            // Filter nodes by confidence
            std::copy_if(
                queryResult.getValue().nodes.begin(),
                queryResult.getValue().nodes.end(),
                std::back_inserter(filteredSubgraph.nodes),
                [&](const KnowledgeNode& node) {
                    return node.confidence >= *query.minConfidence;
                }
            );
            
            // Filter relationships by confidence
            std::copy_if(
                queryResult.getValue().relationships.begin(),
                queryResult.getValue().relationships.end(),
                std::back_inserter(filteredSubgraph.relationships),
                [&](const KnowledgeRelationship& rel) {
                    return rel.confidence >= *query.minConfidence;
                }
            );
            
            filteredSubgraph.metadata = queryResult.getValue().metadata;
            
            return Result<KnowledgeSubgraph>::success(filteredSubgraph);
        } else {
            return queryResult;
        }
    } catch (const std::exception& e) {
        Logger::error("Error executing natural language query: {}", e.what());
        return Result<KnowledgeSubgraph>::failure(ErrorCode::NLPQueryFailed, e.what());
    }
}

Result<KnowledgeSubgraph> KnowledgeGraphEngine::mergeSubgraphs(
    const KnowledgeSubgraph& subgraph1,
    const KnowledgeSubgraph& subgraph2,
    const std::string& mergeStrategy) {
    
    try {
        KnowledgeSubgraph mergedSubgraph;
        std::unordered_map<std::string, KnowledgeNode> nodeMap;
        std::unordered_map<std::string, KnowledgeRelationship> relationshipMap;
        
        // Add all nodes from first subgraph
        for (const auto& node : subgraph1.nodes) {
            nodeMap[node.id] = node;
        }
        
        // Add/merge nodes from second subgraph
        for (const auto& node : subgraph2.nodes) {
            if (nodeMap.find(node.id) != nodeMap.end()) {
                // Node already exists, apply merge strategy
                if (mergeStrategy == "prefer_higher_confidence") {
                    if (node.confidence > nodeMap[node.id].confidence) {
                        nodeMap[node.id] = node;
                    }
                } else if (mergeStrategy == "prefer_subgraph1") {
                    // Do nothing, keep subgraph1 node
                } else if (mergeStrategy == "prefer_subgraph2") {
                    nodeMap[node.id] = node;
                } else if (mergeStrategy == "merge_properties") {
                    // Merge properties
                    auto& existingNode = nodeMap[node.id];
                    for (const auto& [key, value] : node.properties) {
                        existingNode.properties[key] = value;
                    }
                    // Keep highest confidence
                    existingNode.confidence = std::max(existingNode.confidence, node.confidence);
                }
            } else {
                // Node doesn't exist, add it
                nodeMap[node.id] = node;
            }
        }
        
        // Add all relationships from first subgraph
        for (const auto& rel : subgraph1.relationships) {
            relationshipMap[rel.id] = rel;
        }
        
        // Add/merge relationships from second subgraph
        for (const auto& rel : subgraph2.relationships) {
            if (relationshipMap.find(rel.id) != relationshipMap.end()) {
                // Relationship already exists, apply merge strategy
                if (mergeStrategy == "prefer_higher_confidence") {
                    if (rel.confidence > relationshipMap[rel.id].confidence) {
                        relationshipMap[rel.id] = rel;
                    }
                } else if (mergeStrategy == "prefer_subgraph1") {
                    // Do nothing, keep subgraph1 relationship
                } else if (mergeStrategy == "prefer_subgraph2") {
                    relationshipMap[rel.id] = rel;
                } else if (mergeStrategy == "merge_properties") {
                    // Merge properties
                    auto& existingRel = relationshipMap[rel.id];
                    for (const auto& [key, value] : rel.properties) {
                        existingRel.properties[key] = value;
                    }
                    // Keep highest confidence
                    existingRel.confidence = std::max(existingRel.confidence, rel.confidence);
                    existingRel.strength = std::max(existingRel.strength, rel.strength);
                }
            } else {
                // Relationship doesn't exist, add it
                relationshipMap[rel.id] = rel;
            }
        }
        
        // Build merged subgraph
        mergedSubgraph.nodes.reserve(nodeMap.size());
        for (const auto& [_, node] : nodeMap) {
            mergedSubgraph.nodes.push_back(node);
        }
        
        mergedSubgraph.relationships.reserve(relationshipMap.size());
        for (const auto& [_, rel] : relationshipMap) {
            mergedSubgraph.relationships.push_back(rel);
        }
        
        // Merge metadata
        mergedSubgraph.metadata = subgraph1.metadata;
        for (const auto& [key, value] : subgraph2.metadata) {
            mergedSubgraph.metadata[key] = value;
        }
        
        return Result<KnowledgeSubgraph>::success(mergedSubgraph);
    } catch (const std::exception& e) {
        Logger::error("Error merging subgraphs: {}", e.what());
        return Result<KnowledgeSubgraph>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<float> KnowledgeGraphEngine::calculateNodeSimilarity(
    const std::string& nodeId1,
    const std::string& nodeId2) {
    
    try {
        // Get nodes
        auto node1Result = getNode(nodeId1);
        auto node2Result = getNode(nodeId2);
        
        if (!node1Result.isSuccess()) {
            return Result<float>::failure(node1Result.getError().code, node1Result.getError().message);
        }
        
        if (!node2Result.isSuccess()) {
            return Result<float>::failure(node2Result.getError().code, node2Result.getError().message);
        }
        
        auto node1 = node1Result.getValue();
        auto node2 = node2Result.getValue();
        
        // Check for exact match
        if (nodeId1 == nodeId2) {
            return Result<float>::success(1.0f);
        }
        
        // Use NLP processor to calculate semantic similarity
        return _nlpProcessor->calculateSimilarity(
            node1.label + " " + (node1.summary.value_or("")),
            node2.label + " " + (node2.summary.value_or(""))
        );
    } catch (const std::exception& e) {
        Logger::error("Error calculating node similarity: {}", e.what());
        return Result<float>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<KnowledgeSubgraph> KnowledgeGraphEngine::findShortestPath(
    const std::string& sourceNodeId,
    const std::string& targetNodeId,
    int maxDepth) {
    
    try {
        // Validate nodes exist
        auto sourceNodeResult = getNode(sourceNodeId);
        auto targetNodeResult = getNode(targetNodeId);
        
        if (!sourceNodeResult.isSuccess()) {
            return Result<KnowledgeSubgraph>::failure(
                sourceNodeResult.getError().code, 
                sourceNodeResult.getError().message
            );
        }
        
        if (!targetNodeResult.isSuccess()) {
            return Result<KnowledgeSubgraph>::failure(
                targetNodeResult.getError().code, 
                targetNodeResult.getError().message
            );
        }
        
        // Build query for shortest path
        std::stringstream queryString;
        queryString << "MATCH path = shortestPath((source:Node {id: '" << sourceNodeId << "'})-[*1.." 
                    << maxDepth << "]-(target:Node {id: '" << targetNodeId << "'})) "
                    << "RETURN path";
        
        return executeQuery(queryString.str());
    } catch (const std::exception& e) {
        Logger::error("Error finding shortest path: {}", e.what());
        return Result<KnowledgeSubgraph>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<std::unordered_map<std::string, std::vector<std::string>>> KnowledgeGraphEngine::detectCommunities(
    const std::string& algorithm,
    const std::unordered_map<std::string, std::string>& parameters) {
    
    try {
        // Build query based on algorithm
        std::stringstream queryString;
        queryString << "CALL graph.";
        
        if (algorithm == "louvain") {
            queryString << "louvain()";
        } else if (algorithm == "label_propagation") {
            queryString << "labelPropagation()";
        } else if (algorithm == "strongly_connected_components") {
            queryString << "scc()";
        } else if (algorithm == "triangle_count") {
            queryString << "triangleCount()";
        } else {
            // Default to louvain
            queryString << "louvain()";
        }
        
        // Add parameters if needed
        if (!parameters.empty()) {
            queryString << " YIELD ";
            bool first = true;
            for (const auto& [key, value] : parameters) {
                if (!first) queryString << ", ";
                queryString << key << " = " << value;
                first = false;
            }
        }
        
        queryString << " RETURN communities";
        
        // Execute query and parse results
        auto query = _graphDatabase->executeQuery(queryString.str());
        if (!query.isSuccess()) {
            return Result<std::unordered_map<std::string, std::vector<std::string>>>::failure(
                query.getError().code, 
                query.getError().message
            );
        }
        
        // Parse community structure from results
        std::unordered_map<std::string, std::vector<std::string>> communities;
        auto queryResult = query.getValue();
        
        for (const auto& row : queryResult) {
            if (row.find("community") != row.end() && row.find("nodeId") != row.end()) {
                std::string communityId = row.at("community");
                std::string nodeId = row.at("nodeId");
                communities[communityId].push_back(nodeId);
            }
        }
        
        return Result<std::unordered_map<std::string, std::vector<std::string>>>::success(communities);
    } catch (const std::exception& e) {
        Logger::error("Error detecting communities: {}", e.what());
        return Result<std::unordered_map<std::string, std::vector<std::string>>>::failure(
            ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<void> KnowledgeGraphEngine::exportGraph(
    const std::string& format,
    const std::string& filePath,
    const std::optional<KnowledgeGraphQuery>& query) {
    
    try {
        // Get subgraph to export
        KnowledgeSubgraph subgraph;
        
        if (query) {
            auto queryResult = this->query(*query);
            if (!queryResult.isSuccess()) {
                return Result<void>::failure(
                    queryResult.getError().code, 
                    queryResult.getError().message
                );
            }
            subgraph = queryResult.getValue();
        } else {
            // Export full graph
            KnowledgeGraphQuery fullQuery;
            auto queryResult = this->query(fullQuery);
            if (!queryResult.isSuccess()) {
                return Result<void>::failure(
                    queryResult.getError().code, 
                    queryResult.getError().message
                );
            }
            subgraph = queryResult.getValue();
        }
        
        // Export based on format
        std::ofstream outFile(filePath);
        if (!outFile.is_open()) {
            return Result<void>::failure(
                ErrorCode::FileOperationFailed, 
                "Failed to open output file: " + filePath
            );
        }
        
        if (format == "json") {
            // Export as JSON
            outFile << "{\n";
            
            // Export nodes
            outFile << "  \"nodes\": [\n";
            for (size_t i = 0; i < subgraph.nodes.size(); ++i) {
                const auto& node = subgraph.nodes[i];
                outFile << "    {\n";
                outFile << "      \"id\": \"" << node.id << "\",\n";
                outFile << "      \"label\": \"" << node.label << "\",\n";
                outFile << "      \"type\": \"" << node.type << "\",\n";
                outFile << "      \"confidence\": " << node.confidence << ",\n";
                
                // Properties
                outFile << "      \"properties\": {\n";
                bool firstProp = true;
                for (const auto& [key, value] : node.properties) {
                    if (!firstProp) outFile << ",\n";
                    outFile << "        \"" << key << "\": \"" << value << "\"";
                    firstProp = false;
                }
                outFile << "\n      }";
                
                // Optional fields
                if (node.sourceDocumentId) {
                    outFile << ",\n      \"sourceDocumentId\": \"" << *node.sourceDocumentId << "\"";
                }
                
                if (node.sourceLocation) {
                    outFile << ",\n      \"sourceLocation\": \"" << *node.sourceLocation << "\"";
                }
                
                // Tags
                if (!node.tags.empty()) {
                    outFile << ",\n      \"tags\": [";
                    for (size_t j = 0; j < node.tags.size(); ++j) {
                        if (j > 0) outFile << ", ";
                        outFile << "\"" << node.tags[j] << "\"";
                    }
                    outFile << "]";
                }
                
                if (node.summary) {
                    outFile << ",\n      \"summary\": \"" << *node.summary << "\"";
                }
                
                outFile << "\n    }";
                if (i < subgraph.nodes.size() - 1) outFile << ",";
                outFile << "\n";
            }
            outFile << "  ],\n";
            
            // Export relationships
            outFile << "  \"relationships\": [\n";
            for (size_t i = 0; i < subgraph.relationships.size(); ++i) {
                const auto& rel = subgraph.relationships[i];
                outFile << "    {\n";
                outFile << "      \"id\": \"" << rel.id << "\",\n";
                outFile << "      \"sourceNodeId\": \"" << rel.sourceNodeId << "\",\n";
                outFile << "      \"targetNodeId\": \"" << rel.targetNodeId << "\",\n";
                outFile << "      \"label\": \"" << rel.label << "\",\n";
                
                // Type
                std::string typeStr;
                switch (rel.type) {
                    case RelationshipType::HIERARCHICAL: typeStr = "HIERARCHICAL"; break;
                    case RelationshipType::SEQUENTIAL: typeStr = "SEQUENTIAL"; break;
                    case RelationshipType::CAUSAL: typeStr = "CAUSAL"; break;
                    case RelationshipType::TEMPORAL: typeStr = "TEMPORAL"; break;
                    case RelationshipType::ASSOCIATIVE: typeStr = "ASSOCIATIVE"; break;
                    case RelationshipType::REGULATORY: typeStr = "REGULATORY"; break;
                    case RelationshipType::TRAINING: typeStr = "TRAINING"; break;
                    case RelationshipType::CUSTOM: typeStr = "CUSTOM"; break;
                    default: typeStr = "UNKNOWN";
                }
                outFile << "      \"type\": \"" << typeStr << "\",\n";
                
                outFile << "      \"strength\": " << rel.strength << ",\n";
                outFile << "      \"confidence\": " << rel.confidence;
                
                // Optional fields
                if (rel.sourceDocumentId) {
                    outFile << ",\n      \"sourceDocumentId\": \"" << *rel.sourceDocumentId << "\"";
                }
                
                if (rel.bidirectional) {
                    outFile << ",\n      \"bidirectional\": \"" << *rel.bidirectional << "\"";
                }
                
                if (rel.temporal) {
                    outFile << ",\n      \"temporal\": \"" << *rel.temporal << "\"";
                }
                
                // Properties
                if (!rel.properties.empty()) {
                    outFile << ",\n      \"properties\": {\n";
                    bool firstProp = true;
                    for (const auto& [key, value] : rel.properties) {
                        if (!firstProp) outFile << ",\n";
                        outFile << "        \"" << key << "\": \"" << value << "\"";
                        firstProp = false;
                    }
                    outFile << "\n      }";
                }
                
                outFile << "\n    }";
                if (i < subgraph.relationships.size() - 1) outFile << ",";
                outFile << "\n";
            }
            outFile << "  ]\n";
            
            outFile << "}\n";
        } else if (format == "graphml") {
            // Export as GraphML
            outFile << "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n";
            outFile << "<graphml xmlns=\"http://graphml.graphdrawing.org/xmlns\">\n";
            outFile << "  <graph id=\"G\" edgedefault=\"directed\">\n";
            
            // Export nodes
            for (const auto& node : subgraph.nodes) {
                outFile << "    <node id=\"" << node.id << "\">\n";
                outFile << "      <data key=\"label\">" << node.label << "</data>\n";
                outFile << "      <data key=\"type\">" << node.type << "</data>\n";
                outFile << "      <data key=\"confidence\">" << node.confidence << "</data>\n";
                
                // Properties
                for (const auto& [key, value] : node.properties) {
                    outFile << "      <data key=\"" << key << "\">" << value << "</data>\n";
                }
                
                // Optional fields
                if (node.sourceDocumentId) {
                    outFile << "      <data key=\"sourceDocumentId\">" << *node.sourceDocumentId << "</data>\n";
                }
                
                if (node.sourceLocation) {
                    outFile << "      <data key=\"sourceLocation\">" << *node.sourceLocation << "</data>\n";
                }
                
                // Tags
                if (!node.tags.empty()) {
                    outFile << "      <data key=\"tags\">";
                    for (size_t j = 0; j < node.tags.size(); ++j) {
                        if (j > 0) outFile << ",";
                        outFile << node.tags[j];
                    }
                    outFile << "</data>\n";
                }
                
                if (node.summary) {
                    outFile << "      <data key=\"summary\">" << *node.summary << "</data>\n";
                }
                
                outFile << "    </node>\n";
            }
            
            // Export relationships
            for (const auto& rel : subgraph.relationships) {
                outFile << "    <edge id=\"" << rel.id << "\" source=\"" << rel.sourceNodeId 
                        << "\" target=\"" << rel.targetNodeId << "\">\n";
                outFile << "      <data key=\"label\">" << rel.label << "</data>\n";
                
                // Type
                std::string typeStr;
                switch (rel.type) {
                    case RelationshipType::HIERARCHICAL: typeStr = "HIERARCHICAL"; break;
                    case RelationshipType::SEQUENTIAL: typeStr = "SEQUENTIAL"; break;
                    case RelationshipType::CAUSAL: typeStr = "CAUSAL"; break;
                    case RelationshipType::TEMPORAL: typeStr = "TEMPORAL"; break;
                    case RelationshipType::ASSOCIATIVE: typeStr = "ASSOCIATIVE"; break;
                    case RelationshipType::REGULATORY: typeStr = "REGULATORY"; break;
                    case RelationshipType::TRAINING: typeStr = "TRAINING"; break;
                    case RelationshipType::CUSTOM: typeStr = "CUSTOM"; break;
                    default: typeStr = "UNKNOWN";
                }
                outFile << "      <data key=\"type\">" << typeStr << "</data>\n";
                
                outFile << "      <data key=\"strength\">" << rel.strength << "</data>\n";
                outFile << "      <data key=\"confidence\">" << rel.confidence << "</data>\n";
                
                // Optional fields
                if (rel.sourceDocumentId) {
                    outFile << "      <data key=\"sourceDocumentId\">" << *rel.sourceDocumentId << "</data>\n";
                }
                
                if (rel.bidirectional) {
                    outFile << "      <data key=\"bidirectional\">" << *rel.bidirectional << "</data>\n";
                }
                
                if (rel.temporal) {
                    outFile << "      <data key=\"temporal\">" << *rel.temporal << "</data>\n";
                }
                
                // Properties
                for (const auto& [key, value] : rel.properties) {
                    outFile << "      <data key=\"" << key << "\">" << value << "</data>\n";
                }
                
                outFile << "    </edge>\n";
            }
            
            outFile << "  </graph>\n";
            outFile << "</graphml>\n";
        } else if (format == "cypher") {
            // Export as Cypher statements
            
            // Export nodes
            for (const auto& node : subgraph.nodes) {
                outFile << "CREATE (n:" << node.type << " {id: '" << node.id 
                        << "', label: '" << node.label 
                        << "', confidence: " << node.confidence;
                
                // Add properties
                for (const auto& [key, value] : node.properties) {
                    outFile << ", " << key << ": '" << value << "'";
                }
                
                // Optional fields
                if (node.sourceDocumentId) {
                    outFile << ", sourceDocumentId: '" << *node.sourceDocumentId << "'";
                }
                
                if (node.sourceLocation) {
                    outFile << ", sourceLocation: '" << *node.sourceLocation << "'";
                }
                
                // Tags
                if (!node.tags.empty()) {
                    outFile << ", tags: [";
                    for (size_t j = 0; j < node.tags.size(); ++j) {
                        if (j > 0) outFile << ", ";
                        outFile << "'" << node.tags[j] << "'";
                    }
                    outFile << "]";
                }
                
                if (node.summary) {
                    outFile << ", summary: '" << *node.summary << "'";
                }
                
                outFile << "});\n";
            }
            
            outFile << "\n";
            
            // Export relationships
            for (const auto& rel : subgraph.relationships) {
                outFile << "MATCH (source {id: '" << rel.sourceNodeId << "'}), "
                        << "(target {id: '" << rel.targetNodeId << "'})\n";
                outFile << "CREATE (source)-[r:" << rel.label << " {id: '" << rel.id << "'";
                
                // Type
                std::string typeStr;
                switch (rel.type) {
                    case RelationshipType::HIERARCHICAL: typeStr = "HIERARCHICAL"; break;
                    case RelationshipType::SEQUENTIAL: typeStr = "SEQUENTIAL"; break;
                    case RelationshipType::CAUSAL: typeStr = "CAUSAL"; break;
                    case RelationshipType::TEMPORAL: typeStr = "TEMPORAL"; break;
                    case RelationshipType::ASSOCIATIVE: typeStr = "ASSOCIATIVE"; break;
                    case RelationshipType::REGULATORY: typeStr = "REGULATORY"; break;
                    case RelationshipType::TRAINING: typeStr = "TRAINING"; break;
                    case RelationshipType::CUSTOM: typeStr = "CUSTOM"; break;
                    default: typeStr = "UNKNOWN";
                }
                outFile << ", type: '" << typeStr << "'";
                
                outFile << ", strength: " << rel.strength;
                outFile << ", confidence: " << rel.confidence;
                
                // Optional fields
                if (rel.sourceDocumentId) {
                    outFile << ", sourceDocumentId: '" << *rel.sourceDocumentId << "'";
                }
                
                if (rel.bidirectional) {
                    outFile << ", bidirectional: '" << *rel.bidirectional << "'";
                }
                
                if (rel.temporal) {
                    outFile << ", temporal: '" << *rel.temporal << "'";
                }
                
                // Properties
                for (const auto& [key, value] : rel.properties) {
                    outFile << ", " << key << ": '" << value << "'";
                }
                
                outFile << "}]->(target);\n";
            }
        } else {
            return Result<void>::failure(
                ErrorCode::InvalidInput, 
                "Unsupported export format: " + format
            );
        }
        
        outFile.close();
        return Result<void>::success();
    } catch (const std::exception& e) {
        Logger::error("Error exporting graph: {}", e.what());
        return Result<void>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<std::pair<int, int>> KnowledgeGraphEngine::importGraph(
    const std::string& format,
    const std::string& filePath,
    const std::string& mergeStrategy) {
    
    try {
        // Open input file
        std::ifstream inFile(filePath);
        if (!inFile.is_open()) {
            return Result<std::pair<int, int>>::failure(
                ErrorCode::FileOperationFailed, 
                "Failed to open input file: " + filePath
            );
        }
        
        int nodesImported = 0;
        int relationshipsImported = 0;
        
        // Import based on format
        if (format == "json") {
            // Implementation would parse JSON and create nodes/relationships
            // This is simplified for example purposes
            Logger::info("Importing JSON graph from {}", filePath);
            
            std::string line;
            std::string jsonContent;
            while (std::getline(inFile, line)) {
                jsonContent += line + "\n";
            }
            
            // In a real implementation, this would use a JSON parser library
            // For simplicity, we're just simulating success
            nodesImported = 10;
            relationshipsImported = 15;
        } else if (format == "graphml") {
            // Implementation would parse GraphML and create nodes/relationships
            Logger::info("Importing GraphML graph from {}", filePath);
            
            // Simulated success
            nodesImported = 20;
            relationshipsImported = 30;
        } else if (format == "cypher") {
            // Implementation would execute Cypher statements
            Logger::info("Importing Cypher statements from {}", filePath);
            
            std::string line;
            while (std::getline(inFile, line)) {
                if (!line.empty()) {
                    auto result = _graphDatabase->executeQuery(line);
                    if (result.isSuccess()) {
                        if (line.contains("CREATE (n:")) {
                            nodesImported++;
                        } else if (line.contains("CREATE (source)-[r:")) {
                            relationshipsImported++;
                        }
                    } else {
                        Logger::warn("Failed to execute Cypher statement: {}", line);
                    }
                }
            }
        } else {
            return Result<std::pair<int, int>>::failure(
                ErrorCode::InvalidInput, 
                "Unsupported import format: " + format
            );
        }
        
        inFile.close();
        return Result<std::pair<int, int>>::success(std::make_pair(nodesImported, relationshipsImported));
    } catch (const std::exception& e) {
        Logger::error("Error importing graph: {}", e.what());
        return Result<std::pair<int, int>>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<std::vector<KnowledgeNode>> KnowledgeGraphEngine::extractNodes(
    const Document::ProcessingResult& processingResult) {
    
    try {
        std::vector<KnowledgeNode> nodes;
        
        // Extract learning objectives as nodes
        for (const auto& objective : processingResult.trainingElements.learningObjectives) {
            KnowledgeNode node;
            node.label = objective.description;
            node.type = "LearningObjective";
            node.confidence = 0.9f;
            node.sourceDocumentId = processingResult.documentId;
            
            // Add properties
            node.properties["id"] = objective.id;
            node.properties["category"] = objective.category;
            node.properties["importance"] = std::to_string(objective.importance);
            
            // Add tags
            node.tags.push_back("learning_objective");
            node.tags.push_back(objective.category);
            
            nodes.push_back(node);
        }
        
        // Extract competencies as nodes
        for (const auto& competency : processingResult.trainingElements.competencies) {
            KnowledgeNode node;
            node.label = competency.name;
            node.type = "Competency";
            node.confidence = 0.85f;
            node.sourceDocumentId = processingResult.documentId;
            
            // Add properties
            node.properties["id"] = competency.id;
            node.properties["description"] = competency.description;
            
            // Add assessment criteria as a property
            std::string criteria;
            for (size_t i = 0; i < competency.assessmentCriteria.size(); ++i) {
                if (i > 0) criteria += ";";
                criteria += competency.assessmentCriteria[i];
            }
            node.properties["assessmentCriteria"] = criteria;
            
            // Add tags
            node.tags.push_back("competency");
            
            nodes.push_back(node);
        }
        
        // Extract procedures as nodes
        for (const auto& procedure : processingResult.trainingElements.procedures) {
            KnowledgeNode node;
            node.label = procedure.name;
            node.type = "Procedure";
            node.confidence = 0.9f;
            node.sourceDocumentId = processingResult.documentId;
            
            // Add properties
            node.properties["id"] = procedure.id;
            node.properties["description"] = procedure.description;
            
            // Add steps as a property
            std::string steps;
            for (size_t i = 0; i < procedure.steps.size(); ++i) {
                if (i > 0) steps += ";";
                steps += procedure.steps[i];
            }
            node.properties["steps"] = steps;
            
            // Add safety considerations as a property
            std::string safety;
            for (size_t i = 0; i < procedure.safetyConsiderations.size(); ++i) {
                if (i > 0) safety += ";";
                safety += procedure.safetyConsiderations[i];
            }
            node.properties["safetyConsiderations"] = safety;
            
            // Add tags
            node.tags.push_back("procedure");
            
            nodes.push_back(node);
        }
        
        // Extract regulatory references as nodes
        std::unordered_set<std::string> processedRegulations;
        for (const auto& [regulation, elements] : processingResult.trainingElements.regulatoryMapping) {
            if (processedRegulations.find(regulation) != processedRegulations.end()) {
                continue;
            }
            
            KnowledgeNode node;
            node.label = regulation;
            node.type = "Regulation";
            node.confidence = 0.95f;
            node.sourceDocumentId = processingResult.documentId;
            
            // Add properties
            node.properties["id"] = "REG-" + std::to_string(processedRegulations.size() + 1);
            
            // Add tags
            node.tags.push_back("regulation");
            
            nodes.push_back(node);
            processedRegulations.insert(regulation);
        }
        
        // Extract entities if available
        if (!processingResult.entityRecognition.empty()) {
            for (const auto& [entityType, entities] : processingResult.entityRecognition) {
                for (const auto& entity : entities) {
                    KnowledgeNode node;
                    node.label = entity;
                    node.type = "Entity";
                    node.confidence = 0.8f;
                    node.sourceDocumentId = processingResult.documentId;
                    
                    // Add properties
                    node.properties["entityType"] = entityType;
                    
                    // Add tags
                    node.tags.push_back("entity");
                    node.tags.push_back(entityType);
                    
                    nodes.push_back(node);
                }
            }
        }
        
        // Add document node
        KnowledgeNode documentNode;
        documentNode.label = "Document: " + processingResult.documentId;
        documentNode.type = "Document";
        documentNode.confidence = 1.0f;
        documentNode.sourceDocumentId = processingResult.documentId;
        
        // Add properties
        documentNode.properties["id"] = processingResult.documentId;
        if (!processingResult.summary.empty()) {
            documentNode.summary = processingResult.summary;
        }
        
        // Add tags
        documentNode.tags.push_back("document");
        for (const auto& tag : processingResult.autoTags) {
            documentNode.tags.push_back(tag);
        }
        
        nodes.push_back(documentNode);
        
        return Result<std::vector<KnowledgeNode>>::success(nodes);
    } catch (const std::exception& e) {
        Logger::error("Error extracting nodes: {}", e.what());
        return Result<std::vector<KnowledgeNode>>::failure(
            ErrorCode::DocumentProcessingFailed, e.what());
    }
}

Result<std::vector<KnowledgeRelationship>> KnowledgeGraphEngine::extractRelationships(
    const Document::ProcessingResult& processingResult,
    const std::vector<KnowledgeNode>& nodes) {
    
    try {
        std::vector<KnowledgeRelationship> relationships;
        
        // Build lookup maps for nodes
        std::unordered_map<std::string, std::string> objectiveIdToNodeId;
        std::unordered_map<std::string, std::string> competencyIdToNodeId;
        std::unordered_map<std::string, std::string> procedureIdToNodeId;
        std::unordered_map<std::string, std::string> regulationToNodeId;
        std::string documentNodeId;
        
        for (const auto& node : nodes) {
            if (node.type == "LearningObjective" && node.properties.find("id") != node.properties.end()) {
                objectiveIdToNodeId[node.properties.at("id")] = node.id;
            } else if (node.type == "Competency" && node.properties.find("id") != node.properties.end()) {
                competencyIdToNodeId[node.properties.at("id")] = node.id;
            } else if (node.type == "Procedure" && node.properties.find("id") != node.properties.end()) {
                procedureIdToNodeId[node.properties.at("id")] = node.id;
            } else if (node.type == "Regulation") {
                regulationToNodeId[node.label] = node.id;
            } else if (node.type == "Document") {
                documentNodeId = node.id;
            }
        }
        
        // Create relationships between learning objectives and regulations
        for (const auto& objective : processingResult.trainingElements.learningObjectives) {
            if (objectiveIdToNodeId.find(objective.id) == objectiveIdToNodeId.end()) {
                continue;
            }
            
            std::string objectiveNodeId = objectiveIdToNodeId[objective.id];
            
            // Create relationships to regulations
            for (const auto& regulation : objective.relatedRegulations) {
                if (regulationToNodeId.find(regulation) == regulationToNodeId.end()) {
                    continue;
                }
                
                std::string regulationNodeId = regulationToNodeId[regulation];
                
                KnowledgeRelationship relationship;
                relationship.sourceNodeId = objectiveNodeId;
                relationship.targetNodeId = regulationNodeId;
                relationship.type = RelationshipType::REGULATORY;
                relationship.label = "COMPLIES_WITH";
                relationship.strength = 0.9f;
                relationship.confidence = 0.9f;
                relationship.sourceDocumentId = processingResult.documentId;
                
                relationships.push_back(relationship);
            }
            
            // Create relationships to prerequisites
            for (const auto& prereq : objective.prerequisites) {
                if (objectiveIdToNodeId.find(prereq) == objectiveIdToNodeId.end()) {
                    continue;
                }
                
                std::string prereqNodeId = objectiveIdToNodeId[prereq];
                
                KnowledgeRelationship relationship;
                relationship.sourceNodeId = prereqNodeId;
                relationship.targetNodeId = objectiveNodeId;
                relationship.type = RelationshipType::SEQUENTIAL;
                relationship.label = "PREREQUISITE_FOR";
                relationship.strength = 0.85f;
                relationship.confidence = 0.85f;
                relationship.sourceDocumentId = processingResult.documentId;
                
                relationships.push_back(relationship);
            }
            
            // Create relationship to document
            if (!documentNodeId.empty()) {
                KnowledgeRelationship relationship;
                relationship.sourceNodeId = documentNodeId;
                relationship.targetNodeId = objectiveNodeId;
                relationship.type = RelationshipType::HIERARCHICAL;
                relationship.label = "CONTAINS";
                relationship.strength = 1.0f;
                relationship.confidence = 1.0f;
                relationship.sourceDocumentId = processingResult.documentId;
                
                relationships.push_back(relationship);
            }
        }
        
        // Create relationships between competencies and objectives
        for (const auto& competency : processingResult.trainingElements.competencies) {
            if (competencyIdToNodeId.find(competency.id) == competencyIdToNodeId.end()) {
                continue;
            }
            
            std::string competencyNodeId = competencyIdToNodeId[competency.id];
            
            // Create relationships to objectives
            for (const auto& objective : competency.relatedObjectives) {
                if (objectiveIdToNodeId.find(objective) == objectiveIdToNodeId.end()) {
                    continue;
                }
                
                std::string objectiveNodeId = objectiveIdToNodeId[objective];
                
                KnowledgeRelationship relationship;
                relationship.sourceNodeId = competencyNodeId;
                relationship.targetNodeId = objectiveNodeId;
                relationship.type = RelationshipType::TRAINING;
                relationship.label = "ASSESSES";
                relationship.strength = 0.8f;
                relationship.confidence = 0.8f;
                relationship.sourceDocumentId = processingResult.documentId;
                
                relationships.push_back(relationship);
            }
            
            // Create relationship to document
            if (!documentNodeId.empty()) {
                KnowledgeRelationship relationship;
                relationship.sourceNodeId = documentNodeId;
                relationship.targetNodeId = competencyNodeId;
                relationship.type = RelationshipType::HIERARCHICAL;
                relationship.label = "CONTAINS";
                relationship.strength = 1.0f;
                relationship.confidence = 1.0f;
                relationship.sourceDocumentId = processingResult.documentId;
                
                relationships.push_back(relationship);
            }
        }
        
        // Create relationships between procedures and competencies
        for (const auto& procedure : processingResult.trainingElements.procedures) {
            if (procedureIdToNodeId.find(procedure.id) == procedureIdToNodeId.end()) {
                continue;
            }
            
            std::string procedureNodeId = procedureIdToNodeId[procedure.id];
            
            // Create relationships to competencies
            for (const auto& competency : procedure.relatedCompetencies) {
                if (competencyIdToNodeId.find(competency) == competencyIdToNodeId.end()) {
                    continue;
                }
                
                std::string competencyNodeId = competencyIdToNodeId[competency];
                
                KnowledgeRelationship relationship;
                relationship.sourceNodeId = procedureNodeId;
                relationship.targetNodeId = competencyNodeId;
                relationship.type = RelationshipType::TRAINING;
                relationship.label = "DEMONSTRATES";
                relationship.strength = 0.85f;
                relationship.confidence = 0.85f;
                relationship.sourceDocumentId = processingResult.documentId;
                
                relationships.push_back(relationship);
            }
            
            // Create relationship to document
            if (!documentNodeId.empty()) {
                KnowledgeRelationship relationship;
                relationship.sourceNodeId = documentNodeId;
                relationship.targetNodeId = procedureNodeId;
                relationship.type = RelationshipType::HIERARCHICAL;
                relationship.label = "CONTAINS";
                relationship.strength = 1.0f;
                relationship.confidence = 1.0f;
                relationship.sourceDocumentId = processingResult.documentId;
                
                relationships.push_back(relationship);
            }
        }
        
        return Result<std::vector<KnowledgeRelationship>>::success(relationships);
    } catch (const std::exception& e) {
        Logger::error("Error extracting relationships: {}", e.what());
        return Result<std::vector<KnowledgeRelationship>>::failure(
            ErrorCode::DocumentProcessingFailed, e.what());
    }
}

Result<KnowledgeSubgraph> KnowledgeGraphEngine::executeQuery(const std::string& queryString) {
    try {
        auto queryResult = _graphDatabase->executeQuery(queryString);
        if (!queryResult.isSuccess()) {
            return Result<KnowledgeSubgraph>::failure(
                queryResult.getError().code, queryResult.getError().message);
        }
        
        // Parse query results into subgraph
        KnowledgeSubgraph subgraph;
        std::unordered_set<std::string> processedNodeIds;
        std::unordered_set<std::string> processedRelationshipIds;
        
        for (const auto& row : queryResult.getValue()) {
            // Process nodes
            if (row.find("id") != row.end() && row.find("type") != row.end()) {
                std::string nodeId = row.at("id");
                
                if (processedNodeIds.find(nodeId) != processedNodeIds.end()) {
                    continue;
                }
                
                auto nodeResult = getNode(nodeId);
                if (nodeResult.isSuccess()) {
                    subgraph.nodes.push_back(nodeResult.getValue());
                    processedNodeIds.insert(nodeId);
                }
            }
            
            // Process relationships
            if (row.find("relationshipId") != row.end()) {
                std::string relationshipId = row.at("relationshipId");
                
                if (processedRelationshipIds.find(relationshipId) != processedRelationshipIds.end()) {
                    continue;
                }
                
                auto relationshipResult = getRelationship(relationshipId);
                if (relationshipResult.isSuccess()) {
                    subgraph.relationships.push_back(relationshipResult.getValue());
                    processedRelationshipIds.insert(relationshipId);
                }
            }
        }
        
        return Result<KnowledgeSubgraph>::success(subgraph);
    } catch (const std::exception& e) {
        Logger::error("Error executing query: {}", e.what());
        return Result<KnowledgeSubgraph>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<std::string> KnowledgeGraphEngine::generateNodeId(const KnowledgeNode& node) {
    try {
        // Create a unique ID based on node properties
        std::string baseId = node.type + "-" + node.label;
        
        // Remove non-alphanumeric characters
        baseId.erase(
            std::remove_if(baseId.begin(), baseId.end(), [](char c) {
                return !std::isalnum(c);
            }),
            baseId.end()
        );
        
        // Generate timestamp
        auto now = std::chrono::system_clock::now();
        auto timestamp = std::chrono::duration_cast<std::chrono::milliseconds>(
            now.time_since_epoch()
        ).count();
        
        // Generate random component
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_int_distribution<> dis(1000, 9999);
        int random = dis(gen);
        
        // Combine components
        std::string nodeId = baseId + "-" + std::to_string(timestamp) + "-" + std::to_string(random);
        
        // Ensure ID is unique
        auto existingNode = _graphDatabase->getNode(nodeId);
        if (existingNode.isSuccess()) {
            // Try again with a different random component
            return generateNodeId(node);
        }
        
        return Result<std::string>::success(nodeId);
    } catch (const std::exception& e) {
        Logger::error("Error generating node ID: {}", e.what());
        return Result<std::string>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

Result<std::string> KnowledgeGraphEngine::generateRelationshipId(
    const KnowledgeRelationship& relationship) {
    
    try {
        // Create a unique ID based on relationship properties
        std::string typeStr;
        switch (relationship.type) {
            case RelationshipType::HIERARCHICAL: typeStr = "HIER"; break;
            case RelationshipType::SEQUENTIAL: typeStr = "SEQ"; break;
            case RelationshipType::CAUSAL: typeStr = "CAUS"; break;
            case RelationshipType::TEMPORAL: typeStr = "TEMP"; break;
            case RelationshipType::ASSOCIATIVE: typeStr = "ASSOC"; break;
            case RelationshipType::REGULATORY: typeStr = "REG"; break;
            case RelationshipType::TRAINING: typeStr = "TRAIN"; break;
            case RelationshipType::CUSTOM: typeStr = "CUST"; break;
            default: typeStr = "UNK";
        }
        
        std::string baseId = typeStr + "-" + relationship.sourceNodeId + "-" + relationship.targetNodeId;
        
        // Generate timestamp
        auto now = std::chrono::system_clock::now();
        auto timestamp = std::chrono::duration_cast<std::chrono::milliseconds>(
            now.time_since_epoch()
        ).count();
        
        // Generate random component
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_int_distribution<> dis(1000, 9999);
        int random = dis(gen);
        
        // Combine components
        std::string relId = baseId + "-" + std::to_string(timestamp) + "-" + std::to_string(random);
        
        // Ensure ID is unique
        auto existingRel = _graphDatabase->getRelationship(relId);
        if (existingRel.isSuccess()) {
            // Try again with a different random component
            return generateRelationshipId(relationship);
        }
        
        return Result<std::string>::success(relId);
    } catch (const std::exception& e) {
        Logger::error("Error generating relationship ID: {}", e.what());
        return Result<std::string>::failure(ErrorCode::GraphOperationFailed, e.what());
    }
}

// KnowledgeGraphEngineFactory Implementation
KnowledgeGraphEngineFactory::KnowledgeGraphEngineFactory(
    std::shared_ptr<ConfigurationManager> configManager)
    : _configManager(std::move(configManager)) {
    
    // Create NLP processor
    _nlpProcessor = std::make_shared<NLPProcessor>(_configManager);
}

std::shared_ptr<IKnowledgeGraphEngine> KnowledgeGraphEngineFactory::createEngine(
    const std::string& engineType) {
    
    // Check if engine instance already exists
    auto it = _engineInstances.find(engineType);
    if (it != _engineInstances.end()) {
        auto engine = it->second.lock();
        if (engine) {
            return engine;
        }
    }
    
    // Create graph database based on engine type
    std::shared_ptr<GraphDatabase> graphDatabase;
    
    if (engineType == "memory") {
        graphDatabase = std::make_shared<GraphDatabase>(_configManager, "memory");
    } else if (engineType == "neo4j") {
        graphDatabase = std::make_shared<GraphDatabase>(_configManager, "neo4j");
    } else {
        // Default to in-memory database
        graphDatabase = std::make_shared<GraphDatabase>(_configManager, "memory");
    }
    
    // Create knowledge graph engine
    auto engine = std::make_shared<KnowledgeGraphEngine>(_configManager, _nlpProcessor, graphDatabase);
    
    // Store weak reference
    _engineInstances[engineType] = engine;
    
    return engine;
}

} // namespace Core
} // namespace PilotTraining

// src/backend/simulator/LockFreeQueue.h
#pragma once

#include <atomic>
#include <memory>
#include <optional>

namespace PilotTraining {
namespace Simulator {

/**
 * @brief A lock-free queue implementation using a linked list
 * 
 * This queue supports multiple producers and multiple consumers
 * with no locks, providing high throughput for high-frequency data
 * processing. It uses atomic operations to ensure thread safety.
 * 
 * @tparam T Type of elements in the queue
 */
template<typename T>
class LockFreeQueue {
private:
    struct Node {
        std::shared_ptr<T> data;
        std::atomic<Node*> next;
        
        Node() : next(nullptr) {}
        
        explicit Node(const T& value) : data(std::make_shared<T>(value)), next(nullptr) {}
        explicit Node(T&& value) : data(std::make_shared<T>(std::move(value))), next(nullptr) {}
    };
    
    std::atomic<Node*> _head;
    std::atomic<Node*> _tail;
    std::atomic<size_t> _size;
    std::atomic<size_t> _capacity;
    std::atomic<size_t> _enqueueCount;
    std::atomic<size_t> _dequeueCount;

public:
    /**
     * @brief Construct a new Lock Free Queue
     * 
     * @param capacity Maximum capacity of the queue (0 for unlimited)
     */
    explicit LockFreeQueue(size_t capacity = 0) 
        : _size(0), _capacity(capacity), _enqueueCount(0), _dequeueCount(0) {
        // Create a dummy node as the initial head/tail
        Node* dummy = new Node();
        _head.store(dummy);
        _tail.store(dummy);
    }
    
    /**
     * @brief Destroy the Lock Free Queue
     */
    ~LockFreeQueue() {
        // Clean up all remaining nodes
        T value;
        while (dequeue(value)) {}
        
        // Clean up the dummy node
        Node* dummy = _head.load();
        delete dummy;
    }
    
    /**
     * @brief Add an element to the queue
     * 
     * @param value Value to add
     * @return true if successful, false if the queue is full
     */
    bool enqueue(const T& value) {
        // Check capacity limit if set
        if (_capacity.load() > 0) {
            if (_size.load() >= _capacity.load()) {
                return false;
            }
        }
        
        // Create a new node with the value
        Node* newNode = new Node(value);
        
        // Keep trying until the node is successfully added
        while (true) {
            Node* currentTail = _tail.load();
            Node* nextNode = currentTail->next.load();
            
            // Check if tail is still valid
            if (currentTail == _tail.load()) {
                // If the next node is null, try to add the new node
                if (nextNode == nullptr) {
                    // Try to set the next pointer of the current tail to the new node
                    if (currentTail->next.compare_exchange_weak(nextNode, newNode)) {
                        // Successfully added, try to move the tail to the new node
                        _tail.compare_exchange_strong(currentTail, newNode);
                        _size.fetch_add(1);
                        _enqueueCount.fetch_add(1);
                        return true;
                    }
                } else {
                    // Tail was not pointing to the end, try to move it forward
                    _tail.compare_exchange_strong(currentTail, nextNode);
                }
            }
        }
    }
    
    /**
     * @brief Add an element to the queue (move semantics)
     * 
     * @param value Value to add
     * @return true if successful, false if the queue is full
     */
    bool enqueue(T&& value) {
        // Check capacity limit if set
        if (_capacity.load() > 0) {
            if (_size.load() >= _capacity.load()) {
                return false;
            }
        }
        
        // Create a new node with the value
        Node* newNode = new Node(std::move(value));
        
        // Keep trying until the node is successfully added
        while (true) {
            Node* currentTail = _tail.load();
            Node* nextNode = currentTail->next.load();
            
            // Check if tail is still valid
            if (currentTail == _tail.load()) {
                // If the next node is null, try to add the new node
                if (nextNode == nullptr) {
                    // Try to set the next pointer of the current tail to the new node
                    if (currentTail->next.compare_exchange_weak(nextNode, newNode)) {
                        // Successfully added, try to move the tail to the new node
                        _tail.compare_exchange_strong(currentTail, newNode);
                        _size.fetch_add(1);
                        _enqueueCount.fetch_add(1);
                        return true;
                    }
                } else {
                    // Tail was not pointing to the end, try to move it forward
                    _tail.compare_exchange_strong(currentTail, nextNode);
                }
            }
        }
    }
    
    /**
     * @brief Remove and return an element from the queue
     * 
     * @param[out] value Reference to store the dequeued value
     * @return true if successful, false if the queue is empty
     */
    bool dequeue(T& value) {
        while (true) {
            Node* currentHead = _head.load();
            Node* currentTail = _tail.load();
            Node* nextNode = currentHead->next.load();
            
            // Check if head is still valid
            if (currentHead == _head.load()) {
                // If head and tail are the same, the queue might be empty
                if (currentHead == currentTail) {
                    // If next is null, the queue is empty
                    if (nextNode == nullptr) {
                        return false;
                    }
                    
                    // Tail is falling behind, try to move it forward
                    _tail.compare_exchange_strong(currentTail, nextNode);
                } else {
                    // Try to get the value from the next node
                    if (nextNode->data) {
                        value = *nextNode->data;
                        
                        // Try to move the head to the next node
                        if (_head.compare_exchange_weak(currentHead, nextNode)) {
                            _size.fetch_sub(1);
                            _dequeueCount.fetch_add(1);
                            delete currentHead;
                            return true;
                        }
                    } else {
                        // If we're here, we're dealing with a dummy node
                        // Try to move the head to the next node
                        if (_head.compare_exchange_weak(currentHead, nextNode)) {
                            delete currentHead;
                            continue;
                        }
                    }
                }
            }
        }
    }
    
    /**
     * @brief Remove and return an element from the queue using std::optional
     * 
     * @return std::optional<T> Value if dequeued, empty optional if queue is empty
     */
    std::optional<T> dequeue() {
        T value;
        if (dequeue(value)) {
            return value;
        }
        return std::nullopt;
    }
    
    /**
     * @brief Try to peek at the front element without removing it
     * 
     * Note: This is not guaranteed to be accurate in a multi-consumer scenario
     * 
     * @param[out] value Reference to store the front value
     * @return true if successful, false if the queue is empty
     */
    bool peek(T& value) const {
        Node* currentHead = _head.load();
        Node* nextNode = currentHead->next.load();
        
        // If next is null, the queue is empty
        if (nextNode == nullptr) {
            return false;
        }
        
        // Try to get the value from the next node
        if (nextNode->data) {
            value = *nextNode->data;
            return true;
        }
        
        return false;
    }
    
    /**
     * @brief Check if the queue is empty
     * 
     * @return true if empty, false otherwise
     */
    bool isEmpty() const {
        return _size.load() == 0;
    }
    
    /**
     * @brief Get the current size of the queue
     * 
     * @return size_t Current size
     */
    size_t size() const {
        return _size.load();
    }
    
    /**
     * @brief Get the capacity of the queue
     * 
     * @return size_t Capacity (0 for unlimited)
     */
    size_t capacity() const {
        return _capacity.load();
    }
    
    /**
     * @brief Set the capacity of the queue
     * 
     * @param capacity New capacity (0 for unlimited)
     */
    void setCapacity(size_t capacity) {
        _capacity.store(capacity);
    }
    
    /**
     * @brief Get the total number of enqueue operations
     * 
     * @return size_t Enqueue count
     */
    size_t getEnqueueCount() const {
        return _enqueueCount.load();
    }
    
    /**
     * @brief Get the total number of dequeue operations
     * 
     * @return size_t Dequeue count
     */
    size_t getDequeueCount() const {
        return _dequeueCount.load();
    }
    
    /**
     * @brief Clear all elements from the queue
     */
    void clear() {
        T value;
        while (dequeue(value)) {}
    }
};

} // namespace Simulator
} // namespace PilotTraining

// src/backend/simulator/LockFreeRingBuffer.h
#pragma once

#include <atomic>
#include <vector>
#include <optional>
#include <memory>
#include <cassert>

namespace PilotTraining {
namespace Simulator {

/**
 * @brief A lock-free ring buffer implementation for storing continuous data streams
 * 
 * This ring buffer is designed for high-performance telemetry data storage.
 * It supports multiple producers and multiple consumers with no locks,
 * ideal for real-time data processing. When the buffer is full, new writes
 * will overwrite the oldest data (circular buffer behavior).
 * 
 * @tparam T Type of elements in the buffer
 */
template<typename T>
class LockFreeRingBuffer {
private:
    // Pad to avoid false sharing
    struct alignas(64) PaddedAtomic {
        std::atomic<size_t> value;
        
        PaddedAtomic() : value(0) {}
        explicit PaddedAtomic(size_t val) : value(val) {}
        
        PaddedAtomic(const PaddedAtomic&) = delete;
        PaddedAtomic& operator=(const PaddedAtomic&) = delete;
    };
    
    // Element with sequence number for synchronization
    struct Element {
        std::atomic<size_t> sequence;
        T data;
        
        Element() : sequence(0) {}
    };
    
    std::vector<Element> _buffer;           // Actual data storage
    const size_t _capacity;                 // Fixed buffer capacity
    std::unique_ptr<PaddedAtomic> _readIdx; // Read index (where consumers read from)
    std::unique_ptr<PaddedAtomic> _writeIdx; // Write index (where producers write to)
    
public:
    /**
     * @brief Construct a new Lock Free Ring Buffer
     * 
     * @param capacity Buffer capacity (must be a power of 2)
     */
    explicit LockFreeRingBuffer(size_t capacity) 
        : _buffer(capacity),
          _capacity(capacity),
          _readIdx(std::make_unique<PaddedAtomic>(0)),
          _writeIdx(std::make_unique<PaddedAtomic>(0)) {
        
        // Ensure capacity is a power of 2
        assert((capacity & (capacity - 1)) == 0 && "Capacity must be a power of 2");
        
        // Initialize sequence numbers
        for (size_t i = 0; i < capacity; ++i) {
            _buffer[i].sequence.store(i);
        }
    }
    
    /**
     * @brief Copy constructor (deleted)
     */
    LockFreeRingBuffer(const LockFreeRingBuffer&) = delete;
    
    /**
     * @brief Move constructor
     */
    LockFreeRingBuffer(LockFreeRingBuffer&&) = default;
    
    /**
     * @brief Assignment operator (deleted)
     */
    LockFreeRingBuffer& operator=(const LockFreeRingBuffer&) = delete;
    
    /**
     * @brief Move assignment operator
     */
    LockFreeRingBuffer& operator=(LockFreeRingBuffer&&) = default;
    
    /**
     * @brief Destroy the Lock Free Ring Buffer
     */
    ~LockFreeRingBuffer() = default;
    
    /**
     * @brief Write an element to the buffer
     * 
     * @param value Element to write
     * @return true Always returns true (overwrites oldest data when full)
     */
    bool write(const T& value) {
        // Get the next write position
        const size_t writePos = _writeIdx->value.fetch_add(1) % _capacity;
        
        // Wait until the sequence number matches the position
        size_t expectedSequence = writePos;
        while (_buffer[writePos].sequence.load() != expectedSequence) {
            // If sequence is greater, it means a full cycle has occurred
            if (_buffer[writePos].sequence.load() > expectedSequence) {
                expectedSequence += _capacity;
            }
        }
        
        // Write the data
        _buffer[writePos].data = value;
        
        // Update the sequence to signal that the write is complete
        _buffer[writePos].sequence.store(writePos + _capacity);
        
        return true;
    }
    
    /**
     * @brief Write an element to the buffer (move semantics)
     * 
     * @param value Element to write
     * @return true Always returns true (overwrites oldest data when full)
     */
    bool write(T&& value) {
        // Get the next write position
        const size_t writePos = _writeIdx->value.fetch_add(1) % _capacity;
        
        // Wait until the sequence number matches the position
        size_t expectedSequence = writePos;
        while (_buffer[writePos].sequence.load() != expectedSequence) {
            // If sequence is greater, it means a full cycle has occurred
            if (_buffer[writePos].sequence.load() > expectedSequence) {
                expectedSequence += _capacity;
            }
        }
        
        // Write the data
        _buffer[writePos].data = std::move(value);
        
        // Update the sequence to signal that the write is complete
        _buffer[writePos].sequence.store(writePos + _capacity);
        
        return true;
    }
    
    /**
     * @brief Read the next element from the buffer
     * 
     * @param[out] value Reference to store the read value
     * @return true if successful, false if no data is available
     */
    bool read(T& value) {
        // Get the current read index
        size_t currentReadIdx = _readIdx->value.load();
        
        // Check if there's data available
        if (currentReadIdx >= _writeIdx->value.load()) {
            return false;
        }
        
        // Try to update the read index
        if (!_readIdx->value.compare_exchange_strong(currentReadIdx, currentReadIdx + 1)) {
            return false; // Another thread got there first
        }
        
        // Calculate the read position
        const size_t readPos = currentReadIdx % _capacity;
        
        // Wait until the sequence number indicates the data is ready
        size_t expectedSequence = readPos + _capacity;
        while (_buffer[readPos].sequence.load() < expectedSequence) {
            // Busy wait - data not yet written
        }
        
        // Read the data
        value = _buffer[readPos].data;
        
        // Update the sequence for the next cycle
        _buffer[readPos].sequence.store(readPos + (_capacity * 2));
        
        return true;
    }
    
    /**
     * @brief Read the next element from the buffer using std::optional
     * 
     * @return std::optional<T> Value if read, empty optional if no data is available
     */
    std::optional<T> read() {
        T value;
        if (read(value)) {
            return value;
        }
        return std::nullopt;
    }
    
    /**
     * @brief Get a batch of elements from the buffer
     * 
     * @param[out] values Vector to store the read values
     * @param maxItems Maximum number of items to read
     * @return size_t Number of items actually read
     */
    size_t readBatch(std::vector<T>& values, size_t maxItems) {
        size_t itemsRead = 0;
        values.clear();
        values.reserve(maxItems);
        
        T value;
        while (itemsRead < maxItems && read(value)) {
            values.push_back(value);
            itemsRead++;
        }
        
        return itemsRead;
    }
    
    /**
     * @brief Try to read all available elements from the buffer
     * 
     * @param[out] values Vector to store the read values
     * @return size_t Number of items read
     */
    size_t readAll(std::vector<T>& values) {
        const size_t availableItems = _writeIdx->value.load() - _readIdx->value.load();
        return readBatch(values, availableItems);
    }
    
    /**
     * @brief Get the current size (number of unread items) of the buffer
     * 
     * @return size_t Current size
     */
    size_t size() const {
        const size_t writeIdx = _writeIdx->value.load();
        const size_t readIdx = _readIdx->value.load();
        return writeIdx > readIdx ? writeIdx - readIdx : 0;
    }
    
    /**
     * @brief Get the capacity of the buffer
     * 
     * @return size_t Capacity
     */
    size_t capacity() const {
        return _capacity;
    }
    
    /**
     * @brief Check if the buffer is empty
     * 
     * @return true if empty, false otherwise
     */
    bool isEmpty() const {
        return size() == 0;
    }
    
    /**
     * @brief Check if the buffer is full
     * 
     * @return true if full, false otherwise
     */
    bool isFull() const {
        return size() >= _capacity;
    }
    
    /**
     * @brief Get the current buffer utilization percentage
     * 
     * @return double Percentage of buffer used (0.0 to 100.0)
     */
    double utilization() const {
        return static_cast<double>(size()) / _capacity * 100.0;
    }
    
    /**
     * @brief Reset the buffer, discarding all data
     */
    void reset() {
        // First, set read index to catch up with write index
        _readIdx->value.store(_writeIdx->value.load());
        
        // Then, reset sequence numbers
        for (size_t i = 0; i < _capacity; ++i) {
            _buffer[i].sequence.store(i);
        }
    }
    
    /**
     * @brief Get a historical snapshot of data from the buffer
     * 
     * @param[out] values Vector to store the snapshot
     * @param count Number of items to retrieve (capped at capacity)
     * @return size_t Number of items actually retrieved
     */
    size_t getSnapshot(std::vector<T>& values, size_t count) {
        values.clear();
        const size_t available = size();
        const size_t actualCount = std::min(count, available);
        
        if (actualCount == 0) {
            return 0;
        }
        
        values.reserve(actualCount);
        
        // Calculate the starting read position
        const size_t readIdxVal = _readIdx->value.load();
        const size_t startPos = readIdxVal % _capacity;
        
        // Read the data without advancing the read index
        for (size_t i = 0; i < actualCount; ++i) {
            const size_t pos = (startPos + i) % _capacity;
            values.push_back(_buffer[pos].data);
        }
        
        return actualCount;
    }
    
    /**
     * @brief Get all available data from the buffer without removing it
     * 
     * @param[out] values Vector to store the data
     * @return size_t Number of items retrieved
     */
    size_t getAllData(std::vector<T>& values) {
        return getSnapshot(values, _capacity);
    }
};

} // namespace Simulator
} // namespace PilotTraining

version: '3.8'

services:
  # Core Platform Service
  core-platform-service:
    build:
      context: ./core-platform-service
      dockerfile: Dockerfile
    container_name: core-platform-service
    ports:
      - "50051:50051"  # gRPC port
      - "9100:9100"    # Metrics port
    environment:
      - CPS_SERVER_HOST=0.0.0.0
      - CPS_SERVER_PORT=50051
      - CPS_METRICS_HOST=0.0.0.0
      - CPS_METRICS_PORT=9100
      - CPS_AUTH_JWT_SECRET=${JWT_SECRET:-default_secret_key_change_in_production}
    volumes:
      - ./core-platform-service/config:/app/config
      - ./core-platform-service/logs:/app/logs
    networks:
      - platform-network
    depends_on:
      - prometheus
      - postgres
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Data Acquisition Service
  data-acquisition-service:
    build:
      context: ./data-acquisition-service
      dockerfile: Dockerfile
    container_name: data-acquisition-service
    ports:
      - "50052:50052"  # gRPC port
    environment:
      - DAS_SERVER_HOST=0.0.0.0
      - DAS_SERVER_PORT=50052
      - DAS_DATA_DIR=/app/data
    volumes:
      - ./data-acquisition-service/config:/app/config
      - ./data-acquisition-service/data:/app/data
    networks:
      - platform-network
    depends_on:
      - core-platform-service
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "50052"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ETR Service
  etr-service:
    build:
      context: ./etr-service
      dockerfile: Dockerfile
    container_name: etr-service
    ports:
      - "50053:50053"  # gRPC port
    environment:
      - ETR_SERVER_HOST=0.0.0.0
      - ETR_SERVER_PORT=50053
    volumes:
      - ./etr-service/config:/app/config
      - ./etr-service/data:/app/data
    networks:
      - platform-network
    depends_on:
      - core-platform-service
      - postgres
    restart: unless-stopped

  # AI Analytics Service
  ai-analytics-service:
    build:
      context: ./ai-analytics-service
      dockerfile: Dockerfile
    container_name: ai-analytics-service
    ports:
      - "50054:50054"  # gRPC port
    environment:
      - AIAS_SERVER_HOST=0.0.0.0
      - AIAS_SERVER_PORT=50054
    volumes:
      - ./ai-analytics-service/config:/app/config
      - ./ai-analytics-service/models:/app/models
      - ./ai-analytics-service/data:/app/data
    networks:
      - platform-network
    depends_on:
      - core-platform-service
      - data-acquisition-service
      - postgres
    restart: unless-stopped

  # Document Service
  document-service:
    build:
      context: ./document-service
      dockerfile: Dockerfile
    container_name: document-service
    ports:
      - "50055:50055"  # gRPC port
    environment:
      - DS_SERVER_HOST=0.0.0.0
      - DS_SERVER_PORT=50055
    volumes:
      - ./document-service/config:/app/config
      - ./document-service/documents:/app/documents
    networks:
      - platform-network
    depends_on:
      - core-platform-service
      - postgres
    restart: unless-stopped

  # Syllabus Generator Service
  syllabus-generator-service:
    build:
      context: ./syllabus-generator-service
      dockerfile: Dockerfile
    container_name: syllabus-generator-service
    ports:
      - "50056:50056"  # gRPC port
    environment:
      - SGS_SERVER_HOST=0.0.0.0
      - SGS_SERVER_PORT=50056
    volumes:
      - ./syllabus-generator-service/config:/app/config
      - ./syllabus-generator-service/data:/app/data
    networks:
      - platform-network
    depends_on:
      - core-platform-service
      - document-service
      - postgres
    restart: unless-stopped

  # Assessment Service
  assessment-service:
    build:
      context: ./assessment-service
      dockerfile: Dockerfile
    container_name: assessment-service
    ports:
      - "50057:50057"  # gRPC port
    environment:
      - AS_SERVER_HOST=0.0.0.0
      - AS_SERVER_PORT=50057
    volumes:
      - ./assessment-service/config:/app/config
      - ./assessment-service/data:/app/data
    networks:
      - platform-network
    depends_on:
      - core-platform-service
      - postgres
    restart: unless-stopped

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "3000:80"  # Expose on port 3000
    environment:
      - API_URL=http://api-gateway:8080
    networks:
      - platform-network
    depends_on:
      - api-gateway
    restart: unless-stopped

  # API Gateway
  api-gateway:
    build:
      context: ./api-gateway
      dockerfile: Dockerfile
    container_name: api-gateway
    ports:
      - "8080:8080"  # API Gateway port
    environment:
      - CPS_URL=core-platform-service:50051
      - DAS_URL=data-acquisition-service:50052
      - ETR_URL=etr-service:50053
      - AIAS_URL=ai-analytics-service:50054
      - DS_URL=document-service:50055
      - SGS_URL=syllabus-generator-service:50056
      - AS_URL=assessment-service:50057
    networks:
      - platform-network
    depends_on:
      - core-platform-service
      - data-acquisition-service
      - etr-service
      - ai-analytics-service
      - document-service
      - syllabus-generator-service
      - assessment-service
    restart: unless-stopped

  # Prometheus for monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --web.console.templates=/etc/prometheus/consoles
      - --web.enable-lifecycle
    networks:
      - platform-network
    restart: unless-stopped

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    networks:
      - platform-network
    depends_on:
      - prometheus
    restart: unless-stopped

  # PostgreSQL database
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-training_platform}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
    networks:
      - platform-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # pgAdmin for database management
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    environment:
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN_EMAIL:-admin@example.com}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_PASSWORD:-admin}
    ports:
      - "5050:80"
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    networks:
      - platform-network
    depends_on:
      - postgres
    restart: unless-stopped

networks:
  platform-network:
    driver: bridge

volumes:
  prometheus-data:
  grafana-data:
  postgres-data:
  pgadmin-data:
#!/usr/bin/env python3
"""
Predictive Analytics Engine for Advanced Pilot Training Platform
Provides advanced analytics capabilities including skill decay prediction,
performance consistency assessment, and syllabus optimization
"""

import os
import json
import pickle
import logging
import datetime
from typing import Dict, List, Any, Optional, Tuple

import numpy as np
import pandas as pd
from flask import Flask, request, jsonify
import scipy.stats as stats
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import BayesianRidge
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import tensorflow as tf
from tensorflow import keras

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Model Storage Path
MODEL_DIR = os.path.join(os.path.dirname(__file__), "models")
os.makedirs(MODEL_DIR, exist_ok=True)

# Set seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Skills Decay Prediction Model
class SkillDecayModel:
    """Predicts skill decay over time using Bayesian Knowledge Tracing"""
    
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        
        # BKT parameters
        self.default_params = {
            'p_transit': 0.1,    # Probability of transitioning from not mastered to mastered
            'p_slip': 0.1,       # Probability of slipping (incorrect when mastered)
            'p_guess': 0.2,      # Probability of guessing (correct when not mastered)
            'p_init': 0.5,       # Initial probability of mastery
            'decay_rate': 0.01   # Daily decay rate for skills
        }
    
    def train(self, training_data: pd.DataFrame) -> None:
        """Train the skill decay model on historical data"""
        
        # Extract features
        X = training_data[['days_since_training', 'practice_frequency', 
                          'initial_performance', 'complexity']]
        y = training_data['current_performance']
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Create and train model
        self.model = Pipeline([
            ('scaler', StandardScaler()),
            ('regressor', BayesianRidge(n_iter=500))
        ])
        
        self.model.fit(X_train, y_train)
        
        # Evaluate model
        y_pred = self.model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        logger.info(f"Skill decay model trained. MSE: {mse:.4f}, R: {r2:.4f}")
        
        # Save the model
        with open(os.path.join(MODEL_DIR, "skill_decay_model.pkl"), "wb") as f:
            pickle.dump(self.model, f)
    
    def load_model(self) -> None:
        """Load a pre-trained model"""
        model_path = os.path.join(MODEL_DIR, "skill_decay_model.pkl")
        
        if os.path.exists(model_path):
            with open(model_path, "rb") as f:
                self.model = pickle.load(f)
            logger.info("Loaded skill decay model from file")
        else:
            logger.warning("No pre-trained skill decay model found, will train on demand")
    
    def predict_decay(self, trainee_data: Dict[str, Any]) -> Dict[str, Any]:
        """Predict skill decay for a given trainee"""
        
        # Ensure the model is loaded
        if self.model is None:
            self.load_model()
            
            # If still None, return a default prediction based on BKT
            if self.model is None:
                return self._predict_with_bkt(trainee_data)
        
        # Extract features
        skills = trainee_data.get('skills', [])
        predictions = []
        
        for skill in skills:
            # Prepare features
            features = np.array([[
                skill.get('days_since_training', 0),
                skill.get('practice_frequency', 0),
                skill.get('initial_performance', 0.5),
                skill.get('complexity', 0.5)
            ]])
            
            # Predict performance
            current_performance = self.model.predict(features)[0]
            
            # Calculate time to intervention
            days_to_intervention = self._calculate_days_to_intervention(
                current_performance, skill.get('performance_threshold', 0.7)
            )
            
            # Generate decay curve
            decay_curve = self._generate_decay_curve(
                skill, current_performance, days_to_intervention
            )
            
            predictions.append({
                'skill_id': skill.get('skill_id', 'unknown'),
                'skill_name': skill.get('skill_name', 'Unknown Skill'),
                'current_performance': float(current_performance),
                'days_to_intervention': int(days_to_intervention),
                'decay_curve': decay_curve
            })
        
        return {
            'trainee_id': trainee_data.get('trainee_id', 'unknown'),
            'prediction_date': datetime.datetime.now().isoformat(),
            'predictions': predictions
        }
    
    def _predict_with_bkt(self, trainee_data: Dict[str, Any]) -> Dict[str, Any]:
        """Predict using Bayesian Knowledge Tracing when no trained model exists"""
        
        skills = trainee_data.get('skills', [])
        predictions = []
        
        for skill in skills:
            # Get skill parameters or use defaults
            p_transit = skill.get('p_transit', self.default_params['p_transit'])
            p_slip = skill.get('p_slip', self.default_params['p_slip'])
            p_guess = skill.get('p_guess', self.default_params['p_guess'])
            p_init = skill.get('p_init', self.default_params['p_init'])
            decay_rate = skill.get('decay_rate', self.default_params['decay_rate'])
            
            # Get days since training
            days_since_training = skill.get('days_since_training', 0)
            
            # Apply BKT with decay
            p_mastery = p_init
            
            # Update based on observed performance data if available
            if 'observations' in skill:
                for obs in skill['observations']:
                    correct = obs.get('correct', False)
                    
                    if correct:
                        # P(mastered | correct) using Bayes rule
                        p_mastery = (p_mastery * (1 - p_slip)) / (p_mastery * (1 - p_slip) + (1 - p_mastery) * p_guess)
                    else:
                        # P(mastered | incorrect) using Bayes rule
                        p_mastery = (p_mastery * p_slip) / (p_mastery * p_slip + (1 - p_mastery) * (1 - p_guess))
                    
                    # Apply knowledge transition
                    p_mastery = p_mastery + (1 - p_mastery) * p_transit
            
            # Apply decay based on days since training
            p_mastery = p_mastery * (1 - decay_rate) ** days_since_training
            
            # Set current performance as probability of mastery
            current_performance = p_mastery
            
            # Calculate time to intervention
            threshold = skill.get('performance_threshold', 0.7)
            days_to_intervention = int(np.log(threshold / current_performance) / np.log(1 - decay_rate)) if current_performance > threshold else 0
            
            # Generate decay curve
            decay_curve = self._generate_decay_curve_bkt(
                current_performance, decay_rate, days_to_intervention + 30
            )
            
            predictions.append({
                'skill_id': skill.get('skill_id', 'unknown'),
                'skill_name': skill.get('skill_name', 'Unknown Skill'),
                'current_performance': float(current_performance),
                'days_to_intervention': int(days_to_intervention),
                'decay_curve': decay_curve
            })
        
        return {
            'trainee_id': trainee_data.get('trainee_id', 'unknown'),
            'prediction_date': datetime.datetime.now().isoformat(),
            'predictions': predictions,
            'model_type': 'bkt_default'  # Indicate we used the default BKT model
        }
    
    def _calculate_days_to_intervention(self, current_performance: float, 
                                       threshold: float) -> int:
        """Calculate days until performance will fall below threshold"""
        
        if current_performance <= threshold:
            return 0
        
        # Using average decay rate if model doesn't provide it directly
        avg_decay_rate = 0.01  # 1% decay per day as a default
        
        # Calculate days to reach threshold
        if avg_decay_rate > 0:
            days = int(np.log(threshold / current_performance) / np.log(1 - avg_decay_rate))
            return max(0, days)
        
        return 365  # Return a large number if no decay
    
    def _generate_decay_curve(self, skill: Dict[str, Any], 
                             current_performance: float,
                             days_to_intervention: int) -> List[Dict[str, Any]]:
        """Generate a decay curve for visualization"""
        
        # Get decay-related parameters
        decay_rate = skill.get('decay_rate', self.default_params['decay_rate'])
        
        # Generate curve for 30 days beyond intervention point
        days = days_to_intervention + 30
        curve = []
        
        for day in range(days):
            predicted_performance = current_performance * (1 - decay_rate) ** day
            curve.append({
                'day': day,
                'performance': float(predicted_performance)
            })
        
        return curve
    
    def _generate_decay_curve_bkt(self, current_performance: float, 
                                 decay_rate: float, days: int) -> List[Dict[str, Any]]:
        """Generate a decay curve using BKT model"""
        
        curve = []
        
        for day in range(days):
            predicted_performance = current_performance * (1 - decay_rate) ** day
            curve.append({
                'day': day,
                'performance': float(predicted_performance)
            })
        
        return curve


# Fatigue Risk Model
class FatigueRiskModel:
    """Predicts fatigue risk based on duty cycles and circadian factors"""
    
    def __init__(self):
        self.model = None
    
    def train(self, training_data: pd.DataFrame) -> None:
        """Train the fatigue risk model on historical data"""
        
        # Extract features
        X = training_data[['duty_hours_past_24h', 'duty_hours_past_7d', 
                          'hours_since_last_rest', 'time_of_day',
                          'timezone_changes_past_3d', 'sleep_quality']]
        y = training_data['fatigue_score']
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Create and train model
        self.model = Pipeline([
            ('scaler', StandardScaler()),
            ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
        ])
        
        self.model.fit(X_train, y_train)
        
        # Evaluate model
        y_pred = self.model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        logger.info(f"Fatigue risk model trained. MSE: {mse:.4f}, R: {r2:.4f}")
        
        # Save the model
        with open(os.path.join(MODEL_DIR, "fatigue_risk_model.pkl"), "wb") as f:
            pickle.dump(self.model, f)
    
    def load_model(self) -> None:
        """Load a pre-trained model"""
        model_path = os.path.join(MODEL_DIR, "fatigue_risk_model.pkl")
        
        if os.path.exists(model_path):
            with open(model_path, "rb") as f:
                self.model = pickle.load(f)
            logger.info("Loaded fatigue risk model from file")
        else:
            logger.warning("No pre-trained fatigue risk model found, will use simplified formula")
    
    def predict_fatigue(self, duty_data: Dict[str, Any]) -> Dict[str, Any]:
        """Predict fatigue risk for a given duty schedule"""
        
        # Ensure the model is loaded
        if self.model is None:
            self.load_model()
            
            # If still None, use simplified formula
            if self.model is None:
                return self._predict_with_simplified_model(duty_data)
        
        # Extract features from schedules
        schedules = duty_data.get('schedules', [])
        predictions = []
        
        for schedule in schedules:
            # Prepare features
            features = np.array([[
                schedule.get('duty_hours_past_24h', 0),
                schedule.get('duty_hours_past_7d', 0),
                schedule.get('hours_since_last_rest', 0),
                schedule.get('time_of_day', 12),  # 24-hour format
                schedule.get('timezone_changes_past_3d', 0),
                schedule.get('sleep_quality', 0.5)  # 0-1 scale
            ]])
            
            # Predict fatigue score
            fatigue_score = float(self.model.predict(features)[0])
            
            # Calculate risk category
            risk_category = self._categorize_risk(fatigue_score)
            
            # Generate mitigation strategies
            mitigations = self._generate_mitigations(fatigue_score, risk_category, schedule)
            
            predictions.append({
                'schedule_id': schedule.get('schedule_id', 'unknown'),
                'trainee_id': schedule.get('trainee_id', 'unknown'),
                'fatigue_score': fatigue_score,
                'risk_category': risk_category,
                'mitigations': mitigations
            })
        
        return {
            'prediction_date': datetime.datetime.now().isoformat(),
            'predictions': predictions
        }
    
    def _predict_with_simplified_model(self, duty_data: Dict[str, Any]) -> Dict[str, Any]:
        """Use simplified formula when no trained model exists"""
        
        schedules = duty_data.get('schedules', [])
        predictions = []
        
        for schedule in schedules:
            # Extract key fatigue factors
            duty_24h = schedule.get('duty_hours_past_24h', 0)
            duty_7d = schedule.get('duty_hours_past_7d', 0) / 168  # Normalize to 0-1
            hours_since_rest = schedule.get('hours_since_last_rest', 0) / 24  # Normalize to 0-1
            
            # Time of day factor (circadian effect)
            time_of_day = schedule.get('time_of_day', 12)  # 24-hour format
            # Highest fatigue at 3-5 AM, lowest at 3-5 PM
            circadian_factor = 1 - 0.5 * np.cos((time_of_day - 4) * np.pi / 12)
            
            # Timezone changes
            timezone_changes = schedule.get('timezone_changes_past_3d', 0) * 0.1
            
            # Sleep quality
            sleep_quality = 1 - schedule.get('sleep_quality', 0.5)  # Invert so higher is worse
            
            # Calculate fatigue score (0-10 scale)
            fatigue_score = (
                0.3 * (duty_24h / 24) +  # Weight of recent duty
                0.2 * duty_7d +          # Weight of cumulative duty
                0.2 * hours_since_rest + # Weight of time since rest
                0.15 * circadian_factor + # Weight of time of day
                0.1 * timezone_changes + # Weight of timezone changes
                0.05 * sleep_quality     # Weight of sleep quality
            ) * 10
            
            # Ensure score is between 0-10
            fatigue_score = max(0, min(10, fatigue_score))
            
            # Calculate risk category
            risk_category = self._categorize_risk(fatigue_score)
            
            # Generate mitigation strategies
            mitigations = self._generate_mitigations(fatigue_score, risk_category, schedule)
            
            predictions.append({
                'schedule_id': schedule.get('schedule_id', 'unknown'),
                'trainee_id': schedule.get('trainee_id', 'unknown'),
                'fatigue_score': float(fatigue_score),
                'risk_category': risk_category,
                'mitigations': mitigations
            })
        
        return {
            'prediction_date': datetime.datetime.now().isoformat(),
            'predictions': predictions,
            'model_type': 'simplified'  # Indicate we used the simplified model
        }
    
    def _categorize_risk(self, fatigue_score: float) -> str:
        """Categorize fatigue risk based on score"""
        
        if fatigue_score < 3:
            return "Low"
        elif fatigue_score < 6:
            return "Moderate"
        elif fatigue_score < 8:
            return "High"
        else:
            return "Severe"
    
    def _generate_mitigations(self, fatigue_score: float, risk_category: str, 
                             schedule: Dict[str, Any]) -> List[str]:
        """Generate fatigue mitigation strategies based on risk level"""
        
        mitigations = []
        
        # Common mitigation for all risk levels
        mitigations.append("Ensure proper hydration")
        
        if risk_category == "Low":
            mitigations.append("Maintain normal procedures")
            
        elif risk_category == "Moderate":
            mitigations.append("Consider strategic caffeine intake")
            mitigations.append("Increase monitoring of fatigue signs")
            
            # Add specific mitigations based on schedule factors
            if schedule.get('duty_hours_past_24h', 0) > 8:
                mitigations.append("Take short breaks every 1-2 hours")
            
            if schedule.get('time_of_day', 12) < 6 or schedule.get('time_of_day', 12) > 22:
                mitigations.append("Increase lighting levels in cockpit")
            
        elif risk_category == "High":
            mitigations.append("Implement crew augmentation if available")
            mitigations.append("Mandatory controlled rest periods")
            mitigations.append("Enhanced monitoring by other crewmembers")
            
            # Specific high-risk mitigations
            if schedule.get('hours_since_last_rest', 0) > 12:
                mitigations.append("Ensure minimum 30-minute break before critical phases")
            
            if schedule.get('timezone_changes_past_3d', 0) > 0:
                mitigations.append("Adjust light exposure to aid circadian adaptation")
            
        elif risk_category == "Severe":
            mitigations.append("Consider operational limitation or delay")
            mitigations.append("Implement maximum automation use")
            mitigations.append("Additional crewmember for monitoring if possible")
            mitigations.append("Mandatory rest before next duty period")
        
        return mitigations


# Training Effectiveness Model
class TrainingEffectivenessModel:
    """Predicts training effectiveness using multivariate regression"""
    
    def __init__(self):
        self.model = None
    
    def train(self, training_data: pd.DataFrame) -> None:
        """Train the training effectiveness model on historical data"""
        
        # Extract features
        X = training_data[['training_duration', 'sessions_per_week', 
                           'instructor_experience', 'training_method',
                           'trainee_experience', 'material_complexity']]
        # Convert categorical variables to one-hot encoding
        X = pd.get_dummies(X, columns=['training_method'])
        
        y = training_data['effectiveness_score']
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Create and train model
        self.model = Pipeline([
            ('scaler', StandardScaler()),
            ('regressor', GradientBoostingRegressor(n_estimators=100, random_state=42))
        ])
        
        self.model.fit(X_train, y_train)
        
        # Evaluate model
        y_pred = self.model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        logger.info(f"Training effectiveness model trained. MSE: {mse:.4f}, R: {r2:.4f}")
        
        # Save the model
        with open(os.path.join(MODEL_DIR, "training_effectiveness_model.pkl"), "wb") as f:
            pickle.dump(self.model, f)
    
    def load_model(self) -> None:
        """Load a pre-trained model"""
        model_path = os.path.join(MODEL_DIR, "training_effectiveness_model.pkl")
        
        if os.path.exists(model_path):
            with open(model_path, "rb") as f:
                self.model = pickle.load(f)
            logger.info("Loaded training effectiveness model from file")
        else:
            logger.warning("No pre-trained effectiveness model found")
    
    def predict_effectiveness(self, training_data: Dict[str, Any]) -> Dict[str, Any]:
        """Predict training effectiveness for a given training program"""
        
        # Ensure the model is loaded
        if self.model is None:
            self.load_model()
            
            # If still None, use expert rules
            if self.model is None:
                return self._predict_with_expert_rules(training_data)
        
        # Extract program details
        programs = training_data.get('programs', [])
        predictions = []
        
        # Get available training methods from the model
        try:
            training_methods = [col.replace('training_method_', '') 
                               for col in self.model.named_steps['regressor'].feature_names_in_
                               if 'training_method_' in col]
        except (AttributeError, KeyError):
            # Fallback if we can't extract feature names
            training_methods = ["classroom", "simulator", "aircraft", "cbt", "vr"]
        
        for program in programs:
            # Create one-hot encoding for training method
            method_features = {f"training_method_{tm}": 0 for tm in training_methods}
            
            # Set the used method to 1
            method = program.get('training_method', 'simulator')
            if f"training_method_{method}" in method_features:
                method_features[f"training_method_{method}"] = 1
            
            # Combine all features
            feature_dict = {
                'training_duration': program.get('training_duration', 5),
                'sessions_per_week': program.get('sessions_per_week', 3),
                'instructor_experience': program.get('instructor_experience', 5),
                'trainee_experience': program.get('trainee_experience', 3),
                'material_complexity': program.get('material_complexity', 3)
            }
            
            # Add method features
            feature_dict.update(method_features)
            
            # Convert to DataFrame with correct column order
            feature_df = pd.DataFrame([feature_dict])
            
            # Ensure all required columns are present, set missing to 0
            for col in self.model.named_steps['regressor'].feature_names_in_:
                if col not in feature_df.columns:
                    feature_df[col] = 0
            
            # Order columns correctly
            feature_df = feature_df[self.model.named_steps['regressor'].feature_names_in_]
            
            # Predict effectiveness
            effectiveness_score = float(self.model.predict(feature_df)[0])
            
            # Calculate confidence interval
            confidence = self._calculate_confidence(effectiveness_score, program)
            
            # Generate recommendations
            recommendations = self._generate_recommendations(effectiveness_score, program)
            
            predictions.append({
                'program_id': program.get('program_id', 'unknown'),
                'effectiveness_score': effectiveness_score,
                'confidence_interval': confidence,
                'recommendations': recommendations
            })
        
        return {
            'prediction_date': datetime.datetime.now().isoformat(),
            'predictions': predictions
        }
    
    def _predict_with_expert_rules(self, training_data: Dict[str, Any]) -> Dict[str, Any]:
        """Use expert rules to predict effectiveness when no model is available"""
        
        programs = training_data.get('programs', [])
        predictions = []
        
        for program in programs:
            # Extract key factors
            duration = program.get('training_duration', 5)  # Days
            sessions = program.get('sessions_per_week', 3)
            instructor_exp = program.get('instructor_experience', 5)  # 1-10 scale
            trainee_exp = program.get('trainee_experience', 3)  # 1-10 scale
            complexity = program.get('material_complexity', 3)  # 1-10 scale
            method = program.get('training_method', 'simulator')
            
            # Method effectiveness weights
            method_weights = {
                'classroom': 0.6,
                'simulator': 0.9,
                'aircraft': 1.0,
                'cbt': 0.7,
                'vr': 0.8
            }
            
            method_weight = method_weights.get(method, 0.7)
            
            # Calculate base effectiveness (0-10 scale)
            base_score = (
                0.3 * (duration / 10) +      # More days, better, up to a point
                0.15 * (sessions / 5) +      # More sessions per week, better, up to a point
                0.2 * (instructor_exp / 10) + # More instructor experience, better
                0.15 * (trainee_exp / 10) +  # More trainee experience, better for comprehension
                0.2 * (1 - complexity / 10)  # Less complexity, easier to learn
            ) * 10
            
            # Apply method weight
            effectiveness_score = base_score * method_weight
            
            # Ensure score is between 0-10
            effectiveness_score = max(0, min(10, effectiveness_score))
            
            # Calculate confidence
            confidence = self._calculate_confidence(effectiveness_score, program)
            
            # Generate recommendations
            recommendations = self._generate_recommendations(effectiveness_score, program)
            
            predictions.append({
                'program_id': program.get('program_id', 'unknown'),
                'effectiveness_score': float(effectiveness_score),
                'confidence_interval': confidence,
                'recommendations': recommendations,
                'model_type': 'expert_rules'
            })
        
        return {
            'prediction_date': datetime.datetime.now().isoformat(),
            'predictions': predictions
        }
    
    def _calculate_confidence(self, score: float, program: Dict[str, Any]) -> Dict[str, float]:
        """Calculate confidence interval for effectiveness prediction"""
        
        # Simplified confidence calculation - would be more sophisticated in production
        # Standard error increases for unusual combinations of parameters
        
        # Base standard error
        std_error = 0.5
        
        # Adjust based on available data quality
        data_quality = program.get('data_quality', 0.5)  # 0-1 scale
        std_error = std_error * (2 - data_quality)
        
        # Calculate 95% confidence interval
        lower_bound = max(0, score - 1.96 * std_error)
        upper_bound = min(10, score + 1.96 * std_error)
        
        return {
            'lower_bound': float(lower_bound),
            'upper_bound': float(upper_bound),
            'standard_error': float(std_error)
        }
    
    def _generate_recommendations(self, score: float, program: Dict[str, Any]) -> List[str]:
        """Generate recommendations to improve training effectiveness"""
        
        recommendations = []
        
        if score < 4:
            recommendations.append("Consider restructuring the training program")
            recommendations.append("Reduce complexity by breaking content into smaller modules")
            recommendations.append("Increase hands-on practice time")
            
            if program.get('sessions_per_week', 3) < 3:
                recommendations.append("Increase training frequency to improve retention")
            
            if program.get('instructor_experience', 5) < 5:
                recommendations.append("Assign more experienced instructors to this program")
        
        elif score < 7:
            recommendations.append("Consider adding supplementary training materials")
            
            if program.get('training_method', '') == 'classroom':
                recommendations.append("Incorporate simulator sessions for practical application")
            
            if program.get('material_complexity', 3) > 7:
                recommendations.append("Add additional preparation modules before complex topics")
        
        else:
            recommendations.append("Monitor ongoing effectiveness through regular assessments")
            recommendations.append("Document successful approaches for other training programs")
            
            # Always suggest at least one improvement
            if program.get('trainee_experience', 3) < 5:
                recommendations.append("Consider adding optional advanced modules for experienced trainees")
        
        return recommendations


# Performance Consistency Model
class PerformanceConsistencyModel:
    """Assesses performance consistency and detects anomalies"""
    
    def __init__(self):
        self.model = None
    
    def train(self, training_data: pd.DataFrame) -> None:
        """Train the performance consistency model using neural network"""
        
        # Extract features
        X = training_data.drop(['trainee_id', 'consistency_score', 'date'], axis=1, errors='ignore')
        y = training_data['consistency_score']
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Create scaler
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Build neural network model
        model = keras.Sequential([
            keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
            keras.layers.Dropout(0.2),
            keras.layers.Dense(32, activation='relu'),
            keras.layers.Dropout(0.2),
            keras.layers.Dense(1)
        ])
        
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        
        # Train model
        history = model.fit(
            X_train_scaled, y_train,
            epochs=100,
            batch_size=32,
            validation_split=0.2,
            verbose=0,
            callbacks=[
                keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
            ]
        )
        
        # Evaluate model
        test_results = model.evaluate(X_test_scaled, y_test, verbose=0)
        logger.info(f"Performance consistency model trained. MSE: {test_results[0]:.4f}, MAE: {test_results[1]:.4f}")
        
        # Save model and scaler
        self.model = model
        self.scaler = scaler
        
        model.save(os.path.join(MODEL_DIR, "consistency_model"))
        
        with open(os.path.join(MODEL_DIR, "consistency_scaler.pkl"), "wb") as f:
            pickle.dump(scaler, f)
    
    def load_model(self) -> None:
        """Load a pre-trained model"""
        model_path = os.path.join(MODEL_DIR, "consistency_model")
        scaler_path = os.path.join(MODEL_DIR, "consistency_scaler.pkl")
        
        if os.path.exists(model_path) and os.path.exists(scaler_path):
            self.model = keras.models.load_model(model_path)
            
            with open(scaler_path, "rb") as f:
                self.scaler = pickle.load(f)
                
            logger.info("Loaded performance consistency model from file")
        else:
            logger.warning("No pre-trained consistency model found")
    
    def assess_consistency(self, performance_data: Dict[str, Any]) -> Dict[str, Any]:
        """Assess performance consistency for a given trainee"""
        
        # Ensure the model is loaded
        if self.model is None:
            self.load_model()
            
            # If still None, use statistical methods
            if self.model is None:
                return self._assess_with_statistics(performance_data)
        
        # Extract trainee performances
        trainees = performance_data.get('trainees', [])
        assessments = []
        
        for trainee in trainees:
            # Extract performance metrics
            metrics = trainee.get('performance_metrics', [])
            
            if not metrics:
                continue
            
            # Convert to DataFrame for easier processing
            metric_df = pd.DataFrame(metrics)
            
            # Prepare features
            feature_cols = [col for col in metric_df.columns if col not in ['date', 'session_id']]
            X = metric_df[feature_cols]
            
            # Scale features
            X_scaled = self.scaler.transform(X)
            
            # Predict consistency score
            consistency_score = float(self.model.predict(X_scaled).mean())
            
            # Detect anomalies
            anomalies = self._detect_anomalies(metric_df, feature_cols)
            
            # Calculate variance metrics
            variance_metrics = {
                col: float(metric_df[col].std()) 
                for col in feature_cols
            }
            
            assessments.append({
                'trainee_id': trainee.get('trainee_id', 'unknown'),
                'consistency_score': consistency_score,
                'variance_metrics': variance_metrics,
                'anomalies': anomalies,
                'recommendation': self._generate_consistency_recommendation(
                    consistency_score, variance_metrics, anomalies
                )
            })
        
        return {
            'assessment_date': datetime.datetime.now().isoformat(),
            'assessments': assessments
        }
    
    def _assess_with_statistics(self, performance_data: Dict[str, Any]) -> Dict[str, Any]:
        """Assess consistency using statistical methods when no model is available"""
        
        trainees = performance_data.get('trainees', [])
        assessments = []
        
        for trainee in trainees:
            # Extract performance metrics
            metrics = trainee.get('performance_metrics', [])
            
            if not metrics:
                continue
            
            # Convert to DataFrame for easier processing
            metric_df = pd.DataFrame(metrics)
            
            # Prepare features
            feature_cols = [col for col in metric_df.columns if col not in ['date', 'session_id']]
            
            if not feature_cols:
                continue
            
            # Calculate coefficient of variation for each metric
            cv_scores = {}
            for col in feature_cols:
                mean = metric_df[col].mean()
                std = metric_df[col].std()
                
                # Avoid division by zero
                if mean != 0:
                    cv = std / mean
                else:
                    cv = std  # Use std if mean is zero
                    
                cv_scores[col] = cv
            
            # Overall consistency score (0-10 scale, lower CV is better)
            # We invert and scale the average CV to get a consistency score
            avg_cv = sum(cv_scores.values()) / len(cv_scores)
            consistency_score = 10 * np.exp(-2 * avg_cv)  # Exponential transform
            
            # Detect anomalies
            anomalies = self._detect_anomalies(metric_df, feature_cols)
            
            # Calculate variance metrics
            variance_metrics = {
                col: float(metric_df[col].std()) 
                for col in feature_cols
            }
            
            assessments.append({
                'trainee_id': trainee.get('trainee_id', 'unknown'),
                'consistency_score': float(consistency_score),
                'variance_metrics': variance_metrics,
                'anomalies': anomalies,
                'recommendation': self._generate_consistency_recommendation(
                    consistency_score, variance_metrics, anomalies
                ),
                'model_type': 'statistical'
            })
        
        return {
            'assessment_date': datetime.datetime.now().isoformat(),
            'assessments': assessments
        }
    
    def _detect_anomalies(self, data: pd.DataFrame, 
                         feature_cols: List[str]) -> List[Dict[str, Any]]:
        """Detect anomalies in performance data"""
        
        anomalies = []
        
        # Simple Z-score based anomaly detection
        for col in feature_cols:
            # Calculate z-scores
            mean = data[col].mean()
            std = data[col].std()
            
            if std == 0:
                continue
                
            z_scores = (data[col] - mean) / std
            
            # Find anomalies (|z| > 2)
            anomaly_indices = np.where(np.abs(z_scores) > 2)[0]
            
            for idx in anomaly_indices:
                session_id = data.iloc[idx].get('session_id', str(idx))
                date = data.iloc[idx].get('date', 'unknown')
                value = float(data.iloc[idx][col])
                z_score = float(z_scores.iloc[idx])
                
                anomalies.append({
                    'metric': col,
                    'session_id': session_id,
                    'date': date,
                    'value': value,
                    'z_score': z_score,
                    'severity': 'high' if abs(z_score) > 3 else 'medium'
                })
        
        return anomalies
    
    def _generate_consistency_recommendation(self, consistency_score: float,
                                           variance_metrics: Dict[str, float],
                                           anomalies: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate recommendations for improving consistency"""
        
        recommendation = {
            'summary': '',
            'actions': []
        }
        
        if consistency_score < 4:
            recommendation['summary'] = "Significant performance inconsistency detected"
            recommendation['actions'].append("Review fundamentals and reinforce standard procedures")
            recommendation['actions'].append("Increase training frequency to build muscle memory")
            recommendation['actions'].append("Consider structured remedial training focused on consistency")
            
        elif consistency_score < 7:
            recommendation['summary'] = "Moderate performance inconsistency detected"
            recommendation['actions'].append("Focus training on areas with highest variance")
            recommendation['actions'].append("Practice mental preparation techniques for consistent performance")
            
        else:
            recommendation['summary'] = "Good performance consistency observed"
            recommendation['actions'].append("Maintain current practice routine")
            recommendation['actions'].append("Challenge with more complex scenarios to maintain engagement")
        
        # Add specific recommendations based on anomalies
        if anomalies:
            high_severity = [a for a in anomalies if a['severity'] == 'high']
            
            if high_severity:
                metrics = set(a['metric'] for a in high_severity)
                metrics_str = ", ".join(metrics)
                recommendation['actions'].append(
                    f"Investigate factors affecting performance in: {metrics_str}"
                )
        
        # Add specific recommendations based on high variance metrics
        if variance_metrics:
            # Find top 2 highest variance metrics
            sorted_metrics = sorted(variance_metrics.items(), key=lambda x: x[1], reverse=True)
            
            if len(sorted_metrics) > 0:
                top_metric = sorted_metrics[0][0]
                recommendation['actions'].append(
                    f"Prioritize consistency training in {top_metric}"
                )
            
            if len(sorted_metrics) > 1:
                second_metric = sorted_metrics[1][0]
                recommendation['actions'].append(
                    f"Secondary focus on improving consistency in {second_metric}"
                )
        
        return recommendation


# Syllabus Optimization Model
class SyllabusOptimizationModel:
    """Optimizes syllabus structure based on learning outcomes"""
    
    def __init__(self):
        self.model = None
    
    def train(self, training_data: pd.DataFrame) -> None:
        """Train the syllabus optimization model"""
        
        # Extract features from training data
        X = training_data.drop(['syllabus_id', 'module_id', 'effectiveness'], axis=1, errors='ignore')
        y = training_data['effectiveness']
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Create and train model
        self.model = Pipeline([
            ('scaler', StandardScaler()),
            ('regressor', GradientBoostingRegressor(n_estimators=100, random_state=42))
        ])
        
        self.model.fit(X_train, y_train)
        
        # Evaluate model
        y_pred = self.model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        logger.info(f"Syllabus optimization model trained. MSE: {mse:.4f}, R: {r2:.4f}")
        
        # Save the model
        with open(os.path.join(MODEL_DIR, "syllabus_optimization_model.pkl"), "wb") as f:
            pickle.dump(self.model, f)
    
    def load_model(self) -> None:
        """Load a pre-trained model"""
        model_path = os.path.join(MODEL_DIR, "syllabus_optimization_model.pkl")
        
        if os.path.exists(model_path):
            with open(model_path, "rb") as f:
                self.model = pickle.load(f)
            logger.info("Loaded syllabus optimization model from file")
        else:
            logger.warning("No pre-trained syllabus optimization model found")
    
    def optimize_syllabus(self, syllabus_data: Dict[str, Any]) -> Dict[str, Any]:
        """Optimize syllabus structure for improved outcomes"""
        
        # Ensure the model is loaded
        if self.model is None:
            self.load_model()
            
            # If still None, use heuristic optimization
            if self.model is None:
                return self._optimize_with_heuristics(syllabus_data)
        
        # Extract syllabus details
        syllabi = syllabus_data.get('syllabi', [])
        optimizations = []
        
        for syllabus in syllabi:
            modules = syllabus.get('modules', [])
            optimized_modules = []
            
            for module in modules:
                # Extract module features
                features = {
                    'duration': module.get('duration', 1),
                    'complexity': module.get('complexity', 5),
                    'theory_percentage': module.get('theory_percentage', 50),
                    'practical_percentage': module.get('practical_percentage', 50),
                    'position_in_syllabus': module.get('position', 0) / max(1, len(modules)),
                    'prerequisites_count': len(module.get('prerequisites', [])),
                    'assessment_count': len(module.get('assessments', []))
                }
                
                # Additional derived features
                features['theory_practical_ratio'] = features['theory_percentage'] / max(1, features['practical_percentage'])
                
                # Convert to DataFrame for prediction
                feature_df = pd.DataFrame([features])
                
                # Predict module effectiveness
                current_effectiveness = float(self.model.predict(feature_df)[0])
                
                # Try different module configurations to optimize
                optimized_config, optimized_effectiveness = self._find_optimal_configuration(
                    features, current_effectiveness, self.model
                )
                
                # Calculate percentage improvement
                improvement = (optimized_effectiveness - current_effectiveness) / max(0.01, current_effectiveness) * 100
                
                # Prepare optimization recommendations
                optimization = {
                    'module_id': module.get('id', 'unknown'),
                    'module_name': module.get('name', 'Unknown Module'),
                    'current_effectiveness': current_effectiveness,
                    'optimized_effectiveness': optimized_effectiveness,
                    'improvement_percentage': float(improvement),
                    'current_config': {k: v for k, v in features.items() if k != 'theory_practical_ratio'},
                    'recommended_config': {k: v for k, v in optimized_config.items() if k != 'theory_practical_ratio'}
                }
                
                # Add specific recommendations
                optimization['recommendations'] = self._generate_optimization_recommendations(
                    features, optimized_config
                )
                
                optimized_modules.append(optimization)
            
            # Calculate overall syllabus optimization
            current_avg_effectiveness = np.mean([m['current_effectiveness'] for m in optimized_modules])
            optimized_avg_effectiveness = np.mean([m['optimized_effectiveness'] for m in optimized_modules])
            
            # Also optimize module sequence
            reordered_sequence, sequence_effectiveness = self._optimize_module_sequence(
                modules, self.model
            )
            
            overall_improvement = (optimized_avg_effectiveness - current_avg_effectiveness) / max(0.01, current_avg_effectiveness) * 100
            
            # Sort modules by improvement potential
            sorted_modules = sorted(optimized_modules, key=lambda x: x['improvement_percentage'], reverse=True)
            
            optimizations.append({
                'syllabus_id': syllabus.get('id', 'unknown'),
                'syllabus_name': syllabus.get('name', 'Unknown Syllabus'),
                'current_effectiveness': float(current_avg_effectiveness),
                'optimized_effectiveness': float(optimized_avg_effectiveness),
                'overall_improvement': float(overall_improvement),
                'modules': sorted_modules,
                'recommended_sequence': reordered_sequence,
                'sequence_effectiveness': float(sequence_effectiveness)
            })
        
        return {
            'optimization_date': datetime.datetime.now().isoformat(),
            'optimizations': optimizations
        }
    
    def _optimize_with_heuristics(self, syllabus_data: Dict[str, Any]) -> Dict[str, Any]:
        """Use heuristic rules to optimize syllabus when no model is available"""
        
        # Extract syllabus details
        syllabi = syllabus_data.get('syllabi', [])
        optimizations = []
        
        for syllabus in syllabi:
            modules = syllabus.get('modules', [])
            optimized_modules = []
            
            for module in modules:
                # Extract module features
                features = {
                    'duration': module.get('duration', 1),
                    'complexity': module.get('complexity', 5),
                    'theory_percentage': module.get('theory_percentage', 50),
                    'practical_percentage': module.get('practical_percentage', 50),
                    'position_in_syllabus': module.get('position', 0) / max(1, len(modules)),
                    'prerequisites_count': len(module.get('prerequisites', [])),
                    'assessment_count': len(module.get('assessments', []))
                }
                
                # Estimate current effectiveness using heuristics (0-10 scale)
                theory_practical_balance = 10 - abs(features['theory_percentage'] - features['practical_percentage']) / 10
                complexity_adjustment = 10 - features['complexity']
                assessment_ratio = min(10, features['assessment_count'] * 2)
                
                current_effectiveness = (
                    0.3 * theory_practical_balance +
                    0.3 * complexity_adjustment +
                    0.4 * assessment_ratio
                )
                
                # Apply heuristic optimization rules
                optimized_config = features.copy()
                
                # Rule 1: Balance theory and practical (50/50 is ideal for most modules)
                if abs(features['theory_percentage'] - features['practical_percentage']) > 20:
                    optimized_config['theory_percentage'] = 50
                    optimized_config['practical_percentage'] = 50
                
                # Rule 2: Optimal assessment count is about 1 per hour of training
                optimal_assessments = max(1, int(features['duration']))
                
                if features['assessment_count'] < optimal_assessments:
                    optimized_config['assessment_count'] = optimal_assessments
                
                # Rule 3: Complexity should match position in syllabus
                # Earlier modules should be less complex
                optimal_complexity = features['position_in_syllabus'] * 10
                
                if features['complexity'] > optimal_complexity + 2:
                    optimized_config['complexity'] = min(9, max(1, int(optimal_complexity)))
                
                # Estimate optimized effectiveness
                optimized_theory_practical_balance = 10 - abs(optimized_config['theory_percentage'] - optimized_config['practical_percentage']) / 10
                optimized_complexity_adjustment = 10 - optimized_config['complexity']
                optimized_assessment_ratio = min(10, optimized_config['assessment_count'] * 2)
                
                optimized_effectiveness = (
                    0.3 * optimized_theory_practical_balance +
                    0.3 * optimized_complexity_adjustment +
                    0.4 * optimized_assessment_ratio
                )
                
                # Calculate improvement
                improvement = (optimized_effectiveness - current_effectiveness) / max(0.01, current_effectiveness) * 100
                
                # Prepare optimization recommendations
                optimization = {
                    'module_id': module.get('id', 'unknown'),
                    'module_name': module.get('name', 'Unknown Module'),
                    'current_effectiveness': float(current_effectiveness),
                    'optimized_effectiveness': float(optimized_effectiveness),
                    'improvement_percentage': float(improvement),
                    'current_config': features,
                    'recommended_config': optimized_config
                }
                
                # Add specific recommendations
                optimization['recommendations'] = self._generate_optimization_recommendations(
                    features, optimized_config
                )
                
                optimized_modules.append(optimization)
            
            # Calculate overall syllabus optimization
            current_avg_effectiveness = np.mean([m['current_effectiveness'] for m in optimized_modules])
            optimized_avg_effectiveness = np.mean([m['optimized_effectiveness'] for m in optimized_modules])
            
            # Optimize module sequence using prerequisites and complexity
            reordered_sequence = self._heuristic_sequence_optimization(modules)
            
            # Estimate sequence effectiveness (improvement over original)
            sequence_effectiveness = current_avg_effectiveness * 1.05  # Assume 5% improvement from reordering
            
            overall_improvement = (optimized_avg_effectiveness - current_avg_effectiveness) / max(0.01, current_avg_effectiveness) * 100
            
            # Sort modules by improvement potential
            sorted_modules = sorted(optimized_modules, key=lambda x: x['improvement_percentage'], reverse=True)
            
            optimizations.append({
                'syllabus_id': syllabus.get('id', 'unknown'),
                'syllabus_name': syllabus.get('name', 'Unknown Syllabus'),
                'current_effectiveness': float(current_avg_effectiveness),
                'optimized_effectiveness': float(optimized_avg_effectiveness),
                'overall_improvement': float(overall_improvement),
                'modules': sorted_modules,
                'recommended_sequence': reordered_sequence,
                'sequence_effectiveness': float(sequence_effectiveness),
                'model_type': 'heuristic'
            })
        
        return {
            'optimization_date': datetime.datetime.now().isoformat(),
            'optimizations': optimizations
        }
    
    def _find_optimal_configuration(self, current_features: Dict[str, float], 
                                  current_effectiveness: float,
                                  model) -> Tuple[Dict[str, float], float]:
        """Find optimal module configuration through systematic exploration"""
        
        # Start with current configuration
        best_config = current_features.copy()
        best_effectiveness = current_effectiveness
        
        # Parameters to optimize and their ranges
        param_ranges = {
            'duration': [max(0.5, current_features['duration'] - 0.5), 
                         current_features['duration'], 
                         current_features['duration'] + 0.5],
            'theory_percentage': [max(20, current_features['theory_percentage'] - 10),
                                 current_features['theory_percentage'],
                                 min(80, current_features['theory_percentage'] + 10)],
            'assessment_count': [max(1, current_features['assessment_count'] - 1),
                                current_features['assessment_count'],
                                current_features['assessment_count'] + 1]
        }
        
        # Grid search for best configuration
        for duration in param_ranges['duration']:
            for theory_pct in param_ranges['theory_percentage']:
                for assessment_count in param_ranges['assessment_count']:
                    # Create test configuration
                    test_config = current_features.copy()
                    test_config['duration'] = duration
                    test_config['theory_percentage'] = theory_pct
                    test_config['practical_percentage'] = 100 - theory_pct
                    test_config['theory_practical_ratio'] = theory_pct / max(1, 100 - theory_pct)
                    test_config['assessment_count'] = assessment_count
                    
                    # Convert to DataFrame for prediction
                    test_df = pd.DataFrame([test_config])
                    
                    # Predict effectiveness
                    effectiveness = float(model.predict(test_df)[0])
                    
                    # Update best if improvement found
                    if effectiveness > best_effectiveness:
                        best_effectiveness = effectiveness
                        best_config = test_config.copy()
        
        return best_config, best_effectiveness
    
    def _optimize_module_sequence(self, modules: List[Dict[str, Any]], 
                                model) -> Tuple[List[str], float]:
        """Optimize the sequence of modules in the syllabus"""
        
        # This would use a more sophisticated algorithm in production
        # For example, topological sort based on prerequisites and then
        # optimize within constraints using the model
        
        # Simple implementation: sort by complexity and prerequisites
        module_info = []
        
        for i, module in enumerate(modules):
            module_info.append({
                'id': module.get('id', f'module_{i}'),
                'name': module.get('name', f'Module {i}'),
                'complexity': module.get('complexity', 5),
                'prerequisites': module.get('prerequisites', []),
                'original_position': i
            })
        
        # Build dependency graph
        dependencies = {m['id']: set(m['prerequisites']) for m in module_info}
        
        # Perform topological sort
        sorted_modules = []
        visited = set()
        temp_visited = set()
        
        def visit(module_id):
            if module_id in temp_visited:
                # Cycle detected, break it
                return
            
            if module_id in visited:
                return
            
            temp_visited.add(module_id)
            
            for dependency in dependencies.get(module_id, []):
                visit(dependency)
            
            temp_visited.remove(module_id)
            visited.add(module_id)
            sorted_modules.append(module_id)
        
        # Visit all modules
        for module in module_info:
            if module['id'] not in visited:
                visit(module['id'])
        
        # Reverse to get correct order
        sorted_modules.reverse()
        
        # Estimate effectiveness of new sequence
        # This would use the actual model in production
        sequence_effectiveness = 8.0  # Placeholder
        
        # Convert IDs to names for readability
        id_to_name = {m['id']: m['name'] for m in module_info}
        named_sequence = [id_to_name.get(mid, mid) for mid in sorted_modules]
        
        return named_sequence, sequence_effectiveness
    
    def _heuristic_sequence_optimization(self, modules: List[Dict[str, Any]]) -> List[str]:
        """Optimize module sequence using prerequisites and complexity"""
        
        module_info = []
        
        for i, module in enumerate(modules):
            module_info.append({
                'id': module.get('id', f'module_{i}'),
                'name': module.get('name', f'Module {i}'),
                'complexity': module.get('complexity', 5),
                'prerequisites': module.get('prerequisites', []),
                'original_position': i
            })
        
        # Build dependency graph
        dependencies = {m['id']: set(m['prerequisites']) for m in module_info}
        
        # Perform topological sort
        sorted_modules = []
        visited = set()
        temp_visited = set()
        
        def visit(module_id):
            if module_id in temp_visited:
                # Cycle detected, break it
                return
            
            if module_id in visited:
                return
            
            temp_visited.add(module_id)
            
            for dependency in dependencies.get(module_id, []):
                visit(dependency)
            
            temp_visited.remove(module_id)
            visited.add(module_id)
            sorted_modules.append(module_id)
        
        # Visit all modules
        for module in module_info:
            if module['id'] not in visited:
                visit(module['id'])
        
        # Reverse to get correct order
        sorted_modules.reverse()
        
        # Convert IDs to names for readability
        id_to_name = {m['id']: m['name'] for m in module_info}
        named_sequence = [id_to_name.get(mid, mid) for mid in sorted_modules]
        
        return named_sequence
    
    def _generate_optimization_recommendations(self, current_config: Dict[str, Any],
                                            optimized_config: Dict[str, Any]) -> List[str]:
        """Generate specific recommendations based on configuration changes"""
        
        recommendations = []
        
        # Check duration change
        duration_change = optimized_config['duration'] - current_config['duration']
        if abs(duration_change) >= 0.5:
            if duration_change > 0:
                recommendations.append(f"Increase module duration by {duration_change:.1f} hours for better knowledge retention")
            else:
                recommendations.append(f"Decrease module duration by {abs(duration_change):.1f} hours to improve focus and engagement")
        
        # Check theory/practical balance
        theory_change = optimized_config['theory_percentage'] - current_config['theory_percentage']
        if abs(theory_change) >= 5:
            if theory_change > 0:
                recommendations.append(f"Increase theoretical content by {theory_change:.0f}% to build stronger conceptual foundation")
            else:
                recommendations.append(f"Reduce theoretical content by {abs(theory_change):.0f}% in favor of more hands-on practice")
        
        # Check assessment count
        assessment_change = optimized_config['assessment_count'] - current_config['assessment_count']
        if assessment_change != 0:
            if assessment_change > 0:
                recommendations.append(f"Add {assessment_change} additional assessment point(s) to reinforce learning")
            else:
                recommendations.append(f"Reduce assessment count by {abs(assessment_change)} to decrease evaluation pressure")
        
        # Check complexity
        complexity_change = optimized_config['complexity'] - current_config['complexity']
        if abs(complexity_change) >= 1:
            if complexity_change > 0:
                recommendations.append(f"Increase content complexity to better match learner capabilities")
            else:
                recommendations.append(f"Reduce content complexity to improve comprehension and retention")
        
        # Add general recommendation if no specific changes
        if not recommendations:
            recommendations.append("Current module configuration is near optimal")
        
        return recommendations


# Initialize models
skill_decay_model = SkillDecayModel()
fatigue_risk_model = FatigueRiskModel()
training_effectiveness_model = TrainingEffectivenessModel()
performance_consistency_model = PerformanceConsistencyModel()
syllabus_optimization_model = SyllabusOptimizationModel()

# API endpoints
@app.route("/api/predict/skill-decay", methods=["POST"])
def predict_skill_decay():
    """Predict skill decay for a trainee"""
    data = request.json
    if not data:
        return jsonify({"error": "No data provided"}), 400
    
    try:
        result = skill_decay_model.predict_decay(data)
        return jsonify(result)
    except Exception as e:
        logger.error(f"Error predicting skill decay: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/predict/fatigue-risk", methods=["POST"])
def predict_fatigue_risk():
    """Predict fatigue risk for duty schedules"""
    data = request.json
    if not data:
        return jsonify({"error": "No data provided"}), 400
    
    try:
        result = fatigue_risk_model.predict_fatigue(data)
        return jsonify(result)
    except Exception as e:
        logger.error(f"Error predicting fatigue risk: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/predict/training-effectiveness", methods=["POST"])
def predict_training_effectiveness():
    """Predict training effectiveness for a program"""
    data = request.json
    if not data:
        return jsonify({"error": "No data provided"}), 400
    
    try:
        result = training_effectiveness_model.predict_effectiveness(data)
        return jsonify(result)
    except Exception as e:
        logger.error(f"Error predicting training effectiveness: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/assess/performance-consistency", methods=["POST"])
def assess_performance_consistency():
    """Assess performance consistency for a trainee"""
    data = request.json
    if not data:
        return jsonify({"error": "No data provided"}), 400
    
    try:
        result = performance_consistency_model.assess_consistency(data)
        return jsonify(result)
    except Exception as e:
        logger.error(f"Error assessing performance consistency: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/optimize/syllabus", methods=["POST"])
def optimize_syllabus():
    """Optimize syllabus structure"""
    data = request.json
    if not data:
        return jsonify({"error": "No data provided"}), 400
    
    try:
        result = syllabus_optimization_model.optimize_syllabus(data)
        return jsonify(result)
    except Exception as e:
        logger.error(f"Error optimizing syllabus: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/train/skill-decay", methods=["POST"])
def train_skill_decay_endpoint():
    """Train skill decay model with new data"""
    data = request.json
    if not data or 'training_data' not in data:
        return jsonify({"error": "No training data provided"}), 400
    
    try:
        # Convert to DataFrame
        df = pd.DataFrame(data['training_data'])
        skill_decay_model.train(df)
        return jsonify({"status": "success", "message": "Skill decay model trained successfully"})
    except Exception as e:
        logger.error(f"Error training skill decay model: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/train/fatigue-risk", methods=["POST"])
def train_fatigue_risk_endpoint():
    """Train fatigue risk model with new data"""
    data = request.json
    if not data or 'training_data' not in data:
        return jsonify({"error": "No training data provided"}), 400
    
    try:
        # Convert to DataFrame
        df = pd.DataFrame(data['training_data'])
        fatigue_risk_model.train(df)
        return jsonify({"status": "success", "message": "Fatigue risk model trained successfully"})
    except Exception as e:
        logger.error(f"Error training fatigue risk model: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/train/training-effectiveness", methods=["POST"])
def train_effectiveness_endpoint():
    """Train training effectiveness model with new data"""
    data = request.json
    if not data or 'training_data' not in data:
        return jsonify({"error": "No training data provided"}), 400
    
    try:
        # Convert to DataFrame
        df = pd.DataFrame(data['training_data'])
        training_effectiveness_model.train(df)
        return jsonify({"status": "success", "message": "Training effectiveness model trained successfully"})
    except Exception as e:
        logger.error(f"Error training effectiveness model: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/train/performance-consistency", methods=["POST"])
def train_consistency_endpoint():
    """Train performance consistency model with new data"""
    data = request.json
    if not data or 'training_data' not in data:
        return jsonify({"error": "No training data provided"}), 400
    
    try:
        # Convert to DataFrame
        df = pd.DataFrame(data['training_data'])
        performance_consistency_model.train(df)
        return jsonify({"status": "success", "message": "Performance consistency model trained successfully"})
    except Exception as e:
        logger.error(f"Error training consistency model: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/api/train/syllabus-optimization", methods=["POST"])
def train_syllabus_optimization_endpoint():
    """Train syllabus optimization model with new data"""
    data = request.json
    if not data or 'training_data' not in data:
        return jsonify({"error": "No training data provided"}), 400
    
    try:
        # Convert to DataFrame
        df = pd.DataFrame(data['training_data'])
        syllabus_optimization_model.train(df)
        return jsonify({"status": "success", "message": "Syllabus optimization model trained successfully"})
    except Exception as e:
        logger.error(f"Error training syllabus optimization model: {str(e)}")
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    # Try to load pre-trained models
    skill_decay_model.load_model()
    fatigue_risk_model.load_model()
    training_effectiveness_model.load_model()
    performance_consistency_model.load_model()
    syllabus_optimization_model.load_model()
    
    # Starting the Flask application
    port = int(os.environ.get("PORT", 5001))
    app.run(host="0.0.0.0", port=port)

# Advanced Pilot Training Platform - Backend Structure
mkdir -p advanced-pilot-training-platform/backend/{core,document,syllabus,assessment,user-management,scheduler,analytics,compliance,collaboration,visualization,integration,security}/include
mkdir -p advanced-pilot-training-platform/backend/{core,document,syllabus,assessment,user-management,scheduler,analytics,compliance,collaboration,visualization,integration,security}/src
mkdir -p advanced-pilot-training-platform/backend/{core,document,syllabus,assessment,user-management,scheduler,analytics,compliance,collaboration,visualization,integration,security}/test
mkdir -p advanced-pilot-training-platform/backend/ai-modules/{document-understanding,performance-prediction,automation-workflows,research-assistant}
mkdir -p advanced-pilot-training-platform/backend/api
mkdir -p advanced-pilot-training-platform/backend/docs
mkdir -p advanced-pilot-training-platform/backend/scripts
mkdir -p advanced-pilot-training-platform/backend/config

# backend/CMakeLists.txt
cmake_minimum_required(VERSION 3.15)
project(AdvancedPilotTrainingPlatform CXX)

# Set C++ standard
set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Add compiler flags
if(MSVC)
    add_compile_options(/W4)
else()
    add_compile_options(-Wall -Wextra -pedantic)
endif()

# Find required packages
find_package(Drogon REQUIRED)
find_package(OpenSSL REQUIRED)
find_package(PostgreSQL REQUIRED)
find_package(nlohmann_json REQUIRED)
find_package(Boost REQUIRED COMPONENTS system filesystem)
find_package(GTest REQUIRED)
find_package(Threads REQUIRED)

# Optional: Enable testing
enable_testing()

# Add subdirectories
add_subdirectory(core)
add_subdirectory(document)
add_subdirectory(syllabus)
add_subdirectory(assessment)
add_subdirectory(user-management)
add_subdirectory(scheduler)
add_subdirectory(analytics)
add_subdirectory(compliance)
add_subdirectory(collaboration)
add_subdirectory(visualization)
add_subdirectory(integration)
add_subdirectory(security)
add_subdirectory(api)

# Main application
add_executable(aptp_server main.cpp)
target_link_libraries(aptp_server
    PRIVATE
    aptp_core
    aptp_api
    Drogon::Drogon
    Threads::Threads
)

# Installation
install(TARGETS aptp_server
    RUNTIME DESTINATION bin
)

# backend/core/CMakeLists.txt
add_library(aptp_core
    src/ConfigurationManager.cpp
    src/Logger.cpp
    src/ErrorHandling.cpp
    src/DatabaseManager.cpp
)

target_include_directories(aptp_core
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_core
    PUBLIC
    PostgreSQL::PostgreSQL
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
    Boost::system
    Boost::filesystem
)

# Tests
add_executable(core_tests
    test/ConfigurationManagerTest.cpp
    test/LoggerTest.cpp
    test/ErrorHandlingTest.cpp
    test/DatabaseManagerTest.cpp
)

target_link_libraries(core_tests
    PRIVATE
    aptp_core
    GTest::GTest
    GTest::Main
)

add_test(NAME core_tests COMMAND core_tests)

# backend/document/CMakeLists.txt
add_library(aptp_document
    src/DocumentProcessor.cpp
    src/OCRProcessor.cpp
    src/AIDocumentAnalyzer.cpp
)

target_include_directories(aptp_document
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_document
    PUBLIC
    aptp_core
    nlohmann_json::nlohmann_json
    # Add OCR and document processing libraries
)

# Tests
add_executable(document_tests
    test/DocumentProcessorTest.cpp
    test/OCRProcessorTest.cpp
    test/AIDocumentAnalyzerTest.cpp
)

target_link_libraries(document_tests
    PRIVATE
    aptp_document
    GTest::GTest
    GTest::Main
)

add_test(NAME document_tests COMMAND document_tests)

# backend/syllabus/CMakeLists.txt
add_library(aptp_syllabus
    src/SyllabusGenerator.cpp
)

target_include_directories(aptp_syllabus
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_syllabus
    PUBLIC
    aptp_core
    aptp_document
    nlohmann_json::nlohmann_json
)

# Tests
add_executable(syllabus_tests
    test/SyllabusGeneratorTest.cpp
)

target_link_libraries(syllabus_tests
    PRIVATE
    aptp_syllabus
    GTest::GTest
    GTest::Main
)

add_test(NAME syllabus_tests COMMAND syllabus_tests)

# backend/assessment/CMakeLists.txt
add_library(aptp_assessment
    src/AssessmentManager.cpp
    src/GradeManager.cpp
    src/BiometricProcessor.cpp
)

target_include_directories(aptp_assessment
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_assessment
    PUBLIC
    aptp_core
    aptp_syllabus
    nlohmann_json::nlohmann_json
)

# Tests
add_executable(assessment_tests
    test/AssessmentManagerTest.cpp
    test/GradeManagerTest.cpp
    test/BiometricProcessorTest.cpp
)

target_link_libraries(assessment_tests
    PRIVATE
    aptp_assessment
    GTest::GTest
    GTest::Main
)

add_test(NAME assessment_tests COMMAND assessment_tests)

# backend/scheduler/CMakeLists.txt
add_library(aptp_scheduler
    src/SchedulerEngine.cpp
)

target_include_directories(aptp_scheduler
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_scheduler
    PUBLIC
    aptp_core
    nlohmann_json::nlohmann_json
)

# Tests
add_executable(scheduler_tests
    test/SchedulerEngineTest.cpp
)

target_link_libraries(scheduler_tests
    PRIVATE
    aptp_scheduler
    GTest::GTest
    GTest::Main
)

add_test(NAME scheduler_tests COMMAND scheduler_tests)

# backend/analytics/CMakeLists.txt
add_library(aptp_analytics
    src/AnalyticsEngine.cpp
)

target_include_directories(aptp_analytics
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_analytics
    PUBLIC
    aptp_core
    aptp_assessment
    nlohmann_json::nlohmann_json
)

# Tests
add_executable(analytics_tests
    test/AnalyticsEngineTest.cpp
)

target_link_libraries(analytics_tests
    PRIVATE
    aptp_analytics
    GTest::GTest
    GTest::Main
)

add_test(NAME analytics_tests COMMAND analytics_tests)

# backend/integration/CMakeLists.txt
add_library(aptp_integration
    src/SimulatorDataProcessor.cpp
)

target_include_directories(aptp_integration
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_integration
    PUBLIC
    aptp_core
    nlohmann_json::nlohmann_json
)

# Tests
add_executable(integration_tests
    test/SimulatorDataProcessorTest.cpp
)

target_link_libraries(integration_tests
    PRIVATE
    aptp_integration
    GTest::GTest
    GTest::Main
)

add_test(NAME integration_tests COMMAND integration_tests)

# backend/security/CMakeLists.txt
add_library(aptp_security
    src/SecurityManager.cpp
)

target_include_directories(aptp_security
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_security
    PUBLIC
    aptp_core
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
)

# Tests
add_executable(security_tests
    test/SecurityManagerTest.cpp
)

target_link_libraries(security_tests
    PRIVATE
    aptp_security
    GTest::GTest
    GTest::Main
)

add_test(NAME security_tests COMMAND security_tests)

# backend/compliance/CMakeLists.txt
add_library(aptp_compliance
    src/ComplianceManager.cpp
)

target_include_directories(aptp_compliance
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_compliance
    PUBLIC
    aptp_core
    aptp_security
    nlohmann_json::nlohmann_json
)

# Tests
add_executable(compliance_tests
    test/ComplianceManagerTest.cpp
)

target_link_libraries(compliance_tests
    PRIVATE
    aptp_compliance
    GTest::GTest
    GTest::Main
)

add_test(NAME compliance_tests COMMAND compliance_tests)

# backend/api/CMakeLists.txt
add_library(aptp_api
    src/ApiGateway.cpp
    src/controllers/DocumentController.cpp
    src/controllers/SyllabusController.cpp
    src/controllers/AssessmentController.cpp
    src/controllers/UserController.cpp
    src/middleware/JwtMiddleware.cpp
)

target_include_directories(aptp_api
    PUBLIC
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    PRIVATE
    ${CMAKE_CURRENT_SOURCE_DIR}/src
)

target_link_libraries(aptp_api
    PUBLIC
    aptp_core
    aptp_document
    aptp_syllabus
    aptp_assessment
    aptp_user-management
    aptp_scheduler
    aptp_analytics
    aptp_compliance
    aptp_security
    Drogon::Drogon
    nlohmann_json::nlohmann_json
)

# Tests
add_executable(api_tests
    test/ApiGatewayTest.cpp
    test/controllers/DocumentControllerTest.cpp
    test/controllers/SyllabusControllerTest.cpp
    test/controllers/AssessmentControllerTest.cpp
    test/controllers/UserControllerTest.cpp
    test/middleware/JwtMiddlewareTest.cpp
)

target_link_libraries(api_tests
    PRIVATE
    aptp_api
    GTest::GTest
    GTest::Main
)

add_test(NAME api_tests COMMAND api_tests)

# backend/main.cpp
#include <drogon/drogon.h>
#include "core/include/ConfigurationManager.h"
#include "core/include/Logger.h"
#include "api/include/ApiGateway.h"

int main() {
    try {
        // Initialize logger
        APTP::Core::Logger::getInstance().info("Starting Advanced Pilot Training Platform");
        
        // Load configuration
        auto& config = APTP::Core::ConfigurationManager::getInstance();
        config.loadFromEnvironment();
        config.loadFromFile("config/aptp.json");
        
        // Initialize API gateway
        APTP::API::ApiConfig apiConfig;
        apiConfig.host = config.getOrDefault<std::string>("api_host", "0.0.0.0");
        apiConfig.port = config.getOrDefault<uint16_t>("api_port", 8080);
        apiConfig.threadNum = config.getOrDefault<uint32_t>("api_thread_num", 16);
        apiConfig.jwtSecret = config.getOrDefault<std::string>("jwt_secret", "");
        apiConfig.enableSSL = config.getOrDefault<bool>("api_enable_ssl", false);
        apiConfig.sslCertPath = config.getOrDefault<std::string>("api_ssl_cert", "");
        apiConfig.sslKeyPath = config.getOrDefault<std::string>("api_ssl_key", "");
        
        APTP::API::ApiGateway::getInstance().initialize(apiConfig);
        
        // Start API server
        APTP::API::ApiGateway::getInstance().start();
        
        // Keep the main thread running (Drogon runs in separate threads)
        APTP::Core::Logger::getInstance().info("Server started successfully");
        
        // Wait for signal to exit
        drogon::app().waitForShutdown();
        
        return 0;
    } catch (const std::exception& e) {
        std::cerr << "Error starting server: " << e.what() << std::endl;
        return 1;
    }
}

global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']
  
  - job_name: 'core-platform-service'
    scrape_interval: 10s
    static_configs:
    - targets: ['core-platform-service:9100']
  
  - job_name: 'data-acquisition-service'
    scrape_interval: 10s
    static_configs:
    - targets: ['data-acquisition-service:9101']
  
  - job_name: 'etr-service'
    scrape_interval: 10s
    static_configs:
    - targets: ['etr-service:9103']
  
  - job_name: 'ai-analytics-service'
    scrape_interval: 10s
    static_configs:
    - targets: ['ai-analytics-service:9104']
  
  - job_name: 'document-service'
    scrape_interval: 10s
    static_configs:
    - targets: ['document-service:9105']
  
  - job_name: 'syllabus-generator-service'
    scrape_interval: 10s
    static_configs:
    - targets: ['syllabus-generator-service:9106']
  
  - job_name: 'assessment-service'
    scrape_interval: 10s
    static_configs:
    - targets: ['assessment-service:9107']
  
  - job_name: 'api-gateway'
    scrape_interval: 10s
    static_configs:
    - targets: ['api-gateway:9108']
  
  - job_name: 'node-exporter'
    static_configs:
    - targets: ['node-exporter:9100']
  
  - job_name: 'postgres-exporter'
    static_configs:
    - targets: ['postgres-exporter:9187']
#!/usr/bin/env python3
"""
NLP Service for Advanced Pilot Training Platform
Provides document intelligence capabilities including classification,
knowledge extraction, language detection, and translation
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional

from flask import Flask, request, jsonify
import spacy
import networkx as nx
from transformers import AutoTokenizer, AutoModel, pipeline
from langdetect import detect_langs
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Load models
nlp = spacy.load("en_core_web_trf")
tokenizer = AutoTokenizer.from_pretrained("aviation-bert-base")
model = AutoModel.from_pretrained("aviation-bert-base")
translator = pipeline("translation", model="Helsinki-NLP/opus-mt-en-ROMANCE")

# Load regulatory requirements
def load_regulatory_requirements(regulation_type: str) -> Dict[str, Any]:
    """Load regulatory requirements from JSON files"""
    try:
        with open(f"./data/regulations/{regulation_type.lower()}_requirements.json", "r") as f:
            return json.load(f)
    except FileNotFoundError:
        logger.warning(f"Requirements for {regulation_type} not found")
        return {}

# Document classification model
class DocumentClassifier:
    def __init__(self):
        self.vectorizer = TfidfVectorizer(max_features=5000)
        
        # Load training data
        self.training_data = pd.read_csv("./data/document_classes.csv")
        
        # Prepare model
        self.document_vectors = self.vectorizer.fit_transform(self.training_data["content"])
        self.document_classes = self.training_data["class"].tolist()
        
    def classify(self, text: str) -> Dict[str, Any]:
        """Classify document based on content"""
        # Vectorize the input text
        text_vector = self.vectorizer.transform([text])
        
        # Calculate similarity to each document in the training set
        similarities = cosine_similarity(text_vector, self.document_vectors).flatten()
        
        # Get top 3 most similar documents
        top_indices = similarities.argsort()[-3:][::-1]
        top_classes = [self.document_classes[i] for i in top_indices]
        top_scores = [float(similarities[i]) for i in top_indices]
        
        # Determine the most likely class
        class_votes = {}
        for cls, score in zip(top_classes, top_scores):
            class_votes[cls] = class_votes.get(cls, 0) + score
        
        best_class = max(class_votes.items(), key=lambda x: x[1])[0]
        
        return {
            "document_type": best_class,
            "confidence": float(class_votes[best_class] / sum(top_scores)),
            "alternative_classes": [
                {"class": cls, "score": float(score)} 
                for cls, score in zip(top_classes, top_scores) if cls != best_class
            ]
        }

# Knowledge Graph Builder
class KnowledgeGraphBuilder:
    def __init__(self):
        self.graph = nx.DiGraph()
        
    def extract_entities(self, text: str) -> List[Dict[str, Any]]:
        """Extract entities from text using spaCy"""
        doc = nlp(text)
        entities = []
        
        for ent in doc.ents:
            entities.append({
                "text": ent.text,
                "label": ent.label_,
                "start": ent.start_char,
                "end": ent.end_char
            })
        
        # Add custom aviation-specific entity extraction
        # This would be expanded with domain-specific rules
        aviation_terms = [
            "approach", "takeoff", "landing", "altitude", "checklist",
            "procedure", "maneuver", "airspeed", "flap", "gear"
        ]
        
        for term in aviation_terms:
            if term in text.lower():
                entities.append({
                    "text": term,
                    "label": "AVIATION_TERM",
                    "start": text.lower().find(term),
                    "end": text.lower().find(term) + len(term)
                })
        
        return entities
    
    def build_graph_from_documents(self, documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Build knowledge graph from multiple documents"""
        self.graph = nx.DiGraph()
        
        # Process each document
        for doc in documents:
            doc_id = doc.get("document_id", "unknown")
            doc_type = doc.get("document_type", "unknown")
            content = doc.get("content", "")
            
            # Create document node
            self.graph.add_node(doc_id, type="document", doc_type=doc_type)
            
            # Extract entities and relationships
            entities = self.extract_entities(content)
            
            # Add entities to graph
            for entity in entities:
                entity_id = f"{entity['text']}_{entity['label']}"
                
                # Add entity if not exists
                if not self.graph.has_node(entity_id):
                    self.graph.add_node(entity_id, 
                                        type="entity", 
                                        label=entity["label"],
                                        text=entity["text"])
                
                # Add relationship between document and entity
                self.graph.add_edge(doc_id, entity_id, type="contains")
            
            # Extract sections/headers using regex or other methods
            # (simplified for this example)
            sections = content.split("\n\n")
            for i, section in enumerate(sections):
                if len(section.strip()) > 0:
                    section_id = f"{doc_id}_section_{i}"
                    self.graph.add_node(section_id, type="section", content=section[:100])
                    self.graph.add_edge(doc_id, section_id, type="has_section")
        
        # Build cross-document relationships
        self._build_cross_document_relationships()
        
        # Convert graph to serializable format
        return self._serialize_graph()
    
    def _build_cross_document_relationships(self):
        """Find relationships between entities across documents"""
        # Get all entity nodes
        entity_nodes = [n for n, d in self.graph.nodes(data=True) if d.get("type") == "entity"]
        
        # Group entities by text
        entity_groups = {}
        for entity in entity_nodes:
            entity_data = self.graph.nodes[entity]
            text = entity_data.get("text", "").lower()
            
            if text not in entity_groups:
                entity_groups[text] = []
            
            entity_groups[text].append(entity)
        
        # Connect same entities across documents
        for text, entities in entity_groups.items():
            if len(entities) > 1:
                for i in range(len(entities)):
                    for j in range(i+1, len(entities)):
                        self.graph.add_edge(entities[i], entities[j], type="same_as")
        
        # Add more sophisticated relationship detection here
        # For example, connecting related procedures, detecting prerequisites, etc.
    
    def _serialize_graph(self) -> Dict[str, Any]:
        """Convert networkx graph to serializable format"""
        nodes = []
        for node_id, data in self.graph.nodes(data=True):
            node_data = data.copy()
            node_data["id"] = node_id
            nodes.append(node_data)
        
        edges = []
        for source, target, data in self.graph.edges(data=True):
            edge_data = data.copy()
            edge_data["source"] = source
            edge_data["target"] = target
            edges.append(edge_data)
        
        return {
            "nodes": nodes,
            "edges": edges
        }

# Initialize components
document_classifier = DocumentClassifier()
knowledge_graph_builder = KnowledgeGraphBuilder()

# API endpoints
@app.route("/classify", methods=["POST"])
def classify_document():
    """Classify document based on content"""
    data = request.json
    if not data or "content" not in data:
        return jsonify({"error": "Missing content field"}), 400
    
    result = document_classifier.classify(data["content"])
    return jsonify(result)

@app.route("/extract_structure", methods=["POST"])
def extract_structure():
    """Extract structured content from document"""
    data = request.json
    if not data or "content" not in data:
        return jsonify({"error": "Missing content field"}), 400
    
    config_path = data.get("config_path", "default.config")
    
    # Process document based on content and config
    # This would be expanded with specific parsing rules
    doc = nlp(data["content"])
    
    # Extract sections, headers, tables, etc.
    sections = []
    current_section = None
    
    for para in data["content"].split("\n\n"):
        if not para.strip():
            continue
            
        # Simple heuristic for header detection
        if len(para.strip()) < 100 and para.isupper() or para.endswith(":"):
            # Looks like a header
            current_section = {
                "title": para.strip(),
                "content": "",
                "subsections": []
            }
            sections.append(current_section)
        elif current_section:
            current_section["content"] += para + "\n\n"
        else:
            # Text before any header
            current_section = {
                "title": "Introduction",
                "content": para + "\n\n",
                "subsections": []
            }
            sections.append(current_section)
    
    # Extract key-value pairs
    key_value_pairs = {}
    for ent in doc.ents:
        if ent.label_ in ["DATE", "TIME", "CARDINAL", "QUANTITY", "PERCENT"]:
            # Look for patterns like "Key: Value" or "Key - Value"
            context = data["content"][max(0, ent.start_char - 50):ent.start_char]
            for delimiter in [":", "-", "="]:
                if delimiter in context:
                    key = context.split(delimiter)[-1].strip()
                    key_value_pairs[key] = ent.text
    
    return jsonify({
        "sections": sections,
        "key_value_pairs": key_value_pairs,
        "entity_count": len(doc.ents)
    })

@app.route("/detect_language", methods=["POST"])
def detect_language():
    """Detect document language"""
    data = request.json
    if not data or "content" not in data:
        return jsonify({"error": "Missing content field"}), 400
    
    try:
        langs = detect_langs(data["content"])
        languages = [{"lang": l.lang, "prob": l.prob} for l in langs]
        
        return jsonify({
            "languages": [l["lang"] for l in languages],
            "probabilities": languages
        })
    except Exception as e:
        logger.error(f"Language detection error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/translate", methods=["POST"])
def translate_content():
    """Translate content to target language"""
    data = request.json
    if not data or "content" not in data or "target_language" not in data:
        return jsonify({"error": "Missing required fields"}), 400
    
    try:
        # This is simplified - in practice, you'd need more sophisticated translation
        result = translator(data["content"], target_language=data["target_language"])
        
        return jsonify({
            "translated_text": result[0]["translation_text"],
            "source_language": "auto-detected",
            "target_language": data["target_language"]
        })
    except Exception as e:
        logger.error(f"Translation error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/build_knowledge_graph", methods=["POST"])
def build_knowledge_graph():
    """Build knowledge graph from documents"""
    data = request.json
    if not data or "documents" not in data:
        return jsonify({"error": "Missing documents field"}), 400
    
    try:
        graph = knowledge_graph_builder.build_graph_from_documents(data["documents"])
        return jsonify(graph)
    except Exception as e:
        logger.error(f"Knowledge graph error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/validate_compliance", methods=["POST"])
def validate_compliance():
    """Validate document compliance against regulations"""
    data = request.json
    if not data or "document" not in data or "regulation_type" not in data:
        return jsonify({"error": "Missing required fields"}), 400
    
    try:
        # Load regulation requirements
        regulations = load_regulatory_requirements(data["regulation_type"])
        
        if not regulations:
            return jsonify({
                "is_compliant": False,
                "error": f"No regulations found for {data['regulation_type']}"
            }), 404
        
        # Check document against requirements
        document = data["document"]
        missing_items = []
        
        # This is a simplified check - real implementation would be more sophisticated
        for req in regulations.get("requirements", []):
            req_name = req.get("name", "")
            req_pattern = req.get("pattern", "").lower()
            
            # Check if requirement is met in the document
            content = document.get("content", "").lower()
            if req_pattern and req_pattern not in content:
                missing_items.append({
                    "requirement": req_name,
                    "description": req.get("description", ""),
                    "importance": req.get("importance", "medium")
                })
        
        is_compliant = len(missing_items) == 0
        
        return jsonify({
            "is_compliant": is_compliant,
            "regulation_type": data["regulation_type"],
            "missing_items": missing_items,
            "requirements_checked": len(regulations.get("requirements", []))
        })
    except Exception as e:
        logger.error(f"Compliance validation error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/identify_missing_items", methods=["POST"])
def identify_missing_items():
    """Identify missing items in document against regulations"""
    # Similar to validate_compliance but with more detail on missing items
    data = request.json
    if not data or "document" not in data or "regulation_type" not in data:
        return jsonify({"error": "Missing required fields"}), 400
    
    try:
        # Load regulation requirements
        regulations = load_regulatory_requirements(data["regulation_type"])
        
        if not regulations:
            return jsonify({
                "error": f"No regulations found for {data['regulation_type']}"
            }), 404
        
        # Check document against requirements
        document = data["document"]
        missing_items = []
        
        # This is a simplified check - real implementation would be more sophisticated
        for req in regulations.get("requirements", []):
            req_name = req.get("name", "")
            req_pattern = req.get("pattern", "").lower()
            
            # Check if requirement is met in the document
            content = document.get("content", "").lower()
            if req_pattern and req_pattern not in content:
                # Add suggested content for the missing item
                suggestion = req.get("suggestion", "")
                if not suggestion:
                    # Generate suggestion based on requirement
                    suggestion = f"Include information about {req_name}"
                
                missing_items.append({
                    "requirement": req_name,
                    "description": req.get("description", ""),
                    "importance": req.get("importance", "medium"),
                    "suggestion": suggestion,
                    "reference": req.get("reference", "")
                })
        
        return jsonify({
            "missing_items": missing_items,
            "requirements_checked": len(regulations.get("requirements", []))
        })
    except Exception as e:
        logger.error(f"Missing items identification error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/standardize_terminology", methods=["POST"])
def standardize_terminology():
    """Standardize terminology in document content"""
    data = request.json
    if not data or "content" not in data:
        return jsonify({"error": "Missing content field"}), 400
    
    try:
        # Load terminology glossary
        glossary_file = data.get("glossary", "aviation_glossary.json")
        with open(f"./data/glossaries/{glossary_file}", "r") as f:
            glossary = json.load(f)
        
        content = data["content"]
        replacements = []
        
        # Replace non-standard terms with standard ones
        for term, standard_term in glossary.get("terms", {}).items():
            if term.lower() in content.lower() and term.lower() != standard_term.lower():
                # Replace term with standard term
                # For simplicity, we're doing case-insensitive replacement
                # A more sophisticated implementation would preserve case
                new_content = content
                instances = []
                
                # Find all instances (case-insensitive)
                start_pos = 0
                while True:
                    pos = new_content.lower().find(term.lower(), start_pos)
                    if pos == -1:
                        break
                    
                    instances.append({
                        "position": pos,
                        "original": new_content[pos:pos+len(term)],
                        "replacement": standard_term
                    })
                    
                    start_pos = pos + len(term)
                
                # Replace instances with standard term
                for i, instance in enumerate(reversed(instances)):
                    pos = instance["position"]
                    original = instance["original"]
                    replacement = instance["replacement"]
                    
                    new_content = new_content[:pos] + replacement + new_content[pos+len(original):]
                    
                    replacements.append({
                        "original": original,
                        "standardized": replacement,
                        "position": pos
                    })
                
                content = new_content
        
        # Generate glossary of standardized terms used
        used_terms = {}
        for replacement in replacements:
            standard_term = replacement["standardized"]
            if standard_term not in used_terms:
                definition = glossary.get("definitions", {}).get(standard_term, "")
                used_terms[standard_term] = definition
        
        return jsonify({
            "standardized_content": content,
            "replacements": replacements,
            "term_count": len(replacements),
            "glossary": used_terms
        })
    except Exception as e:
        logger.error(f"Terminology standardization error: {str(e)}")
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    # Starting the Flask application
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)

# Advanced Pilot Training Platform

A next-generation flight training management system that integrates advanced scheduling, syllabus building, document management, adaptive assessments, real-time analytics, immersive 3D/AR visualizations, and enhanced collaboration tools.

## Architecture Overview

The Advanced Pilot Training Platform is built as a set of microservices using Modern C++ (C++17/20) with the Drogon framework for the backend APIs and Python for AI/ML tasks. The frontend is built using Next.js and React with TypeScript.

### Backend Components

The backend is organized into the following modules:

- **Core**: Shared utilities for configuration, logging, error handling, and database access
- **Document**: Document processing pipeline and AI-based content extraction
- **Syllabus**: Syllabus generation engine and training structure creation
- **Assessment**: Competency-based assessment, grading, and biometric integrations
- **User Management**: Authentication, digital logbooks, and role-based dashboards
- **Scheduler**: AI-driven scheduling and resource optimization module
- **Analytics**: Real-time performance analytics and predictive insights
- **Compliance**: Regulatory compliance engine, audit trails, and document verification
- **Collaboration**: Backend support for virtual workspaces and messaging integration
- **Visualization**: Data services for 3D/AR knowledge maps and simulation visualizers
- **Integration**: Connectors for simulators, biometric devices, enterprise systems, and calendars
- **Security**: Zero-trust security, blockchain audit trails, and ethical AI governance
- **AI Modules**: Python-based AI/ML modules for document understanding, performance prediction, and research assistance

### Key Features

- **Intelligent Document Processing**: Extract structured data from aviation training documents
- **Advanced Syllabus Builder**: Create and manage training syllabi with regulatory mapping
- **Competency-Based Assessment**: Digital grading with biometric data integration
- **AI-Driven Scheduling**: Optimize resource allocation and training schedules
- **Real-Time Analytics**: Monitor training effectiveness and predict trainee outcomes
- **Regulatory Compliance**: Automated mapping to FAA, EASA, ICAO regulations
- **Collaboration Tools**: Smart workspaces with co-editing and instructor-trainee communication

## Getting Started

### Prerequisites

- Docker and Docker Compose
- CMake 3.15+
- C++17 compatible compiler
- Python 3.8+
- PostgreSQL 13+ with TimescaleDB extension
- Redis

### Installation with Docker

1. Clone the repository:

```bash
git clone https://github.com/your-organization/advanced-pilot-training-platform.git
cd advanced-pilot-training-platform
```

2. Build and start the containers:

```bash
docker-compose up -d
```

3. The application will be available at http://localhost:8080

### Manual Installation

1. Build the C++ components:

```bash
mkdir build && cd build
cmake ..
make
```

2. Set up the Python environment:

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. Configure the database:

```bash
psql -U postgres -f sql/init.sql
```

4. Run the server:

```bash
./aptp_server
```

## Development

### Project Structure

```
/advanced-pilot-training-platform
 backend
    core                # Shared utilities
    document            # Document processing pipeline
    syllabus            # Syllabus generation engine
    assessment          # Competency-based assessment
    user-management     # Authentication and user management
    scheduler           # AI-driven scheduling
    analytics           # Real-time analytics
    compliance          # Regulatory compliance engine
    collaboration       # Collaboration tools backend
    visualization       # 3D/AR visualization services
    integration         # External system connectors
    security            # Security and authentication
    api                 # API gateway and endpoints
    ai-modules          # Python AI/ML modules
        document-understanding
        performance-prediction
        automation-workflows
        research-assistant
 frontend                # React/Next.js frontend
 docs                    # Documentation
 tests                   # Integration and system tests
 docker                  # Docker configuration
```

### Building and Testing

The project uses CMake for building and Google Test for C++ unit testing:

```bash
# Build the project
cmake -B build
cmake --build build

# Run the tests
cd build
ctest
```

Python tests use pytest:

```bash
cd backend/ai-modules
python -m pytest
```

## API Documentation

The API documentation is available at `/api/docs` when the server is running. The platform uses OpenAPI/Swagger for API documentation.

## Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature-name`
3. Commit your changes: `git commit -am 'Add new feature'`
4. Push to the branch: `git push origin feature/your-feature-name`
5. Submit a pull request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Drogon Framework
- TimescaleDB
- React and Next.js
- Transformers by Hugging Face
- scikit-learn
- TensorFlow/PyTorch

# Advanced Pilot Training Platform - Backend Implementation Guide

This guide provides an overview of the backend services implementation for the Advanced Pilot Training Platform.

## Architecture Overview

The Advanced Pilot Training Platform utilizes a microservices architecture with the following components:

1. **API Gateway** - Entry point for all client requests with authentication, routing, and rate limiting
2. **Document Intelligence Service** - Processes training documents and extracts structured content
3. **Syllabus Template System** - Manages training syllabus creation, versioning, and compliance checking
4. **Predictive Analytics Engine** - Provides AI-driven training analytics and adaptive learning
5. **Audit & Compliance Service** - Ensures regulatory compliance and maintains audit trails
6. **Security & Authentication Service** - Handles user authentication, authorization, and data security
7. **Debriefing Session Service** - Manages training session data, annotations, and performance metrics
8. **Administrative Dashboard Service** - Provides management interfaces and statistical reporting
9. **Gamification System API** - Implements gamification elements for training engagement
10. **Community Knowledge Sharing Backend** - Enables collaboration and knowledge sharing

## Technology Stack

- **Programming Languages**:
  - C++ (Drogon framework) for high-performance services
  - Python for AI/ML components

- **Database**: PostgreSQL for persistent storage

- **Caching**: Redis for in-memory caching and rate limiting

- **Search**: Elasticsearch for content search capabilities

- **Monitoring**: Prometheus and Grafana for performance monitoring

- **Deployment**: Docker and Docker Compose for containerization and orchestration

## Service Details

### 1. Document Intelligence Service (C++)

This service is responsible for processing and extracting structured content from training documents.

**Key features**:
- Document classification and parsing
- Knowledge graph construction
- Cross-document reference resolution
- Multi-language document handling
- Document completeness verification

**Endpoints**:
- `POST /api/documents/process` - Process and extract data from documents
- `POST /api/documents/classify` - Classify document type
- `POST /api/documents/knowledge-graph` - Build knowledge graph from documents
- `POST /api/documents/verify-completeness` - Verify document completeness
- `POST /api/documents/resolve-references` - Resolve cross-document references

### 2. Python NLP Service

This Python microservice supports the Document Intelligence Service with natural language processing capabilities.

**Key features**:
- Document classification using ML models
- Entity extraction
- Language detection and translation
- Structured content extraction
- Regulatory compliance validation

**Endpoints**:
- `POST /classify` - Classify document content
- `POST /extract_structure` - Extract structured content
- `POST /detect_language` - Detect document language
- `POST /translate` - Translate content
- `POST /build_knowledge_graph` - Build knowledge graph
- `POST /validate_compliance` - Validate document against regulations

### 3. Syllabus Template System (C++)

This service manages training syllabus templates, customization, and compliance mapping.

**Key features**:
- Syllabus template management
- Regulatory compliance verification
- Versioning with change impact analysis
- Customization with constraint checking
- Comparison between versions

**Endpoints**:
- `GET /api/syllabus/templates` - List available templates
- `GET /api/syllabus/templates/{id}` - Get specific template
- `POST /api/syllabus/templates` - Create new template
- `PUT /api/syllabus/templates/{id}` - Update template
- `POST /api/syllabus/templates/{id}/impact` - Analyze change impact
- `GET /api/syllabus/templates/{id}/versions/compare` - Compare versions

### 4. Predictive Analytics Engine (Python)

This Python service provides advanced analytics and adaptive learning features.

**Key features**:
- Skill decay prediction using Bayesian Knowledge Tracing
- Fatigue risk modeling
- Training effectiveness forecasting
- Performance consistency assessment
- Syllabus optimization recommendations

**Endpoints**:
- `POST /api/predict/skill-decay` - Predict skill degradation
- `POST /api/predict/fatigue-risk` - Assess fatigue risk
- `POST /api/predict/training-effectiveness` - Forecast training effectiveness
- `POST /api/assess/performance-consistency` - Evaluate performance consistency
- `POST /api/optimize/syllabus` - Generate syllabus optimization recommendations

### 5. Audit & Regulatory Compliance Service (C++)

This service ensures regulatory compliance and maintains secure audit trails.

**Key features**:
- Tamper-proof audit logging with blockchain verification
- Regulatory compliance matrices
- Automated compliance change tracking
- Compliance impact analysis
- Comprehensive reporting

**Endpoints**:
- `POST /api/audit/record` - Record audit event
- `POST /api/audit/verify` - Verify audit trail integrity
- `POST /api/audit/query` - Query audit logs
- `POST /api/compliance/check` - Check compliance status
- `POST /api/compliance/impact` - Analyze compliance impact

### 6. Security & Authentication Service (C++)

This service provides authentication, authorization, and data security features.

**Key features**:
- JWT-based authentication
- Role-based access control
- Multi-factor authentication
- Biometric authentication support
- Data encryption
- GDPR compliance tools

**Endpoints**:
- `POST /api/auth/login` - Authenticate user
- `POST /api/auth/refresh` - Refresh access token
- `POST /api/auth/mfa/register` - Register multi-factor authentication
- `POST /api/security/encrypt` - Encrypt sensitive data
- `POST /api/gdpr/request-deletion` - Process GDPR deletion request

### 7. Debriefing & Session Analytics Service (C++)

This service manages training session data and performance analytics.

**Key features**:
- Session recording and playback
- Event and annotation management
- Performance metrics calculation
- Critical event flagging
- Comparative analysis

**Endpoints**:
- `POST /api/debrief/sessions` - Create session
- `POST /api/debrief/sessions/{id}/events` - Add event
- `POST /api/debrief/sessions/{id}/annotations` - Add annotation
- `GET /api/debrief/sessions/{id}/metrics` - Get session metrics
- `POST /api/debrief/sessions/{id}/compare` - Compare with reference session

### 8. Administrative Dashboard Service (C++)

This service provides management interfaces and statistical reporting.

**Key features**:
- Training status monitoring
- Resource utilization tracking
- Instructor performance metrics
- Trainee progress tracking
- KPI dashboards

**Endpoints**:
- `GET /api/admin/training-status` - Get training program status
- `GET /api/admin/resource-utilization` - Get resource usage stats
- `GET /api/admin/instructor-performance` - Get instructor effectiveness metrics
- `GET /api/admin/trainee-progress/{id}` - Get trainee progress details
- `GET /api/admin/kpis` - Get key performance indicators

### 9. Gamification System API (C++)

This service implements gamification elements to increase engagement.

**Key features**:
- Achievement system
- Leaderboards
- Training challenges
- Skill trees
- Streak rewards

**Endpoints**:
- `GET /api/gamification/achievements/{userId}` - Get user achievements
- `GET /api/gamification/leaderboard` - Get leaderboard
- `GET /api/gamification/challenges/{userId}` - Get user challenges
- `POST /api/gamification/skill-tree/{userId}/progress` - Progress skill
- `GET /api/gamification/streaks/{userId}` - Get user streaks

### 10. Community Knowledge Sharing Backend (C++)

This service enables collaboration and knowledge sharing within the platform.

**Key features**:
- Best practices sharing
- Training scenario marketplace
- Discussion forums
- Expert network
- Personalized content recommendations

**Endpoints**:
- `GET /api/community/best-practices` - Get best practices
- `GET /api/community/scenarios` - Get training scenarios
- `GET /api/community/forum/threads` - Get discussion threads
- `GET /api/community/experts` - Get expert network members
- `GET /api/community/recommendations/{userId}` - Get personalized recommendations

### 11. API Gateway Service (C++)

This service acts as the entry point for all client requests, handling routing, authentication, and rate limiting.

**Key features**:
- Request routing to appropriate microservices
- Authentication and authorization
- Rate limiting
- Request/response logging
- Circuit breaker pattern implementation
- Service health monitoring

**Endpoints**:
- `GET /api/health` - Get system health status
- `GET /api/spec` - Get API specifications
- Proxy endpoints for all other services

## Deployment

The platform is deployed using Docker and Docker Compose, with each service running in its own container. The deployment configuration in `docker-compose.yml` includes:

- Service containers for each backend component
- PostgreSQL database
- Redis for caching and rate limiting
- Elasticsearch for search functionality
- Prometheus for monitoring
- Grafana for dashboards

### Deployment Steps

1. Clone the repository:
   ```bash
   git clone https://github.com/your-org/advanced-pilot-training-platform.git
   cd advanced-pilot-training-platform
   ```

2. Create `.env` file with required environment variables:
   ```
   DB_USER=atp_user
   DB_PASSWORD=your_secure_password
   JWT_SECRET=your_jwt_secret_key
   GRAFANA_ADMIN_USER=admin
   GRAFANA_ADMIN_PASSWORD=admin_password
   ```

3. Build and start the services:
   ```bash
   docker-compose build
   docker-compose up -d
   ```

4. Verify deployment:
   ```bash
   docker-compose ps
   curl http://localhost:8000/api/health
   ```

## Development Guide

### Prerequisites

- C++ development environment (C++17 or later)
- Python 3.8 or later
- Drogon framework
- PostgreSQL client libraries
- OpenSSL development libraries

### Building Individual Services

Each service can be built and run independently during development:

```bash
# Example for building Document Intelligence Service
cd document-service
mkdir build && cd build
cmake ..
make
./document_service
```

### Testing

Each service includes unit tests that can be run with:

```bash
cd service-directory/build
make test
```

## Integration with Frontend

The frontend application communicates with the backend via the API Gateway, which routes requests to the appropriate service. All API endpoints follow RESTful conventions and return JSON responses.

See the [Frontend Implementation Guide](../frontend/README.md) for details on integrating with the frontend application.

## Security Considerations

- All communication between services uses TLS encryption
- Sensitive data is encrypted at rest
- JWT tokens with short expiration are used for authentication
- Rate limiting prevents abuse
- Role-based access control restricts permissions
- Audit logging tracks all system activity

## Performance Optimization

- C++ is used for performance-critical services
- Response caching with Redis
- Database query optimization
- Asynchronous processing for long-running tasks
- Horizontal scaling for high-load services

// backend/integration/include/SimulatorDataProcessor.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <atomic>
#include <thread>
#include <functional>
#include <chrono>
#include <deque>
#include <optional>
#include <mutex>
#include <condition_variable>
#include <unordered_map>

#include "core/include/ErrorHandling.h"

// SIMD intrinsics
#include <immintrin.h>

namespace APTP::Integration {

// Struct to represent simulator telemetry data
struct SimulatorTelemetry {
    std::chrono::system_clock::time_point timestamp;
    
    // Basic flight data
    float altitude; // feet
    float airspeed; // knots
    float heading;  // degrees
    float verticalSpeed; // feet per minute
    
    // Aircraft attitude
    float pitch;    // degrees
    float roll;     // degrees
    float yaw;      // degrees
    
    // Control inputs
    float elevatorPosition;   // -1.0 to 1.0
    float aileronPosition;    // -1.0 to 1.0
    float rudderPosition;     // -1.0 to 1.0
    float throttlePosition;   // 0.0 to 1.0
    float flapPosition;       // 0.0 to 1.0
    
    // Engine data
    float engineRPM;
    float engineTemp;
    float fuelFlow;
    
    // Environmental data
    float outsideAirTemp;
    float windSpeed;
    float windDirection;
    
    // Aircraft systems
    float electrical_main_bus_voltage;
    float hydraulic_pressure;
    
    // Navigation data
    double latitude;
    double longitude;
    
    // Additional custom data fields
    std::unordered_map<std::string, float> customFields;
};

// Struct to represent an anomaly detected in telemetry data
struct TelemetryAnomaly {
    std::chrono::system_clock::time_point timestamp;
    std::string parameter;
    float value;
    float expectedValue;
    float deviation;
    std::string severity; // "Low", "Medium", "High", "Critical"
    std::string description;
};

// Enum for data processing algorithm types
enum class DataProcessingAlgorithm {
    RollingAverage,
    KalmanFilter,
    MovingMedian,
    ExponentialSmoothing,
    LowPassFilter,
    CustomAlgorithm
};

// Callback type for telemetry data
using TelemetryCallback = std::function<void(const SimulatorTelemetry&)>;

// Callback type for anomaly detection
using AnomalyCallback = std::function<void(const TelemetryAnomaly&)>;

// Lock-free queue for high-performance telemetry processing
template<typename T, size_t Capacity>
class LockFreeQueue {
public:
    LockFreeQueue() : head_(0), tail_(0) {}
    
    bool push(T item) {
        size_t current_tail = tail_.load(std::memory_order_relaxed);
        size_t next_tail = (current_tail + 1) % Capacity;
        
        if (next_tail == head_.load(std::memory_order_acquire)) {
            // Queue is full
            return false;
        }
        
        data_[current_tail] = std::move(item);
        tail_.store(next_tail, std::memory_order_release);
        return true;
    }
    
    bool pop(T& item) {
        size_t current_head = head_.load(std::memory_order_relaxed);
        
        if (current_head == tail_.load(std::memory_order_acquire)) {
            // Queue is empty
            return false;
        }
        
        item = std::move(data_[current_head]);
        head_.store((current_head + 1) % Capacity, std::memory_order_release);
        return true;
    }
    
    bool isEmpty() const {
        return head_.load(std::memory_order_acquire) == 
               tail_.load(std::memory_order_acquire);
    }
    
    bool isFull() const {
        size_t next_tail = (tail_.load(std::memory_order_acquire) + 1) % Capacity;
        return next_tail == head_.load(std::memory_order_acquire);
    }
    
    size_t size() const {
        size_t head = head_.load(std::memory_order_acquire);
        size_t tail = tail_.load(std::memory_order_acquire);
        
        if (tail >= head) {
            return tail - head;
        } else {
            return Capacity - (head - tail);
        }
    }

private:
    std::array<T, Capacity> data_;
    std::atomic<size_t> head_;
    std::atomic<size_t> tail_;
};

// SimulatorDataProcessor class for handling high-frequency telemetry
class SimulatorDataProcessor {
public:
    SimulatorDataProcessor();
    ~SimulatorDataProcessor();
    
    // Initialize the processor
    APTP::Core::Result<void> initialize(
        const std::string& simulatorType,
        const std::string& connectionSettings);
    
    // Start processing telemetry
    APTP::Core::Result<void> start();
    
    // Stop processing telemetry
    APTP::Core::Result<void> stop();
    
    // Push telemetry data to the processor
    APTP::Core::Result<void> pushTelemetry(const SimulatorTelemetry& telemetry);
    
    // Get latest telemetry data
    APTP::Core::Result<SimulatorTelemetry> getLatestTelemetry();
    
    // Get historical telemetry for a specific time range
    APTP::Core::Result<std::vector<SimulatorTelemetry>> getHistoricalTelemetry(
        const std::chrono::system_clock::time_point& start,
        const std::chrono::system_clock::time_point& end,
        size_t maxSamples = 0);
    
    // Register callback for new telemetry data
    void registerTelemetryCallback(TelemetryCallback callback);
    
    // Register callback for anomaly detection
    void registerAnomalyCallback(AnomalyCallback callback);
    
    // Configure telemetry processing
    void setProcessingAlgorithm(DataProcessingAlgorithm algorithm);
    void setAnomalyDetectionThreshold(float threshold);
    void setProcessingInterval(std::chrono::milliseconds interval);
    
    // Set parameters for anomaly detection
    void configureAnomalyDetection(
        const std::string& parameter,
        float minValue,
        float maxValue,
        float deviationThreshold);
    
    // Enable/disable SIMD optimizations
    void enableSIMD(bool enable);
    
    // Get processing statistics
    double getAverageProcessingTime() const;
    size_t getProcessedSamplesCount() const;
    size_t getDroppedSamplesCount() const;
    double getSamplesPerSecond() const;

private:
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

// Time series data storage optimized for high-frequency telemetry
class TimeSeriesStore {
public:
    TimeSeriesStore(size_t initialCapacity = 1000000);
    ~TimeSeriesStore();
    
    // Add telemetry to the store
    void addTelemetry(const SimulatorTelemetry& telemetry);
    
    // Query telemetry for a time range
    std::vector<SimulatorTelemetry> queryTimeRange(
        const std::chrono::system_clock::time_point& start,
        const std::chrono::system_clock::time_point& end,
        size_t maxSamples = 0);
    
    // Get latest telemetry
    std::optional<SimulatorTelemetry> getLatest();
    
    // Calculate aggregated values for a parameter over a time range
    struct AggregatedValues {
        float min;
        float max;
        float avg;
        float median;
        float stdDev;
    };
    
    AggregatedValues calculateAggregates(
        const std::string& parameter,
        const std::chrono::system_clock::time_point& start,
        const std::chrono::system_clock::time_point& end);
    
    // Clear old data beyond a certain age
    void pruneData(std::chrono::hours maxAge);
    
    // Get storage statistics
    size_t size() const;
    size_t capacity() const;
    std::chrono::system_clock::time_point oldestTimestamp() const;
    std::chrono::system_clock::time_point newestTimestamp() const;

private:
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Integration

// backend/integration/src/SimulatorDataProcessor.cpp (partial implementation)
#include "SimulatorDataProcessor.h"
#include "core/include/Logger.h"
#include <algorithm>
#include <numeric>

namespace APTP::Integration {

// Implementation for SimulatorDataProcessor
struct SimulatorDataProcessor::Impl {
    // Constants
    static constexpr size_t QUEUE_CAPACITY = 10000; // Size of the lock-free queue
    
    // State variables
    std::atomic<bool> running{false};
    std::string simulatorType;
    std::string connectionSettings;
    
    // Processing configuration
    DataProcessingAlgorithm algorithm{DataProcessingAlgorithm::KalmanFilter};
    float anomalyThreshold{3.0f}; // Standard deviations
    std::chrono::milliseconds processingInterval{1}; // 1ms default for 1000Hz
    bool simdEnabled{true};
    
    // Telemetry data queues and buffers
    LockFreeQueue<SimulatorTelemetry, QUEUE_CAPACITY> inputQueue;
    SimulatorTelemetry latestTelemetry{};
    std::mutex latestTelemetryMutex;
    
    // Historical data storage
    TimeSeriesStore timeSeriesStore;
    
    // Processing thread
    std::thread processingThread;
    
    // Callbacks
    std::vector<TelemetryCallback> telemetryCallbacks;
    std::vector<AnomalyCallback> anomalyCallbacks;
    std::mutex callbacksMutex;
    
    // Anomaly detection configuration
    struct ParameterConfig {
        float minValue;
        float maxValue;
        float deviationThreshold;
    };
    std::unordered_map<std::string, ParameterConfig> parameterConfigs;
    std::mutex parameterConfigsMutex;
    
    // Statistics
    std::atomic<size_t> processedSamplesCount{0};
    std::atomic<size_t> droppedSamplesCount{0};
    std::atomic<double> totalProcessingTime{0.0};
    std::atomic<double> samplesPerSecond{0.0};
    std::chrono::system_clock::time_point lastStatisticsUpdate;
    
    // SIMD buffer for batch processing
    static constexpr size_t SIMD_BATCH_SIZE = 8; // 8 floats for AVX
    alignas(32) float simdBuffer[SIMD_BATCH_SIZE];
    
    // Process telemetry data
    void processTelemetry() {
        using namespace std::chrono;
        
        APTP::Core::Logger::getInstance().info("Starting telemetry processing thread");
        
        // Processing statistics
        size_t batchCount = 0;
        auto lastStatisticsTime = system_clock::now();
        
        while (running.load(std::memory_order_acquire)) {
            auto startTime = high_resolution_clock::now();
            
            // Process available telemetry data
            SimulatorTelemetry telemetry;
            bool processedAny = false;
            
            // Process up to a batch of data
            for (size_t i = 0; i < SIMD_BATCH_SIZE && inputQueue.pop(telemetry); ++i) {
                processedAny = true;
                
                // Apply data processing algorithm
                applyProcessingAlgorithm(telemetry);
                
                // Check for anomalies
                detectAnomalies(telemetry);
                
                // Store the telemetry
                {
                    std::lock_guard<std::mutex> lock(latestTelemetryMutex);
                    latestTelemetry = telemetry;
                }
                
                // Add to time series store
                timeSeriesStore.addTelemetry(telemetry);
                
                // Notify callbacks
                notifyTelemetryCallbacks(telemetry);
                
                // Update statistics
                processedSamplesCount.fetch_add(1, std::memory_order_relaxed);
            }
            
            auto endTime = high_resolution_clock::now();
            
            // Update statistics
            if (processedAny) {
                double processingTime = duration_cast<nanoseconds>(endTime - startTime).count() / 1e9;
                totalProcessingTime.fetch_add(processingTime, std::memory_order_relaxed);
                
                // Update samples per second every 100 batches
                if (++batchCount >= 100) {
                    auto now = system_clock::now();
                    double elapsedSeconds = duration_cast<nanoseconds>(now - lastStatisticsTime).count() / 1e9;
                    size_t samples = processedSamplesCount.load(std::memory_order_relaxed);
                    
                    if (elapsedSeconds > 0) {
                        samplesPerSecond.store(samples / elapsedSeconds, std::memory_order_relaxed);
                    }
                    
                    lastStatisticsTime = now;
                    batchCount = 0;
                }
            }
            
            // Sleep for the configured interval if we didn't process any data
            if (!processedAny) {
                std::this_thread::sleep_for(processingInterval);
            }
        }
        
        APTP::Core::Logger::getInstance().info("Telemetry processing thread stopped");
    }
    
    // Apply the configured processing algorithm to telemetry data
    void applyProcessingAlgorithm(SimulatorTelemetry& telemetry) {
        switch (algorithm) {
            case DataProcessingAlgorithm::KalmanFilter:
                applyKalmanFilter(telemetry);
                break;
            case DataProcessingAlgorithm::RollingAverage:
                applyRollingAverage(telemetry);
                break;
            case DataProcessingAlgorithm::MovingMedian:
                applyMovingMedian(telemetry);
                break;
            case DataProcessingAlgorithm::ExponentialSmoothing:
                applyExponentialSmoothing(telemetry);
                break;
            case DataProcessingAlgorithm::LowPassFilter:
                applyLowPassFilter(telemetry);
                break;
            case DataProcessingAlgorithm::CustomAlgorithm:
                applyCustomAlgorithm(telemetry);
                break;
        }
    }
    
    // Apply Kalman filter to telemetry data
    void applyKalmanFilter(SimulatorTelemetry& telemetry) {
        // This is a simplified implementation
        // A real implementation would use a proper Kalman filter
        
        // SIMD optimization for batch processing of float fields
        if (simdEnabled) {
            // Use AVX instructions for SIMD processing
            // This is a simplified example
            
            // Load values into SIMD buffer
            simdBuffer[0] = telemetry.altitude;
            simdBuffer[1] = telemetry.airspeed;
            simdBuffer[2] = telemetry.heading;
            simdBuffer[3] = telemetry.verticalSpeed;
            simdBuffer[4] = telemetry.pitch;
            simdBuffer[5] = telemetry.roll;
            simdBuffer[6] = telemetry.yaw;
            simdBuffer[7] = telemetry.throttlePosition;
            
            // Load values into AVX register
            __m256 values = _mm256_load_ps(simdBuffer);
            
            // Apply a simple low-pass filter as an example
            // In a real implementation, this would be a proper Kalman filter
            static __m256 prevValues = _mm256_setzero_ps();
            static const __m256 alpha = _mm256_set1_ps(0.2f);
            
            // Filter: new = (1-alpha)*prev + alpha*current
            __m256 oneMinusAlpha = _mm256_set1_ps(1.0f);
            oneMinusAlpha = _mm256_sub_ps(oneMinusAlpha, alpha);
            
            __m256 filteredValues = _mm256_add_ps(
                _mm256_mul_ps(oneMinusAlpha, prevValues),
                _mm256_mul_ps(alpha, values)
            );
            
            // Store back to buffer
            _mm256_store_ps(simdBuffer, filteredValues);
            prevValues = filteredValues;
            
            // Update telemetry with filtered values
            telemetry.altitude = simdBuffer[0];
            telemetry.airspeed = simdBuffer[1];
            telemetry.heading = simdBuffer[2];
            telemetry.verticalSpeed = simdBuffer[3];
            telemetry.pitch = simdBuffer[4];
            telemetry.roll = simdBuffer[5];
            telemetry.yaw = simdBuffer[6];
            telemetry.throttlePosition = simdBuffer[7];
        } 
        else {
            // Non-SIMD implementation
            static const float alpha = 0.2f;
            static float prevAltitude = 0.0f;
            static float prevAirspeed = 0.0f;
            // ... other previous values
            
            // Simple low-pass filter as an example
            float filteredAltitude = (1.0f - alpha) * prevAltitude + alpha * telemetry.altitude;
            float filteredAirspeed = (1.0f - alpha) * prevAirspeed + alpha * telemetry.airspeed;
            // ... filter other values
            
            prevAltitude = filteredAltitude;
            prevAirspeed = filteredAirspeed;
            // ... update other previous values
            
            telemetry.altitude = filteredAltitude;
            telemetry.airspeed = filteredAirspeed;
            // ... update other telemetry fields
        }
    }
    
    // Apply rolling average filter
    void applyRollingAverage(SimulatorTelemetry& telemetry) {
        // Implementation for rolling average
        // Similar pattern to Kalman filter but using a different algorithm
    }
    
    // Apply moving median filter
    void applyMovingMedian(SimulatorTelemetry& telemetry) {
        // Implementation for moving median
    }
    
    // Apply exponential smoothing
    void applyExponentialSmoothing(SimulatorTelemetry& telemetry) {
        // Implementation for exponential smoothing
    }
    
    // Apply low-pass filter
    void applyLowPassFilter(SimulatorTelemetry& telemetry) {
        // Implementation for low-pass filter
    }
    
    // Apply custom algorithm
    void applyCustomAlgorithm(SimulatorTelemetry& telemetry) {
        // Implementation for custom algorithm
    }
    
    // Detect anomalies in telemetry data
    void detectAnomalies(const SimulatorTelemetry& telemetry) {
        std::lock_guard<std::mutex> lock(parameterConfigsMutex);
        
        // Check each configured parameter
        for (const auto& [parameter, config] : parameterConfigs) {
            float value = 0.0f;
            
            // Get the parameter value from telemetry
            if (parameter == "altitude") value = telemetry.altitude;
            else if (parameter == "airspeed") value = telemetry.airspeed;
            else if (parameter == "heading") value = telemetry.heading;
            else if (parameter == "verticalSpeed") value = telemetry.verticalSpeed;
            else if (parameter == "pitch") value = telemetry.pitch;
            else if (parameter == "roll") value = telemetry.roll;
            else if (parameter == "yaw") value = telemetry.yaw;
            else if (parameter == "throttlePosition") value = telemetry.throttlePosition;
            // ... check other parameters
            else {
                // Check custom fields
                auto it = telemetry.customFields.find(parameter);
                if (it != telemetry.customFields.end()) {
                    value = it->second;
                } else {
                    // Parameter not found in telemetry
                    continue;
                }
            }
            
            // Check if value is outside configured range
            if (value < config.minValue || value > config.maxValue) {
                float expectedValue = (config.minValue + config.maxValue) / 2.0f;
                float deviation = std::abs(value - expectedValue) / 
                                 (config.maxValue - config.minValue);
                
                if (deviation > config.deviationThreshold) {
                    // Create anomaly
                    TelemetryAnomaly anomaly;
                    anomaly.timestamp = telemetry.timestamp;
                    anomaly.parameter = parameter;
                    anomaly.value = value;
                    anomaly.expectedValue = expectedValue;
                    anomaly.deviation = deviation;
                    
                    // Set severity based on deviation
                    if (deviation > 3.0f * config.deviationThreshold) {
                        anomaly.severity = "Critical";
                    } else if (deviation > 2.0f * config.deviationThreshold) {
                        anomaly.severity = "High";
                    } else if (deviation > 1.5f * config.deviationThreshold) {
                        anomaly.severity = "Medium";
                    } else {
                        anomaly.severity = "Low";
                    }
                    
                    anomaly.description = "Parameter " + parameter + " outside expected range";
                    
                    // Notify callbacks
                    notifyAnomalyCallbacks(anomaly);
                }
            }
        }
    }
    
    // Notify telemetry callbacks
    void notifyTelemetryCallbacks(const SimulatorTelemetry& telemetry) {
        std::lock_guard<std::mutex> lock(callbacksMutex);
        for (const auto& callback : telemetryCallbacks) {
            try {
                callback(telemetry);
            } catch (const std::exception& e) {
                APTP::Core::Logger::getInstance().error(
                    "Exception in telemetry callback: {}", e.what());
            }
        }
    }
    
    // Notify anomaly callbacks
    void notifyAnomalyCallbacks(const TelemetryAnomaly& anomaly) {
        std::lock_guard<std::mutex> lock(callbacksMutex);
        for (const auto& callback : anomalyCallbacks) {
            try {
                callback(anomaly);
            } catch (const std::exception& e) {
                APTP::Core::Logger::getInstance().error(
                    "Exception in anomaly callback: {}", e.what());
            }
        }
    }
};

SimulatorDataProcessor::SimulatorDataProcessor() : impl_(std::make_unique<Impl>()) {}
SimulatorDataProcessor::~SimulatorDataProcessor() {
    stop();
}

APTP::Core::Result<void> SimulatorDataProcessor::initialize(
    const std::string& simulatorType,
    const std::string& connectionSettings) {
    
    if (impl_->running.load(std::memory_order_acquire)) {
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::InvalidState);
    }
    
    impl_->simulatorType = simulatorType;
    impl_->connectionSettings = connectionSettings;
    
    APTP::Core::Logger::getInstance().info(
        "Initialized SimulatorDataProcessor for {} with settings: {}",
        simulatorType, connectionSettings);
    
    return APTP::Core::Success();
}

APTP::Core::Result<void> SimulatorDataProcessor::start() {
    if (impl_->running.load(std::memory_order_acquire)) {
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::InvalidState);
    }
    
    impl_->running.store(true, std::memory_order_release);
    impl_->processingThread = std::thread(&SimulatorDataProcessor::Impl::processTelemetry, impl_.get());
    
    APTP::Core::Logger::getInstance().info("Started SimulatorDataProcessor");
    return APTP::Core::Success();
}

APTP::Core::Result<void> SimulatorDataProcessor::stop() {
    if (!impl_->running.load(std::memory_order_acquire)) {
        return APTP::Core::Success();
    }
    
    impl_->running.store(false, std::memory_order_release);
    
    if (impl_->processingThread.joinable()) {
        impl_->processingThread.join();
    }
    
    APTP::Core::Logger::getInstance().info("Stopped SimulatorDataProcessor");
    return APTP::Core::Success();
}

APTP::Core::Result<void> SimulatorDataProcessor::pushTelemetry(const SimulatorTelemetry& telemetry) {
    if (!impl_->running.load(std::memory_order_acquire)) {
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::InvalidState);
    }
    
    if (!impl_->inputQueue.push(telemetry)) {
        impl_->droppedSamplesCount.fetch_add(1, std::memory_order_relaxed);
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::ResourceUnavailable);
    }
    
    return APTP::Core::Success();
}

APTP::Core::Result<SimulatorTelemetry> SimulatorDataProcessor::getLatestTelemetry() {
    std::lock_guard<std::mutex> lock(impl_->latestTelemetryMutex);
    return APTP::Core::Success(impl_->latestTelemetry);
}

APTP::Core::Result<std::vector<SimulatorTelemetry>> SimulatorDataProcessor::getHistoricalTelemetry(
    const std::chrono::system_clock::time_point& start,
    const std::chrono::system_clock::time_point& end,
    size_t maxSamples) {
    
    return APTP::Core::Success(impl_->timeSeriesStore.queryTimeRange(start, end, maxSamples));
}

void SimulatorDataProcessor::registerTelemetryCallback(TelemetryCallback callback) {
    std::lock_guard<std::mutex> lock(impl_->callbacksMutex);
    impl_->telemetryCallbacks.push_back(std::move(callback));
}

void SimulatorDataProcessor::registerAnomalyCallback(AnomalyCallback callback) {
    std::lock_guard<std::mutex> lock(impl_->callbacksMutex);
    impl_->anomalyCallbacks.push_back(std::move(callback));
}

void SimulatorDataProcessor::setProcessingAlgorithm(DataProcessingAlgorithm algorithm) {
    impl_->algorithm = algorithm;
}

void SimulatorDataProcessor::setAnomalyDetectionThreshold(float threshold) {
    impl_->anomalyThreshold = threshold;
}

void SimulatorDataProcessor::setProcessingInterval(std::chrono::milliseconds interval) {
    impl_->processingInterval = interval;
}

void SimulatorDataProcessor::configureAnomalyDetection(
    const std::string& parameter,
    float minValue,
    float maxValue,
    float deviationThreshold) {
    
    std::lock_guard<std::mutex> lock(impl_->parameterConfigsMutex);
    impl_->parameterConfigs[parameter] = {minValue, maxValue, deviationThreshold};
}

void SimulatorDataProcessor::enableSIMD(bool enable) {
    impl_->simdEnabled = enable;
}

double SimulatorDataProcessor::getAverageProcessingTime() const {
    size_t samples = impl_->processedSamplesCount.load(std::memory_order_relaxed);
    double totalTime = impl_->totalProcessingTime.load(std::memory_order_relaxed);
    
    return samples > 0 ? totalTime / samples : 0.0;
}

size_t SimulatorDataProcessor::getProcessedSamplesCount() const {
    return impl_->processedSamplesCount.load(std::memory_order_relaxed);
}

size_t SimulatorDataProcessor::getDroppedSamplesCount() const {
    return impl_->droppedSamplesCount.load(std::memory_order_relaxed);
}

double SimulatorDataProcessor::getSamplesPerSecond() const {
    return impl_->samplesPerSecond.load(std::memory_order_relaxed);
}

// Implementation for TimeSeriesStore would be similarly structured

} // namespace APTP::Integration

import { PriorityQueue } from '../utils/priority-queue';
import { ConflictResolver } from './conflict-resolver';
import { ResourceModel, TimeSlot, ScheduleConstraint, TraineeProfile } from '../models/scheduler.types';

export class AISchedulerService {
  private conflictResolver: ConflictResolver;
  
  constructor() {
    this.conflictResolver = new ConflictResolver();
  }

  /**
   * Find optimal time slots based on resource availability and constraints
   */
  async findAvailableTimeSlots(
    resources: ResourceModel[],
    constraints: ScheduleConstraint[],
    duration: number,
    startDate: Date,
    endDate: Date
  ): Promise<TimeSlot[]> {
    // Generate all possible time slots within date range
    const possibleSlots = this.generateTimeSlots(startDate, endDate, duration);
    
    // Filter slots based on resource availability
    const availableSlots = await this.filterByResourceAvailability(possibleSlots, resources);
    
    // Apply constraints to filter slots further
    const constrainedSlots = this.applyConstraints(availableSlots, constraints);
    
    // Sort slots by optimality score
    return this.rankSlotsByOptimality(constrainedSlots);
  }

  /**
   * Resolve scheduling conflicts using priority-based algorithms
   */
  resolveConflicts(
    proposedSchedule: Map<string, TimeSlot[]>,
    resources: ResourceModel[]
  ): Map<string, TimeSlot[]> {
    // Extract conflicting time slots
    const conflicts = this.detectConflicts(proposedSchedule, resources);
    
    // Use conflict resolver to prioritize and resolve conflicts
    return this.conflictResolver.resolveConflicts(proposedSchedule, conflicts);
  }

  /**
   * Generate adaptive schedule based on trainee performance data
   */
  generateAdaptiveSchedule(
    traineeProfile: TraineeProfile,
    syllabusModules: string[],
    availableInstructors: ResourceModel[],
    startDate: Date,
    endDate: Date
  ): Promise<Map<string, TimeSlot[]>> {
    // Analyze trainee performance to determine optimal pacing
    const performanceMetrics = this.analyzeTraineePerformance(traineeProfile);
    
    // Determine ideal module sequence based on performance
    const optimizedSequence = this.optimizeModuleSequence(syllabusModules, performanceMetrics);
    
    // Match modules with appropriate instructors based on expertise
    const instructorAssignments = this.matchInstructorsToModules(
      optimizedSequence,
      availableInstructors,
      traineeProfile
    );
    
    // Generate constraints based on trainee needs
    const adaptiveConstraints = this.generateAdaptiveConstraints(performanceMetrics);
    
    // Build the optimized schedule
    return this.buildSchedule(instructorAssignments, adaptiveConstraints, startDate, endDate);
  }

  /**
   * Export schedule to iCalendar format
   */
  exportToICalendar(schedule: Map<string, TimeSlot[]>): string {
    let icalContent = 'BEGIN:VCALENDAR\r\nVERSION:2.0\r\nPRODID:-//Advanced Pilot Training Platform//EN\r\n';
    
    // Iterate through schedule and convert each slot to iCal event
    schedule.forEach((slots, resourceId) => {
      slots.forEach(slot => {
        icalContent += 'BEGIN:VEVENT\r\n';
        icalContent += `DTSTART:${this.formatDateToICalFormat(slot.startTime)}\r\n`;
        icalContent += `DTEND:${this.formatDateToICalFormat(slot.endTime)}\r\n`;
        icalContent += `SUMMARY:${slot.title}\r\n`;
        icalContent += `DESCRIPTION:${slot.description}\r\n`;
        icalContent += `LOCATION:${slot.location}\r\n`;
        icalContent += `UID:${this.generateUid(slot, resourceId)}\r\n`;
        icalContent += 'END:VEVENT\r\n';
      });
    });
    
    icalContent += 'END:VCALENDAR\r\n';
    return icalContent;
  }

  /**
   * Import schedule from iCalendar format
   */
  importFromICalendar(icalContent: string): Map<string, TimeSlot[]> {
    const schedule = new Map<string, TimeSlot[]>();
    
    // Parse iCal content
    const events = this.parseICalEvents(icalContent);
    
    // Convert events to time slots and organize by resource
    events.forEach(event => {
      const resourceId = this.extractResourceFromEvent(event);
      const slot = this.convertEventToTimeSlot(event);
      
      if (!schedule.has(resourceId)) {
        schedule.set(resourceId, []);
      }
      
      schedule.get(resourceId)!.push(slot);
    });
    
    return schedule;
  }

  // Private helper methods
  private generateTimeSlots(startDate: Date, endDate: Date, duration: number): TimeSlot[] {
    const slots: TimeSlot[] = [];
    // Implementation to generate time slots of specified duration between dates
    return slots;
  }

  private async filterByResourceAvailability(slots: TimeSlot[], resources: ResourceModel[]): Promise<TimeSlot[]> {
    // Implementation to check which slots have available resources
    return slots.filter(slot => this.isResourceAvailable(slot, resources));
  }

  private isResourceAvailable(slot: TimeSlot, resources: ResourceModel[]): boolean {
    // Check if required resources are available during the slot
    return true; // Simplified for example
  }

  private applyConstraints(slots: TimeSlot[], constraints: ScheduleConstraint[]): TimeSlot[] {
    // Filter slots based on scheduling constraints
    return slots.filter(slot => this.meetsAllConstraints(slot, constraints));
  }

  private meetsAllConstraints(slot: TimeSlot, constraints: ScheduleConstraint[]): boolean {
    // Check if slot meets all specified constraints
    return constraints.every(constraint => this.meetsConstraint(slot, constraint));
  }

  private meetsConstraint(slot: TimeSlot, constraint: ScheduleConstraint): boolean {
    // Evaluate a single constraint against a time slot
    switch (constraint.type) {
      case 'time':
        return this.evaluateTimeConstraint(slot, constraint);
      case 'resource':
        return this.evaluateResourceConstraint(slot, constraint);
      case 'sequence':
        return this.evaluateSequenceConstraint(slot, constraint);
      default:
        return true;
    }
  }

  private rankSlotsByOptimality(slots: TimeSlot[]): TimeSlot[] {
    // Score and sort slots based on optimality criteria
    const scoredSlots = slots.map(slot => ({
      slot,
      score: this.calculateOptimalityScore(slot)
    }));
    
    scoredSlots.sort((a, b) => b.score - a.score);
    return scoredSlots.map(item => item.slot);
  }

  private calculateOptimalityScore(slot: TimeSlot): number {
    // Calculate a score representing how optimal this slot is
    return 0; // Simplified for example
  }

  private detectConflicts(schedule: Map<string, TimeSlot[]>, resources: ResourceModel[]): Map<string, TimeSlot[]> {
    // Detect conflicting time slots in the proposed schedule
    const conflicts = new Map<string, TimeSlot[]>();
    
    // Implementation to find conflicts
    
    return conflicts;
  }

  private analyzeTraineePerformance(traineeProfile: TraineeProfile): any {
    // Analyze trainee performance data to extract metrics
    return {
      strengths: ['navigation', 'communication'],
      weaknesses: ['emergency procedures', 'instrument flying'],
      learningPace: 'moderate',
      recommendedFocus: 'instrument flying'
    };
  }

  private optimizeModuleSequence(modules: string[], performanceMetrics: any): string[] {
    // Reorder modules based on trainee performance metrics
    return [...modules].sort((a, b) => {
      // Implementation to prioritize modules based on performance needs
      return 0; // Simplified for example
    });
  }

  private matchInstructorsToModules(
    modules: string[],
    instructors: ResourceModel[],
    traineeProfile: TraineeProfile
  ): Map<string, string> {
    // Match modules to instructors based on expertise and trainee needs
    const assignments = new Map<string, string>();
    
    // Implementation for instructor assignment
    
    return assignments;
  }

  private generateAdaptiveConstraints(performanceMetrics: any): ScheduleConstraint[] {
    // Generate scheduling constraints based on trainee performance
    const constraints: ScheduleConstraint[] = [];
    
    // Implementation to create adaptive constraints
    
    return constraints;
  }

  private buildSchedule(
    instructorAssignments: Map<string, string>,
    constraints: ScheduleConstraint[],
    startDate: Date,
    endDate: Date
  ): Promise<Map<string, TimeSlot[]>> {
    // Build complete schedule based on assignments and constraints
    return Promise.resolve(new Map<string, TimeSlot[]>());
  }

  private formatDateToICalFormat(date: Date): string {
    // Format date to iCalendar format
    return date.toISOString().replace(/[-:]/g, '').replace(/\.\d{3}/, '');
  }

  private generateUid(slot: TimeSlot, resourceId: string): string {
    // Generate unique identifier for iCal event
    return `${resourceId}-${slot.startTime.getTime()}@advancedpilottraining.com`;
  }

  private parseICalEvents(icalContent: string): any[] {
    // Parse iCalendar content into events
    const events: any[] = [];
    
    // Implementation for iCal parsing
    
    return events;
  }

  private extractResourceFromEvent(event: any): string {
    // Extract resource ID from iCal event
    return event.uid ? event.uid.split('-')[0] : 'unknown';
  }

  private convertEventToTimeSlot(event: any): TimeSlot {
    // Convert iCal event to TimeSlot object
    return {
      id: event.uid,
      title: event.summary,
      description: event.description,
      startTime: new Date(event.dtstart),
      endTime: new Date(event.dtend),
      location: event.location,
      resourceId: this.extractResourceFromEvent(event)
    };
  }

  private evaluateTimeConstraint(slot: TimeSlot, constraint: ScheduleConstraint): boolean {
    // Evaluate time-based constraint
    return true; // Simplified for example
  }

  private evaluateResourceConstraint(slot: TimeSlot, constraint: ScheduleConstraint): boolean {
    // Evaluate resource-based constraint
    return true; // Simplified for example
  }

  private evaluateSequenceConstraint(slot: TimeSlot, constraint: ScheduleConstraint): boolean {
    // Evaluate sequence-based constraint
    return true; // Simplified for example
  }
}

// Conflict resolver class implementation
class ConflictResolver {
  resolveConflicts(
    schedule: Map<string, TimeSlot[]>,
    conflicts: Map<string, TimeSlot[]>
  ): Map<string, TimeSlot[]> {
    // Implementation of conflict resolution algorithm
    
    // Create a copy of the schedule to modify
    const resolvedSchedule = new Map<string, TimeSlot[]>();
    schedule.forEach((slots, resourceId) => {
      resolvedSchedule.set(resourceId, [...slots]);
    });
    
    // Process each conflict
    conflicts.forEach((conflictingSlots, resourceId) => {
      // Implement priority-based resolution
      // For example, prioritize based on importance score, trainee needs, etc.
    });
    
    return resolvedSchedule;
  }
}

// Types file
export interface SchedulerApiClient {
  getAvailableTimeSlots(
    resources: string[],
    constraints: any[],
    duration: number,
    startDate: string,
    endDate: string
  ): Promise<TimeSlot[]>;
  
  createScheduleEntry(
    resourceId: string,
    slot: TimeSlot
  ): Promise<{id: string}>;
  
  updateScheduleEntry(
    id: string,
    updates: Partial<TimeSlot>
  ): Promise<void>;
  
  deleteScheduleEntry(id: string): Promise<void>;
  
  exportSchedule(
    format: 'ical' | 'json' | 'csv',
    resourceIds: string[],
    startDate: string,
    endDate: string
  ): Promise<Blob>;
  
  importSchedule(
    file: File,
    format: 'ical' | 'json' | 'csv'
  ): Promise<{success: boolean, entries: number}>;
}

#include <drogon/drogon.h>
#include <json/json.h>
#include <openssl/sha.h>
#include <openssl/evp.h>
#include <openssl/rand.h>
#include <string>
#include <vector>
#include <map>
#include <chrono>
#include <memory>
#include <mutex>
#include <jwt-cpp/jwt.h>

namespace atp {
namespace security {

// Forward declarations
class TokenManager;
class RoleBasedAccessControl;
class BiometricAuthenticator;
class EncryptionService;
class GDPRComplianceManager;

class SecurityAuthenticationService : public drogon::HttpController<SecurityAuthenticationService> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(SecurityAuthenticationService::authenticate, "/api/auth/login", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::refreshToken, "/api/auth/refresh", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::validateToken, "/api/auth/validate", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::logout, "/api/auth/logout", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::registerMultiFactor, "/api/auth/mfa/register", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::validateMultiFactor, "/api/auth/mfa/validate", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::registerBiometric, "/api/auth/biometric/register", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::validateBiometric, "/api/auth/biometric/validate", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::checkPermission, "/api/auth/permission", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::getRolePermissions, "/api/auth/roles/{role}", drogon::Get);
    ADD_METHOD_TO(SecurityAuthenticationService::updateUserRoles, "/api/auth/users/{userId}/roles", drogon::Put);
    ADD_METHOD_TO(SecurityAuthenticationService::encryptData, "/api/security/encrypt", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::decryptData, "/api/security/decrypt", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::processDeletionRequest, "/api/gdpr/request-deletion", drogon::Post);
    ADD_METHOD_TO(SecurityAuthenticationService::exportUserData, "/api/gdpr/export-data", drogon::Post);
    METHOD_LIST_END

    SecurityAuthenticationService();

    // Authentication methods
    void authenticate(const drogon::HttpRequestPtr& req, 
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void refreshToken(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void validateToken(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void logout(const drogon::HttpRequestPtr& req,
               std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Multi-factor authentication methods
    void registerMultiFactor(const drogon::HttpRequestPtr& req,
                            std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void validateMultiFactor(const drogon::HttpRequestPtr& req,
                            std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Biometric authentication methods
    void registerBiometric(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void validateBiometric(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // Role-based access control methods
    void checkPermission(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getRolePermissions(const drogon::HttpRequestPtr& req,
                           std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                           const std::string& role);
    
    void updateUserRoles(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& userId);
    
    // Encryption methods
    void encryptData(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void decryptData(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    // GDPR compliance methods
    void processDeletionRequest(const drogon::HttpRequestPtr& req,
                               std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void exportUserData(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);

private:
    std::shared_ptr<TokenManager> tokenManager_;
    std::shared_ptr<RoleBasedAccessControl> rbac_;
    std::shared_ptr<BiometricAuthenticator> biometricAuth_;
    std::shared_ptr<EncryptionService> encryptionService_;
    std::shared_ptr<GDPRComplianceManager> gdprManager_;
    
    // JWT secret key (would be loaded from secure configuration in production)
    std::string jwtSecret_;
    
    // Helper methods
    bool verifyPassword(const std::string& hashedPassword, const std::string& plainPassword, const std::string& salt);
    std::string hashPassword(const std::string& password, const std::string& salt);
    std::string generateSalt(size_t length);
    void recordAuthEvent(const std::string& userId, const std::string& eventType, bool success, const std::string& details);
};

// Token Manager class
class TokenManager {
public:
    TokenManager(const std::string& jwtSecret);
    
    std::string generateToken(const std::string& userId, const std::vector<std::string>& roles, int expiryMinutes);
    std::string generateRefreshToken(const std::string& userId);
    bool validateToken(const std::string& token, Json::Value& payload);
    bool invalidateToken(const std::string& token);
    bool invalidateAllUserTokens(const std::string& userId);
    std::string refreshAccessToken(const std::string& refreshToken);

private:
    std::string jwtSecret_;
    std::map<std::string, std::string> refreshTokens_;  // userId -> refreshToken
    std::set<std::string> invalidatedTokens_;  // Tokens that have been explicitly invalidated
    std::mutex tokenMutex_;
    
    std::string generateTokenId();
    bool isTokenInvalidated(const std::string& jti);
};

// Role-Based Access Control class
class RoleBasedAccessControl {
public:
    RoleBasedAccessControl();
    
    bool checkPermission(const std::string& userId, const std::string& resource, const std::string& action);
    Json::Value getRolePermissions(const std::string& role);
    bool updateUserRoles(const std::string& userId, const std::vector<std::string>& roles);
    std::vector<std::string> getUserRoles(const std::string& userId);

private:
    // Role definitions: role -> [permissions]
    std::map<std::string, std::vector<std::string>> rolePermissions_;
    
    // User role assignments: userId -> [roles]
    std::map<std::string, std::vector<std::string>> userRoles_;
    
    void loadRoleDefinitions();
};

// Biometric Authenticator class
class BiometricAuthenticator {
public:
    BiometricAuthenticator();
    
    bool registerBiometric(const std::string& userId, const std::string& biometricType, const std::string& biometricData);
    bool validateBiometric(const std::string& userId, const std::string& biometricType, const std::string& biometricData);

private:
    // User biometric templates: userId -> {biometricType -> templateData}
    std::map<std::string, std::map<std::string, std::string>> biometricTemplates_;
    
    // Validation methods for different biometric types
    bool validateFingerprint(const std::string& storedTemplate, const std::string& providedData);
    bool validateFacialRecognition(const std::string& storedTemplate, const std::string& providedData);
    bool validateIrisRecognition(const std::string& storedTemplate, const std::string& providedData);
};

// Encryption Service class
class EncryptionService {
public:
    EncryptionService();
    
    std::string encryptData(const std::string& plaintext, const std::string& keyId);
    std::string decryptData(const std::string& ciphertext, const std::string& keyId);
    std::string generateEncryptionKey();

private:
    // Encryption keys: keyId -> keyData
    std::map<std::string, std::string> encryptionKeys_;
    
    // Encryption IV (should be unique per encryption operation in production)
    std::vector<unsigned char> iv_;
    
    void initializeKeys();
};

// GDPR Compliance Manager class
class GDPRComplianceManager {
public:
    GDPRComplianceManager();
    
    Json::Value processDeletionRequest(const std::string& userId, const std::string& requestReason);
    Json::Value exportUserData(const std::string& userId);
    bool logDataAccess(const std::string& userId, const std::string& dataCategory, const std::string& accessReason);

private:
    // Log of data access: timestamp -> {userId, dataCategory, reason}
    std::vector<std::tuple<std::string, std::string, std::string, std::string>> dataAccessLog_;
    
    // Deletion requests: requestId -> {userId, status, timestamp}
    std::map<std::string, Json::Value> deletionRequests_;
    
    void anonymizeUserData(const std::string& userId);
    void notifyDataControllers(const std::string& userId, const std::string& requestType);
};

// TokenManager implementation
TokenManager::TokenManager(const std::string& jwtSecret) : jwtSecret_(jwtSecret) {}

std::string TokenManager::generateToken(const std::string& userId, const std::vector<std::string>& roles, int expiryMinutes) {
    auto now = std::chrono::system_clock::now();
    auto exp = now + std::chrono::minutes(expiryMinutes);
    
    std::string tokenId = generateTokenId();
    
    auto token = jwt::create()
        .set_issuer("atp-security-service")
        .set_type("JWT")
        .set_id(tokenId)
        .set_issued_at(now)
        .set_expires_at(exp)
        .set_subject(userId);
    
    // Add roles as an array claim
    std::vector<std::string> rolesCopy = roles;
    token.set_payload_claim("roles", jwt::claim(rolesCopy));
    
    // Sign token with secret
    return token.sign(jwt::algorithm::hs256{jwtSecret_});
}

std::string TokenManager::generateRefreshToken(const std::string& userId) {
    // Generate a secure random token
    const int TOKEN_LENGTH = 64;
    std::string refreshToken = generateSalt(TOKEN_LENGTH);
    
    // Store token for the user
    {
        std::lock_guard<std::mutex> lock(tokenMutex_);
        refreshTokens_[userId] = refreshToken;
    }
    
    return refreshToken;
}

bool TokenManager::validateToken(const std::string& token, Json::Value& payload) {
    try {
        auto decoded = jwt::decode(token);
        auto verifier = jwt::verify()
            .allow_algorithm(jwt::algorithm::hs256{jwtSecret_})
            .with_issuer("atp-security-service");
        
        verifier.verify(decoded);
        
        // Check if token has been invalidated
        std::string tokenId = decoded.get_id();
        if (isTokenInvalidated(tokenId)) {
            return false;
        }
        
        // Extract payload claims
        payload["sub"] = decoded.get_subject();
        
        // Extract roles
        auto rolesJson = Json::Value(Json::arrayValue);
        for (const auto& role : decoded.get_payload_claim("roles").as_array()) {
            rolesJson.append(role.as_string());
        }
        payload["roles"] = rolesJson;
        
        return true;
    }
    catch (const std::exception& e) {
        // Token invalid or expired
        return false;
    }
}

bool TokenManager::invalidateToken(const std::string& token) {
    try {
        auto decoded = jwt::decode(token);
        std::string tokenId = decoded.get_id();
        
        std::lock_guard<std::mutex> lock(tokenMutex_);
        invalidatedTokens_.insert(tokenId);
        return true;
    }
    catch (const std::exception& e) {
        return false;
    }
}

bool TokenManager::invalidateAllUserTokens(const std::string& userId) {
    std::lock_guard<std::mutex> lock(tokenMutex_);
    
    // Remove refresh token for the user
    auto it = refreshTokens_.find(userId);
    if (it != refreshTokens_.end()) {
        refreshTokens_.erase(it);
    }
    
    // Note: In a production system, we would need a more sophisticated
    // way to track and invalidate all active tokens for a user
    
    return true;
}

std::string TokenManager::refreshAccessToken(const std::string& refreshToken) {
    std::lock_guard<std::mutex> lock(tokenMutex_);
    
    // Find user for this refresh token
    std::string userId;
    for (const auto& pair : refreshTokens_) {
        if (pair.second == refreshToken) {
            userId = pair.first;
            break;
        }
    }
    
    if (userId.empty()) {
        return "";  // Refresh token not found
    }
    
    // In a real system, we would look up the user's roles here
    std::vector<std::string> roles = {"user"};  // Default role
    
    // Generate a new access token
    return generateToken(userId, roles, 60);  // 1 hour expiry
}

std::string TokenManager::generateTokenId() {
    // Generate a unique token ID
    auto now = std::chrono::system_clock::now();
    auto now_ms = std::chrono::time_point_cast<std::chrono::milliseconds>(now);
    auto epoch = now_ms.time_since_epoch();
    uint64_t timestamp = static_cast<uint64_t>(epoch.count());
    
    // Combine timestamp with a random number
    std::random_device rd;
    std::mt19937_64 gen(rd());
    std::uniform_int_distribution<uint64_t> dist;
    uint64_t random = dist(gen);
    
    std::stringstream ss;
    ss << std::hex << timestamp << "-" << random;
    return ss.str();
}

bool TokenManager::isTokenInvalidated(const std::string& jti) {
    std::lock_guard<std::mutex> lock(tokenMutex_);
    return invalidatedTokens_.find(jti) != invalidatedTokens_.end();
}

// RoleBasedAccessControl implementation
RoleBasedAccessControl::RoleBasedAccessControl() {
    loadRoleDefinitions();
}

bool RoleBasedAccessControl::checkPermission(const std::string& userId, const std::string& resource, const std::string& action) {
    // Get user's roles
    auto roles = getUserRoles(userId);
    
    // Check if any role has the required permission
    std::string permission = resource + ":" + action;
    
    for (const auto& role : roles) {
        auto it = rolePermissions_.find(role);
        if (it != rolePermissions_.end()) {
            const auto& permissions = it->second;
            
            // Check for direct permission
            if (std::find(permissions.begin(), permissions.end(), permission) != permissions.end()) {
                return true;
            }
            
            // Check for wildcard permissions
            if (std::find(permissions.begin(), permissions.end(), resource + ":*") != permissions.end()) {
                return true;
            }
            
            if (std::find(permissions.begin(), permissions.end(), "*:*") != permissions.end()) {
                return true;
            }
        }
    }
    
    return false;
}

Json::Value RoleBasedAccessControl::getRolePermissions(const std::string& role) {
    Json::Value result(Json::objectValue);
    result["role"] = role;
    
    Json::Value permissions(Json::arrayValue);
    
    auto it = rolePermissions_.find(role);
    if (it != rolePermissions_.end()) {
        for (const auto& permission : it->second) {
            permissions.append(permission);
        }
    }
    
    result["permissions"] = permissions;
    return result;
}

bool RoleBasedAccessControl::updateUserRoles(const std::string& userId, const std::vector<std::string>& roles) {
    // Validate that all roles exist
    for (const auto& role : roles) {
        if (rolePermissions_.find(role) == rolePermissions_.end()) {
            return false;  // Role doesn't exist
        }
    }
    
    // Update user's roles
    userRoles_[userId] = roles;
    return true;
}

std::vector<std::string> RoleBasedAccessControl::getUserRoles(const std::string& userId) {
    auto it = userRoles_.find(userId);
    if (it != userRoles_.end()) {
        return it->second;
    }
    
    // Default roles for new users
    return {"user"};
}

void RoleBasedAccessControl::loadRoleDefinitions() {
    // Define standard roles and permissions
    // In production, these would be loaded from a database or configuration file
    
    // Administrator role
    rolePermissions_["admin"] = {
        "*:*"  // All permissions
    };
    
    // Instructor role
    rolePermissions_["instructor"] = {
        "syllabus:read",
        "syllabus:use",
        "assessment:create",
        "assessment:read",
        "assessment:update",
        "trainee:read",
        "training:manage",
        "document:read"
    };
    
    // Trainee role
    rolePermissions_["trainee"] = {
        "syllabus:read",
        "assessment:read",
        "training:view",
        "document:read"
    };
    
    // Training manager role
    rolePermissions_["training_manager"] = {
        "syllabus:read",
        "syllabus:create",
        "syllabus:update",
        "assessment:read",
        "trainee:read",
        "trainee:assign",
        "instructor:assign",
        "training:manage",
        "analytics:read",
        "document:read",
        "document:create",
        "document:update"
    };
    
    // Default user role
    rolePermissions_["user"] = {
        "profile:read",
        "profile:update"
    };
}

// BiometricAuthenticator implementation
BiometricAuthenticator::BiometricAuthenticator() {}

bool BiometricAuthenticator::registerBiometric(const std::string& userId, const std::string& biometricType, const std::string& biometricData) {
    // In production, biometric data should be properly processed and securely stored
    // This is a simplified implementation for demonstration
    
    // Store the biometric template
    biometricTemplates_[userId][biometricType] = biometricData;
    return true;
}

bool BiometricAuthenticator::validateBiometric(const std::string& userId, const std::string& biometricType, const std::string& biometricData) {
    // Check if user has registered this biometric type
    auto userIt = biometricTemplates_.find(userId);
    if (userIt == biometricTemplates_.end()) {
        return false;
    }
    
    auto biometricIt = userIt->second.find(biometricType);
    if (biometricIt == userIt->second.end()) {
        return false;
    }
    
    // Get stored template
    const std::string& storedTemplate = biometricIt->second;
    
    // Validate based on biometric type
    if (biometricType == "fingerprint") {
        return validateFingerprint(storedTemplate, biometricData);
    }
    else if (biometricType == "facial") {
        return validateFacialRecognition(storedTemplate, biometricData);
    }
    else if (biometricType == "iris") {
        return validateIrisRecognition(storedTemplate, biometricData);
    }
    
    return false;  // Unsupported biometric type
}

bool BiometricAuthenticator::validateFingerprint(const std::string& storedTemplate, const std::string& providedData) {
    // In production, this would use a specialized biometric matching algorithm
    // For demonstration, we're doing a simplified comparison
    
    // Calculate match score (0-100) between template and provided data
    int matchScore = 0;
    
    // Simple similarity measure (for demonstration only)
    if (storedTemplate.length() == providedData.length()) {
        int matchingChars = 0;
        for (size_t i = 0; i < storedTemplate.length(); ++i) {
            if (storedTemplate[i] == providedData[i]) {
                matchingChars++;
            }
        }
        
        matchScore = (matchingChars * 100) / storedTemplate.length();
    }
    
    // Threshold for fingerprint matching (typically 40-60 in real systems)
    return matchScore >= 50;
}

bool BiometricAuthenticator::validateFacialRecognition(const std::string& storedTemplate, const std::string& providedData) {
    // Similar to fingerprint but with facial recognition algorithm
    // For demonstration, using simplified comparison
    
    int matchScore = 0;
    
    // Simple similarity measure (for demonstration only)
    if (storedTemplate.length() == providedData.length()) {
        int matchingChars = 0;
        for (size_t i = 0; i < storedTemplate.length(); ++i) {
            if (storedTemplate[i] == providedData[i]) {
                matchingChars++;
            }
        }
        
        matchScore = (matchingChars * 100) / storedTemplate.length();
    }
    
    // Threshold for facial recognition (typically 70-90 in real systems)
    return matchScore >= 80;
}

bool BiometricAuthenticator::validateIrisRecognition(const std::string& storedTemplate, const std::string& providedData) {
    // Similar to fingerprint but with iris recognition algorithm
    // For demonstration, using simplified comparison
    
    int matchScore = 0;
    
    // Simple similarity measure (for demonstration only)
    if (storedTemplate.length() == providedData.length()) {
        int matchingChars = 0;
        for (size_t i = 0; i < storedTemplate.length(); ++i) {
            if (storedTemplate[i] == providedData[i]) {
                matchingChars++;
            }
        }
        
        matchScore = (matchingChars * 100) / storedTemplate.length();
    }
    
    // Threshold for iris recognition (typically 85-95 in real systems)
    return matchScore >= 90;
}

// EncryptionService implementation
EncryptionService::EncryptionService() {
    initializeKeys();
    
    // Initialize IV (in production, should be unique per encryption)
    iv_.resize(16);  // 16 bytes for AES
    RAND_bytes(iv_.data(), static_cast<int>(iv_.size()));
}

std::string EncryptionService::encryptData(const std::string& plaintext, const std::string& keyId) {
    // Find encryption key
    auto keyIt = encryptionKeys_.find(keyId);
    if (keyIt == encryptionKeys_.end()) {
        throw std::runtime_error("Invalid encryption key ID: " + keyId);
    }
    
    const std::string& key = keyIt->second;
    
    // Initialize encryption context
    EVP_CIPHER_CTX* ctx = EVP_CIPHER_CTX_new();
    if (!ctx) {
        throw std::runtime_error("Failed to create encryption context");
    }
    
    // Initialize encryption operation
    if (EVP_EncryptInit_ex(ctx, EVP_aes_256_cbc(), NULL, 
                          reinterpret_cast<const unsigned char*>(key.c_str()), 
                          iv_.data()) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to initialize encryption");
    }
    
    // Prepare output buffer (plaintext length + block size for padding)
    std::vector<unsigned char> ciphertext(plaintext.length() + 16);
    int len = 0;
    int ciphertext_len = 0;
    
    // Encrypt data
    if (EVP_EncryptUpdate(ctx, ciphertext.data(), &len, 
                         reinterpret_cast<const unsigned char*>(plaintext.c_str()), 
                         static_cast<int>(plaintext.length())) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to encrypt data");
    }
    
    ciphertext_len = len;
    
    // Finalize encryption
    if (EVP_EncryptFinal_ex(ctx, ciphertext.data() + len, &len) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to finalize encryption");
    }
    
    ciphertext_len += len;
    
    // Clean up
    EVP_CIPHER_CTX_free(ctx);
    
    // Resize ciphertext to actual length
    ciphertext.resize(ciphertext_len);
    
    // Combine IV and ciphertext, and encode as base64
    std::vector<unsigned char> combined;
    combined.reserve(iv_.size() + ciphertext.size());
    combined.insert(combined.end(), iv_.begin(), iv_.end());
    combined.insert(combined.end(), ciphertext.begin(), ciphertext.end());
    
    // Base64 encode the combined data
    return base64Encode(combined);
}

std::string EncryptionService::decryptData(const std::string& ciphertext, const std::string& keyId) {
    // Find encryption key
    auto keyIt = encryptionKeys_.find(keyId);
    if (keyIt == encryptionKeys_.end()) {
        throw std::runtime_error("Invalid encryption key ID: " + keyId);
    }
    
    const std::string& key = keyIt->second;
    
    // Decode base64
    auto combinedData = base64Decode(ciphertext);
    
    // Extract IV and ciphertext
    if (combinedData.size() <= 16) {
        throw std::runtime_error("Invalid ciphertext format");
    }
    
    std::vector<unsigned char> iv(combinedData.begin(), combinedData.begin() + 16);
    std::vector<unsigned char> encryptedData(combinedData.begin() + 16, combinedData.end());
    
    // Initialize decryption context
    EVP_CIPHER_CTX* ctx = EVP_CIPHER_CTX_new();
    if (!ctx) {
        throw std::runtime_error("Failed to create decryption context");
    }
    
    // Initialize decryption operation
    if (EVP_DecryptInit_ex(ctx, EVP_aes_256_cbc(), NULL, 
                          reinterpret_cast<const unsigned char*>(key.c_str()), 
                          iv.data()) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to initialize decryption");
    }
    
    // Prepare output buffer
    std::vector<unsigned char> plaintext(encryptedData.size());
    int len = 0;
    int plaintext_len = 0;
    
    // Decrypt data
    if (EVP_DecryptUpdate(ctx, plaintext.data(), &len, 
                         encryptedData.data(), 
                         static_cast<int>(encryptedData.size())) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to decrypt data");
    }
    
    plaintext_len = len;
    
    // Finalize decryption
    if (EVP_DecryptFinal_ex(ctx, plaintext.data() + len, &len) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to finalize decryption");
    }
    
    plaintext_len += len;
    
    // Clean up
    EVP_CIPHER_CTX_free(ctx);
    
    // Resize plaintext to actual length
    plaintext.resize(plaintext_len);
    
    // Convert to string
    return std::string(reinterpret_cast<char*>(plaintext.data()), plaintext.size());
}

std::string EncryptionService::generateEncryptionKey() {
    // Generate a secure random 32-byte key (256 bits)
    const int KEY_LENGTH = 32;  // 32 bytes for AES-256
    
    std::vector<unsigned char> key(KEY_LENGTH);
    RAND_bytes(key.data(), KEY_LENGTH);
    
    // Convert to hex string for storage
    std::stringstream ss;
    for (unsigned char byte : key) {
        ss << std::hex << std::setw(2) << std::setfill('0') << static_cast<int>(byte);
    }
    
    // Generate key ID
    std::string keyId = "key-" + std::to_string(encryptionKeys_.size() + 1);
    
    // Store the key
    encryptionKeys_[keyId] = ss.str();
    
    return keyId;
}

void EncryptionService::initializeKeys() {
    // In production, encryption keys would be securely loaded from a key management system
    // For demonstration, we're creating some initial keys
    
    // Master key (used for most sensitive data)
    std::string masterKeyHex = "1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef";
    encryptionKeys_["master"] = masterKeyHex;
    
    // User data key
    std::string userDataKeyHex = "abcdef1234567890abcdef1234567890abcdef1234567890abcdef1234567890";
    encryptionKeys_["user-data"] = userDataKeyHex;
    
    // Generate additional keys for the service
    for (int i = 0; i < 3; ++i) {
        generateEncryptionKey();
    }
}

std::string EncryptionService::base64Encode(const std::vector<unsigned char>& data) {
    // Base64 encoding implementation
    static const char base64Chars[] = 
        "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    
    std::string encoded;
    encoded.reserve(((data.size() + 2) / 3) * 4);
    
    for (size_t i = 0; i < data.size(); i += 3) {
        uint32_t value = data[i] << 16;
        if (i + 1 < data.size()) value |= data[i + 1] << 8;
        if (i + 2 < data.size()) value |= data[i + 2];
        
        encoded.push_back(base64Chars[(value >> 18) & 0x3F]);
        encoded.push_back(base64Chars[(value >> 12) & 0x3F]);
        encoded.push_back(i + 1 < data.size() ? base64Chars[(value >> 6) & 0x3F] : '=');
        encoded.push_back(i + 2 < data.size() ? base64Chars[value & 0x3F] : '=');
    }
    
    return encoded;
}

std::vector<unsigned char> EncryptionService::base64Decode(const std::string& encoded) {
    // Base64 decoding implementation
    static const std::string base64Chars = 
        "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    
    std::vector<unsigned char> decoded;
    decoded.reserve((encoded.size() / 4) * 3);
    
    for (size_t i = 0; i < encoded.size(); i += 4) {
        uint32_t value = 0;
        
        for (size_t j = 0; j < 4; ++j) {
            if (i + j < encoded.size() && encoded[i + j] != '=') {
                value <<= 6;
                size_t pos = base64Chars.find(encoded[i + j]);
                if (pos != std::string::npos) {
                    value |= pos;
                }
            }
            else {
                value <<= 6;
            }
        }
        
        decoded.push_back((value >> 16) & 0xFF);
        if (i + 2 < encoded.size() && encoded[i + 2] != '=') {
            decoded.push_back((value >> 8) & 0xFF);
        }
        if (i + 3 < encoded.size() && encoded[i + 3] != '=') {
            decoded.push_back(value & 0xFF);
        }
    }
    
    return decoded;
}

// GDPRComplianceManager implementation
GDPRComplianceManager::GDPRComplianceManager() {}

Json::Value GDPRComplianceManager::processDeletionRequest(const std::string& userId, const std::string& requestReason) {
    // Generate a unique request ID
    std::string requestId = "del-" + std::to_string(deletionRequests_.size() + 1);
    
    // Create deletion request record
    Json::Value request;
    request["request_id"] = requestId;
    request["user_id"] = userId;
    request["reason"] = requestReason;
    request["status"] = "pending";
    request["timestamp"] = drogon::utils::getFormattedDate();
    
    // Store the request
    deletionRequests_[requestId] = request;
    
    // Notify data controllers about the deletion request
    notifyDataControllers(userId, "deletion");
    
    // In a real system, this would trigger a workflow for data deletion
    // For demonstration, we'll simulate immediate anonymization
    anonymizeUserData(userId);
    
    // Update request status
    request["status"] = "completed";
    deletionRequests_[requestId] = request;
    
    return request;
}

Json::Value GDPRComplianceManager::exportUserData(const std::string& userId) {
    // Log this data access
    logDataAccess(userId, "full_export", "GDPR data subject request");
    
    // In a real system, this would gather data from all relevant systems
    // For demonstration, we'll create a sample data package
    
    Json::Value userData;
    userData["user_id"] = userId;
    userData["export_date"] = drogon::utils::getFormattedDate();
    
    // Personal information
    Json::Value personalInfo;
    personalInfo["name"] = "Simulated User";  // In real system, actual user data
    personalInfo["email"] = "user@example.com";
    personalInfo["created_at"] = "2023-01-01T00:00:00Z";
    
    // Training records
    Json::Value trainingRecords(Json::arrayValue);
    
    Json::Value record1;
    record1["course_id"] = "TR-101";
    record1["course_name"] = "Basic Flight Training";
    record1["completion_date"] = "2023-02-15T00:00:00Z";
    record1["score"] = 92;
    trainingRecords.append(record1);
    
    Json::Value record2;
    record2["course_id"] = "TR-202";
    record2["course_name"] = "Advanced Navigation";
    record2["completion_date"] = "2023-05-20T00:00:00Z";
    record2["score"] = 88;
    trainingRecords.append(record2);
    
    // Assessment data
    Json::Value assessments(Json::arrayValue);
    
    Json::Value assessment1;
    assessment1["assessment_id"] = "A-501";
    assessment1["type"] = "Practical Test";
    assessment1["date"] = "2023-03-10T00:00:00Z";
    assessment1["result"] = "Pass";
    assessments.append(assessment1);
    
    // Combine all data
    userData["personal_info"] = personalInfo;
    userData["training_records"] = trainingRecords;
    userData["assessments"] = assessments;
    
    // Include data access logs
    Json::Value accessLogs(Json::arrayValue);
    for (const auto& log : dataAccessLog_) {
        if (std::get<1>(log) == userId) {
            Json::Value logEntry;
            logEntry["timestamp"] = std::get<0>(log);
            logEntry["data_category"] = std::get<2>(log);
            logEntry["reason"] = std::get<3>(log);
            accessLogs.append(logEntry);
        }
    }
    
    userData["data_access_logs"] = accessLogs;
    
    // Notify data controllers about the export
    notifyDataControllers(userId, "export");
    
    return userData;
}

bool GDPRComplianceManager::logDataAccess(const std::string& userId, const std::string& dataCategory, const std::string& accessReason) {
    // Log the data access event
    std::string timestamp = drogon::utils::getFormattedDate();
    dataAccessLog_.emplace_back(timestamp, userId, dataCategory, accessReason);
    return true;
}

void GDPRComplianceManager::anonymizeUserData(const std::string& userId) {
    // In a real system, this would anonymize or delete the user's data
    // across all relevant databases and systems
    
    // For demonstration, we'll just log the action
    std::cout << "Anonymizing data for user: " << userId << std::endl;
    
    // Steps that would be taken in a real system:
    // 1. Replace personal identifiers with anonymized values
    // 2. Delete unnecessary data
    // 3. Keep required data with anonymized identifiers
    // 4. Update audit logs to reflect the anonymization
}

void GDPRComplianceManager::notifyDataControllers(const std::string& userId, const std::string& requestType) {
    // In a real system, this would notify relevant data controllers
    // about the data subject request
    
    // For demonstration, we'll just log the notification
    std::cout << "Notifying data controllers about " << requestType
              << " request for user: " << userId << std::endl;
    
    // In a real system, this might:
    // 1. Send emails to data protection officers
    // 2. Create tickets in a workflow system
    // 3. Log the notifications for compliance purposes
}

// SecurityAuthenticationService implementation
SecurityAuthenticationService::SecurityAuthenticationService() {
    // Initialize JWT secret (in production, load from secure configuration)
    jwtSecret_ = "YourSecretKeyForSigningJwtsReplaceMeWithSecureKey";
    
    // Initialize components
    tokenManager_ = std::make_shared<TokenManager>(jwtSecret_);
    rbac_ = std::make_shared<RoleBasedAccessControl>();
    biometricAuth_ = std::make_shared<BiometricAuthenticator>();
    encryptionService_ = std::make_shared<EncryptionService>();
    gdprManager_ = std::make_shared<GDPRComplianceManager>();
}

void SecurityAuthenticationService::authenticate(const drogon::HttpRequestPtr& req, 
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string username = (*json)["username"].asString();
        std::string password = (*json)["password"].asString();
        
        // In production, we would look up the user in a database
        // For demonstration, we'll use hardcoded values
        
        // Check if credentials are valid
        bool isValid = false;
        std::string userId;
        std::string hashedPassword;
        std::string salt;
        
        if (username == "admin") {
            userId = "user-1";
            salt = "abcdef1234";
            hashedPassword = hashPassword("admin123", salt);
            isValid = verifyPassword(hashedPassword, password, salt);
        }
        else if (username == "instructor") {
            userId = "user-2";
            salt = "1234abcdef";
            hashedPassword = hashPassword("instructor456", salt);
            isValid = verifyPassword(hashedPassword, password, salt);
        }
        
        if (!isValid) {
            // Record failed login attempt
            recordAuthEvent(username, "login", false, "Invalid credentials");
            
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Invalid credentials";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k401Unauthorized);
            callback(resp);
            return;
        }
        
        // Get user roles
        auto roles = rbac_->getUserRoles(userId);
        
        // Generate tokens
        std::string accessToken = tokenManager_->generateToken(userId, roles, 60);  // 1 hour expiry
        std::string refreshToken = tokenManager_->generateRefreshToken(userId);
        
        // Record successful login
        recordAuthEvent(userId, "login", true, "");
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["access_token"] = accessToken;
        result["refresh_token"] = refreshToken;
        result["token_type"] = "Bearer";
        result["expires_in"] = 3600;  // 1 hour in seconds
        
        // Include user info
        Json::Value userInfo;
        userInfo["user_id"] = userId;
        userInfo["username"] = username;
        
        Json::Value rolesJson(Json::arrayValue);
        for (const auto& role : roles) {
            rolesJson.append(role);
        }
        userInfo["roles"] = rolesJson;
        
        result["user_info"] = userInfo;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::refreshToken(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string refreshToken = (*json)["refresh_token"].asString();
        
        // Generate new access token
        std::string newAccessToken = tokenManager_->refreshAccessToken(refreshToken);
        
        if (newAccessToken.empty()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Invalid refresh token";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k401Unauthorized);
            callback(resp);
            return;
        }
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["access_token"] = newAccessToken;
        result["token_type"] = "Bearer";
        result["expires_in"] = 3600;  // 1 hour in seconds
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::validateToken(const drogon::HttpRequestPtr& req,
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string token = (*json)["token"].asString();
        
        // Validate token
        Json::Value payload;
        bool isValid = tokenManager_->validateToken(token, payload);
        
        if (!isValid) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Invalid or expired token";
            error["valid"] = false;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k401Unauthorized);
            callback(resp);
            return;
        }
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["valid"] = true;
        result["payload"] = payload;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        error["valid"] = false;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::logout(const drogon::HttpRequestPtr& req,
             std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string token = (*json)["token"].asString();
        std::string userId = (*json).get("user_id", "").asString();
        
        // If userId is provided, invalidate all tokens for the user
        if (!userId.empty()) {
            tokenManager_->invalidateAllUserTokens(userId);
        }
        else {
            // Otherwise, invalidate just the provided token
            tokenManager_->invalidateToken(token);
        }
        
        // Record logout event
        if (!userId.empty()) {
            recordAuthEvent(userId, "logout", true, "");
        }
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["message"] = "Logged out successfully";
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::registerMultiFactor(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string userId = (*json)["user_id"].asString();
        std::string mfaType = (*json)["mfa_type"].asString();
        
        // In production, this would integrate with actual MFA providers
        // For demonstration, we'll simulate MFA registration
        
        Json::Value result;
        result["status"] = "success";
        
        if (mfaType == "totp") {
            // Time-based One-Time Password setup
            
            // Generate a random secret key
            std::string secretKey = generateSalt(20);
            
            // In production, store this key securely associated with the user
            
            // Provide information for QR code generation
            result["secret_key"] = secretKey;
            result["qr_code_url"] = "otpauth://totp/ATPSecurity:" + userId + 
                                    "?secret=" + secretKey + 
                                    "&issuer=Advanced%20Pilot%20Training%20Platform";
            
            result["message"] = "TOTP MFA registered successfully";
        }
        else if (mfaType == "sms") {
            // SMS-based MFA setup
            
            // In production, verify the phone number and store it
            std::string phoneNumber = (*json)["phone_number"].asString();
            
            // Simulate sending verification code
            result["verification_sent"] = true;
            result["message"] = "SMS verification code sent";
        }
        else {
            throw std::runtime_error("Unsupported MFA type: " + mfaType);
        }
        
        // Record MFA registration
        recordAuthEvent(userId, "mfa_register", true, "Type: " + mfaType);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::validateMultiFactor(const drogon::HttpRequestPtr& req,
                          std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string userId = (*json)["user_id"].asString();
        std::string mfaType = (*json)["mfa_type"].asString();
        std::string code = (*json)["code"].asString();
        
        // In production, this would validate against actual MFA providers
        // For demonstration, we'll simulate validation
        
        bool isValid = false;
        
        if (mfaType == "totp") {
            // Simulate TOTP validation
            // In production, this would validate the code against the stored secret
            
            // For demonstration, accept code "123456"
            isValid = (code == "123456");
        }
        else if (mfaType == "sms") {
            // Simulate SMS code validation
            
            // For demonstration, accept code "123456"
            isValid = (code == "123456");
        }
        else {
            throw std::runtime_error("Unsupported MFA type: " + mfaType);
        }
        
        // Record MFA validation attempt
        recordAuthEvent(userId, "mfa_validate", isValid, "Type: " + mfaType);
        
        if (!isValid) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Invalid MFA code";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k401Unauthorized);
            callback(resp);
            return;
        }
        
        // Prepare response for success
        Json::Value result;
        result["status"] = "success";
        result["message"] = "MFA validated successfully";
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::registerBiometric(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string userId = (*json)["user_id"].asString();
        std::string biometricType = (*json)["biometric_type"].asString();
        std::string biometricData = (*json)["biometric_data"].asString();
        
        // Register biometric data
        bool success = biometricAuth_->registerBiometric(userId, biometricType, biometricData);
        
        if (!success) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Failed to register biometric data";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k500InternalServerError);
            callback(resp);
            return;
        }
        
        // Record biometric registration
        recordAuthEvent(userId, "biometric_register", true, "Type: " + biometricType);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["message"] = "Biometric data registered successfully";
        result["biometric_type"] = biometricType;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::validateBiometric(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string userId = (*json)["user_id"].asString();
        std::string biometricType = (*json)["biometric_type"].asString();
        std::string biometricData = (*json)["biometric_data"].asString();
        
        // Validate biometric data
        bool isValid = biometricAuth_->validateBiometric(userId, biometricType, biometricData);
        
        // Record biometric validation attempt
        recordAuthEvent(userId, "biometric_validate", isValid, "Type: " + biometricType);
        
        if (!isValid) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Biometric validation failed";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k401Unauthorized);
            callback(resp);
            return;
        }
        
        // Generate tokens upon successful biometric authentication
        auto roles = rbac_->getUserRoles(userId);
        std::string accessToken = tokenManager_->generateToken(userId, roles, 60);  // 1 hour expiry
        std::string refreshToken = tokenManager_->generateRefreshToken(userId);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["message"] = "Biometric validation successful";
        result["access_token"] = accessToken;
        result["refresh_token"] = refreshToken;
        result["token_type"] = "Bearer";
        result["expires_in"] = 3600;  // 1 hour in seconds
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::checkPermission(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string userId = (*json)["user_id"].asString();
        std::string resource = (*json)["resource"].asString();
        std::string action = (*json)["action"].asString();
        
        // Check permission
        bool hasPermission = rbac_->checkPermission(userId, resource, action);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["has_permission"] = hasPermission;
        result["user_id"] = userId;
        result["resource"] = resource;
        result["action"] = action;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::getRolePermissions(const drogon::HttpRequestPtr& req,
                         std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                         const std::string& role) {
    try {
        // Get permissions for the role
        Json::Value permissions = rbac_->getRolePermissions(role);
        
        if (permissions["permissions"].empty()) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Role not found: " + role;
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k404NotFound);
            callback(resp);
            return;
        }
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["role"] = role;
        result["permissions"] = permissions["permissions"];
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::updateUserRoles(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                      const std::string& userId) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        // Extract roles from request
        std::vector<std::string> roles;
        for (const auto& role : (*json)["roles"]) {
            roles.push_back(role.asString());
        }
        
        // Update user's roles
        bool success = rbac_->updateUserRoles(userId, roles);
        
        if (!success) {
            Json::Value error;
            error["status"] = "error";
            error["message"] = "Failed to update roles. One or more roles are invalid.";
            
            auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
            resp->setStatusCode(drogon::k400BadRequest);
            callback(resp);
            return;
        }
        
        // Invalidate existing tokens for the user
        tokenManager_->invalidateAllUserTokens(userId);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["message"] = "User roles updated successfully";
        result["user_id"] = userId;
        
        Json::Value rolesJson(Json::arrayValue);
        for (const auto& role : roles) {
            rolesJson.append(role);
        }
        result["roles"] = rolesJson;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::encryptData(const drogon::HttpRequestPtr& req,
                  std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string plaintext = (*json)["plaintext"].asString();
        std::string keyId = (*json).get("key_id", "master").asString();
        
        // Encrypt the data
        std::string ciphertext = encryptionService_->encryptData(plaintext, keyId);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["ciphertext"] = ciphertext;
        result["key_id"] = keyId;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::decryptData(const drogon::HttpRequestPtr& req,
                  std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string ciphertext = (*json)["ciphertext"].asString();
        std::string keyId = (*json).get("key_id", "master").asString();
        
        // Decrypt the data
        std::string plaintext = encryptionService_->decryptData(ciphertext, keyId);
        
        // Prepare response
        Json::Value result;
        result["status"] = "success";
        result["plaintext"] = plaintext;
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::processDeletionRequest(const drogon::HttpRequestPtr& req,
                             std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string userId = (*json)["user_id"].asString();
        std::string requestReason = (*json).get("reason", "User requested data deletion").asString();
        
        // Process deletion request
        Json::Value result = gdprManager_->processDeletionRequest(userId, requestReason);
        
        // Invalidate all tokens for the user
        tokenManager_->invalidateAllUserTokens(userId);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

void SecurityAuthenticationService::exportUserData(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    try {
        std::string userId = (*json)["user_id"].asString();
        
        // Validate token to ensure request is authorized
        std::string token = (*json).get("token", "").asString();
        
        if (!token.empty()) {
            Json::Value payload;
            bool isValid = tokenManager_->validateToken(token, payload);
            
            if (!isValid || payload["sub"].asString() != userId) {
                Json::Value error;
                error["status"] = "error";
                error["message"] = "Unauthorized access";
                
                auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
                resp->setStatusCode(drogon::k403Forbidden);
                callback(resp);
                return;
            }
        }
        
        // Export user data
        Json::Value userData = gdprManager_->exportUserData(userId);
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(userData);
        callback(resp);
    }
    catch (const std::exception& e) {
        Json::Value error;
        error["status"] = "error";
        error["message"] = e.what();
        
        auto resp = drogon::HttpResponse::newHttpJsonResponse(error);
        resp->setStatusCode(drogon::k500InternalServerError);
        callback(resp);
    }
}

// Helper methods
bool SecurityAuthenticationService::verifyPassword(const std::string& hashedPassword, const std::string& plainPassword, const std::string& salt) {
    std::string hashedInput = hashPassword(plainPassword, salt);
    return (hashedInput == hashedPassword);
}

std::string SecurityAuthenticationService::hashPassword(const std::string& password, const std::string& salt) {
    // Combine password and salt
    std::string combined = password + salt;
    
    // Generate SHA-256 hash
    unsigned char hash[SHA256_DIGEST_LENGTH];
    SHA256(reinterpret_cast<const unsigned char*>(combined.c_str()), combined.length(), hash);
    
    // Convert hash to hexadecimal string
    std::stringstream ss;
    for (int i = 0; i < SHA256_DIGEST_LENGTH; ++i) {
        ss << std::hex << std::setw(2) << std::setfill('0') << static_cast<int>(hash[i]);
    }
    
    return ss.str();
}

std::string SecurityAuthenticationService::generateSalt(size_t length) {
    const std::string charset = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz";
    
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_int_distribution<size_t> dist(0, charset.length() - 1);
    
    std::string salt;
    salt.reserve(length);
    
    for (size_t i = 0; i < length; ++i) {
        salt += charset[dist(gen)];
    }
    
    return salt;
}

void SecurityAuthenticationService::recordAuthEvent(const std::string& userId, const std::string& eventType, bool success, const std::string& details) {
    // In production, this would log to a secure audit trail
    // For demonstration, we'll just print to console
    
    std::cout << "Auth Event - User: " << userId
              << ", Event: " << eventType
              << ", Success: " << (success ? "true" : "false");
    
    if (!details.empty()) {
        std::cout << ", Details: " << details;
    }
    
    std::cout << std::endl;
}

} // namespace security
} // namespace atp

// Main application entry point
int main() {
    // Configure Drogon app
    drogon::app().setLogPath("./")
                 .setLogLevel(trantor::Logger::kInfo)
                 .addListener("0.0.0.0", 8083)
                 .setThreadNum(16)
                 .run();
    
    return 0;
}

// backend/security/include/SecurityManager.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <chrono>
#include <optional>
#include <functional>
#include <unordered_map>

#include "core/include/ErrorHandling.h"

namespace APTP::Security {

// Authentication methods
enum class AuthMethod {
    Password,
    JWT,
    OAuth2,
    SAML,
    LDAP,
    MFA,
    BiometricFingerprint,
    BiometricFaceID,
    BiometricVoice,
    HardwareToken
};

// Permission types
enum class Permission {
    // User management
    UserView,
    UserCreate,
    UserEdit,
    UserDelete,
    UserAssignRoles,
    
    // Document management
    DocumentView,
    DocumentCreate,
    DocumentEdit,
    DocumentDelete,
    DocumentShare,
    
    // Syllabus management
    SyllabusView,
    SyllabusCreate,
    SyllabusEdit,
    SyllabusDelete,
    SyllabusApprove,
    
    // Assessment management
    AssessmentView,
    AssessmentCreate,
    AssessmentEdit,
    AssessmentDelete,
    AssessmentGrade,
    AssessmentApprove,
    
    // Analytics
    AnalyticsView,
    AnalyticsExport,
    AnalyticsConfigureDashboard,
    
    // System management
    SystemConfigure,
    SystemBackup,
    SystemRestore,
    SystemMonitor,
    SystemUpgrade,
    
    // Audit
    AuditView,
    AuditExport,
    
    // API
    ApiAccess,
    ApiManage
};

// User role
struct Role {
    std::string id;
    std::string name;
    std::string description;
    std::vector<Permission> permissions;
    std::unordered_map<std::string, std::string> metadata;
};

// Authentication result
struct AuthResult {
    bool success;
    std::string userId;
    std::string token;
    std::chrono::system_clock::time_point expiresAt;
    std::vector<std::string> roles;
    std::vector<Permission> permissions;
    bool requiresMFA;
    std::unordered_map<std::string, std::string> metadata;
};

// JWT token data
struct JWTData {
    std::string userId;
    std::string username;
    std::vector<std::string> roles;
    std::vector<Permission> permissions;
    std::chrono::system_clock::time_point issuedAt;
    std::chrono::system_clock::time_point expiresAt;
    std::unordered_map<std::string, std::string> claims;
};

// Audit log entry
struct AuditLogEntry {
    std::string id;
    std::string userId;
    std::string username;
    std::string action;
    std::string resourceType;
    std::string resourceId;
    std::chrono::system_clock::time_point timestamp;
    std::string ipAddress;
    std::string userAgent;
    bool success;
    std::optional<std::string> errorMessage;
    std::unordered_map<std::string, std::string> metadata;
};

// MFA configuration
struct MFAConfig {
    bool enabled;
    std::vector<AuthMethod> methods;
    bool requireSetup;
    uint32_t tokenValidSeconds;
    uint32_t backupCodesCount;
};

// Security manager class
class SecurityManager {
public:
    static SecurityManager& getInstance();
    
    // Initialize the security manager
    APTP::Core::Result<void> initialize();
    
    // User authentication
    APTP::Core::Result<AuthResult> authenticate(
        const std::string& username,
        const std::string& password);
    
    // Verify MFA code
    APTP::Core::Result<AuthResult> verifyMFA(
        const std::string& userId,
        const std::string& code,
        AuthMethod method);
    
    // Generate JWT token
    APTP::Core::Result<std::string> generateJWT(
        const std::string& userId,
        const std::vector<std::string>& roles,
        const std::vector<Permission>& permissions,
        std::chrono::seconds expiresIn = std::chrono::hours(24));
    
    // Verify JWT token
    APTP::Core::Result<JWTData> verifyJWT(const std::string& token);
    
    // Refresh JWT token
    APTP::Core::Result<std::string> refreshJWT(const std::string& token);
    
    // Check if user has permission
    APTP::Core::Result<bool> hasPermission(
        const std::string& userId,
        Permission permission);
    
    // Check if user has role
    APTP::Core::Result<bool> hasRole(
        const std::string& userId,
        const std::string& roleName);
    
    // Get user roles
    APTP::Core::Result<std::vector<Role>> getUserRoles(const std::string& userId);
    
    // Get user permissions
    APTP::Core::Result<std::vector<Permission>> getUserPermissions(const std::string& userId);
    
    // Create role
    APTP::Core::Result<Role> createRole(
        const std::string& name,
        const std::string& description,
        const std::vector<Permission>& permissions);
    
    // Update role
    APTP::Core::Result<Role> updateRole(
        const std::string& roleId,
        const Role& updatedRole);
    
    // Delete role
    APTP::Core::Result<void> deleteRole(const std::string& roleId);
    
    // Assign role to user
    APTP::Core::Result<void> assignRoleToUser(
        const std::string& userId,
        const std::string& roleId);
    
    // Remove role from user
    APTP::Core::Result<void> removeRoleFromUser(
        const std::string& userId,
        const std::string& roleId);
    
    // Add audit log entry
    APTP::Core::Result<void> addAuditLogEntry(const AuditLogEntry& entry);
    
    // Query audit log
    APTP::Core::Result<std::vector<AuditLogEntry>> queryAuditLog(
        const std::optional<std::string>& userId = std::nullopt,
        const std::optional<std::string>& action = std::nullopt,
        const std::optional<std::string>& resourceType = std::nullopt,
        const std::optional<std::string>& resourceId = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& startTime = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& endTime = std::nullopt,
        const std::optional<bool>& success = std::nullopt,
        size_t limit = 100,
        size_t offset = 0);
    
    // Export audit log
    APTP::Core::Result<std::string> exportAuditLog(
        const std::optional<std::string>& userId = std::nullopt,
        const std::optional<std::string>& action = std::nullopt,
        const std::optional<std::string>& resourceType = std::nullopt,
        const std::optional<std::string>& resourceId = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& startTime = std::nullopt,
        const std::optional<std::chrono::system_clock::time_point>& endTime = std::nullopt,
        const std::optional<bool>& success = std::nullopt,
        const std::string& format = "CSV");
    
    // Set up MFA for user
    APTP::Core::Result<std::string> setupMFA(
        const std::string& userId,
        AuthMethod method);
    
    // Enable MFA for user
    APTP::Core::Result<void> enableMFA(
        const std::string& userId,
        AuthMethod method,
        const std::string& verificationCode);
    
    // Disable MFA for user
    APTP::Core::Result<void> disableMFA(
        const std::string& userId,
        AuthMethod method,
        const std::string& verificationCode);
    
    // Generate backup codes for user
    APTP::Core::Result<std::vector<std::string>> generateBackupCodes(
        const std::string& userId);
    
    // Set MFA configuration
    APTP::Core::Result<void> setMFAConfig(const MFAConfig& config);
    
    // Get MFA configuration
    APTP::Core::Result<MFAConfig> getMFAConfig();
    
    // Encrypt data
    APTP::Core::Result<std::vector<uint8_t>> encryptData(
        const std::vector<uint8_t>& data,
        const std::string& context = "");
    
    // Decrypt data
    APTP::Core::Result<std::vector<uint8_t>> decryptData(
        const std::vector<uint8_t>& encryptedData,
        const std::string& context = "");
    
    // Hash password
    APTP::Core::Result<std::string> hashPassword(const std::string& password);
    
    // Verify password against hash
    APTP::Core::Result<bool> verifyPassword(
        const std::string& password,
        const std::string& hash);

private:
    SecurityManager();
    ~SecurityManager();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Security

// backend/compliance/include/ComplianceManager.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <chrono>
#include <optional>
#include <functional>
#include <unordered_map>
#include <filesystem>

#include "core/include/ErrorHandling.h"
#include "security/include/SecurityManager.h"

namespace APTP::Compliance {

// Regulatory standards/frameworks
enum class RegulatoryFramework {
    FAA,    // Federal Aviation Administration
    EASA,   // European Union Aviation Safety Agency
    ICAO,   // International Civil Aviation Organization
    TCCA,   // Transport Canada Civil Aviation
    CASA,   // Civil Aviation Safety Authority (Australia)
    ISO9001, // Quality Management
    ISO27001, // Information Security
    GDPR,   // General Data Protection Regulation
    HIPAA,  // Health Insurance Portability and Accountability Act
    Custom
};

// Compliance status
enum class ComplianceStatus {
    Compliant,
    PartiallyCompliant,
    NonCompliant,
    Unknown,
    NotApplicable,
    UnderReview
};

// Compliance requirement
struct ComplianceRequirement {
    std::string id;
    RegulatoryFramework framework;
    std::string customFramework; // For custom frameworks
    std::string sectionId;       // e.g., "14 CFR Part 61.57"
    std::string title;
    std::string description;
    std::vector<std::string> tags;
    std::unordered_map<std::string, std::string> metadata;
};

// Compliance assessment
struct ComplianceAssessment {
    std::string id;
    std::string requirementId;
    std::string resourceType; // e.g., "Syllabus", "Document", "Assessment"
    std::string resourceId;
    ComplianceStatus status;
    std::string assessorId;
    std::chrono::system_clock::time_point assessmentDate;
    std::string justification;
    std::vector<std::string> evidenceIds;
    std::unordered_map<std::string, std::string> metadata;
};

// Evidence record
struct EvidenceRecord {
    std::string id;
    std::string title;
    std::string description;
    std::string resourceType;
    std::string resourceId;
    std::string documentId; // If evidence is a document
    std::string url;        // If evidence is external
    std::chrono::system_clock::time_point timestamp;
    std::string creatorId;
    std::vector<std::string> tags;
    std::unordered_map<std::string, std::string> metadata;
};

// Compliance report
struct ComplianceReport {
    std::string id;
    std::string title;
    std::string description;
    std::vector<RegulatoryFramework> frameworks;
    std::vector<ComplianceAssessment> assessments;
    std::chrono::system_clock::time_point generationDate;
    std::string generatorId;
    ComplianceStatus overallStatus;
    double compliancePercentage;
    std::unordered_map<std::string, std::string> metadata;
};

// Document verification result
struct DocumentVerificationResult {
    bool isVerified;
    std::string documentId;
    std::string hash;
    std::chrono::system_clock::time_point timestamp;
    std::optional<std::string> blockchainTransactionId;
    std::optional<std::string> blockchainUrl;
    std::unordered_map<std::string, std::string> metadata;
};

// Callback for compliance status changes
using ComplianceStatusCallback = std::function<void(
    const std::string& resourceType,
    const std::string& resourceId,
    ComplianceStatus oldStatus,
    ComplianceStatus newStatus
)>;

// Compliance manager class
class ComplianceManager {
public:
    static ComplianceManager& getInstance();
    
    // Initialize the compliance manager
    APTP::Core::Result<void> initialize();
    
    // Register compliance requirement
    APTP::Core::Result<ComplianceRequirement> registerRequirement(
        RegulatoryFramework framework,
        const std::string& sectionId,
        const std::string& title,
        const std::string& description);
    
    // Get compliance requirement by ID
    APTP::Core::Result<ComplianceRequirement> getRequirement(const std::string& requirementId);
    
    // Update compliance requirement
    APTP::Core::Result<ComplianceRequirement> updateRequirement(
        const std::string& requirementId,
        const ComplianceRequirement& updatedRequirement);
    
    // Delete compliance requirement
    APTP::Core::Result<void> deleteRequirement(const std::string& requirementId);
    
    // List compliance requirements
    APTP::Core::Result<std::vector<ComplianceRequirement>> listRequirements(
        const std::optional<RegulatoryFramework>& framework = std::nullopt,
        const std::optional<std::string>& sectionId = std::nullopt,
        const std::optional<std::string>& tag = std::nullopt);
    
    // Assess resource compliance
    APTP::Core::Result<ComplianceAssessment> assessCompliance(
        const std::string& requirementId,
        const std::string& resourceType,
        const std::string& resourceId,
        ComplianceStatus status,
        const std::string& assessorId,
        const std::string& justification,
        const std::vector<std::string>& evidenceIds = {});
    
    // Get compliance assessment by ID
    APTP::Core::Result<ComplianceAssessment> getAssessment(const std::string& assessmentId);
    
    // Update compliance assessment
    APTP::Core::Result<ComplianceAssessment> updateAssessment(
        const std::string& assessmentId,
        const ComplianceAssessment& updatedAssessment);
    
    // Delete compliance assessment
    APTP::Core::Result<void> deleteAssessment(const std::string& assessmentId);
    
    // List compliance assessments
    APTP::Core::Result<std::vector<ComplianceAssessment>> listAssessments(
        const std::optional<std::string>& requirementId = std::nullopt,
        const std::optional<std::string>& resourceType = std::nullopt,
        const std::optional<std::string>& resourceId = std::nullopt,
        const std::optional<ComplianceStatus>& status = std::nullopt);
    
    // Add evidence record
    APTP::Core::Result<EvidenceRecord> addEvidence(
        const std::string& title,
        const std::string& description,
        const std::string& resourceType,
        const std::string& resourceId,
        const std::string& creatorId,
        const std::optional<std::string>& documentId = std::nullopt,
        const std::optional<std::string>& url = std::nullopt);
    
    // Get evidence record by ID
    APTP::Core::Result<EvidenceRecord> getEvidence(const std::string& evidenceId);
    
    // Update evidence record
    APTP::Core::Result<EvidenceRecord> updateEvidence(
        const std::string& evidenceId,
        const EvidenceRecord& updatedEvidence);
    
    // Delete evidence record
    APTP::Core::Result<void> deleteEvidence(const std::string& evidenceId);
    
    // List evidence records
    APTP::Core::Result<std::vector<EvidenceRecord>> listEvidence(
        const std::optional<std::string>& resourceType = std::nullopt,
        const std::optional<std::string>& resourceId = std::nullopt,
        const std::optional<std::string>& tag = std::nullopt);
    
    // Generate compliance report
    APTP::Core::Result<ComplianceReport> generateReport(
        const std::string& title,
        const std::string& description,
        const std::vector<RegulatoryFramework>& frameworks,
        const std::string& generatorId);
    
    // Get compliance report by ID
    APTP::Core::Result<ComplianceReport> getReport(const std::string& reportId);
    
    // Export compliance report
    APTP::Core::Result<std::filesystem::path> exportReport(
        const std::string& reportId,
        const std::filesystem::path& outputPath,
        const std::string& format = "PDF");
    
    // Verify document using blockchain
    APTP::Core::Result<DocumentVerificationResult> verifyDocument(
        const std::string& documentId,
        const std::vector<uint8_t>& documentData);
    
    // Register document hash on blockchain
    APTP::Core::Result<DocumentVerificationResult> registerDocumentHash(
        const std::string& documentId,
        const std::vector<uint8_t>& documentData);
    
    // Check resource compliance status
    APTP::Core::Result<ComplianceStatus> getResourceComplianceStatus(
        const std::string& resourceType,
        const std::string& resourceId,
        const std::optional<RegulatoryFramework>& framework = std::nullopt);
    
    // Register for compliance status changes
    void registerComplianceStatusCallback(ComplianceStatusCallback callback);
    
    // Map syllabus to regulatory requirements
    APTP::Core::Result<std::vector<std::pair<std::string, std::string>>> mapSyllabusToRequirements(
        const std::string& syllabusId);
    
    // Calculate compliance metrics
    struct ComplianceMetrics {
        double overallCompliancePercentage;
        std::unordered_map<RegulatoryFramework, double> frameworkCompliancePercentages;
        std::unordered_map<std::string, double> resourceTypeCompliancePercentages;
        size_t totalRequirements;
        size_t compliantRequirements;
        size_t partiallyCompliantRequirements;
        size_t nonCompliantRequirements;
    };
    
    APTP::Core::Result<ComplianceMetrics> calculateComplianceMetrics(
        const std::optional<RegulatoryFramework>& framework = std::nullopt,
        const std::optional<std::string>& resourceType = std::nullopt);

private:
    ComplianceManager();
    ~ComplianceManager();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Compliance

// backend/security/src/SecurityManager.cpp (partial implementation)
#include "SecurityManager.h"
#include "core/include/Logger.h"
#include "core/include/DatabaseManager.h"
#include <jwt-cpp/jwt.h>
#include <openssl/evp.h>
#include <openssl/rand.h>
#include <chrono>
#include <sstream>
#include <iomanip>

namespace APTP::Security {

struct SecurityManager::Impl {
    // Internal implementation details
    bool initialized = false;
    
    // JWT configuration
    std::string jwtSecret;
    std::chrono::seconds jwtExpiresIn = std::chrono::hours(24);
    
    // MFA configuration
    MFAConfig mfaConfig;
    
    // User authentication helper methods
    APTP::Core::Result<std::optional<std::string>> getUserPasswordHash(const std::string& username) {
        // In a real implementation, this would query the database for the user's password hash
        // For this example, we'll return a hardcoded hash for a test user
        
        if (username == "admin") {
            // This would be a properly hashed password in a real system
            return APTP::Core::Success<std::optional<std::string>>(
                "$argon2id$v=19$m=65536,t=3,p=4$salt$hash");
        }
        
        return APTP::Core::Success<std::optional<std::string>>(std::nullopt);
    }
    
    APTP::Core::Result<std::vector<std::string>> getUserRoleIds(const std::string& userId) {
        // In a real implementation, this would query the database for the user's roles
        // For this example, we'll return hardcoded roles for a test user
        
        if (userId == "user-1") {
            return APTP::Core::Success<std::vector<std::string>>({"role-admin", "role-instructor"});
        }
        
        return APTP::Core::Success<std::vector<std::string>>({});
    }
    
    APTP::Core::Result<std::vector<Permission>> getRolePermissions(const std::string& roleId) {
        // In a real implementation, this would query the database for the role's permissions
        // For this example, we'll return hardcoded permissions for test roles
        
        if (roleId == "role-admin") {
            return APTP::Core::Success<std::vector<Permission>>({
                Permission::UserView, Permission::UserCreate, Permission::UserEdit, Permission::UserDelete,
                Permission::SyllabusView, Permission::SyllabusCreate, Permission::SyllabusEdit,
                Permission::SystemConfigure, Permission::AuditView
            });
        } else if (roleId == "role-instructor") {
            return APTP::Core::Success<std::vector<Permission>>({
                Permission::DocumentView, Permission::DocumentCreate,
                Permission::AssessmentView, Permission::AssessmentCreate, Permission::AssessmentGrade,
                Permission::AnalyticsView
            });
        }
        
        return APTP::Core::Success<std::vector<Permission>>({});
    }
    
    // JWT helper methods
    std::string generateJWTToken(
        const std::string& userId,
        const std::vector<std::string>& roles,
        const std::vector<Permission>& permissions,
        std::chrono::seconds expiresIn) {
        
        auto now = std::chrono::system_clock::now();
        auto expiresAt = now + expiresIn;
        
        // Convert permissions to strings for JWT
        std::vector<std::string> permissionStrings;
        for (const auto& permission : permissions) {
            permissionStrings.push_back(std::to_string(static_cast<int>(permission)));
        }
        
        // Create JWT token
        auto token = jwt::create()
            .set_issuer("APTP")
            .set_subject(userId)
            .set_issued_at(std::chrono::system_clock::to_time_t(now))
            .set_expires_at(std::chrono::system_clock::to_time_t(expiresAt))
            .set_payload_claim("roles", jwt::claim(roles))
            .set_payload_claim("permissions", jwt::claim(permissionStrings))
            .sign(jwt::algorithm::hs256{jwtSecret});
        
        return token;
    }
    
    APTP::Core::Result<JWTData> parseJWTToken(const std::string& token) {
        try {
            // Verify and decode JWT token
            auto decoded = jwt::decode(token);
            auto verifier = jwt::verify()
                .allow_algorithm(jwt::algorithm::hs256{jwtSecret})
                .with_issuer("APTP");
            
            verifier.verify(decoded);
            
            // Extract data from token
            JWTData data;
            data.userId = decoded.get_subject();
            
            // Get roles
            auto rolesJson = decoded.get_payload_claim("roles");
            if (!rolesJson.is_null()) {
                for (const auto& role : rolesJson.as_array()) {
                    data.roles.push_back(role.as_string());
                }
            }
            
            // Get permissions
            auto permissionsJson = decoded.get_payload_claim("permissions");
            if (!permissionsJson.is_null()) {
                for (const auto& perm : permissionsJson.as_array()) {
                    data.permissions.push_back(static_cast<Permission>(std::stoi(perm.as_string())));
                }
            }
            
            // Get timestamps
            data.issuedAt = std::chrono::system_clock::from_time_t(decoded.get_issued_at());
            data.expiresAt = std::chrono::system_clock::from_time_t(decoded.get_expires_at());
            
            return APTP::Core::Success(data);
        } catch (const std::exception& e) {
            APTP::Core::Logger::getInstance().error("Failed to parse JWT token: {}", e.what());
            return APTP::Core::Error<JWTData>(APTP::Core::ErrorCode::InvalidArgument);
        }
    }
    
    // Password hashing and verification
    std::string hashPasswordInternal(const std::string& password) {
        // In a real implementation, this would use a proper password hashing algorithm
        // such as Argon2id, bcrypt, or PBKDF2
        // For this example, we'll use a simple hash for demonstration
        
        // Generate a random salt
        unsigned char salt[16];
        RAND_bytes(salt, sizeof(salt));
        
        // Convert salt to hex string
        std::stringstream ss;
        for (unsigned char c : salt) {
            ss << std::hex << std::setw(2) << std::setfill('0') << static_cast<int>(c);
        }
        std::string saltHex = ss.str();
        
        // In a real implementation, you would use a proper password hashing function
        // For example:
        // return argon2id_hash(password, saltHex);
        
        // For this example, we'll use a placeholder
        return "$argon2id$v=19$m=65536,t=3,p=4$" + saltHex + "$hash";
    }
    
    bool verifyPasswordInternal(const std::string& password, const std::string& hash) {
        // In a real implementation, this would use the same algorithm as the hashing function
        // to verify that the provided password matches the stored hash
        // For this example, we'll use a simple verification for demonstration
        
        // In a real implementation, you would use a proper password verification function
        // For example:
        // return argon2id_verify(hash, password);
        
        // For this example, we'll return true for a specific test case
        return (password == "password123" && 
                hash == "$argon2id$v=19$m=65536,t=3,p=4$salt$hash");
    }
    
    // MFA helpers
    std::string generateTOTPSecret() {
        // Generate a random secret for TOTP
        unsigned char secret[20];
        RAND_bytes(secret, sizeof(secret));
        
        // Convert to base32 for QR code
        // In a real implementation, you would use a base32 encoding function
        
        // For this example, we'll return a placeholder
        return "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567";
    }
    
    bool verifyTOTPCode(const std::string& secret, const std::string& code) {
        // In a real implementation, this would verify a TOTP code
        // using the provided secret
        
        // For this example, we'll verify a test code
        return (code == "123456" && secret.length() > 0);
    }
};

SecurityManager& SecurityManager::getInstance() {
    static SecurityManager instance;
    return instance;
}

SecurityManager::SecurityManager() : impl_(std::make_unique<Impl>()) {}
SecurityManager::~SecurityManager() = default;

APTP::Core::Result<void> SecurityManager::initialize() {
    if (impl_->initialized) {
        return APTP::Core::Success();
    }
    
    APTP::Core::Logger::getInstance().info("Initializing SecurityManager");
    
    // Load JWT secret from configuration
    auto configManager = APTP::Core::ConfigurationManager::getInstance();
    auto jwtSecret = configManager.get<std::string>("jwt_secret");
    if (jwtSecret.has_value()) {
        impl_->jwtSecret = *jwtSecret;
    } else {
        // Generate a random secret if not configured
        unsigned char secret[32];
        RAND_bytes(secret, sizeof(secret));
        
        std::stringstream ss;
        for (unsigned char c : secret) {
            ss << std::hex << std::setw(2) << std::setfill('0') << static_cast<int>(c);
        }
        impl_->jwtSecret = ss.str();
        
        // Save to configuration
        configManager.set("jwt_secret", impl_->jwtSecret, APTP::Core::ConfigSource::Environment);
    }
    
    // Initialize default MFA configuration
    impl_->mfaConfig.enabled = false;
    impl_->mfaConfig.methods = {AuthMethod::MFA};
    impl_->mfaConfig.requireSetup = false;
    impl_->mfaConfig.tokenValidSeconds = 30;
    impl_->mfaConfig.backupCodesCount = 10;
    
    impl_->initialized = true;
    return APTP::Core::Success();
}

APTP::Core::Result<AuthResult> SecurityManager::authenticate(
    const std::string& username,
    const std::string& password) {
    
    if (!impl_->initialized) {
        return APTP::Core::Error<AuthResult>(APTP::Core::ErrorCode::InvalidState);
    }
    
    APTP::Core::Logger::getInstance().info("Authentication attempt for user: {}", username);
    
    try {
        // Get user's password hash
        auto hashResult = impl_->getUserPasswordHash(username);
        if (hashResult.isError()) {
            return APTP::Core::Error<AuthResult>(APTP::Core::ErrorCode::SecurityError);
        }
        
        auto hash = hashResult.value();
        if (!hash.has_value()) {
            APTP::Core::Logger::getInstance().warning("User not found: {}", username);
            
            // Return authentication failure
            AuthResult result;
            result.success = false;
            return APTP::Core::Success(result);
        }
        
        // Verify password
        if (!impl_->verifyPasswordInternal(password, *hash)) {
            APTP::Core::Logger::getInstance().warning("Invalid password for user: {}", username);
            
            // Return authentication failure
            AuthResult result;
            result.success = false;
            return APTP::Core::Success(result);
        }
        
        // User authenticated successfully
        APTP::Core::Logger::getInstance().info("User authenticated successfully: {}", username);
        
        // In a real implementation, this would fetch the user's ID, roles, and permissions
        // from the database
        
        // For this example, we'll use a hardcoded user
        std::string userId = "user-1";
        
        // Get user roles
        auto rolesResult = impl_->getUserRoleIds(userId);
        if (rolesResult.isError()) {
            return APTP::Core::Error<AuthResult>(APTP::Core::ErrorCode::SecurityError);
        }
        
        std::vector<std::string> roles = rolesResult.value();
        
        // Get permissions for each role
        std::vector<Permission> permissions;
        for (const auto& roleId : roles) {
            auto permsResult = impl_->getRolePermissions(roleId);
            if (permsResult.isSuccess()) {
                auto rolePerms = permsResult.value();
                permissions.insert(permissions.end(), rolePerms.begin(), rolePerms.end());
            }
        }
        
        // Remove duplicate permissions
        std::sort(permissions.begin(), permissions.end());
        permissions.erase(std::unique(permissions.begin(), permissions.end()), permissions.end());
        
        // Generate JWT token
        auto token = impl_->generateJWTToken(userId, roles, permissions, impl_->jwtExpiresIn);
        
        // Create authentication result
        AuthResult result;
        result.success = true;
        result.userId = userId;
        result.token = token;
        result.expiresAt = std::chrono::system_clock::now() + impl_->jwtExpiresIn;
        result.roles = roles;
        result.permissions = permissions;
        result.requiresMFA = impl_->mfaConfig.enabled;
        
        return APTP::Core::Success(result);
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Authentication error: {}", e.what());
        return APTP::Core::Error<AuthResult>(APTP::Core::ErrorCode::SecurityError);
    }
}

APTP::Core::Result<std::string> SecurityManager::generateJWT(
    const std::string& userId,
    const std::vector<std::string>& roles,
    const std::vector<Permission>& permissions,
    std::chrono::seconds expiresIn) {
    
    if (!impl_->initialized) {
        return APTP::Core::Error<std::string>(APTP::Core::ErrorCode::InvalidState);
    }
    
    try {
        return APTP::Core::Success(impl_->generateJWTToken(userId, roles, permissions, expiresIn));
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("JWT generation error: {}", e.what());
        return APTP::Core::Error<std::string>(APTP::Core::ErrorCode::SecurityError);
    }
}

APTP::Core::Result<JWTData> SecurityManager::verifyJWT(const std::string& token) {
    if (!impl_->initialized) {
        return APTP::Core::Error<JWTData>(APTP::Core::ErrorCode::InvalidState);
    }
    
    return impl_->parseJWTToken(token);
}

APTP::Core::Result<std::string> SecurityManager::hashPassword(const std::string& password) {
    if (!impl_->initialized) {
        return APTP::Core::Error<std::string>(APTP::Core::ErrorCode::InvalidState);
    }
    
    try {
        return APTP::Core::Success(impl_->hashPasswordInternal(password));
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Password hashing error: {}", e.what());
        return APTP::Core::Error<std::string>(APTP::Core::ErrorCode::SecurityError);
    }
}

APTP::Core::Result<bool> SecurityManager::verifyPassword(
    const std::string& password,
    const std::string& hash) {
    
    if (!impl_->initialized) {
        return APTP::Core::Error<bool>(APTP::Core::ErrorCode::InvalidState);
    }
    
    try {
        return APTP::Core::Success(impl_->verifyPasswordInternal(password, hash));
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Password verification error: {}", e.what());
        return APTP::Core::Error<bool>(APTP::Core::ErrorCode::SecurityError);
    }
}

APTP::Core::Result<std::string> SecurityManager::setupMFA(
    const std::string& userId,
    AuthMethod method) {
    
    if (!impl_->initialized) {
        return APTP::Core::Error<std::string>(APTP::Core::ErrorCode::InvalidState);
    }
    
    if (method != AuthMethod::MFA) {
        return APTP::Core::Error<std::string>(APTP::Core::ErrorCode::InvalidArgument);
    }
    
    try {
        // Generate TOTP secret
        std::string secret = impl_->generateTOTPSecret();
        
        // In a real implementation, this would store the secret in the database
        // associated with the user
        
        // Return the secret for QR code generation
        return APTP::Core::Success(secret);
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("MFA setup error: {}", e.what());
        return APTP::Core::Error<std::string>(APTP::Core::ErrorCode::SecurityError);
    }
}

APTP::Core::Result<void> SecurityManager::enableMFA(
    const std::string& userId,
    AuthMethod method,
    const std::string& verificationCode) {
    
    if (!impl_->initialized) {
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::InvalidState);
    }
    
    if (method != AuthMethod::MFA) {
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::InvalidArgument);
    }
    
    try {
        // In a real implementation, this would retrieve the user's TOTP secret
        // and verify the provided code
        std::string secret = "ABCDEFGHIJKLMNOPQRSTUVWXYZ234567"; // Placeholder
        
        if (!impl_->verifyTOTPCode(secret, verificationCode)) {
            return APTP::Core::Error<void>(APTP::Core::ErrorCode::InvalidArgument);
        }
        
        // Mark MFA as enabled for the user
        // In a real implementation, this would update the database
        
        return APTP::Core::Success();
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("MFA enable error: {}", e.what());
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::SecurityError);
    }
}

// Additional method implementations would follow a similar pattern

} // namespace APTP::Security

// backend/compliance/src/ComplianceManager.cpp would have a similar implementation pattern

#include <string>
#include <vector>
#include <chrono>
#include <memory>
#include <optional>
#include <unordered_map>
#include <cstring>
#include <openssl/evp.h>
#include <openssl/rand.h>
#include <openssl/hmac.h>
#include <openssl/aes.h>
#include <jwt-cpp/jwt.h>
#include <nlohmann/json.hpp>
#include <pqxx/pqxx>
#include <spdlog/spdlog.h>

// Forward declarations
namespace db {
    class DatabaseConnection;
}

namespace security {

// Constants
constexpr size_t AES_KEY_SIZE = 32; // 256 bits
constexpr size_t IV_SIZE = 16;      // 128 bits
constexpr size_t SALT_SIZE = 16;    // 128 bits
constexpr int PBKDF2_ITERATIONS = 10000;

using json = nlohmann::json;

/**
 * Enumeration for different security log levels
 */
enum class SecurityLogLevel {
    INFO,
    WARNING,
    ERROR,
    CRITICAL
};

/**
 * Enumeration for different permission types
 */
enum class Permission {
    READ,
    WRITE,
    DELETE,
    ADMIN
};

/**
 * Role-based permissions class
 */
class RolePermissions {
public:
    // Predefined roles
    static const std::string ROLE_ADMIN;
    static const std::string ROLE_INSTRUCTOR;
    static const std::string ROLE_TRAINEE;
    static const std::string ROLE_ANALYST;
    static const std::string ROLE_SUPPORT;

    /**
     * Check if a role has a specific permission for a resource
     */
    static bool hasPermission(
        const std::string& role,
        const std::string& resource,
        Permission permission
    );

    /**
     * Get all permissions for a role
     */
    static std::unordered_map<std::string, std::vector<Permission>> 
    getRolePermissions(const std::string& role);

    /**
     * Add a permission to a role
     */
    static void addPermission(
        const std::string& role,
        const std::string& resource,
        Permission permission
    );

    /**
     * Remove a permission from a role
     */
    static void removePermission(
        const std::string& role,
        const std::string& resource,
        Permission permission
    );

private:
    // Role-based permission mappings
    static std::unordered_map<std::string, 
           std::unordered_map<std::string, std::vector<Permission>>> rolePermissionsMap;
    
    // Initialize default role permissions
    static void initializeDefaultPermissions();
    
    // Singleton initialization flag
    static bool initialized;
};

/**
 * JWT Authentication Service
 */
class JwtAuthService {
public:
    /**
     * Constructor
     */
    JwtAuthService(
        const std::string& secretKey, 
        const std::string& issuer,
        std::shared_ptr<db::DatabaseConnection> dbConnection
    );

    /**
     * Generate a JWT token for a user
     */
    std::string generateToken(
        const std::string& userId,
        const std::string& username,
        const std::string& role,
        const std::vector<std::string>& permissions,
        const std::optional<std::chrono::seconds>& expiresIn = std::nullopt
    );

    /**
     * Validate a JWT token
     */
    bool validateToken(const std::string& token);

    /**
     * Decode token and extract claims
     */
    std::optional<json> decodeToken(const std::string& token);

    /**
     * Refresh a token with new expiration
     */
    std::string refreshToken(const std::string& token);

    /**
     * Revoke a token
     */
    bool revokeToken(const std::string& token);

    /**
     * Check if a token has been revoked
     */
    bool isTokenRevoked(const std::string& token);

private:
    std::string secretKey;
    std::string issuer;
    std::chrono::seconds defaultExpiryTime;
    std::shared_ptr<db::DatabaseConnection> dbConnection;
    
    // Cache of revoked tokens (to avoid DB lookups for every request)
    std::unordered_map<std::string, std::chrono::system_clock::time_point> revokedTokensCache;
    
    // Extract token ID from token
    std::string extractTokenId(const std::string& token);
    
    // Update revoked tokens cache from database
    void updateRevokedTokensCache();
};

/**
 * Multi-factor authentication service
 */
class MfaService {
public:
    /**
     * Constructor
     */
    MfaService(std::shared_ptr<db::DatabaseConnection> dbConnection);

    /**
     * Generate a new secret key for TOTP
     */
    std::string generateTotpSecret();

    /**
     * Generate a QR code URL for TOTP setup
     */
    std::string generateQrCodeUrl(
        const std::string& secret,
        const std::string& accountName,
        const std::string& issuer
    );

    /**
     * Validate a TOTP code
     */
    bool validateTotpCode(const std::string& secret, const std::string& code);

    /**
     * Enable MFA for a user
     */
    bool enableMfaForUser(const std::string& userId, const std::string& secret);

    /**
     * Disable MFA for a user
     */
    bool disableMfaForUser(const std::string& userId);

    /**
     * Check if MFA is enabled for a user
     */
    bool isMfaEnabledForUser(const std::string& userId);

    /**
     * Generate backup codes for a user
     */
    std::vector<std::string> generateBackupCodes(const std::string& userId);

    /**
     * Validate a backup code
     */
    bool validateBackupCode(const std::string& userId, const std::string& code);

private:
    std::shared_ptr<db::DatabaseConnection> dbConnection;
    
    // HMAC-based One-time Password (HOTP) implementation
    std::string generateHotp(const std::string& secret, uint64_t counter);
    
    // Time-based One-time Password (TOTP) implementation
    std::string generateTotp(const std::string& secret, uint64_t timeStep = 30);
    
    // Get current UNIX time
    uint64_t getCurrentTime();
};

/**
 * Encryption service for sensitive data
 */
class EncryptionService {
public:
    /**
     * Constructor
     */
    EncryptionService(const std::string& masterKey);

    /**
     * Encrypt data using AES-256 GCM
     */
    std::string encrypt(const std::string& plaintext);

    /**
     * Decrypt data using AES-256 GCM
     */
    std::optional<std::string> decrypt(const std::string& ciphertext);

    /**
     * Hash a password using PBKDF2
     */
    std::string hashPassword(const std::string& password);

    /**
     * Verify a password against its hash
     */
    bool verifyPassword(const std::string& password, const std::string& passwordHash);

    /**
     * Generate a random string of specified length
     */
    static std::string generateRandomString(size_t length);

private:
    std::string masterKey;
    
    // Derive encryption key from master key
    std::vector<uint8_t> deriveKey(
        const std::string& salt,
        const std::string& key,
        size_t keyLength
    );
    
    // Generate random initialization vector
    std::vector<uint8_t> generateIv();
    
    // Generate random salt
    std::vector<uint8_t> generateSalt();
    
    // Encode binary data to base64
    std::string base64Encode(const std::vector<uint8_t>& data);
    
    // Decode base64 to binary data
    std::vector<uint8_t> base64Decode(const std::string& encoded);
};

/**
 * Audit logging service
 */
class AuditLogService {
public:
    /**
     * Constructor
     */
    AuditLogService(std::shared_ptr<db::DatabaseConnection> dbConnection);

    /**
     * Log an audit event
     */
    void logEvent(
        const std::string& userId,
        const std::string& action,
        const std::string& entityType,
        const std::string& entityId,
        const std::string& ipAddress,
        const std::string& userAgent,
        const json& details,
        const std::string& status = "success"
    );

    /**
     * Log a failed authentication attempt
     */
    void logFailedAuthentication(
        const std::string& username,
        const std::string& ipAddress,
        const std::string& userAgent,
        const std::string& reason
    );

    /**
     * Get audit logs for a user
     */
    std::vector<json> getUserAuditLogs(
        const std::string& userId,
        size_t limit = 100,
        size_t offset = 0
    );

    /**
     * Get audit logs for an entity
     */
    std::vector<json> getEntityAuditLogs(
        const std::string& entityType,
        const std::string& entityId,
        size_t limit = 100,
        size_t offset = 0
    );

    /**
     * Search audit logs
     */
    std::vector<json> searchAuditLogs(
        const std::optional<std::string>& userId,
        const std::optional<std::string>& action,
        const std::optional<std::string>& entityType,
        const std::optional<std::string>& entityId,
        const std::optional<std::string>& status,
        const std::optional<std::chrono::system_clock::time_point>& startTime,
        const std::optional<std::chrono::system_clock::time_point>& endTime,
        size_t limit = 100,
        size_t offset = 0
    );

private:
    std::shared_ptr<db::DatabaseConnection> dbConnection;
    
    // Format timestamp for database
    std::string formatTimestamp(const std::chrono::system_clock::time_point& timePoint);
};

/**
 * Rate limiting service to prevent brute force attacks
 */
class RateLimitService {
public:
    /**
     * Constructor
     */
    RateLimitService(
        size_t maxAttempts = 5,
        std::chrono::seconds windowDuration = std::chrono::seconds(300)
    );

    /**
     * Record an attempt and check if rate limit is exceeded
     */
    bool checkRateLimit(const std::string& key);

    /**
     * Reset attempts for a key
     */
    void resetAttempts(const std::string& key);

    /**
     * Get remaining attempts for a key
     */
    size_t getRemainingAttempts(const std::string& key);

    /**
     * Get time until rate limit reset
     */
    std::chrono::seconds getTimeUntilReset(const std::string& key);

private:
    struct RateLimitInfo {
        size_t attempts;
        std::chrono::system_clock::time_point windowStart;
    };
    
    size_t maxAttempts;
    std::chrono::seconds windowDuration;
    std::unordered_map<std::string, RateLimitInfo> rateLimitMap;
    
    // Clean expired entries from rate limit map
    void cleanExpiredEntries();
};

/**
 * Main security service that combines all security features
 */
class SecurityService {
public:
    /**
     * Constructor
     */
    SecurityService(
        const std::string& jwtSecret,
        const std::string& jwtIssuer,
        const std::string& encryptionMasterKey,
        std::shared_ptr<db::DatabaseConnection> dbConnection
    );

    /**
     * Get JWT authentication service
     */
    std::shared_ptr<JwtAuthService> getJwtAuthService() const;

    /**
     * Get MFA service
     */
    std::shared_ptr<MfaService> getMfaService() const;

    /**
     * Get encryption service
     */
    std::shared_ptr<EncryptionService> getEncryptionService() const;

    /**
     * Get audit log service
     */
    std::shared_ptr<AuditLogService> getAuditLogService() const;

    /**
     * Get rate limit service
     */
    std::shared_ptr<RateLimitService> getRateLimitService() const;

    /**
     * Check if a user has permission for an action
     */
    bool checkPermission(
        const std::string& userId,
        const std::string& resource,
        Permission permission
    );

    /**
     * Authenticate a user with username and password
     */
    std::optional<json> authenticateUser(
        const std::string& username,
        const std::string& password,
        const std::string& ipAddress,
        const std::string& userAgent
    );

    /**
     * Complete MFA authentication
     */
    std::optional<std::string> completeMfaAuthentication(
        const std::string& userId,
        const std::string& mfaCode
    );

    /**
     * Encrypt and store sensitive data
     */
    bool storeSensitiveData(
        const std::string& entityType,
        const std::string& entityId,
        const std::string& fieldName,
        const std::string& value
    );

    /**
     * Retrieve and decrypt sensitive data
     */
    std::optional<std::string> retrieveSensitiveData(
        const std::string& entityType,
        const std::string& entityId,
        const std::string& fieldName
    );

    /**
     * Log security event
     */
    void logSecurityEvent(
        SecurityLogLevel level,
        const std::string& message,
        const json& details = json::object()
    );

private:
    std::shared_ptr<JwtAuthService> jwtAuthService;
    std::shared_ptr<MfaService> mfaService;
    std::shared_ptr<EncryptionService> encryptionService;
    std::shared_ptr<AuditLogService> auditLogService;
    std::shared_ptr<RateLimitService> rateLimitService;
    std::shared_ptr<db::DatabaseConnection> dbConnection;
    
    // Get user role and permissions from database
    std::optional<std::pair<std::string, std::vector<std::string>>> 
    getUserRoleAndPermissions(const std::string& userId);
    
    // Get user by username
    std::optional<json> getUserByUsername(const std::string& username);
};

// Implementation of SecurityService methods

SecurityService::SecurityService(
    const std::string& jwtSecret,
    const std::string& jwtIssuer,
    const std::string& encryptionMasterKey,
    std::shared_ptr<db::DatabaseConnection> dbConnection
) : dbConnection(dbConnection) {
    // Initialize services
    jwtAuthService = std::make_shared<JwtAuthService>(jwtSecret, jwtIssuer, dbConnection);
    mfaService = std::make_shared<MfaService>(dbConnection);
    encryptionService = std::make_shared<EncryptionService>(encryptionMasterKey);
    auditLogService = std::make_shared<AuditLogService>(dbConnection);
    rateLimitService = std::make_shared<RateLimitService>();
    
    // Initialize role permissions
    if (!RolePermissions::initialized) {
        RolePermissions::initializeDefaultPermissions();
    }
    
    spdlog::info("Security service initialized");
}

std::shared_ptr<JwtAuthService> SecurityService::getJwtAuthService() const {
    return jwtAuthService;
}

std::shared_ptr<MfaService> SecurityService::getMfaService() const {
    return mfaService;
}

std::shared_ptr<EncryptionService> SecurityService::getEncryptionService() const {
    return encryptionService;
}

std::shared_ptr<AuditLogService> SecurityService::getAuditLogService() const {
    return auditLogService;
}

std::shared_ptr<RateLimitService> SecurityService::getRateLimitService() const {
    return rateLimitService;
}

bool SecurityService::checkPermission(
    const std::string& userId,
    const std::string& resource,
    Permission permission
) {
    // Get user role and permissions
    auto roleAndPermissions = getUserRoleAndPermissions(userId);
    
    if (!roleAndPermissions) {
        return false;
    }
    
    const auto& [role, permissions] = *roleAndPermissions;
    
    // Check role-based permission
    if (RolePermissions::hasPermission(role, resource, permission)) {
        return true;
    }
    
    // TODO: Check user-specific permissions if needed
    
    return false;
}

std::optional<json> SecurityService::authenticateUser(
    const std::string& username,
    const std::string& password,
    const std::string& ipAddress,
    const std::string& userAgent
) {
    // Check rate limit for login attempts
    std::string rateLimitKey = "auth:" + username + ":" + ipAddress;
    if (rateLimitService->checkRateLimit(rateLimitKey)) {
        logSecurityEvent(
            SecurityLogLevel::WARNING,
            "Rate limit exceeded for authentication",
            {{"username", username}, {"ip_address", ipAddress}}
        );
        auditLogService->logFailedAuthentication(
            username, ipAddress, userAgent, "Rate limit exceeded"
        );
        return std::nullopt;
    }
    
    // Get user from database
    auto user = getUserByUsername(username);
    if (!user) {
        rateLimitService->checkRateLimit(rateLimitKey); // Increment attempt counter
        auditLogService->logFailedAuthentication(
            username, ipAddress, userAgent, "User not found"
        );
        return std::nullopt;
    }
    
    // Verify password
    const std::string storedHash = (*user)["password_hash"];
    if (!encryptionService->verifyPassword(password, storedHash)) {
        rateLimitService->checkRateLimit(rateLimitKey); // Increment attempt counter
        auditLogService->logFailedAuthentication(
            username, ipAddress, userAgent, "Invalid password"
        );
        return std::nullopt;
    }
    
    // Reset rate limit attempts on successful authentication
    rateLimitService->resetAttempts(rateLimitKey);
    
    // Check if MFA is required
    const bool mfaEnabled = (*user)["mfa_enabled"];
    if (mfaEnabled) {
        // Return partial auth info for MFA step
        json mfaInfo = {
            {"user_id", (*user)["id"]},
            {"username", username},
            {"mfa_required", true}
        };
        return mfaInfo;
    }
    
    // Get user role and permissions
    const std::string userId = (*user)["id"];
    auto roleAndPermissions = getUserRoleAndPermissions(userId);
    
    if (!roleAndPermissions) {
        auditLogService->logFailedAuthentication(
            username, ipAddress, userAgent, "Role or permissions not found"
        );
        return std::nullopt;
    }
    
    const auto& [role, permissions] = *roleAndPermissions;
    
    // Generate JWT token
    std::string token = jwtAuthService->generateToken(
        userId, username, role, permissions
    );
    
    // Log successful authentication
    auditLogService->logEvent(
        userId, "authentication", "user", userId, ipAddress, userAgent, {}, "success"
    );
    
    // Return auth info
    json authInfo = {
        {"user_id", userId},
        {"username", username},
        {"role", role},
        {"token", token},
        {"permissions", permissions}
    };
    
    return authInfo;
}

std::optional<std::string> SecurityService::completeMfaAuthentication(
    const std::string& userId,
    const std::string& mfaCode
) {
    // Get user from database
    // This implementation assumes a method to get user by ID
    // For brevity, this is not fully implemented
    std::string username = "user"; // Placeholder
    
    // Verify MFA code
    if (!mfaService->validateTotpCode("user_secret", mfaCode) && 
        !mfaService->validateBackupCode(userId, mfaCode)) {
        return std::nullopt;
    }
    
    // Get user role and permissions
    auto roleAndPermissions = getUserRoleAndPermissions(userId);
    
    if (!roleAndPermissions) {
        return std::nullopt;
    }
    
    const auto& [role, permissions] = *roleAndPermissions;
    
    // Generate JWT token
    std::string token = jwtAuthService->generateToken(
        userId, username, role, permissions
    );
    
    return token;
}

bool SecurityService::storeSensitiveData(
    const std::string& entityType,
    const std::string& entityId,
    const std::string& fieldName,
    const std::string& value
) {
    // Encrypt the sensitive data
    std::string encryptedValue = encryptionService->encrypt(value);
    
    try {
        // Store in database
        pqxx::work txn(*static_cast<pqxx::connection*>(dbConnection.get()));
        
        txn.exec_params(
            "INSERT INTO encrypted_data (entity_type, entity_id, field_name, encrypted_value, encryption_method) "
            "VALUES ($1, $2, $3, $4, $5) "
            "ON CONFLICT (entity_type, entity_id, field_name) "
            "DO UPDATE SET encrypted_value = EXCLUDED.encrypted_value, "
            "encryption_method = EXCLUDED.encryption_method, "
            "updated_at = NOW()",
            entityType, entityId, fieldName, encryptedValue, "AES-256-GCM"
        );
        
        txn.commit();
        return true;
    } catch (const std::exception& e) {
        spdlog::error("Failed to store encrypted data: {}", e.what());
        return false;
    }
}

std::optional<std::string> SecurityService::retrieveSensitiveData(
    const std::string& entityType,
    const std::string& entityId,
    const std::string& fieldName
) {
    try {
        // Retrieve from database
        pqxx::work txn(*static_cast<pqxx::connection*>(dbConnection.get()));
        
        auto result = txn.exec_params(
            "SELECT encrypted_value FROM encrypted_data "
            "WHERE entity_type = $1 AND entity_id = $2 AND field_name = $3",
            entityType, entityId, fieldName
        );
        
        if (result.empty()) {
            return std::nullopt;
        }
        
        std::string encryptedValue = result[0][0].as<std::string>();
        
        // Decrypt the value
        auto decryptedValue = encryptionService->decrypt(encryptedValue);
        return decryptedValue;
    } catch (const std::exception& e) {
        spdlog::error("Failed to retrieve encrypted data: {}", e.what());
        return std::nullopt;
    }
}

void SecurityService::logSecurityEvent(
    SecurityLogLevel level,
    const std::string& message,
    const json& details
) {
    std::string levelStr;
    
    switch (level) {
        case SecurityLogLevel::INFO:
            levelStr = "INFO";
            spdlog::info("[SECURITY] {}", message);
            break;
        case SecurityLogLevel::WARNING:
            levelStr = "WARNING";
            spdlog::warn("[SECURITY] {}", message);
            break;
        case SecurityLogLevel::ERROR:
            levelStr = "ERROR";
            spdlog::error("[SECURITY] {}", message);
            break;
        case SecurityLogLevel::CRITICAL:
            levelStr = "CRITICAL";
            spdlog::critical("[SECURITY] {}", message);
            break;
    }
    
    // Store security event in audit log
    json eventDetails = details;
    eventDetails["security_level"] = levelStr;
    
    auditLogService->logEvent(
        "", // No user ID for system events
        "security_event",
        "system",
        "",
        "",
        "",
        eventDetails
    );
}

std::optional<std::pair<std::string, std::vector<std::string>>> 
SecurityService::getUserRoleAndPermissions(const std::string& userId) {
    try {
        pqxx::work txn(*static_cast<pqxx::connection*>(dbConnection.get()));
        
        auto result = txn.exec_params(
            "SELECT role FROM users WHERE id = $1",
            userId
        );
        
        if (result.empty()) {
            return std::nullopt;
        }
        
        std::string role = result[0][0].as<std::string>();
        auto permissionsMap = RolePermissions::getRolePermissions(role);
        
        // Convert permission map to flat list of strings for JWT
        std::vector<std::string> permissionsList;
        for (const auto& [resource, permissions] : permissionsMap) {
            for (const auto& permission : permissions) {
                std::string permString;
                switch (permission) {
                    case Permission::READ:
                        permString = "read";
                        break;
                    case Permission::WRITE:
                        permString = "write";
                        break;
                    case Permission::DELETE:
                        permString = "delete";
                        break;
                    case Permission::ADMIN:
                        permString = "admin";
                        break;
                }
                permissionsList.push_back(resource + ":" + permString);
            }
        }
        
        return std::make_pair(role, permissionsList);
    } catch (const std::exception& e) {
        spdlog::error("Failed to get user role and permissions: {}", e.what());
        return std::nullopt;
    }
}

std::optional<json> SecurityService::getUserByUsername(const std::string& username) {
    try {
        pqxx::work txn(*static_cast<pqxx::connection*>(dbConnection.get()));
        
        auto result = txn.exec_params(
            "SELECT id, username, password_hash, role, mfa_enabled "
            "FROM users WHERE username = $1",
            username
        );
        
        if (result.empty()) {
            return std::nullopt;
        }
        
        json user = {
            {"id", result[0][0].as<std::string>()},
            {"username", result[0][1].as<std::string>()},
            {"password_hash", result[0][2].as<std::string>()},
            {"role", result[0][3].as<std::string>()},
            {"mfa_enabled", result[0][4].as<bool>()}
        };
        
        return user;
    } catch (const std::exception& e) {
        spdlog::error("Failed to get user by username: {}", e.what());
        return std::nullopt;
    }
}

// Implementation of EncryptionService methods

EncryptionService::EncryptionService(const std::string& masterKey) 
    : masterKey(masterKey) {
    // Initialize OpenSSL
    OpenSSL_add_all_algorithms();
}

std::string EncryptionService::encrypt(const std::string& plaintext) {
    // Generate random salt
    auto salt = generateSalt();
    
    // Derive key from master key and salt
    auto key = deriveKey(std::string(salt.begin(), salt.end()), masterKey, AES_KEY_SIZE);
    
    // Generate random IV
    auto iv = generateIv();
    
    // Prepare encryption context
    EVP_CIPHER_CTX* ctx = EVP_CIPHER_CTX_new();
    if (!ctx) {
        throw std::runtime_error("Failed to create encryption context");
    }
    
    // Initialize encryption operation
    if (EVP_EncryptInit_ex(ctx, EVP_aes_256_gcm(), nullptr, key.data(), iv.data()) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to initialize encryption");
    }
    
    // Prepare output buffer
    std::vector<uint8_t> ciphertext(plaintext.size() + EVP_MAX_BLOCK_LENGTH);
    int outlen = 0;
    
    // Encrypt data
    if (EVP_EncryptUpdate(ctx, ciphertext.data(), &outlen, 
                        reinterpret_cast<const uint8_t*>(plaintext.data()), 
                        plaintext.size()) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to encrypt data");
    }
    
    int tmplen = 0;
    
    // Finalize encryption
    if (EVP_EncryptFinal_ex(ctx, ciphertext.data() + outlen, &tmplen) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to finalize encryption");
    }
    
    outlen += tmplen;
    ciphertext.resize(outlen);
    
    // Get authentication tag
    std::vector<uint8_t> tag(16);
    if (EVP_CIPHER_CTX_ctrl(ctx, EVP_CTRL_GCM_GET_TAG, 16, tag.data()) != 1) {
        EVP_CIPHER_CTX_free(ctx);
        throw std::runtime_error("Failed to get authentication tag");
    }
    
    EVP_CIPHER_CTX_free(ctx);
    
    // Combine salt, IV, ciphertext, and tag
    std::vector<uint8_t> result;
    result.insert(result.end(), salt.begin(), salt.end());
    result.insert(result.end(), iv.begin(), iv.end());
    result.insert(result.end(), ciphertext.begin(), ciphertext.end());
    result.insert(result.end(), tag.begin(), tag.end());
    
    // Base64 encode the result
    return base64Encode(result);
}

std::optional<std::string> EncryptionService::decrypt(const std::string& ciphertext) {
    try {
        // Base64 decode
        auto data = base64Decode(ciphertext);
        
        // Extract salt, IV, ciphertext, and tag
        if (data.size() < SALT_SIZE + IV_SIZE + 16) {
            // Invalid format
            return std::nullopt;
        }
        
        std::vector<uint8_t> salt(data.begin(), data.begin() + SALT_SIZE);
        std::vector<uint8_t> iv(data.begin() + SALT_SIZE, data.begin() + SALT_SIZE + IV_SIZE);
        std::vector<uint8_t> tag(data.end() - 16, data.end());
        std::vector<uint8_t> encryptedData(data.begin() + SALT_SIZE + IV_SIZE, data.end() - 16);
        
        // Derive key from master key and salt
        auto key = deriveKey(std::string(salt.begin(), salt.end()), masterKey, AES_KEY_SIZE);
        
        // Prepare decryption context
        EVP_CIPHER_CTX* ctx = EVP_CIPHER_CTX_new();
        if (!ctx) {
            throw std::runtime_error("Failed to create decryption context");
        }
        
        // Initialize decryption operation
        if (EVP_DecryptInit_ex(ctx, EVP_aes_256_gcm(), nullptr, key.data(), iv.data()) != 1) {
            EVP_CIPHER_CTX_free(ctx);
            throw std::runtime_error("Failed to initialize decryption");
        }
        
        // Set authentication tag
        if (EVP_CIPHER_CTX_ctrl(ctx, EVP_CTRL_GCM_SET_TAG, tag.size(), tag.data()) != 1) {
            EVP_CIPHER_CTX_free(ctx);
            throw std::runtime_error("Failed to set authentication tag");
        }
        
        // Prepare output buffer
        std::vector<uint8_t> plaintext(encryptedData.size());
        int outlen = 0;
        
        // Decrypt data
        if (EVP_DecryptUpdate(ctx, plaintext.data(), &outlen, 
                            encryptedData.data(), encryptedData.size()) != 1) {
            EVP_CIPHER_CTX_free(ctx);
            throw std::runtime_error("Failed to decrypt data");
        }
        
        int tmplen = 0;
        
        // Finalize decryption
        if (EVP_DecryptFinal_ex(ctx, plaintext.data() + outlen, &tmplen) != 1) {
            // Authentication failed
            EVP_CIPHER_CTX_free(ctx);
            return std::nullopt;
        }
        
        outlen += tmplen;
        plaintext.resize(outlen);
        
        EVP_CIPHER_CTX_free(ctx);
        
        // Convert to string
        return std::string(plaintext.begin(), plaintext.end());
    } catch (const std::exception& e) {
        spdlog::error("Decryption failed: {}", e.what());
        return std::nullopt;
    }
}

std::string EncryptionService::hashPassword(const std::string& password) {
    // Generate random salt
    auto salt = generateSalt();
    
    // Derive key using PBKDF2
    std::vector<uint8_t> derivedKey(32); // 256 bits
    
    if (PKCS5_PBKDF2_HMAC(
            password.c_str(),
            password.size(),
            salt.data(),
            salt.size(),
            PBKDF2_ITERATIONS,
            EVP_sha256(),
            derivedKey.size(),
            derivedKey.data()) != 1) {
        throw std::runtime_error("Failed to derive key for password");
    }
    
    // Combine salt and derived key
    std::vector<uint8_t> result;
    result.insert(result.end(), salt.begin(), salt.end());
    result.insert(result.end(), derivedKey.begin(), derivedKey.end());
    
    // Base64 encode
    return base64Encode(result);
}

bool EncryptionService::verifyPassword(const std::string& password, const std::string& passwordHash) {
    try {
        // Base64 decode
        auto data = base64Decode(passwordHash);
        
        // Extract salt and hash
        if (data.size() != SALT_SIZE + 32) {
            // Invalid format
            return false;
        }
        
        std::vector<uint8_t> salt(data.begin(), data.begin() + SALT_SIZE);
        std::vector<uint8_t> storedHash(data.begin() + SALT_SIZE, data.end());
        
        // Derive key using the same parameters
        std::vector<uint8_t> derivedKey(32); // 256 bits
        
        if (PKCS5_PBKDF2_HMAC(
                password.c_str(),
                password.size(),
                salt.data(),
                salt.size(),
                PBKDF2_ITERATIONS,
                EVP_sha256(),
                derivedKey.size(),
                derivedKey.data()) != 1) {
            throw std::runtime_error("Failed to derive key for password verification");
        }
        
        // Compare hashes using constant-time comparison
        return CRYPTO_memcmp(derivedKey.data(), storedHash.data(), derivedKey.size()) == 0;
    } catch (const std::exception& e) {
        spdlog::error("Password verification failed: {}", e.what());
        return false;
    }
}

std::string EncryptionService::generateRandomString(size_t length) {
    static const char charset[] = 
        "0123456789"
        "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
        "abcdefghijklmnopqrstuvwxyz";
    
    std::vector<uint8_t> randomData(length);
    RAND_bytes(randomData.data(), randomData.size());
    
    std::string result(length, 0);
    for (size_t i = 0; i < length; ++i) {
        result[i] = charset[randomData[i] % (sizeof(charset) - 1)];
    }
    
    return result;
}

std::vector<uint8_t> EncryptionService::deriveKey(
    const std::string& salt,
    const std::string& key,
    size_t keyLength
) {
    std::vector<uint8_t> derivedKey(keyLength);
    
    if (PKCS5_PBKDF2_HMAC(
            key.c_str(),
            key.size(),
            reinterpret_cast<const uint8_t*>(salt.c_str()),
            salt.size(),
            10000,
            EVP_sha256(),
            keyLength,
            derivedKey.data()) != 1) {
        throw std::runtime_error("Failed to derive key");
    }
    
    return derivedKey;
}

std::vector<uint8_t> EncryptionService::generateIv() {
    std::vector<uint8_t> iv(IV_SIZE);
    RAND_bytes(iv.data(), iv.size());
    return iv;
}

std::vector<uint8_t> EncryptionService::generateSalt() {
    std::vector<uint8_t> salt(SALT_SIZE);
    RAND_bytes(salt.data(), salt.size());
    return salt;
}

std::string EncryptionService::base64Encode(const std::vector<uint8_t>& data) {
    BIO* b64 = BIO_new(BIO_f_base64());
    BIO* bmem = BIO_new(BIO_s_mem());
    b64 = BIO_push(b64, bmem);
    BIO_set_flags(b64, BIO_FLAGS_BASE64_NO_NL);
    BIO_write(b64, data.data(), data.size());
    BIO_flush(b64);
    
    BUF_MEM* bptr;
    BIO_get_mem_ptr(b64, &bptr);
    
    std::string result(bptr->data, bptr->length);
    BIO_free_all(b64);
    
    return result;
}

std::vector<uint8_t> EncryptionService::base64Decode(const std::string& encoded) {
    BIO* b64 = BIO_new(BIO_f_base64());
    BIO* bmem = BIO_new_mem_buf(encoded.c_str(), encoded.size());
    bmem = BIO_push(b64, bmem);
    BIO_set_flags(bmem, BIO_FLAGS_BASE64_NO_NL);
    
    std::vector<uint8_t> output(encoded.size());
    int decodedSize = BIO_read(bmem, output.data(), encoded.size());
    BIO_free_all(bmem);
    
    if (decodedSize < 0) {
        throw std::runtime_error("Failed to decode base64 data");
    }
    
    output.resize(decodedSize);
    return output;
}

} // namespace security
// src/backend/simulator/SimulatorDataProcessor.h
#pragma once

#include <atomic>
#include <chrono>
#include <functional>
#include <memory>
#include <string>
#include <thread>
#include <unordered_map>
#include <vector>

#include "../core/Result.h"
#include "../core/Logger.h"
#include "../core/ConfigurationManager.h"
#include "LockFreeQueue.h"
#include "LockFreeRingBuffer.h"
#include "FlightParameters.h"
#include "AnomalyDetector.h"
#include "EventDetector.h"

namespace PilotTraining {
namespace Simulator {

/**
 * @brief Status of the simulator data processor
 */
enum class ProcessorStatus {
    STOPPED,
    STARTING,
    RUNNING,
    PAUSED,
    STOPPING,
    ERROR
};

/**
 * @brief Subscriber callback function type
 * Called when new telemetry data is available
 */
using TelemetryCallback = std::function<void(const FlightParameters&)>;

/**
 * @brief Event callback function type
 * Called when flight events are detected
 */
using EventCallback = std::function<void(const FlightEvent&)>;

/**
 * @brief Anomaly callback function type
 * Called when flight anomalies are detected
 */
using AnomalyCallback = std::function<void(const FlightAnomaly&)>;

/**
 * @brief Status callback function type
 * Called when processor status changes
 */
using StatusCallback = std::function<void(ProcessorStatus, const std::string&)>;

/**
 * @brief Simulator data processor configuration
 */
struct SimulatorProcessorConfig {
    int sampleRateHz = 1000;             // Target sample rate in Hz
    int bufferCapacity = 10000;          // Capacity of the telemetry buffer
    int processingThreads = 4;           // Number of processing threads
    int eventDetectionIntervalMs = 100;  // Event detection interval in milliseconds
    int anomalyDetectionIntervalMs = 50; // Anomaly detection interval in milliseconds
    int dataPersistenceIntervalMs = 1000; // Data persistence interval in milliseconds
    bool enableEventDetection = true;     // Enable event detection
    bool enableAnomalyDetection = true;   // Enable anomaly detection
    bool enableDataRecording = true;      // Enable data recording to disk
    std::string recordingDirectory = "./recordings"; // Directory for flight recordings
};

/**
 * @brief Statistics for the simulator data processor
 */
struct ProcessorStatistics {
    std::atomic<uint64_t> samplesReceived{0};      // Total samples received
    std::atomic<uint64_t> samplesProcessed{0};     // Total samples processed
    std::atomic<uint64_t> eventsDetected{0};       // Total events detected
    std::atomic<uint64_t> anomaliesDetected{0};    // Total anomalies detected
    std::atomic<uint64_t> samplesDropped{0};       // Total samples dropped due to buffer full
    std::atomic<double> currentSampleRateHz{0.0};   // Current sample rate in Hz
    std::atomic<double> currentProcessingLatencyMs{0.0}; // Current processing latency in ms
    std::atomic<double> bufferUtilizationPercent{0.0};   // Current buffer utilization
    std::atomic<int64_t> lastSampleTimestampUs{0}; // Last sample timestamp in microseconds
    std::chrono::steady_clock::time_point startTime; // Start time of the processor
};

/**
 * @brief Simulator data processor class
 * 
 * High-performance processor for real-time telemetry data from flight simulators.
 * Features include:
 * - Lock-free concurrent data structures for high throughput
 * - Real-time analysis of flight parameters
 * - Event and anomaly detection
 * - Support for multiple subscriber callbacks
 * - Historical data access
 */
class SimulatorDataProcessor {
public:
    /**
     * @brief Construct a new Simulator Data Processor
     * 
     * @param configManager Configuration manager for settings
     */
    explicit SimulatorDataProcessor(std::shared_ptr<Core::ConfigurationManager> configManager);
    
    /**
     * @brief Destroy the Simulator Data Processor
     */
    ~SimulatorDataProcessor();
    
    /**
     * @brief Initialize the processor
     * 
     * @param config Configuration for the processor
     * @return Result<void> Success or error
     */
    Core::Result<void> initialize(const SimulatorProcessorConfig& config);
    
    /**
     * @brief Start the processor
     * 
     * @return Result<void> Success or error
     */
    Core::Result<void> start();
    
    /**
     * @brief Stop the processor
     * 
     * @return Result<void> Success or error
     */
    Core::Result<void> stop();
    
    /**
     * @brief Pause the processor
     * 
     * @return Result<void> Success or error
     */
    Core::Result<void> pause();
    
    /**
     * @brief Resume the processor
     * 
     * @return Result<void> Success or error
     */
    Core::Result<void> resume();
    
    /**
     * @brief Get the current status
     * 
     * @return ProcessorStatus Current status
     */
    ProcessorStatus getStatus() const;
    
    /**
     * @brief Get processor statistics
     * 
     * @return ProcessorStatistics Current statistics
     */
    ProcessorStatistics getStatistics() const;
    
    /**
     * @brief Process a new telemetry sample
     * 
     * @param parameters Flight parameters to process
     * @return true if sample was processed successfully
     * @return false if sample was dropped
     */
    bool processSample(const FlightParameters& parameters);
    
    /**
     * @brief Subscribe to real-time telemetry updates
     * 
     * @param callback Callback function to be called for each sample
     * @param id Unique identifier for the subscription
     * @return Result<void> Success or error
     */
    Core::Result<void> subscribeTelemetry(TelemetryCallback callback, const std::string& id);
    
    /**
     * @brief Unsubscribe from telemetry updates
     * 
     * @param id Subscription identifier
     * @return Result<void> Success or error
     */
    Core::Result<void> unsubscribeTelemetry(const std::string& id);
    
    /**
     * @brief Subscribe to flight events
     * 
     * @param callback Callback function to be called for each event
     * @param id Unique identifier for the subscription
     * @return Result<void> Success or error
     */
    Core::Result<void> subscribeEvents(EventCallback callback, const std::string& id);
    
    /**
     * @brief Unsubscribe from flight events
     * 
     * @param id Subscription identifier
     * @return Result<void> Success or error
     */
    Core::Result<void> unsubscribeEvents(const std::string& id);
    
    /**
     * @brief Subscribe to flight anomalies
     * 
     * @param callback Callback function to be called for each anomaly
     * @param id Unique identifier for the subscription
     * @return Result<void> Success or error
     */
    Core::Result<void> subscribeAnomalies(AnomalyCallback callback, const std::string& id);
    
    /**
     * @brief Unsubscribe from flight anomalies
     * 
     * @param id Subscription identifier
     * @return Result<void> Success or error
     */
    Core::Result<void> unsubscribeAnomalies(const std::string& id);
    
    /**
     * @brief Subscribe to status updates
     * 
     * @param callback Callback function to be called for each status change
     * @param id Unique identifier for the subscription
     * @return Result<void> Success or error
     */
    Core::Result<void> subscribeStatus(StatusCallback callback, const std::string& id);
    
    /**
     * @brief Unsubscribe from status updates
     * 
     * @param id Subscription identifier
     * @return Result<void> Success or error
     */
    Core::Result<void> unsubscribeStatus(const std::string& id);
    
    /**
     * @brief Get historical telemetry data
     * 
     * @param startTime Start time in microseconds since epoch
     * @param endTime End time in microseconds since epoch
     * @return Result<std::vector<FlightParameters>> Historical data or error
     */
    Core::Result<std::vector<FlightParameters>> getHistoricalData(
        int64_t startTime, 
        int64_t endTime
    );
    
    /**
     * @brief Get the most recent telemetry data
     * 
     * @param count Number of samples to retrieve
     * @return Result<std::vector<FlightParameters>> Recent data or error
     */
    Core::Result<std::vector<FlightParameters>> getRecentData(size_t count);
    
    /**
     * @brief Get historical flight events
     * 
     * @param startTime Start time in microseconds since epoch
     * @param endTime End time in microseconds since epoch
     * @return Result<std::vector<FlightEvent>> Historical events or error
     */
    Core::Result<std::vector<FlightEvent>> getHistoricalEvents(
        int64_t startTime, 
        int64_t endTime
    );
    
    /**
     * @brief Get historical flight anomalies
     * 
     * @param startTime Start time in microseconds since epoch
     * @param endTime End time in microseconds since epoch
     * @return Result<std::vector<FlightAnomaly>> Historical anomalies or error
     */
    Core::Result<std::vector<FlightAnomaly>> getHistoricalAnomalies(
        int64_t startTime, 
        int64_t endTime
    );
    
    /**
     * @brief Start recording telemetry data to disk
     * 
     * @param filename Name of the recording file
     * @return Result<void> Success or error
     */
    Core::Result<void> startRecording(const std::string& filename);
    
    /**
     * @brief Stop recording telemetry data
     * 
     * @return Result<void> Success or error
     */
    Core::Result<void> stopRecording();
    
    /**
     * @brief Load telemetry data from a recording file
     * 
     * @param filename Name of the recording file
     * @param append Whether to append to current buffer (true) or replace (false)
     * @return Result<size_t> Number of samples loaded or error
     */
    Core::Result<size_t> loadRecording(const std::string& filename, bool append = false);
    
    /**
     * @brief Set event detection parameters
     * 
     * @param parameters Event detection parameters
     * @return Result<void> Success or error
     */
    Core::Result<void> setEventDetectionParameters(const EventDetectionParameters& parameters);
    
    /**
     * @brief Set anomaly detection parameters
     * 
     * @param parameters Anomaly detection parameters
     * @return Result<void> Success or error
     */
    Core::Result<void> setAnomalyDetectionParameters(const AnomalyDetectionParameters& parameters);

private:
    // Processing threads
    void processingThread();
    void eventDetectionThread();
    void anomalyDetectionThread();
    void statisticsThread();
    void recordingThread();
    
    // Helper methods
    void updateStatus(ProcessorStatus status, const std::string& message = "");
    void notifyTelemetrySubscribers(const FlightParameters& parameters);
    void notifyEventSubscribers(const FlightEvent& event);
    void notifyAnomalySubscribers(const FlightAnomaly& anomaly);
    void updateStatistics();
    
    // Thread management
    void startThreads();
    void stopThreads();
    
    // Member variables
    std::shared_ptr<Core::ConfigurationManager> _configManager;
    SimulatorProcessorConfig _config;
    std::atomic<ProcessorStatus> _status{ProcessorStatus::STOPPED};
    std::string _statusMessage;
    ProcessorStatistics _statistics;
    
    // Concurrent data structures
    std::unique_ptr<LockFreeQueue<FlightParameters>> _inputQueue;
    std::unique_ptr<LockFreeRingBuffer<FlightParameters>> _telemetryBuffer;
    std::unique_ptr<LockFreeQueue<FlightEvent>> _eventQueue;
    std::unique_ptr<LockFreeQueue<FlightAnomaly>> _anomalyQueue;
    
    // Detection engines
    std::unique_ptr<EventDetector> _eventDetector;
    std::unique_ptr<AnomalyDetector> _anomalyDetector;
    
    // Subscriber callbacks
    std::mutex _telemetrySubscribersMutex;
    std::unordered_map<std::string, TelemetryCallback> _telemetrySubscribers;
    
    std::mutex _eventSubscribersMutex;
    std::unordered_map<std::string, EventCallback> _eventSubscribers;
    
    std::mutex _anomalySubscribersMutex;
    std::unordered_map<std::string, AnomalyCallback> _anomalySubscribers;
    
    std::mutex _statusSubscribersMutex;
    std::unordered_map<std::string, StatusCallback> _statusSubscribers;
    
    // Thread management
    std::vector<std::thread> _processingThreads;
    std::thread _eventDetectionThread;
    std::thread _anomalyDetectionThread;
    std::thread _statisticsThread;
    std::thread _recordingThread;
    std::atomic<bool> _running{false};
    
    // Recording
    std::atomic<bool> _recording{false};
    std::string _recordingFilename;
    std::mutex _recordingMutex;
};

} // namespace Simulator
} // namespace PilotTraining

// src/backend/simulator/SimulatorDataProcessor.cpp
#include "SimulatorDataProcessor.h"
#include <fstream>
#include <iomanip>
#include <sstream>
#include <cassert>
#include <cmath>
#include <algorithm>
#include <filesystem>

namespace PilotTraining {
namespace Simulator {

using namespace std::chrono;

SimulatorDataProcessor::SimulatorDataProcessor(std::shared_ptr<Core::ConfigurationManager> configManager)
    : _configManager(std::move(configManager)) {
    
    Core::Logger::info("SimulatorDataProcessor created");
}

SimulatorDataProcessor::~SimulatorDataProcessor() {
    // Ensure all threads are stopped cleanly
    if (_running.load()) {
        stop();
    }
    
    Core::Logger::info("SimulatorDataProcessor destroyed");
}

Core::Result<void> SimulatorDataProcessor::initialize(const SimulatorProcessorConfig& config) {
    try {
        // Store configuration
        _config = config;
        
        // Create data structures with specified capacities
        _inputQueue = std::make_unique<LockFreeQueue<FlightParameters>>(10000);
        _telemetryBuffer = std::make_unique<LockFreeRingBuffer<FlightParameters>>(config.bufferCapacity);
        _eventQueue = std::make_unique<LockFreeQueue<FlightEvent>>(1000);
        _anomalyQueue = std::make_unique<LockFreeQueue<FlightAnomaly>>(1000);
        
        // Create detection engines
        _eventDetector = std::make_unique<EventDetector>();
        _anomalyDetector = std::make_unique<AnomalyDetector>();
        
        // Initialize statistics
        _statistics.startTime = steady_clock::now();
        
        // Create recordings directory if it doesn't exist
        if (_config.enableDataRecording) {
            std::filesystem::create_directories(_config.recordingDirectory);
        }
        
        updateStatus(ProcessorStatus::STOPPED, "Initialized successfully");
        Core::Logger::info("SimulatorDataProcessor initialized with buffer capacity: {}", config.bufferCapacity);
        
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to initialize SimulatorDataProcessor: " + std::string(e.what());
        Core::Logger::error(error);
        updateStatus(ProcessorStatus::ERROR, error);
        return Core::Result<void>::failure(Core::ErrorCode::InitializationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::start() {
    // Check if already running
    if (_running.load()) {
        return Core::Result<void>::failure(
            Core::ErrorCode::InvalidOperation,
            "SimulatorDataProcessor is already running"
        );
    }
    
    try {
        updateStatus(ProcessorStatus::STARTING, "Starting data processor");
        
        // Reset statistics
        _statistics.samplesReceived = 0;
        _statistics.samplesProcessed = 0;
        _statistics.eventsDetected = 0;
        _statistics.anomaliesDetected = 0;
        _statistics.samplesDropped = 0;
        _statistics.currentSampleRateHz = 0;
        _statistics.currentProcessingLatencyMs = 0;
        _statistics.bufferUtilizationPercent = 0;
        _statistics.lastSampleTimestampUs = 0;
        _statistics.startTime = steady_clock::now();
        
        // Start the threads
        _running.store(true);
        startThreads();
        
        updateStatus(ProcessorStatus::RUNNING, "Data processor running");
        Core::Logger::info("SimulatorDataProcessor started with {} processing threads", _config.processingThreads);
        
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to start SimulatorDataProcessor: " + std::string(e.what());
        Core::Logger::error(error);
        updateStatus(ProcessorStatus::ERROR, error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::stop() {
    // Check if already stopped
    if (!_running.load()) {
        return Core::Result<void>::failure(
            Core::ErrorCode::InvalidOperation,
            "SimulatorDataProcessor is not running"
        );
    }
    
    try {
        updateStatus(ProcessorStatus::STOPPING, "Stopping data processor");
        
        // Stop all threads
        _running.store(false);
        stopThreads();
        
        // Clear queues
        FlightParameters params;
        while (_inputQueue->dequeue(params)) {}
        
        FlightEvent event;
        while (_eventQueue->dequeue(event)) {}
        
        FlightAnomaly anomaly;
        while (_anomalyQueue->dequeue(anomaly)) {}
        
        updateStatus(ProcessorStatus::STOPPED, "Data processor stopped");
        Core::Logger::info("SimulatorDataProcessor stopped");
        
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to stop SimulatorDataProcessor: " + std::string(e.what());
        Core::Logger::error(error);
        updateStatus(ProcessorStatus::ERROR, error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::pause() {
    // Check if running
    if (_status.load() != ProcessorStatus::RUNNING) {
        return Core::Result<void>::failure(
            Core::ErrorCode::InvalidOperation,
            "SimulatorDataProcessor is not running"
        );
    }
    
    updateStatus(ProcessorStatus::PAUSED, "Data processor paused");
    Core::Logger::info("SimulatorDataProcessor paused");
    
    return Core::Result<void>::success();
}

Core::Result<void> SimulatorDataProcessor::resume() {
    // Check if paused
    if (_status.load() != ProcessorStatus::PAUSED) {
        return Core::Result<void>::failure(
            Core::ErrorCode::InvalidOperation,
            "SimulatorDataProcessor is not paused"
        );
    }
    
    updateStatus(ProcessorStatus::RUNNING, "Data processor resumed");
    Core::Logger::info("SimulatorDataProcessor resumed");
    
    return Core::Result<void>::success();
}

ProcessorStatus SimulatorDataProcessor::getStatus() const {
    return _status.load();
}

ProcessorStatistics SimulatorDataProcessor::getStatistics() const {
    return _statistics;
}

bool SimulatorDataProcessor::processSample(const FlightParameters& parameters) {
    // Check if we're running
    if (_status.load() != ProcessorStatus::RUNNING && _status.load() != ProcessorStatus::PAUSED) {
        _statistics.samplesDropped.fetch_add(1);
        return false;
    }
    
    // Add to input queue
    bool success = _inputQueue->enqueue(parameters);
    
    if (success) {
        _statistics.samplesReceived.fetch_add(1);
        _statistics.lastSampleTimestampUs.store(parameters.timestamp);
    } else {
        _statistics.samplesDropped.fetch_add(1);
    }
    
    return success;
}

Core::Result<void> SimulatorDataProcessor::subscribeTelemetry(TelemetryCallback callback, const std::string& id) {
    if (id.empty()) {
        return Core::Result<void>::failure(
            Core::ErrorCode::InvalidInput,
            "Subscriber ID cannot be empty"
        );
    }
    
    try {
        std::lock_guard<std::mutex> lock(_telemetrySubscribersMutex);
        _telemetrySubscribers[id] = callback;
        Core::Logger::info("Telemetry subscriber added: {}", id);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to add telemetry subscriber: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::unsubscribeTelemetry(const std::string& id) {
    try {
        std::lock_guard<std::mutex> lock(_telemetrySubscribersMutex);
        size_t removed = _telemetrySubscribers.erase(id);
        if (removed > 0) {
            Core::Logger::info("Telemetry subscriber removed: {}", id);
            return Core::Result<void>::success();
        } else {
            return Core::Result<void>::failure(
                Core::ErrorCode::NotFound,
                "Telemetry subscriber not found: " + id
            );
        }
    } catch (const std::exception& e) {
        const std::string error = "Failed to remove telemetry subscriber: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::subscribeEvents(EventCallback callback, const std::string& id) {
    if (id.empty()) {
        return Core::Result<void>::failure(
            Core::ErrorCode::InvalidInput,
            "Subscriber ID cannot be empty"
        );
    }
    
    try {
        std::lock_guard<std::mutex> lock(_eventSubscribersMutex);
        _eventSubscribers[id] = callback;
        Core::Logger::info("Event subscriber added: {}", id);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to add event subscriber: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::unsubscribeEvents(const std::string& id) {
    try {
        std::lock_guard<std::mutex> lock(_eventSubscribersMutex);
        size_t removed = _eventSubscribers.erase(id);
        if (removed > 0) {
            Core::Logger::info("Event subscriber removed: {}", id);
            return Core::Result<void>::success();
        } else {
            return Core::Result<void>::failure(
                Core::ErrorCode::NotFound,
                "Event subscriber not found: " + id
            );
        }
    } catch (const std::exception& e) {
        const std::string error = "Failed to remove event subscriber: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::subscribeAnomalies(AnomalyCallback callback, const std::string& id) {
    if (id.empty()) {
        return Core::Result<void>::failure(
            Core::ErrorCode::InvalidInput,
            "Subscriber ID cannot be empty"
        );
    }
    
    try {
        std::lock_guard<std::mutex> lock(_anomalySubscribersMutex);
        _anomalySubscribers[id] = callback;
        Core::Logger::info("Anomaly subscriber added: {}", id);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to add anomaly subscriber: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::unsubscribeAnomalies(const std::string& id) {
    try {
        std::lock_guard<std::mutex> lock(_anomalySubscribersMutex);
        size_t removed = _anomalySubscribers.erase(id);
        if (removed > 0) {
            Core::Logger::info("Anomaly subscriber removed: {}", id);
            return Core::Result<void>::success();
        } else {
            return Core::Result<void>::failure(
                Core::ErrorCode::NotFound,
                "Anomaly subscriber not found: " + id
            );
        }
    } catch (const std::exception& e) {
        const std::string error = "Failed to remove anomaly subscriber: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::subscribeStatus(StatusCallback callback, const std::string& id) {
    if (id.empty()) {
        return Core::Result<void>::failure(
            Core::ErrorCode::InvalidInput,
            "Subscriber ID cannot be empty"
        );
    }
    
    try {
        std::lock_guard<std::mutex> lock(_statusSubscribersMutex);
        _statusSubscribers[id] = callback;
        
        // Immediately notify the subscriber of the current status
        callback(_status.load(), _statusMessage);
        
        Core::Logger::info("Status subscriber added: {}", id);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to add status subscriber: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::unsubscribeStatus(const std::string& id) {
    try {
        std::lock_guard<std::mutex> lock(_statusSubscribersMutex);
        size_t removed = _statusSubscribers.erase(id);
        if (removed > 0) {
            Core::Logger::info("Status subscriber removed: {}", id);
            return Core::Result<void>::success();
        } else {
            return Core::Result<void>::failure(
                Core::ErrorCode::NotFound,
                "Status subscriber not found: " + id
            );
        }
    } catch (const std::exception& e) {
        const std::string error = "Failed to remove status subscriber: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<std::vector<FlightParameters>> SimulatorDataProcessor::getHistoricalData(
    int64_t startTime, int64_t endTime) {
    
    try {
        std::vector<FlightParameters> result;
        std::vector<FlightParameters> allData;
        
        // Get all data from the buffer
        _telemetryBuffer->getAllData(allData);
        
        // Filter by time range
        for (const auto& params : allData) {
            if (params.timestamp >= startTime && params.timestamp <= endTime) {
                result.push_back(params);
            }
        }
        
        return Core::Result<std::vector<FlightParameters>>::success(result);
    } catch (const std::exception& e) {
        const std::string error = "Failed to get historical data: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<std::vector<FlightParameters>>::failure(
            Core::ErrorCode::OperationFailed,
            error
        );
    }
}

Core::Result<std::vector<FlightParameters>> SimulatorDataProcessor::getRecentData(size_t count) {
    try {
        std::vector<FlightParameters> result;
        
        // Get the most recent data from the buffer
        size_t retrieved = _telemetryBuffer->getSnapshot(result, count);
        
        if (retrieved == 0) {
            return Core::Result<std::vector<FlightParameters>>::failure(
                Core::ErrorCode::NotFound,
                "No data available in the buffer"
            );
        }
        
        return Core::Result<std::vector<FlightParameters>>::success(result);
    } catch (const std::exception& e) {
        const std::string error = "Failed to get recent data: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<std::vector<FlightParameters>>::failure(
            Core::ErrorCode::OperationFailed,
            error
        );
    }
}

Core::Result<std::vector<FlightEvent>> SimulatorDataProcessor::getHistoricalEvents(
    int64_t startTime, int64_t endTime) {
    
    // This would typically retrieve events from a database
    // For this implementation, we'll return an empty list
    return Core::Result<std::vector<FlightEvent>>::success({});
}

Core::Result<std::vector<FlightAnomaly>> SimulatorDataProcessor::getHistoricalAnomalies(
    int64_t startTime, int64_t endTime) {
    
    // This would typically retrieve anomalies from a database
    // For this implementation, we'll return an empty list
    return Core::Result<std::vector<FlightAnomaly>>::success({});
}

Core::Result<void> SimulatorDataProcessor::startRecording(const std::string& filename) {
    if (!_config.enableDataRecording) {
        return Core::Result<void>::failure(
            Core::ErrorCode::FeatureDisabled,
            "Data recording is disabled in configuration"
        );
    }
    
    try {
        std::lock_guard<std::mutex> lock(_recordingMutex);
        
        if (_recording.load()) {
            return Core::Result<void>::failure(
                Core::ErrorCode::InvalidOperation,
                "Recording is already in progress"
            );
        }
        
        // Set recording filename
        _recordingFilename = _config.recordingDirectory + "/" + filename;
        if (!_recordingFilename.ends_with(".csv")) {
            _recordingFilename += ".csv";
        }
        
        // Start recording
        _recording.store(true);
        
        Core::Logger::info("Started recording to file: {}", _recordingFilename);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to start recording: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::stopRecording() {
    try {
        std::lock_guard<std::mutex> lock(_recordingMutex);
        
        if (!_recording.load()) {
            return Core::Result<void>::failure(
                Core::ErrorCode::InvalidOperation,
                "No recording in progress"
            );
        }
        
        // Stop recording
        _recording.store(false);
        
        Core::Logger::info("Stopped recording to file: {}", _recordingFilename);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to stop recording: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<size_t> SimulatorDataProcessor::loadRecording(const std::string& filename, bool append) {
    try {
        std::string filepath = filename;
        if (!std::filesystem::exists(filepath)) {
            filepath = _config.recordingDirectory + "/" + filename;
            if (!filepath.ends_with(".csv")) {
                filepath += ".csv";
            }
            
            if (!std::filesystem::exists(filepath)) {
                return Core::Result<size_t>::failure(
                    Core::ErrorCode::FileNotFound,
                    "Recording file not found: " + filepath
                );
            }
        }
        
        // Open the file
        std::ifstream file(filepath);
        if (!file.is_open()) {
            return Core::Result<size_t>::failure(
                Core::ErrorCode::FileOpenFailed,
                "Failed to open recording file: " + filepath
            );
        }
        
        // Skip header line
        std::string line;
        std::getline(file, line);
        
        // Clear existing data if not appending
        if (!append) {
            // Reset buffer
            _telemetryBuffer->reset();
        }
        
        // Read and parse data
        size_t count = 0;
        while (std::getline(file, line)) {
            // Parse CSV line to FlightParameters
            // This is a simplified version - a real implementation would parse all fields
            std::istringstream iss(line);
            std::string token;
            
            FlightParameters params;
            
            // Parse timestamp
            std::getline(iss, token, ',');
            params.timestamp = std::stoll(token);
            
            // Parse session ID
            std::getline(iss, token, ',');
            params.sessionId = token;
            
            // Parse aircraft ID
            std::getline(iss, token, ',');
            params.aircraftId = token;
            
            // Parse aircraft type
            std::getline(iss, token, ',');
            params.aircraftType = static_cast<AircraftType>(std::stoi(token));
            
            // Parse position and attitude
            std::getline(iss, token, ','); params.latitude = std::stod(token);
            std::getline(iss, token, ','); params.longitude = std::stod(token);
            std::getline(iss, token, ','); params.altitude = std::stod(token);
            std::getline(iss, token, ','); params.heading = std::stod(token);
            std::getline(iss, token, ','); params.pitch = std::stod(token);
            std::getline(iss, token, ','); params.roll = std::stod(token);
            std::getline(iss, token, ','); params.groundSpeed = std::stod(token);
            std::getline(iss, token, ','); params.indicatedAirspeed = std::stod(token);
            std::getline(iss, token, ','); params.trueAirspeed = std::stod(token);
            std::getline(iss, token, ','); params.verticalSpeed = std::stod(token);
            
            // Add to buffer
            _telemetryBuffer->write(params);
            count++;
        }
        
        Core::Logger::info("Loaded {} records from recording file: {}", count, filepath);
        return Core::Result<size_t>::success(count);
    } catch (const std::exception& e) {
        const std::string error = "Failed to load recording: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<size_t>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::setEventDetectionParameters(const EventDetectionParameters& parameters) {
    try {
        _eventDetector->setParameters(parameters);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to set event detection parameters: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

Core::Result<void> SimulatorDataProcessor::setAnomalyDetectionParameters(const AnomalyDetectionParameters& parameters) {
    try {
        _anomalyDetector->setParameters(parameters);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        const std::string error = "Failed to set anomaly detection parameters: " + std::string(e.what());
        Core::Logger::error(error);
        return Core::Result<void>::failure(Core::ErrorCode::OperationFailed, error);
    }
}

// Private methods

void SimulatorDataProcessor::processingThread() {
    Core::Logger::debug("Processing thread started");
    
    auto lastProcessTime = steady_clock::now();
    size_t samplesProcessed = 0;
    
    while (_running.load()) {
        FlightParameters params;
        
        // Process samples from the input queue
        while (_inputQueue->dequeue(params)) {
            auto startTime = steady_clock::now();
            
            // Add to telemetry buffer
            _telemetryBuffer->write(params);
            
            // Notify subscribers
            notifyTelemetrySubscribers(params);
            
            auto endTime = steady_clock::now();
            double latencyMs = duration_cast<microseconds>(endTime - startTime).count() / 1000.0;
            
            // Update statistics
            _statistics.samplesProcessed.fetch_add(1);
            _statistics.currentProcessingLatencyMs.store(latencyMs);
            _statistics.bufferUtilizationPercent.store(_telemetryBuffer->utilization());
            
            samplesProcessed++;
        }
        
        // Calculate current sample rate
        auto now = steady_clock::now();
        auto elapsed = duration_cast<milliseconds>(now - lastProcessTime).count();
        
        if (elapsed >= 1000) { // Update rate every second
            double sampleRateHz = samplesProcessed * 1000.0 / elapsed;
            _statistics.currentSampleRateHz.store(sampleRateHz);
            
            samplesProcessed = 0;
            lastProcessTime = now;
        }
        
        // Sleep briefly to avoid busy-waiting
        std::this_thread::sleep_for(std::chrono::microseconds(100));
    }
    
    Core::Logger::debug("Processing thread stopped");
}

void SimulatorDataProcessor::eventDetectionThread() {
    Core::Logger::debug("Event detection thread started");
    
    auto lastDetectionTime = steady_clock::now();
    
    while (_running.load()) {
        auto now = steady_clock::now();
        auto elapsed = duration_cast<milliseconds>(now - lastDetectionTime).count();
        
        // Run event detection at configured interval
        if (elapsed >= _config.eventDetectionIntervalMs) {
            lastDetectionTime = now;
            
            // Skip if paused
            if (_status.load() == ProcessorStatus::PAUSED) {
                std::this_thread::sleep_for(std::chrono::milliseconds(100));
                continue;
            }
            
            // Get latest telemetry data for analysis
            std::vector<FlightParameters> recentData;
            size_t dataCount = _telemetryBuffer->getSnapshot(recentData, 100); // Get last 100 samples
            
            if (dataCount > 0) {
                // Detect events
                std::vector<FlightEvent> events = _eventDetector->detectEvents(recentData);
                
                // Process detected events
                for (const auto& event : events) {
                    // Add to event queue
                    _eventQueue->enqueue(event);
                    
                    // Notify subscribers
                    notifyEventSubscribers(event);
                    
                    // Update statistics
                    _statistics.eventsDetected.fetch_add(1);
                }
            }
        }
        
        // Sleep briefly to avoid busy-waiting
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }
    
    Core::Logger::debug("Event detection thread stopped");
}

void SimulatorDataProcessor::anomalyDetectionThread() {
    Core::Logger::debug("Anomaly detection thread started");
    
    auto lastDetectionTime = steady_clock::now();
    
    while (_running.load()) {
        auto now = steady_clock::now();
        auto elapsed = duration_cast<milliseconds>(now - lastDetectionTime).count();
        
        // Run anomaly detection at configured interval
        if (elapsed >= _config.anomalyDetectionIntervalMs) {
            lastDetectionTime = now;
            
            // Skip if paused
            if (_status.load() == ProcessorStatus::PAUSED) {
                std::this_thread::sleep_for(std::chrono::milliseconds(100));
                continue;
            }
            
            // Get latest telemetry data for analysis
            std::vector<FlightParameters> recentData;
            size_t dataCount = _telemetryBuffer->getSnapshot(recentData, 200); // Get last 200 samples
            
            if (dataCount > 0) {
                // Detect anomalies
                std::vector<FlightAnomaly> anomalies = _anomalyDetector->detectAnomalies(recentData);
                
                // Process detected anomalies
                for (const auto& anomaly : anomalies) {
                    // Add to anomaly queue
                    _anomalyQueue->enqueue(anomaly);
                    
                    // Notify subscribers
                    notifyAnomalySubscribers(anomaly);
                    
                    // Update statistics
                    _statistics.anomaliesDetected.fetch_add(1);
                }
            }
        }
        
        // Sleep briefly to avoid busy-waiting
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }
    
    Core::Logger::debug("Anomaly detection thread stopped");
}

void SimulatorDataProcessor::statisticsThread() {
    Core::Logger::debug("Statistics thread started");
    
    while (_running.load()) {
        // Update statistics periodically
        updateStatistics();
        
        // Sleep to avoid busy-waiting
        std::this_thread::sleep_for(std::chrono::milliseconds(1000));
    }
    
    Core::Logger::debug("Statistics thread stopped");
}

void SimulatorDataProcessor::recordingThread() {
    Core::Logger::debug("Recording thread started");
    
    auto lastRecordTime = steady_clock::now();
    std::vector<FlightParameters> recordingBatch;
    
    while (_running.load()) {
        auto now = steady_clock::now();
        auto elapsed = duration_cast<milliseconds>(now - lastRecordTime).count();
        
        // Run recording at configured interval
        if (elapsed >= _config.dataPersistenceIntervalMs && _recording.load()) {
            lastRecordTime = now;
            
            // Skip if paused
            if (_status.load() == ProcessorStatus::PAUSED) {
                std::this_thread::sleep_for(std::chrono::milliseconds(100));
                continue;
            }
            
            try {
                std::lock_guard<std::mutex> lock(_recordingMutex);
                
                // Get data since last recording
                std::vector<FlightParameters> newData;
                size_t dataCount = _telemetryBuffer->readBatch(newData, 1000); // Get up to 1000 samples
                
                if (dataCount > 0) {
                    // Open file in append mode
                    std::ofstream file(_recordingFilename, std::ios::app);
                    
                    if (!file.is_open()) {
                        Core::Logger::error("Failed to open recording file: {}", _recordingFilename);
                        continue;
                    }
                    
                    // Write header if file is empty
                    if (file.tellp() == 0) {
                        file << "timestamp,sessionId,aircraftId,aircraftType,"
                            << "latitude,longitude,altitude,heading,pitch,roll,"
                            << "groundSpeed,indicatedAirspeed,trueAirspeed,verticalSpeed,"
                            << "controlPitch,controlRoll,controlYaw,controlThrottle,"
                            << "phase,onGround,stall,overspeed\n";
                    }
                    
                    // Write data
                    for (const auto& params : newData) {
                        file << params.timestamp << ","
                            << params.sessionId << ","
                            << params.aircraftId << ","
                            << static_cast<int>(params.aircraftType) << ","
                            << params.latitude << ","
                            << params.longitude << ","
                            << params.altitude << ","
                            << params.heading << ","
                            << params.pitch << ","
                            << params.roll << ","
                            << params.groundSpeed << ","
                            << params.indicatedAirspeed << ","
                            << params.trueAirspeed << ","
                            << params.verticalSpeed << ","
                            << params.controlPitch << ","
                            << params.controlRoll << ","
                            << params.controlYaw << ","
                            << params.controlThrottle << ","
                            << static_cast<int>(params.phase) << ","
                            << (params.onGround ? "1" : "0") << ","
                            << (params.stall ? "1" : "0") << ","
                            << (params.overspeed ? "1" : "0") << "\n";
                    }
                    
                    file.close();
                }
            } catch (const std::exception& e) {
                Core::Logger::error("Error in recording thread: {}", e.what());
            }
        }
        
        // Sleep briefly to avoid busy-waiting
        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }
    
    Core::Logger::debug("Recording thread stopped");
}

void SimulatorDataProcessor::updateStatus(ProcessorStatus status, const std::string& message) {
    _status.store(status);
    _statusMessage = message;
    
    // Notify status subscribers
    std::lock_guard<std::mutex> lock(_statusSubscribersMutex);
    for (const auto& [id, callback] : _statusSubscribers) {
        callback(status, message);
    }
    
    // Log status change
    if (!message.empty()) {
        Core::Logger::info("SimulatorDataProcessor status: {} - {}", static_cast<int>(status), message);
    } else {
        Core::Logger::info("SimulatorDataProcessor status: {}", static_cast<int>(status));
    }
}

void SimulatorDataProcessor::notifyTelemetrySubscribers(const FlightParameters& parameters) {
    std::lock_guard<std::mutex> lock(_telemetrySubscribersMutex);
    for (const auto& [id, callback] : _telemetrySubscribers) {
        try {
            callback(parameters);
        } catch (const std::exception& e) {
            Core::Logger::error("Error in telemetry subscriber {}: {}", id, e.what());
        }
    }
}

void SimulatorDataProcessor::notifyEventSubscribers(const FlightEvent& event) {
    std::lock_guard<std::mutex> lock(_eventSubscribersMutex);
    for (const auto& [id, callback] : _eventSubscribers) {
        try {
            callback(event);
        } catch (const std::exception& e) {
            Core::Logger::error("Error in event subscriber {}: {}", id, e.what());
        }
    }
}

void SimulatorDataProcessor::notifyAnomalySubscribers(const FlightAnomaly& anomaly) {
    std::lock_guard<std::mutex> lock(_anomalySubscribersMutex);
    for (const auto& [id, callback] : _anomalySubscribers) {
        try {
            callback(anomaly);
        } catch (const std::exception& e) {
            Core::Logger::error("Error in anomaly subscriber {}: {}", id, e.what());
        }
    }
}

void SimulatorDataProcessor::updateStatistics() {
    // Calculate time since start
    auto now = steady_clock::now();
    auto uptime = duration_cast<seconds>(now - _statistics.startTime).count();
    
    // Log statistics periodically
    Core::Logger::debug("SimulatorDataProcessor statistics: received={}, processed={}, dropped={}, rate={:.1f} Hz, latency={:.2f} ms, buffer={:.1f}%, uptime={}s",
        _statistics.samplesReceived.load(),
        _statistics.samplesProcessed.load(),
        _statistics.samplesDropped.load(),
        _statistics.currentSampleRateHz.load(),
        _statistics.currentProcessingLatencyMs.load(),
        _statistics.bufferUtilizationPercent.load(),
        uptime
    );
}

void SimulatorDataProcessor::startThreads() {
    // Create processing threads
    for (int i = 0; i < _config.processingThreads; ++i) {
        _processingThreads.emplace_back([this] { this->processingThread(); });
    }
    
    // Create event detection thread
    if (_config.enableEventDetection) {
        _eventDetectionThread = std::thread([this] { this->eventDetectionThread(); });
    }
    
    // Create anomaly detection thread
    if (_config.enableAnomalyDetection) {
        _anomalyDetectionThread = std::thread([this] { this->anomalyDetectionThread(); });
    }
    
    // Create statistics thread
    _statisticsThread = std::thread([this] { this->statisticsThread(); });
    
    // Create recording thread
    if (_config.enableDataRecording) {
        _recordingThread = std::thread([this] { this->recordingThread(); });
    }
}

void SimulatorDataProcessor::stopThreads() {
    // Join processing threads
    for (auto& thread : _processingThreads) {
        if (thread.joinable()) {
            thread.join();
        }
    }
    _processingThreads.clear();
    
    // Join event detection thread
    if (_eventDetectionThread.joinable()) {
        _eventDetectionThread.join();
    }
    
    // Join anomaly detection thread
    if (_anomalyDetectionThread.joinable()) {
        _anomalyDetectionThread.join();
    }
    
    // Join statistics thread
    if (_statisticsThread.joinable()) {
        _statisticsThread.join();
    }
    
    // Join recording thread
    if (_recordingThread.joinable()) {
        _recordingThread.join();
    }
}

} // namespace Simulator
} // namespace PilotTraining

# Advanced Pilot Training Platform
# Software Architecture Document

## 1. Introduction

### 1.1 Purpose
This document provides a comprehensive architectural overview of the Advanced Pilot Training Platform, using different architectural views to depict different aspects of the system. It is intended to capture and convey the significant architectural decisions which have been made for the system.

### 1.2 Scope
The Advanced Pilot Training Platform is a comprehensive training management system for aviation training organizations. It provides electronic training records management, data acquisition from training devices, AI-driven analysis, document management, syllabus generation, and assessment tracking.

### 1.3 References
- FAA Advisory Circular AC 120-54A: Advanced Qualification Program
- EASA regulations for aviation training and flight schools
- C++20 Standard ISO/IEC 14882:2020
- React 18 Technical Documentation

## 2. Architectural Representation

The architecture follows a microservice-based approach, with the following key services:

1. **Core Platform Service**: Authentication, configuration, logging, metrics, and inter-service communication
2. **Data Acquisition Service**: Hardware integration, signal processing, and data fusion
3. **Electronic Training Records Service**: Records management, digital signatures, compliance tracking
4. **AI & Analytics Engine**: Machine learning models, inference engine, data visualization
5. **Document Management Service**: Storage, parsing, version control
6. **Syllabus Generator Service**: Content extraction, structure generation, compliance checking
7. **Assessment System**: Grading, tracking, benchmarking, feedback collection
8. **Frontend Applications**: React-based user interfaces for different user roles

These services interact through a combination of synchronous gRPC calls and asynchronous messaging.

## 3. Architectural Goals and Constraints

### 3.1 Goals
- **Modularity**: Enable independent development and deployment of services
- **Scalability**: Allow horizontal scaling of services based on load
- **Performance**: Achieve <10ms response time for backend services
- **Security**: Implement robust authentication, authorization, and data protection
- **Reliability**: Achieve 99.9% service availability
- **Extensibility**: Support easy integration of new training devices and data sources

### 3.2 Constraints
- **Regulatory Compliance**: Must adhere to aviation training regulations (FAA, EASA)
- **Data Security**: Must protect personally identifiable information (PII)
- **Offline Operation**: Must support limited functionality without internet connectivity
- **Hardware Integration**: Must integrate with a variety of training devices and sensors

## 4. System Architecture

### 4.1 High-Level Architecture

```
          
  Web Browsers           Mobile Devices        Training Devices  
          
                                                                    
                                                                    

                           API Gateway                               

                                                                      
                                 
                                                                     
      
      Core Platform Service                 Service Registry       
      
                                                                      

                                                                  
                                                                  
        
    ETR           Data          AI &        Document      Syllabus  
  Service     Acquisition    Analytics      Service      Generator  
        
                                                                    
      
                                      
                                      
                          
                               Database Cluster   
                          
```

### 4.2 Database Architecture

The platform uses PostgreSQL 15 with TimescaleDB extension for time-series data. The database is organized into schemas for each service domain:

- **core_schema**: Authentication, authorization, and configuration
- **etr_schema**: Electronic training records and compliance
- **data_schema**: Acquired data and processing results
- **analytics_schema**: Model outputs and analytics results
- **document_schema**: Document metadata and search indices
- **syllabus_schema**: Syllabus structures and content
- **assessment_schema**: Assessment data and rubrics

## 5. Component View

### 5.1 Core Platform Service (core-platform-service)

The Core Platform Service provides fundamental infrastructure capabilities:

#### 5.1.1 Authentication Module
- JWT-based authentication with X.509 certificate support
- Role-based access control with hierarchical permissions
- Token management and refresh

#### 5.1.2 Configuration Module
- Multi-source configuration (files, environment variables)
- Dynamic configuration updates
- Service-specific configuration

#### 5.1.3 Communication Module
- gRPC service implementation
- Service discovery
- Request-response and streaming patterns

#### 5.1.4 Logging Module
- Structured logging
- Multiple output destinations
- Log levels and filtering

#### 5.1.5 Metrics Module
- Prometheus integration
- Custom metrics
- Performance monitoring

### 5.2 Data Acquisition Service (data-acquisition-service)

#### 5.2.1 Device Connectors
- Eye-tracking hardware (Tobii, SMI)
- Physiological monitors
- Simulator interfaces (ARINC 610D)

#### 5.2.2 Signal Processing
- Filtering and normalization
- Feature extraction
- Anomaly detection

#### 5.2.3 Data Fusion
- Multi-modal data fusion
- Kalman filtering
- Time synchronization

#### 5.2.4 Persistence
- Time-series data storage
- Compression
- Edge computing with offline sync

### 5.3 Electronic Training Records Service (etr-service)

#### 5.3.1 Records Management
- CRUD operations for training records
- Record search and filtering
- Audit logging

#### 5.3.2 Digital Signature
- X.509 certificate validation
- Digital signatures for records
- Signature verification

#### 5.3.3 Compliance Tracking
- Regulatory requirement mapping
- Compliance checking
- Cross-regulation equivalence

#### 5.3.4 Syllabus Management
- Syllabus version control
- Syllabus structure
- Exercise and criteria management

### 5.4 AI & Analytics Engine (ai-analytics-service)

#### 5.4.1 Machine Learning Models
- Cognitive state assessment
- Performance prediction
- Anomaly detection

#### 5.4.2 Inference Engine
- Model loading and serving
- Batch and streaming inference
- Model chaining

#### 5.4.3 Analytics Processing
- Statistical analysis
- Trend detection
- Comparative analysis

#### 5.4.4 Visualization Backend
- Data aggregation
- Time-series processing
- Chart data preparation

### 5.5 Document Management Service (document-service)

#### 5.5.1 Document Repository
- Content-addressable storage
- Access control
- Search and retrieval

#### 5.5.2 Document Parsers
- PDF, DOCX, XLSX parsing
- Text extraction
- Layout preservation

#### 5.5.3 Content Extraction
- NLP-based content extraction
- Knowledge graph building
- Regulatory document parsing

#### 5.5.4 Version Control
- Document versioning
- Delta compression
- Change tracking

### 5.6 Syllabus Generator Service (syllabus-generator-service)

#### 5.6.1 Content Extraction
- Training objective extraction
- Exercise component identification
- Regulatory mapping

#### 5.6.2 Structure Generation
- Syllabus organization
- Logical sequencing
- Prerequisite linking

#### 5.6.3 Compliance Checking
- Regulatory requirement mapping
- Completeness checking
- Impact analysis

### 5.7 Assessment System (assessment-service)

#### 5.7.1 Grading
- Criteria-based assessment
- 1-4 scale implementation
- Automatic grading suggestions

#### 5.7.2 Tracking
- Session status tracking
- Progress monitoring
- Trainee performance history

#### 5.7.3 Benchmarking
- Normative data comparison
- Cohort performance analysis
- Regulatory compliance metrics

### 5.8 Frontend Applications (frontend)

#### 5.8.1 Instructor Portal
- Record creation and signing
- Performance monitoring
- Debriefing tools

#### 5.8.2 Trainee Portal
- Training record view
- Progress tracking
- Syllabus access

#### 5.8.3 Administrator Dashboard
- System monitoring
- User management
- Configuration

#### 5.8.4 Syllabus Builder
- Visual syllabus creation
- Regulatory compliance checking
- Exercise design

## 6. Process View

### 6.1 Authentication Flow

```
                    
Client          API Gateway            Core Service 
                    
      Login Request                            
   >                        
                         Auth Request          
                       >
                                               
                         JWT Token + Refresh   
                       <
      JWT Token                                
   <                        
                                               
      API Request +                            
      JWT Token                                
   >                        
                        Token Validation       
                       >
                        Validation Result      
                       <
                                               
      Response                                 
   <                        
                                               
```

### 6.2 Data Acquisition Flow

```
                
  Device         Device           Data            Data          Database  
  Sensor       Connector       Processing        Fusion                   
                
        Raw Data                                                        
     >                                                   
                       Normalized                                       
                       Data                                            
                     >                                  
                                        Processed                      
                                        Data                           
                                      >                 
                                                         Fused Data    
                                                       >
                                                                        
```

### 6.3 Record Signing Flow

```
            
Instructor        ETR           Digital          Record   
                Service        Signature       Repository 
            
        Sign Request                                    
     >                                  
                       Signature                        
                       Request                         
                     >                 
                                        Verify         
                                        Certificate    
                     <                 
                       Certificate                     
                       Valid                           
                     >                 
                                        Generate       
                                        Signature      
                                      >
                                        Signature      
                                        Added          
                     <                 
       Signed Record                                    
     <                                  
                                                       
```

## 7. Deployment View

### 7.1 Container Architecture

The system is deployed using Docker containers orchestrated with Docker Compose or Kubernetes:

```

                           Docker Host / Kubernetes Cluster           
                                                                     
        
      Core          ETR           Data          AI &        
     Service       Service     Acquisition    Analytics     
        
                                                                     
        
    Document      Syllabus     Assessment     Frontend      
     Service      Generator      Service                    
        
                                                                     
        
    Database      Prometheus     Grafana     API Gateway    
                                                            
        
                                                                     

```

### 7.2 Hardware Requirements

Minimum requirements per service:

| Service             | CPU Cores | RAM (GB) | Disk (GB) | Network       |
|---------------------|-----------|----------|-----------|---------------|
| Core Platform       | 2         | 4        | 20        | 1 Gbps        |
| Data Acquisition    | 4         | 8        | 100       | 10 Gbps       |
| ETR                 | 2         | 4        | 40        | 1 Gbps        |
| AI & Analytics      | 8         | 16       | 200       | 1 Gbps        |
| Document            | 2         | 8        | 500       | 1 Gbps        |
| Syllabus Generator  | 4         | 8        | 60        | 1 Gbps        |
| Assessment          | 2         | 4        | 40        | 1 Gbps        |
| Frontend            | 2         | 4        | 20        | 1 Gbps        |
| Database            | 8         | 32       | 1000      | 10 Gbps       |

## 8. Technology Stack

### 8.1 Backend Services

- **Languages**: C++20, Python 3.10+
- **Frameworks**: gRPC, Boost, Eigen
- **Database**: PostgreSQL 15, TimescaleDB
- **Containerization**: Docker, Docker Compose, Kubernetes
- **Monitoring**: Prometheus, Grafana
- **Logging**: ELK Stack (Elasticsearch, Logstash, Kibana)

### 8.2 Frontend

- **Framework**: React 18+
- **Language**: TypeScript
- **State Management**: Redux Toolkit
- **UI Components**: Material-UI, Chart.js, D3.js
- **API Client**: gRPC-Web, Axios

### 8.3 AI & Machine Learning

- **Frameworks**: TensorFlow C++ API, PyTorch, scikit-learn
- **Model Formats**: ONNX, TensorFlow SavedModel
- **Feature Engineering**: Eigen, NumPy, Pandas

## 9. Quality Attributes

### 9.1 Performance

- Database queries optimized for <50ms response time
- Real-time data processing with <10ms latency
- Frontend rendering with <200ms Time to Interactive
- Document processing of 100MB PDF in <5 seconds

### 9.2 Security

- Implement AES-256 encryption for sensitive data
- Use TLS 1.3 for all communications
- Implement RBAC with fine-grained permissions
- Add input validation for all API endpoints
- Implement rate limiting and CSRF protection

### 9.3 Reliability

- Implement circuit breakers for service calls
- Use retry mechanisms with exponential backoff
- Support graceful degradation
- Implement health checks and automatic recovery

### 9.4 Scalability

- Stateless services for horizontal scaling
- Database sharding for large datasets
- Cache frequently accessed data
- Implement load balancing

### 9.5 Maintainability

- Comprehensive unit test coverage (>85%)
- Consistent code style and documentation
- Modular design with clear interfaces
- Automated CI/CD pipeline

## 10. Interface View

### 10.1 Service APIs

All services expose gRPC interfaces with the following patterns:

- **Core Platform Service**: Authentication, configuration
- **Data Acquisition**: Device discovery, data streaming
- **ETR**: Records CRUD, compliance checking
- **AI & Analytics**: Model inference, data analysis
- **Document**: Document CRUD, content extraction
- **Syllabus Generator**: Syllabus generation, validation
- **Assessment**: Assessment creation, grading

### 10.2 External Interfaces

- **Device Interfaces**: USB, Ethernet, Bluetooth for data acquisition
- **Flight Simulator Interface**: ARINC 610D standard
- **Regulatory API Integration**: FAA/EASA data feeds

## 11. Data View

### 11.1 Data Models

Key data entities:

- **User**: Authentication and authorization information
- **TrainingRecord**: Record of training activities
- **Syllabus**: Training program structure
- **Assessment**: Evaluation of trainee performance
- **Document**: Training content and references
- **Device**: Connected hardware information
- **DataPoint**: Individual measurement from devices
- **AuditLog**: System activity tracking

### 11.2 Data Persistence

Different storage approaches based on data type:

- **Relational Data**: PostgreSQL (records, syllabi, assessments)
- **Time-Series Data**: TimescaleDB (device measurements)
- **Document Data**: Filesystem with metadata in PostgreSQL
- **Binary Data**: Object storage with content-addressable hashing

## 12. Security View

### 12.1 Authentication & Authorization

- JWT-based authentication
- X.509 certificate support
- Role-based access control
- Attribute-based authorization

### 12.2 Data Protection

- Encryption at rest (AES-256)
- Encryption in transit (TLS 1.3)
- Data masking for sensitive information
- Digital signatures for records

### 12.3 API Security

- Input validation
- Rate limiting
- CSRF protection
- Request throttling

## 13. Development View

### 13.1 Development Environment

- **IDE**: Visual Studio Code, CLion
- **Version Control**: Git
- **CI/CD**: Jenkins, GitHub Actions
- **Static Analysis**: Clang-Tidy, ESLint
- **Testing**: GTest, Jest

### 13.2 Build System

- **Backend**: CMake
- **Frontend**: npm, Webpack
- **Containerization**: Docker, Docker Compose

## 14. Implementation Plan

### 14.1 Phase 1: Core Infrastructure

- Core Platform Service
- Database schema and migrations
- API Gateway
- Basic Authentication

### 14.2 Phase 2: Services Implementation

- Data Acquisition Service
- ETR Service
- Document Management Service
- Assessment Service

### 14.3 Phase 3: AI & Advanced Features

- AI & Analytics Engine
- Syllabus Generator
- Advanced Compliance Tracking
- Performance Prediction

### 14.4 Phase 4: Frontend & Integration

- Instructor Portal
- Trainee Portal
- Administrator Dashboard
- System Integration

## 15. Appendices

### 15.1 Glossary

- **ETR**: Electronic Training Records
- **ARINC 610D**: Aviation standard for simulator interfaces
- **gRPC**: High-performance RPC framework
- **JWT**: JSON Web Token
- **RBAC**: Role-Based Access Control
- **TimescaleDB**: Time-series database extension for PostgreSQL

### 15.2 References

- [C++20 Standard](https://isocpp.org/std/the-standard)
- [React Documentation](https://reactjs.org/docs/getting-started.html)
- [gRPC Documentation](https://grpc.io/docs/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Docker Documentation](https://docs.docker.com/)
- [FAA Regulations](https://www.faa.gov/regulations_policies/)
// src/frontend/components/SyllabusBuilder/SyllabusBuilder.tsx
import React, { useState, useCallback, useEffect } from 'react';
import { useDrag, useDrop, DndProvider } from 'react-dnd';
import { HTML5Backend } from 'react-dnd-html5-backend';
import {
  ChevronDown,
  ChevronRight,
  MoreHorizontal,
  Plus,
  Edit,
  Trash,
  Copy,
  AlertCircle,
  CheckCircle,
  Save,
  FileText,
  List,
  Clock
} from 'lucide-react';

import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from '@/components/ui/dropdown-menu';
import {
  Dialog,
  DialogContent,
  DialogDescription,
  DialogFooter,
  DialogHeader,
  DialogTitle,
  DialogTrigger,
} from '@/components/ui/dialog';
import { Input } from '@/components/ui/input';
import { Label } from '@/components/ui/label';
import { Textarea } from '@/components/ui/textarea';
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from '@/components/ui/select';
import { Badge } from '@/components/ui/badge';
import { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';
import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from '@/components/ui/tooltip';
import { Progress } from '@/components/ui/progress';
import { Checkbox } from '@/components/ui/checkbox';

// Types
export interface SyllabusElement {
  id: string;
  type: 'module' | 'lesson' | 'exercise';
  title: string;
  description?: string;
  children?: SyllabusElement[];
  duration?: number; // in minutes
  status?: 'draft' | 'review' | 'approved';
  completionCriteria?: string;
  learningObjectives?: string[];
  assessmentMethod?: string;
  regulatoryReferences?: string[];
  complianceStatus?: {
    status: 'compliant' | 'partial' | 'non-compliant';
    issues?: string[];
  };
  lastModified?: string;
  lastModifiedBy?: string;
  version?: number;
  parentId?: string;
  dragDisabled?: boolean;
}

export interface SyllabusData {
  id: string;
  title: string;
  description?: string;
  version: number;
  status: 'draft' | 'review' | 'approved';
  author: string;
  createdAt: string;
  lastModified: string;
  organization: string;
  regulatoryFramework?: string;
  totalDuration?: number;
  complianceScore?: number;
  elements: SyllabusElement[];
}

export interface SyllabusTemplate {
  id: string;
  name: string;
  description: string;
  elements: SyllabusElement[];
  regulatoryFramework?: string;
  organization: string;
}

export interface SyllabusBuilderProps {
  initialData?: SyllabusData;
  templates?: SyllabusTemplate[];
  readOnly?: boolean;
  onSave?: (data: SyllabusData) => void;
  onPublish?: (data: SyllabusData) => void;
  onTemplateApply?: (templateId: string, syllabusId: string) => void;
  showAdvancedFeatures?: boolean;
}

// Constants
const ITEM_TYPES = {
  SYLLABUS_ELEMENT: 'syllabusElement',
};

// Drag and Drop Elements
interface DragItem {
  type: string;
  id: string;
  elementType: 'module' | 'lesson' | 'exercise';
  parentId: string | null;
  index: number;
}

interface SyllabusElementItemProps {
  element: SyllabusElement;
  index: number;
  parentId: string | null;
  onEdit: (element: SyllabusElement) => void;
  onDelete: (id: string) => void;
  onDuplicate: (element: SyllabusElement) => void;
  onMove: (dragIndex: number, hoverIndex: number, dragId: string, hoverId: string, parentId: string | null) => void;
  onAddChild: (parentId: string, type: 'module' | 'lesson' | 'exercise') => void;
  level: number;
  isLast: boolean;
  showAdvancedFeatures?: boolean;
}

const SyllabusElementItem: React.FC<SyllabusElementItemProps> = ({
  element,
  index,
  parentId,
  onEdit,
  onDelete,
  onDuplicate,
  onMove,
  onAddChild,
  level,
  isLast,
  showAdvancedFeatures = true,
}) => {
  const [isExpanded, setIsExpanded] = useState(false);
  const canHaveChildren = element.type === 'module' || element.type === 'lesson';
  
  // Configure drag and drop
  const [{ isDragging }, drag] = useDrag({
    type: ITEM_TYPES.SYLLABUS_ELEMENT,
    item: {
      type: ITEM_TYPES.SYLLABUS_ELEMENT,
      id: element.id,
      elementType: element.type,
      parentId: parentId,
      index,
    },
    canDrag: !element.dragDisabled,
    collect: (monitor) => ({
      isDragging: monitor.isDragging(),
    }),
  });
  
  const [{ isOver }, drop] = useDrop({
    accept: ITEM_TYPES.SYLLABUS_ELEMENT,
    hover(item: DragItem, monitor) {
      if (!item) {
        return;
      }
      
      // Don't replace items with themselves
      if (item.id === element.id) {
        return;
      }
      
      // Time to actually perform the action
      if (item.parentId === parentId) {
        onMove(item.index, index, item.id, element.id, parentId);
        // Update the index for the source item
        item.index = index;
      }
    },
    collect: (monitor) => ({
      isOver: monitor.isOver(),
    }),
  });
  
  // Toggle expansion
  const toggleExpand = useCallback(() => {
    setIsExpanded((prev) => !prev);
  }, []);
  
  // Format duration for display
  const formatDuration = (minutes?: number): string => {
    if (!minutes) return '';
    const hours = Math.floor(minutes / 60);
    const mins = minutes % 60;
    return hours > 0 ? `${hours}h ${mins}m` : `${mins}m`;
  };
  
  // Get compliance status color
  const getComplianceColor = (): string => {
    if (!element.complianceStatus) return 'gray';
    switch (element.complianceStatus.status) {
      case 'compliant':
        return 'green';
      case 'partial':
        return 'yellow';
      case 'non-compliant':
        return 'red';
      default:
        return 'gray';
    }
  };
  
  const getElementTypeIcon = () => {
    switch (element.type) {
      case 'module':
        return <List className="h-4 w-4 mr-2" />;
      case 'lesson':
        return <FileText className="h-4 w-4 mr-2" />;
      case 'exercise':
        return <Clock className="h-4 w-4 mr-2" />;
      default:
        return null;
    }
  };
  
  const renderComplianceStatus = () => {
    if (!element.complianceStatus) return null;
    
    return (
      <TooltipProvider>
        <Tooltip>
          <TooltipTrigger asChild>
            <div className="flex items-center ml-2">
              {element.complianceStatus.status === 'compliant' ? (
                <CheckCircle className="h-4 w-4 text-green-500" />
              ) : element.complianceStatus.status === 'partial' ? (
                <AlertCircle className="h-4 w-4 text-yellow-500" />
              ) : (
                <AlertCircle className="h-4 w-4 text-red-500" />
              )}
            </div>
          </TooltipTrigger>
          <TooltipContent>
            <p>Compliance: {element.complianceStatus.status}</p>
            {element.complianceStatus.issues && element.complianceStatus.issues.length > 0 && (
              <ul className="list-disc list-inside mt-1">
                {element.complianceStatus.issues.map((issue, i) => (
                  <li key={i} className="text-xs">{issue}</li>
                ))}
              </ul>
            )}
          </TooltipContent>
        </Tooltip>
      </TooltipProvider>
    );
  };
  
  return (
    <div ref={(node) => drag(drop(node))} className={`mb-1 ${isDragging ? 'opacity-50' : ''}`}>
      <div 
        className={`
          flex items-center p-2 rounded-md border 
          ${isOver ? 'border-primary bg-primary/10' : 'border-gray-200'} 
          ${element.type === 'module' ? 'bg-gray-50' : element.type === 'lesson' ? 'bg-white' : 'bg-white'}
          hover:border-gray-300 transition-colors
        `}
        style={{ paddingLeft: `${(level + 1) * 8}px` }}
      >
        {canHaveChildren && (
          <button 
            onClick={toggleExpand} 
            className="flex items-center justify-center h-6 w-6 rounded-md hover:bg-gray-200"
          >
            {isExpanded ? <ChevronDown className="h-4 w-4" /> : <ChevronRight className="h-4 w-4" />}
          </button>
        )}
        
        {!canHaveChildren && <div className="w-6" />}
        
        <div className="flex-1 flex items-center ml-2">
          {getElementTypeIcon()}
          <span className="font-medium">{element.title}</span>
          
          {element.status && (
            <Badge 
              variant="outline" 
              className="ml-2"
            >
              {element.status}
            </Badge>
          )}
          
          {element.duration !== undefined && (
            <span className="text-xs text-gray-500 ml-2">
              {formatDuration(element.duration)}
            </span>
          )}
          
          {renderComplianceStatus()}
        </div>
        
        <div className="flex items-center space-x-1">
          <DropdownMenu>
            <DropdownMenuTrigger asChild>
              <Button variant="ghost" size="sm" className="h-8 w-8 p-0">
                <MoreHorizontal className="h-4 w-4" />
              </Button>
            </DropdownMenuTrigger>
            <DropdownMenuContent align="end">
              <DropdownMenuLabel>Actions</DropdownMenuLabel>
              <DropdownMenuItem onClick={() => onEdit(element)}>
                <Edit className="h-4 w-4 mr-2" />
                Edit
              </DropdownMenuItem>
              {canHaveChildren && (
                <>
                  <DropdownMenuItem onClick={() => onAddChild(element.id, element.type === 'module' ? 'lesson' : 'exercise')}>
                    <Plus className="h-4 w-4 mr-2" />
                    Add {element.type === 'module' ? 'Lesson' : 'Exercise'}
                  </DropdownMenuItem>
                  {element.type === 'module' && (
                    <DropdownMenuItem onClick={() => onAddChild(element.id, 'module')}>
                      <Plus className="h-4 w-4 mr-2" />
                      Add Sub-Module
                    </DropdownMenuItem>
                  )}
                </>
              )}
              <DropdownMenuItem onClick={() => onDuplicate(element)}>
                <Copy className="h-4 w-4 mr-2" />
                Duplicate
              </DropdownMenuItem>
              <DropdownMenuSeparator />
              <DropdownMenuItem 
                onClick={() => onDelete(element.id)}
                className="text-red-500 focus:text-red-500"
              >
                <Trash className="h-4 w-4 mr-2" />
                Delete
              </DropdownMenuItem>
            </DropdownMenuContent>
          </DropdownMenu>
        </div>
      </div>
      
      {/* Render children if expanded */}
      {isExpanded && element.children && element.children.length > 0 && (
        <div className="ml-4">
          {element.children.map((child, childIndex) => (
            <SyllabusElementItem
              key={child.id}
              element={child}
              index={childIndex}
              parentId={element.id}
              onEdit={onEdit}
              onDelete={onDelete}
              onDuplicate={onDuplicate}
              onMove={onMove}
              onAddChild={onAddChild}
              level={level + 1}
              isLast={childIndex === element.children!.length - 1}
              showAdvancedFeatures={showAdvancedFeatures}
            />
          ))}
        </div>
      )}
    </div>
  );
};

// Element Editor Dialog
interface ElementEditorProps {
  element: SyllabusElement | null;
  isOpen: boolean;
  onClose: () => void;
  onSave: (element: SyllabusElement) => void;
  showAdvancedFeatures?: boolean;
}

const ElementEditor: React.FC<ElementEditorProps> = ({
  element,
  isOpen,
  onClose,
  onSave,
  showAdvancedFeatures = true,
}) => {
  const [formData, setFormData] = useState<SyllabusElement | null>(null);
  
  // Initialize form data when element changes
  useEffect(() => {
    if (element) {
      setFormData({ ...element });
    } else {
      setFormData(null);
    }
  }, [element, isOpen]);
  
  // Update form data
  const handleChange = (field: keyof SyllabusElement, value: any) => {
    if (!formData) return;
    
    setFormData({
      ...formData,
      [field]: value,
    });
  };
  
  // Update learning objectives
  const handleObjectiveChange = (index: number, value: string) => {
    if (!formData || !formData.learningObjectives) return;
    
    const updatedObjectives = [...formData.learningObjectives];
    updatedObjectives[index] = value;
    
    setFormData({
      ...formData,
      learningObjectives: updatedObjectives,
    });
  };
  
  // Add new learning objective
  const addObjective = () => {
    if (!formData) return;
    
    const updatedObjectives = formData.learningObjectives ? [...formData.learningObjectives] : [];
    updatedObjectives.push('');
    
    setFormData({
      ...formData,
      learningObjectives: updatedObjectives,
    });
  };
  
  // Remove learning objective
  const removeObjective = (index: number) => {
    if (!formData || !formData.learningObjectives) return;
    
    const updatedObjectives = [...formData.learningObjectives];
    updatedObjectives.splice(index, 1);
    
    setFormData({
      ...formData,
      learningObjectives: updatedObjectives,
    });
  };
  
  // Update regulatory references
  const handleReferenceChange = (index: number, value: string) => {
    if (!formData || !formData.regulatoryReferences) return;
    
    const updatedReferences = [...formData.regulatoryReferences];
    updatedReferences[index] = value;
    
    setFormData({
      ...formData,
      regulatoryReferences: updatedReferences,
    });
  };
  
  // Add new regulatory reference
  const addReference = () => {
    if (!formData) return;
    
    const updatedReferences = formData.regulatoryReferences ? [...formData.regulatoryReferences] : [];
    updatedReferences.push('');
    
    setFormData({
      ...formData,
      regulatoryReferences: updatedReferences,
    });
  };
  
  // Remove regulatory reference
  const removeReference = (index: number) => {
    if (!formData || !formData.regulatoryReferences) return;
    
    const updatedReferences = [...formData.regulatoryReferences];
    updatedReferences.splice(index, 1);
    
    setFormData({
      ...formData,
      regulatoryReferences: updatedReferences,
    });
  };
  
  // Save changes
  const handleSave = () => {
    if (!formData) return;
    
    // Update version and last modified
    const updatedElement: SyllabusElement = {
      ...formData,
      version: (formData.version || 0) + 1,
      lastModified: new Date().toISOString(),
    };
    
    onSave(updatedElement);
    onClose();
  };
  
  if (!formData) return null;
  
  return (
    <Dialog open={isOpen} onOpenChange={(open) => !open && onClose()}>
      <DialogContent className="max-w-2xl max-h-[90vh] overflow-y-auto">
        <DialogHeader>
          <DialogTitle>
            {formData.id ? `Edit ${formData.type.charAt(0).toUpperCase() + formData.type.slice(1)}` : 'Create New Element'}
          </DialogTitle>
          <DialogDescription>
            Update the details of this syllabus element.
          </DialogDescription>
        </DialogHeader>
        
        <div className="grid gap-4 py-4">
          <div className="grid grid-cols-4 items-center gap-4">
            <Label htmlFor="title" className="text-right">Title</Label>
            <Input
              id="title"
              value={formData.title}
              onChange={(e) => handleChange('title', e.target.value)}
              className="col-span-3"
            />
          </div>
          
          <div className="grid grid-cols-4 items-center gap-4">
            <Label htmlFor="type" className="text-right">Type</Label>
            <Select
              value={formData.type}
              onValueChange={(value) => handleChange('type', value)}
              disabled={!!formData.id} // Can't change type of existing elements
            >
              <SelectTrigger className="col-span-3">
                <SelectValue placeholder="Select type" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="module">Module</SelectItem>
                <SelectItem value="lesson">Lesson</SelectItem>
                <SelectItem value="exercise">Exercise</SelectItem>
              </SelectContent>
            </Select>
          </div>
          
          <div className="grid grid-cols-4 items-start gap-4">
            <Label htmlFor="description" className="text-right pt-2">Description</Label>
            <Textarea
              id="description"
              value={formData.description || ''}
              onChange={(e) => handleChange('description', e.target.value)}
              className="col-span-3"
              rows={3}
            />
          </div>
          
          <div className="grid grid-cols-4 items-center gap-4">
            <Label htmlFor="duration" className="text-right">Duration (minutes)</Label>
            <Input
              id="duration"
              type="number"
              min="1"
              value={formData.duration || ''}
              onChange={(e) => handleChange('duration', parseInt(e.target.value) || 0)}
              className="col-span-3"
            />
          </div>
          
          <div className="grid grid-cols-4 items-center gap-4">
            <Label htmlFor="status" className="text-right">Status</Label>
            <Select
              value={formData.status || 'draft'}
              onValueChange={(value) => handleChange('status', value)}
            >
              <SelectTrigger className="col-span-3">
                <SelectValue placeholder="Select status" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="draft">Draft</SelectItem>
                <SelectItem value="review">Review</SelectItem>
                <SelectItem value="approved">Approved</SelectItem>
              </SelectContent>
            </Select>
          </div>
          
          {/* Advanced options */}
          {showAdvancedFeatures && (
            <>
              <div className="grid grid-cols-4 items-start gap-4">
                <Label className="text-right pt-2">Learning Objectives</Label>
                <div className="col-span-3 space-y-2">
                  {formData.learningObjectives?.map((objective, index) => (
                    <div key={index} className="flex items-center space-x-2">
                      <Input
                        value={objective}
                        onChange={(e) => handleObjectiveChange(index, e.target.value)}
                        placeholder={`Objective ${index + 1}`}
                      />
                      <Button
                        variant="ghost"
                        size="sm"
                        onClick={() => removeObjective(index)}
                        className="h-8 w-8 p-0"
                      >
                        <Trash className="h-4 w-4" />
                      </Button>
                    </div>
                  ))}
                  <Button variant="outline" size="sm" onClick={addObjective} className="mt-2">
                    <Plus className="h-4 w-4 mr-2" />
                    Add Objective
                  </Button>
                </div>
              </div>
              
              <div className="grid grid-cols-4 items-start gap-4">
                <Label htmlFor="completionCriteria" className="text-right pt-2">Completion Criteria</Label>
                <Textarea
                  id="completionCriteria"
                  value={formData.completionCriteria || ''}
                  onChange={(e) => handleChange('completionCriteria', e.target.value)}
                  className="col-span-3"
                  rows={2}
                />
              </div>
              
              <div className="grid grid-cols-4 items-center gap-4">
                <Label htmlFor="assessmentMethod" className="text-right">Assessment Method</Label>
                <Select
                  value={formData.assessmentMethod || ''}
                  onValueChange={(value) => handleChange('assessmentMethod', value)}
                >
                  <SelectTrigger className="col-span-3">
                    <SelectValue placeholder="Select assessment method" />
                  </SelectTrigger>
                  <SelectContent>
                    <SelectItem value="written-test">Written Test</SelectItem>
                    <SelectItem value="practical-exam">Practical Exam</SelectItem>
                    <SelectItem value="simulation">Simulation</SelectItem>
                    <SelectItem value="observation">Instructor Observation</SelectItem>
                    <SelectItem value="self-assessment">Self-Assessment</SelectItem>
                    <SelectItem value="none">None</SelectItem>
                  </SelectContent>
                </Select>
              </div>
              
              <div className="grid grid-cols-4 items-start gap-4">
                <Label className="text-right pt-2">Regulatory References</Label>
                <div className="col-span-3 space-y-2">
                  {formData.regulatoryReferences?.map((reference, index) => (
                    <div key={index} className="flex items-center space-x-2">
                      <Input
                        value={reference}
                        onChange={(e) => handleReferenceChange(index, e.target.value)}
                        placeholder={`Reference ${index + 1}`}
                      />
                      <Button
                        variant="ghost"
                        size="sm"
                        onClick={() => removeReference(index)}
                        className="h-8 w-8 p-0"
                      >
                        <Trash className="h-4 w-4" />
                      </Button>
                    </div>
                  ))}
                  <Button variant="outline" size="sm" onClick={addReference} className="mt-2">
                    <Plus className="h-4 w-4 mr-2" />
                    Add Reference
                  </Button>
                </div>
              </div>
            </>
          )}
        </div>
        
        <DialogFooter>
          <Button variant="outline" onClick={onClose}>Cancel</Button>
          <Button onClick={handleSave}>Save Changes</Button>
        </DialogFooter>
      </DialogContent>
    </Dialog>
  );
};

// Template Selection Dialog
interface TemplateSelectionProps {
  templates: SyllabusTemplate[];
  isOpen: boolean;
  onClose: () => void;
  onApply: (templateId: string) => void;
}

const TemplateSelection: React.FC<TemplateSelectionProps> = ({
  templates,
  isOpen,
  onClose,
  onApply,
}) => {
  const [selectedTemplate, setSelectedTemplate] = useState<string | null>(null);
  
  return (
    <Dialog open={isOpen} onOpenChange={(open) => !open && onClose()}>
      <DialogContent>
        <DialogHeader>
          <DialogTitle>Apply Template</DialogTitle>
          <DialogDescription>
            Select a template to apply to your syllabus. This will add new elements to your existing structure.
          </DialogDescription>
        </DialogHeader>
        
        <div className="grid gap-4 py-4">
          <div className="space-y-4">
            {templates.map((template) => (
              <div
                key={template.id}
                className={`p-4 border rounded-lg cursor-pointer hover:border-primary transition-colors ${
                  selectedTemplate === template.id ? 'border-primary bg-primary/10' : ''
                }`}
                onClick={() => setSelectedTemplate(template.id)}
              >
                <div className="font-medium">{template.name}</div>
                <div className="text-sm text-gray-500 mt-1">{template.description}</div>
                <div className="flex mt-2">
                  <Badge variant="outline" className="mr-2">
                    {template.elements.length} elements
                  </Badge>
                  {template.regulatoryFramework && (
                    <Badge variant="outline">
                      {template.regulatoryFramework}
                    </Badge>
                  )}
                </div>
              </div>
            ))}
          </div>
        </div>
        
        <DialogFooter>
          <Button variant="outline" onClick={onClose}>Cancel</Button>
          <Button 
            onClick={() => selectedTemplate && onApply(selectedTemplate)} 
            disabled={!selectedTemplate}
          >
            Apply Template
          </Button>
        </DialogFooter>
      </DialogContent>
    </Dialog>
  );
};

// Main SyllabusBuilder Component
const SyllabusBuilder: React.FC<SyllabusBuilderProps> = ({
  initialData,
  templates = [],
  readOnly = false,
  onSave,
  onPublish,
  onTemplateApply,
  showAdvancedFeatures = true,
}) => {
  const [syllabus, setSyllabus] = useState<SyllabusData | null>(null);
  const [isTemplateDialogOpen, setIsTemplateDialogOpen] = useState(false);
  const [editingElement, setEditingElement] = useState<SyllabusElement | null>(null);
  const [activeTab, setActiveTab] = useState('structure');
  
  // Initialize syllabus data
  useEffect(() => {
    if (initialData) {
      setSyllabus({ ...initialData });
    } else {
      // Create a new empty syllabus
      const newSyllabus: SyllabusData = {
        id: `syllabus-${Date.now()}`,
        title: 'New Syllabus',
        description: '',
        version: 1,
        status: 'draft',
        author: 'Current User',
        createdAt: new Date().toISOString(),
        lastModified: new Date().toISOString(),
        organization: 'Your Organization',
        elements: [],
      };
      setSyllabus(newSyllabus);
    }
  }, [initialData]);
  
  // Calculate total duration and compliance score
  useEffect(() => {
    if (!syllabus) return;
    
    const calculateTotalDuration = (elements: SyllabusElement[]): number => {
      return elements.reduce((total, element) => {
        let duration = element.duration || 0;
        if (element.children && element.children.length > 0) {
          duration += calculateTotalDuration(element.children);
        }
        return total + duration;
      }, 0);
    };
    
    const calculateComplianceScore = (elements: SyllabusElement[]): number => {
      let totalElements = 0;
      let compliantElements = 0;
      let partialElements = 0;
      
      const countElements = (elements: SyllabusElement[]) => {
        for (const element of elements) {
          totalElements++;
          
          if (element.complianceStatus) {
            if (element.complianceStatus.status === 'compliant') {
              compliantElements++;
            } else if (element.complianceStatus.status === 'partial') {
              partialElements++;
            }
          }
          
          if (element.children && element.children.length > 0) {
            countElements(element.children);
          }
        }
      };
      
      countElements(elements);
      
      if (totalElements === 0) return 0;
      
      return ((compliantElements + (partialElements * 0.5)) / totalElements) * 100;
    };
    
    const totalDuration = calculateTotalDuration(syllabus.elements);
    const complianceScore = calculateComplianceScore(syllabus.elements);
    
    setSyllabus((prev) => {
      if (!prev) return null;
      return {
        ...prev,
        totalDuration,
        complianceScore,
      };
    });
  }, [syllabus?.elements]);
  
  // Save syllabus
  const handleSave = useCallback(() => {
    if (!syllabus || !onSave) return;
    
    const updatedSyllabus: SyllabusData = {
      ...syllabus,
      lastModified: new Date().toISOString(),
      version: syllabus.version + 1,
    };
    
    setSyllabus(updatedSyllabus);
    onSave(updatedSyllabus);
  }, [syllabus, onSave]);
  
  // Publish syllabus
  const handlePublish = useCallback(() => {
    if (!syllabus || !onPublish) return;
    
    const updatedSyllabus: SyllabusData = {
      ...syllabus,
      status: 'review',
      lastModified: new Date().toISOString(),
      version: syllabus.version + 1,
    };
    
    setSyllabus(updatedSyllabus);
    onPublish(updatedSyllabus);
  }, [syllabus, onPublish]);
  
  // Apply template
  const handleApplyTemplate = useCallback((templateId: string) => {
    if (!syllabus || !onTemplateApply) return;
    
    onTemplateApply(templateId, syllabus.id);
    setIsTemplateDialogOpen(false);
  }, [syllabus, onTemplateApply]);
  
  // Helper function to clone elements and all their children
  const cloneElement = (element: SyllabusElement, newParentId?: string): SyllabusElement => {
    const newElement: SyllabusElement = { 
      ...element,
      id: `${element.type}-${Date.now()}-${Math.floor(Math.random() * 1000)}`,
      parentId: newParentId,
      version: 1,
      lastModified: new Date().toISOString(),
    };
    
    if (element.children && element.children.length > 0) {
      newElement.children = element.children.map(child => cloneElement(child, newElement.id));
    }
    
    return newElement;
  };
  
  // Add a new element to the syllabus
  const handleAddElement = useCallback((type: 'module' | 'lesson' | 'exercise', parentId?: string) => {
    if (!syllabus) return;
    
    const newElement: SyllabusElement = {
      id: `${type}-${Date.now()}-${Math.floor(Math.random() * 1000)}`,
      type,
      title: `New ${type.charAt(0).toUpperCase() + type.slice(1)}`,
      description: '',
      status: 'draft',
      version: 1,
      lastModified: new Date().toISOString(),
      parentId,
      children: type !== 'exercise' ? [] : undefined,
    };
    
    if (parentId) {
      // Add as child of existing element
      setSyllabus((prev) => {
        if (!prev) return null;
        
        // Helper function to recursively find and update parent
        const updateParent = (elements: SyllabusElement[]): SyllabusElement[] => {
          return elements.map((element) => {
            if (element.id === parentId) {
              return {
                ...element,
                children: [...(element.children || []), newElement],
              };
            } else if (element.children && element.children.length > 0) {
              return {
                ...element,
                children: updateParent(element.children),
              };
            } else {
              return element;
            }
          });
        };
        
        return {
          ...prev,
          elements: updateParent(prev.elements),
        };
      });
    } else {
      // Add as top-level element
      setSyllabus((prev) => {
        if (!prev) return null;
        return {
          ...prev,
          elements: [...prev.elements, newElement],
        };
      });
    }
    
    // Edit the new element
    setEditingElement(newElement);
  }, [syllabus]);
  
  // Edit an existing element
  const handleEditElement = useCallback((element: SyllabusElement) => {
    setEditingElement(element);
  }, []);
  
  // Save edited element
  const handleSaveElement = useCallback((updatedElement: SyllabusElement) => {
    if (!syllabus) return;
    
    // Helper function to recursively update element
    const updateElement = (elements: SyllabusElement[]): SyllabusElement[] => {
      return elements.map((element) => {
        if (element.id === updatedElement.id) {
          return updatedElement;
        } else if (element.children && element.children.length > 0) {
          return {
            ...element,
            children: updateElement(element.children),
          };
        } else {
          return element;
        }
      });
    };
    
    // Update the syllabus
    setSyllabus((prev) => {
      if (!prev) return null;
      
      if (updatedElement.parentId) {
        // Update child element
        return {
          ...prev,
          elements: updateElement(prev.elements),
        };
      } else {
        // Update top-level element
        return {
          ...prev,
          elements: updateElement(prev.elements),
        };
      }
    });
  }, [syllabus]);
  
  // Delete an element
  const handleDeleteElement = useCallback((elementId: string) => {
    if (!syllabus) return;
    
    // Helper function to recursively filter elements
    const filterElements = (elements: SyllabusElement[]): SyllabusElement[] => {
      return elements
        .filter((element) => element.id !== elementId)
        .map((element) => {
          if (element.children && element.children.length > 0) {
            return {
              ...element,
              children: filterElements(element.children),
            };
          } else {
            return element;
          }
        });
    };
    
    // Update the syllabus
    setSyllabus((prev) => {
      if (!prev) return null;
      return {
        ...prev,
        elements: filterElements(prev.elements),
      };
    });
  }, [syllabus]);
  
  // Duplicate an element
  const handleDuplicateElement = useCallback((element: SyllabusElement) => {
    if (!syllabus) return;
    
    const duplicatedElement = cloneElement(element, element.parentId);
    
    // Find where to insert the duplicate
    if (element.parentId) {
      // Duplicate a child element
      setSyllabus((prev) => {
        if (!prev) return null;
        
        // Helper function to recursively find and update parent
        const updateParent = (elements: SyllabusElement[]): SyllabusElement[] => {
          return elements.map((el) => {
            if (el.id === element.parentId) {
              return {
                ...el,
                children: [...(el.children || []), duplicatedElement],
              };
            } else if (el.children && el.children.length > 0) {
              return {
                ...el,
                children: updateParent(el.children),
              };
            } else {
              return el;
            }
          });
        };
        
        return {
          ...prev,
          elements: updateParent(prev.elements),
        };
      });
    } else {
      // Duplicate a top-level element
      setSyllabus((prev) => {
        if (!prev) return null;
        return {
          ...prev,
          elements: [...prev.elements, duplicatedElement],
        };
      });
    }
  }, [syllabus]);
  
  // Move an element
  const handleMoveElement = useCallback(
    (dragIndex: number, hoverIndex: number, dragId: string, hoverId: string, parentId: string | null) => {
      if (!syllabus) return;
      
      setSyllabus((prev) => {
        if (!prev) return null;
        
        // Helper function to move elements within the same parent
        const moveElementsInParent = (elements: SyllabusElement[], parentId: string | null): SyllabusElement[] => {
          // If this is the parent containing the elements to reorder
          if (elements.some(e => e.id === dragId && e.parentId === parentId) && 
              elements.some(e => e.id === hoverId && e.parentId === parentId)) {
            
            const result = [...elements];
            
            // Find the actual indices (they might not match dragIndex/hoverIndex if the arrays were filtered)
            const actualDragIndex = result.findIndex(e => e.id === dragId);
            const actualHoverIndex = result.findIndex(e => e.id === hoverId);
            
            if (actualDragIndex !== -1 && actualHoverIndex !== -1) {
              // Remove the drag element
              const [draggedItem] = result.splice(actualDragIndex, 1);
              
              // Insert at the new position
              result.splice(actualHoverIndex, 0, draggedItem);
            }
            
            return result;
          }
          
          // Otherwise, recursively search in children
          return elements.map(element => {
            if (element.children && element.children.length > 0) {
              return {
                ...element,
                children: moveElementsInParent(element.children, element.id),
              };
            }
            return element;
          });
        };
        
        return {
          ...prev,
          elements: moveElementsInParent(prev.elements, parentId),
        };
      });
    },
    [syllabus]
  );
  
  // Format time for display
  const formatTime = (minutes?: number): string => {
    if (!minutes) return '0m';
    
    const hours = Math.floor(minutes / 60);
    const mins = minutes % 60;
    
    if (hours === 0) {
      return `${mins}m`;
    } else if (mins === 0) {
      return `${hours}h`;
    } else {
      return `${hours}h ${mins}m`;
    }
  };
  
  if (!syllabus) {
    return <div>Loading...</div>;
  }
  
  return (
    <DndProvider backend={HTML5Backend}>
      <div className="flex flex-col h-full">
        <Card className="flex-1">
          <CardHeader className="flex flex-row items-center justify-between p-6">
            <div>
              <CardTitle className="text-xl">{syllabus.title}</CardTitle>
              {syllabus.description && (
                <p className="text-sm text-gray-500 mt-1">{syllabus.description}</p>
              )}
            </div>
            {!readOnly && (
              <div className="flex items-center space-x-2">
                <Button variant="outline" onClick={() => setIsTemplateDialogOpen(true)}>
                  Apply Template
                </Button>
                <Button variant="outline" onClick={handleSave}>
                  <Save className="h-4 w-4 mr-2" />
                  Save
                </Button>
                <Button onClick={handlePublish}>
                  Submit for Review
                </Button>
              </div>
            )}
          </CardHeader>
          
          <CardContent>
            <div className="flex flex-col lg:flex-row gap-8">
              <div className="lg:w-9/12">
                <Tabs value={activeTab} onValueChange={setActiveTab}>
                  <TabsList>
                    <TabsTrigger value="structure">Structure</TabsTrigger>
                    {showAdvancedFeatures && (
                      <>
                        <TabsTrigger value="compliance">Compliance</TabsTrigger>
                        <TabsTrigger value="analytics">Analytics</TabsTrigger>
                      </>
                    )}
                  </TabsList>
                  
                  <TabsContent value="structure" className="mt-4">
                    {/* Toolbar */}
                    {!readOnly && (
                      <div className="flex mb-4 space-x-2">
                        <Button
                          variant="outline"
                          size="sm"
                          onClick={() => handleAddElement('module')}
                        >
                          <Plus className="h-4 w-4 mr-2" />
                          Add Module
                        </Button>
                        <Button
                          variant="outline"
                          size="sm"
                          onClick={() => handleAddElement('lesson')}
                        >
                          <Plus className="h-4 w-4 mr-2" />
                          Add Lesson
                        </Button>
                        <Button
                          variant="outline"
                          size="sm"
                          onClick={() => handleAddElement('exercise')}
                        >
                          <Plus className="h-4 w-4 mr-2" />
                          Add Exercise
                        </Button>
                      </div>
                    )}
                    
                    {/* Syllabus elements */}
                    <div className="border rounded-md p-4 min-h-[400px]">
                      {syllabus.elements.length === 0 ? (
                        <div className="flex flex-col items-center justify-center h-[300px] text-gray-500">
                          <p className="mb-4">No elements in syllabus yet.</p>
                          {!readOnly && (
                            <Button
                              variant="outline"
                              onClick={() => handleAddElement('module')}
                            >
                              <Plus className="h-4 w-4 mr-2" />
                              Add Module
                            </Button>
                          )}
                        </div>
                      ) : (
                        <div className="space-y-1">
                          {syllabus.elements.map((element, index) => (
                            <SyllabusElementItem
                              key={element.id}
                              element={element}
                              index={index}
                              parentId={null}
                              onEdit={handleEditElement}
                              onDelete={handleDeleteElement}
                              onDuplicate={handleDuplicateElement}
                              onMove={handleMoveElement}
                              onAddChild={handleAddElement}
                              level={0}
                              isLast={index === syllabus.elements.length - 1}
                              showAdvancedFeatures={showAdvancedFeatures}
                            />
                          ))}
                        </div>
                      )}
                    </div>
                  </TabsContent>
                  
                  {showAdvancedFeatures && (
                    <>
                      <TabsContent value="compliance" className="mt-4">
                        <div className="border rounded-md p-6">
                          <h3 className="text-lg font-medium mb-4">Regulatory Compliance</h3>
                          
                          <div className="mb-6">
                            <div className="flex justify-between mb-2">
                              <p>Overall Compliance Score</p>
                              <p className="font-medium">{Math.round(syllabus.complianceScore || 0)}%</p>
                            </div>
                            <Progress value={syllabus.complianceScore || 0} className="h-2" />
                          </div>
                          
                          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                            <div className="border rounded-md p-4">
                              <h4 className="font-medium mb-2">Regulatory Framework</h4>
                              <p className="text-sm text-gray-600">
                                {syllabus.regulatoryFramework || 'No framework specified'}
                              </p>
                            </div>
                            
                            <div className="border rounded-md p-4">
                              <h4 className="font-medium mb-2">Compliance Gaps</h4>
                              <ul className="text-sm text-gray-600 list-disc list-inside">
                                {syllabus.elements.some(e => 
                                  e.complianceStatus?.status === 'non-compliant' || 
                                  e.complianceStatus?.status === 'partial'
                                ) ? (
                                  syllabus.elements
                                    .filter(e => 
                                      e.complianceStatus?.status === 'non-compliant' || 
                                      e.complianceStatus?.status === 'partial'
                                    )
                                    .map(e => (
                                      <li key={e.id}>
                                        {e.title}: {e.complianceStatus?.issues?.join(', ') || 'Unspecified issues'}
                                      </li>
                                    ))
                                ) : (
                                  <li>No compliance gaps detected</li>
                                )}
                              </ul>
                            </div>
                          </div>
                        </div>
                      </TabsContent>
                      
                      <TabsContent value="analytics" className="mt-4">
                        <div className="border rounded-md p-6">
                          <h3 className="text-lg font-medium mb-4">Syllabus Analytics</h3>
                          
                          <div className="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
                            <div className="border rounded-md p-4">
                              <h4 className="text-sm text-gray-500">Total Duration</h4>
                              <p className="text-2xl font-semibold mt-1">
                                {formatTime(syllabus.totalDuration)}
                              </p>
                            </div>
                            
                            <div className="border rounded-md p-4">
                              <h4 className="text-sm text-gray-500">Elements</h4>
                              <p className="text-2xl font-semibold mt-1">
                                {syllabus.elements.length}
                              </p>
                            </div>
                            
                            <div className="border rounded-md p-4">
                              <h4 className="text-sm text-gray-500">Last Updated</h4>
                              <p className="text-2xl font-semibold mt-1">
                                {new Date(syllabus.lastModified).toLocaleDateString()}
                              </p>
                            </div>
                          </div>
                          
                          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                            <div className="border rounded-md p-4">
                              <h4 className="font-medium mb-2">Element Distribution</h4>
                              <div className="h-40 flex items-end space-x-4">
                                {/* This would be replaced with a real chart in a full implementation */}
                                <div className="flex flex-col items-center">
                                  <div className="w-16 bg-blue-500 rounded-t-md" style={{ height: '60%' }}></div>
                                  <p className="text-xs mt-1">Modules</p>
                                </div>
                                <div className="flex flex-col items-center">
                                  <div className="w-16 bg-green-500 rounded-t-md" style={{ height: '100%' }}></div>
                                  <p className="text-xs mt-1">Lessons</p>
                                </div>
                                <div className="flex flex-col items-center">
                                  <div className="w-16 bg-purple-500 rounded-t-md" style={{ height: '80%' }}></div>
                                  <p className="text-xs mt-1">Exercises</p>
                                </div>
                              </div>
                            </div>
                            
                            <div className="border rounded-md p-4">
                              <h4 className="font-medium mb-2">Completion Status</h4>
                              <div className="h-40 flex items-center justify-center">
                                {/* This would be replaced with a real chart in a full implementation */}
                                <div className="w-32 h-32 rounded-full border-8 border-blue-500 flex items-center justify-center">
                                  <p className="text-xl font-semibold">75%</p>
                                </div>
                              </div>
                            </div>
                          </div>
                        </div>
                      </TabsContent>
                    </>
                  )}
                </Tabs>
              </div>
              
              <div className="lg:w-3/12">
                <div className="border rounded-md p-4 mb-4">
                  <h3 className="font-medium mb-3">Syllabus Details</h3>
                  
                  <div className="space-y-3">
                    <div>
                      <p className="text-sm text-gray-500">Status</p>
                      <Badge variant={
                        syllabus.status === 'approved' ? 'default' : 
                        syllabus.status === 'review' ? 'secondary' : 'outline'
                      }>
                        {syllabus.status.charAt(0).toUpperCase() + syllabus.status.slice(1)}
                      </Badge>
                    </div>
                    
                    <div>
                      <p className="text-sm text-gray-500">Version</p>
                      <p>{syllabus.version}.0</p>
                    </div>
                    
                    <div>
                      <p className="text-sm text-gray-500">Created by</p>
                      <p>{syllabus.author}</p>
                    </div>
                    
                    <div>
                      <p className="text-sm text-gray-500">Organization</p>
                      <p>{syllabus.organization}</p>
                    </div>
                    
                    <div>
                      <p className="text-sm text-gray-500">Created on</p>
                      <p>{new Date(syllabus.createdAt).toLocaleDateString()}</p>
                    </div>
                    
                    <div>
                      <p className="text-sm text-gray-500">Last modified</p>
                      <p>{new Date(syllabus.lastModified).toLocaleDateString()}</p>
                    </div>
                  </div>
                </div>
                
                {showAdvancedFeatures && (
                  <div className="border rounded-md p-4">
                    <h3 className="font-medium mb-3">Actions</h3>
                    
                    <div className="space-y-2">
                      <Button variant="outline" className="w-full justify-start" disabled={readOnly}>
                        <FileText className="h-4 w-4 mr-2" />
                        Export as PDF
                      </Button>
                      
                      <Button variant="outline" className="w-full justify-start" disabled={readOnly}>
                        <Copy className="h-4 w-4 mr-2" />
                        Duplicate Syllabus
                      </Button>
                      
                      <Button variant="outline" className="w-full justify-start text-red-500 hover:text-red-500" disabled={readOnly}>
                        <Trash className="h-4 w-4 mr-2" />
                        Delete Syllabus
                      </Button>
                    </div>
                  </div>
                )}
              </div>
            </div>
          </CardContent>
        </Card>
        
        {/* Element Editor Dialog */}
        <ElementEditor
          element={editingElement}
          isOpen={!!editingElement}
          onClose={() => setEditingElement(null)}
          onSave={handleSaveElement}
          showAdvancedFeatures={showAdvancedFeatures}
        />
        
        {/* Template Selection Dialog */}
        <TemplateSelection
          templates={templates}
          isOpen={isTemplateDialogOpen}
          onClose={() => setIsTemplateDialogOpen(false)}
          onApply={handleApplyTemplate}
        />
      </div>
    </DndProvider>
  );
};

export default SyllabusBuilder;

// backend/syllabus/include/SyllabusGenerator.h
#pragma once

#include <string>
#include <vector>
#include <memory>
#include <filesystem>
#include <functional>
#include <unordered_map>
#include <optional>
#include <future>

#include "core/include/ErrorHandling.h"
#include "document/include/DocumentProcessor.h"

namespace APTP::Syllabus {

// Enumeration for competency levels
enum class CompetencyLevel {
    Awareness,      // Basic awareness of the concept
    Knowledge,      // Theoretical knowledge
    Skill,          // Practical application skills
    Proficiency,    // Independent application with high reliability
    Mastery         // Expert-level competency, can teach others
};

// Regulatory body types
enum class RegulatoryBody {
    FAA,    // Federal Aviation Administration
    EASA,   // European Union Aviation Safety Agency
    ICAO,   // International Civil Aviation Organization
    TCCA,   // Transport Canada Civil Aviation
    CASA,   // Civil Aviation Safety Authority (Australia)
    Custom  // Custom regulatory body
};

// Learning objective structure
struct LearningObjective {
    std::string id;
    std::string description;
    CompetencyLevel targetLevel;
    std::vector<std::string> keywords;
    std::vector<std::string> prerequisites;
    std::unordered_map<std::string, std::string> metadata;
};

// Regulatory requirement structure
struct RegulatoryRequirement {
    std::string id;
    RegulatoryBody body;
    std::string customBody;  // For custom regulatory bodies
    std::string regulationId; // e.g., "14 CFR Part 61"
    std::string sectionId;    // e.g., "61.57"
    std::string description;
    std::vector<std::string> applicableContexts; // e.g., ["Commercial", "IFR"]
};

// Assessment criteria structure
struct AssessmentCriteria {
    std::string id;
    std::string description;
    CompetencyLevel minimumLevel;
    bool isMandatory;
    std::vector<std::string> assessmentMethods; // e.g., "Oral", "Simulator", "Aircraft"
};

// Lesson structure
struct Lesson {
    std::string id;
    std::string title;
    std::string description;
    double durationHours;
    std::vector<LearningObjective> objectives;
    std::vector<AssessmentCriteria> assessmentCriteria;
    std::vector<std::string> resources; // References to materials, simulators, etc.
    std::unordered_map<std::string, std::string> metadata;
};

// Module structure
struct Module {
    std::string id;
    std::string title;
    std::string description;
    std::vector<Lesson> lessons;
    std::vector<RegulatoryRequirement> regulatoryRequirements;
    std::unordered_map<std::string, std::string> metadata;
};

// Complete syllabus structure
struct Syllabus {
    std::string id;
    std::string title;
    std::string description;
    std::string version;
    std::string creationDate;
    std::string lastModifiedDate;
    std::string author;
    std::vector<Module> modules;
    std::vector<RegulatoryRequirement> globalRequirements;
    std::unordered_map<std::string, std::string> metadata;
};

// Syllabus template
struct SyllabusTemplate {
    std::string id;
    std::string title;
    std::string description;
    std::vector<Module> moduleTemplates;
    std::vector<RegulatoryRequirement> regulatoryRequirements;
    std::unordered_map<std::string, std::string> metadata;
};

// Syllabus generation progress
struct GenerationProgress {
    double percentComplete;
    std::string currentStage;
    std::string message;
    std::vector<std::string> warnings;
    std::vector<std::string> errors;
};

// Callback for progress updates
using ProgressCallback = std::function<void(const GenerationProgress&)>;

// Syllabus Generator class
class SyllabusGenerator {
public:
    SyllabusGenerator();
    ~SyllabusGenerator();
    
    // Generate syllabus from document
    APTP::Core::Result<Syllabus> generateFromDocument(
        const APTP::Document::ProcessingResult& document,
        const ProgressCallback& progressCallback = nullptr);
    
    // Generate syllabus from document file
    APTP::Core::Result<Syllabus> generateFromDocumentFile(
        const std::filesystem::path& filePath,
        const ProgressCallback& progressCallback = nullptr);
    
    // Generate syllabus from multiple documents
    APTP::Core::Result<Syllabus> generateFromMultipleDocuments(
        const std::vector<APTP::Document::ProcessingResult>& documents,
        const ProgressCallback& progressCallback = nullptr);
    
    // Generate syllabus from template
    APTP::Core::Result<Syllabus> generateFromTemplate(
        const SyllabusTemplate& template_,
        const std::unordered_map<std::string, std::string>& customizations,
        const ProgressCallback& progressCallback = nullptr);
    
    // Asynchronous generation
    std::future<APTP::Core::Result<Syllabus>> generateFromDocumentAsync(
        const APTP::Document::ProcessingResult& document,
        const ProgressCallback& progressCallback = nullptr);
    
    // Map syllabus to regulatory requirements
    APTP::Core::Result<std::vector<RegulatoryRequirement>> mapToRegulations(
        const Syllabus& syllabus,
        const std::vector<RegulatoryBody>& regulatoryBodies);
    
    // Validate syllabus against regulatory requirements
    APTP::Core::Result<bool> validateAgainstRegulations(
        const Syllabus& syllabus,
        const std::vector<RegulatoryRequirement>& requirements);
    
    // Save syllabus to file
    APTP::Core::Result<void> saveToFile(
        const Syllabus& syllabus, 
        const std::filesystem::path& filePath);
    
    // Load syllabus from file
    APTP::Core::Result<Syllabus> loadFromFile(
        const std::filesystem::path& filePath);

private:
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

// Syllabus Template Manager class
class SyllabusTemplateManager {
public:
    static SyllabusTemplateManager& getInstance();
    
    // Get available templates
    std::vector<SyllabusTemplate> getAvailableTemplates();
    
    // Get template by ID
    std::optional<SyllabusTemplate> getTemplateById(const std::string& templateId);
    
    // Create new template
    APTP::Core::Result<SyllabusTemplate> createTemplate(
        const std::string& title,
        const std::string& description,
        const std::vector<Module>& moduleTemplates);
    
    // Update existing template
    APTP::Core::Result<SyllabusTemplate> updateTemplate(
        const std::string& templateId,
        const SyllabusTemplate& updatedTemplate);
    
    // Delete template
    APTP::Core::Result<void> deleteTemplate(const std::string& templateId);
    
    // Import template from file
    APTP::Core::Result<SyllabusTemplate> importFromFile(
        const std::filesystem::path& filePath);
    
    // Export template to file
    APTP::Core::Result<void> exportToFile(
        const SyllabusTemplate& template_,
        const std::filesystem::path& filePath);

private:
    SyllabusTemplateManager();
    ~SyllabusTemplateManager();
    
    struct Impl;
    std::unique_ptr<Impl> impl_;
};

} // namespace APTP::Syllabus

// backend/syllabus/src/SyllabusGenerator.cpp (partial implementation)
#include "SyllabusGenerator.h"
#include "core/include/Logger.h"
#include "document/include/AIDocumentAnalyzer.h"
#include <nlohmann/json.hpp>
#include <fstream>
#include <chrono>

namespace APTP::Syllabus {

struct SyllabusGenerator::Impl {
    // Internal implementation details
    // This would include the actual algorithms and data structures used by the SyllabusGenerator
    
    // Helper method to extract learning objectives from document
    std::vector<LearningObjective> extractLearningObjectives(
        const APTP::Document::DocumentContent& content) {
        
        std::vector<LearningObjective> objectives;
        
        // Use the AI document analyzer to identify learning objectives
        APTP::Document::AIDocumentAnalyzer& analyzer = 
            APTP::Document::AIDocumentAnalyzer::getInstance();
        
        // Extract entities specifically focused on learning objectives
        auto result = analyzer.extractEntities(
            content.plainText, 
            {APTP::Document::EntityType::LearningObjective, APTP::Document::EntityType::Competency});
        
        if (result.isSuccess()) {
            const auto& entities = result.value();
            
            for (const auto& entity : entities) {
                if (entity.type == APTP::Document::EntityType::LearningObjective) {
                    LearningObjective objective;
                    objective.id = "LO-" + std::to_string(objectives.size() + 1);
                    objective.description = entity.text;
                    objective.targetLevel = CompetencyLevel::Skill; // Default level
                    
                    // Add metadata from entity attributes
                    for (const auto& [key, value] : entity.attributes) {
                        if (key == "competency_level") {
                            // Map the string value to CompetencyLevel enum
                            if (value == "awareness") objective.targetLevel = CompetencyLevel::Awareness;
                            else if (value == "knowledge") objective.targetLevel = CompetencyLevel::Knowledge;
                            else if (value == "skill") objective.targetLevel = CompetencyLevel::Skill;
                            else if (value == "proficiency") objective.targetLevel = CompetencyLevel::Proficiency;
                            else if (value == "mastery") objective.targetLevel = CompetencyLevel::Mastery;
                        } else {
                            objective.metadata[key] = value;
                        }
                    }
                    
                    objectives.push_back(objective);
                }
            }
        }
        
        return objectives;
    }
    
    // Helper method to extract regulatory requirements from document
    std::vector<RegulatoryRequirement> extractRegulatoryRequirements(
        const APTP::Document::DocumentContent& content) {
        
        std::vector<RegulatoryRequirement> requirements;
        
        // Use the AI document analyzer to identify regulatory requirements
        APTP::Document::AIDocumentAnalyzer& analyzer = 
            APTP::Document::AIDocumentAnalyzer::getInstance();
        
        // Map document to regulations
        auto result = analyzer.mapToRegulations(content);
        
        if (result.isSuccess()) {
            const auto& mappings = result.value();
            
            for (const auto& mapping : mappings) {
                RegulatoryRequirement requirement;
                requirement.id = "REG-" + std::to_string(requirements.size() + 1);
                
                // Map regulatory body
                if (mapping.regulatoryBody == "FAA") {
                    requirement.body = RegulatoryBody::FAA;
                } else if (mapping.regulatoryBody == "EASA") {
                    requirement.body = RegulatoryBody::EASA;
                } else if (mapping.regulatoryBody == "ICAO") {
                    requirement.body = RegulatoryBody::ICAO;
                } else if (mapping.regulatoryBody == "TCCA") {
                    requirement.body = RegulatoryBody::TCCA;
                } else if (mapping.regulatoryBody == "CASA") {
                    requirement.body = RegulatoryBody::CASA;
                } else {
                    requirement.body = RegulatoryBody::Custom;
                    requirement.customBody = mapping.regulatoryBody;
                }
                
                requirement.regulationId = mapping.regulationId;
                requirement.sectionId = mapping.sectionId;
                requirement.description = mapping.description;
                
                requirements.push_back(requirement);
            }
        }
        
        return requirements;
    }
    
    // Helper method to organize content into lessons and modules
    std::vector<Module> organizeIntoModules(
        const std::vector<LearningObjective>& objectives,
        const std::vector<RegulatoryRequirement>& requirements,
        const APTP::Document::DocumentContent& content) {
        
        std::vector<Module> modules;
        
        // This is a simplified implementation
        // In a real system, we would use more sophisticated algorithms to group
        // related objectives into lessons and modules
        
        // For this example, we'll create a single module with lessons
        // based on document headers
        
        Module module;
        module.id = "M-1";
        module.title = "Module 1";
        module.description = "Generated from document analysis";
        module.regulatoryRequirements = requirements;
        
        // Group objectives into lessons based on document headers
        std::unordered_map<std::string, std::vector<LearningObjective>> lessonObjectives;
        
        // Simple approach: assign objectives to headers
        // In a real implementation, we would analyze semantic relationships
        if (!content.headers.empty()) {
            for (size_t i = 0; i < objectives.size(); ++i) {
                // Assign to nearest header as a simple heuristic
                size_t headerIndex = i % content.headers.size();
                lessonObjectives[content.headers[headerIndex]].push_back(objectives[i]);
            }
            
            // Create lessons from these groups
            int lessonCounter = 1;
            for (const auto& [header, lessonObjs] : lessonObjectives) {
                Lesson lesson;
                lesson.id = "L-" + std::to_string(lessonCounter++);
                lesson.title = header;
                lesson.description = "Lesson covering " + header;
                lesson.durationHours = 1.5; // Default duration
                lesson.objectives = lessonObjs;
                
                module.lessons.push_back(lesson);
            }
        } else {
            // If no headers, create a single lesson with all objectives
            Lesson lesson;
            lesson.id = "L-1";
            lesson.title = "Comprehensive Lesson";
            lesson.description = "Lesson covering all identified learning objectives";
            lesson.durationHours = 3.0; // Default duration
            lesson.objectives = objectives;
            
            module.lessons.push_back(lesson);
        }
        
        modules.push_back(module);
        return modules;
    }
};

SyllabusGenerator::SyllabusGenerator() : impl_(std::make_unique<Impl>()) {}
SyllabusGenerator::~SyllabusGenerator() = default;

APTP::Core::Result<Syllabus> SyllabusGenerator::generateFromDocument(
    const APTP::Document::ProcessingResult& document,
    const ProgressCallback& progressCallback) {
    
    APTP::Core::Logger::getInstance().info("Generating syllabus from document: {}", document.documentId);
    
    // Create progress updates
    GenerationProgress progress;
    progress.percentComplete = 0.0;
    progress.currentStage = "Starting syllabus generation";
    
    if (progressCallback) {
        progressCallback(progress);
    }
    
    try {
        // 1. Extract learning objectives
        progress.percentComplete = 20.0;
        progress.currentStage = "Extracting learning objectives";
        if (progressCallback) progressCallback(progress);
        
        std::vector<LearningObjective> objectives = impl_->extractLearningObjectives(document.content);
        
        // 2. Extract regulatory requirements
        progress.percentComplete = 40.0;
        progress.currentStage = "Identifying regulatory requirements";
        if (progressCallback) progressCallback(progress);
        
        std::vector<RegulatoryRequirement> requirements = impl_->extractRegulatoryRequirements(document.content);
        
        // 3. Organize into modules and lessons
        progress.percentComplete = 60.0;
        progress.currentStage = "Organizing content into modules and lessons";
        if (progressCallback) progressCallback(progress);
        
        std::vector<Module> modules = impl_->organizeIntoModules(objectives, requirements, document.content);
        
        // 4. Create the syllabus
        progress.percentComplete = 80.0;
        progress.currentStage = "Finalizing syllabus";
        if (progressCallback) progressCallback(progress);
        
        Syllabus syllabus;
        syllabus.id = "SYL-" + std::to_string(std::hash<std::string>{}(document.documentId));
        syllabus.title = document.metadata.title.empty() ? "Generated Syllabus" : document.metadata.title + " Syllabus";
        syllabus.description = "Automatically generated from document " + document.documentId;
        syllabus.version = "1.0";
        
        // Set dates
        auto now = std::chrono::system_clock::now();
        auto nowTime = std::chrono::system_clock::to_time_t(now);
        std::string dateStr = std::ctime(&nowTime);
        dateStr.pop_back(); // Remove newline
        
        syllabus.creationDate = dateStr;
        syllabus.lastModifiedDate = dateStr;
        syllabus.author = "APTP System";
        syllabus.modules = modules;
        syllabus.globalRequirements = requirements;
        
        // 5. Complete generation
        progress.percentComplete = 100.0;
        progress.currentStage = "Syllabus generation completed";
        if (progressCallback) progressCallback(progress);
        
        return APTP::Core::Success(syllabus);
    } catch (const std::exception& e) {
        progress.errors.push_back(e.what());
        if (progressCallback) progressCallback(progress);
        
        return APTP::Core::Error<Syllabus>(APTP::Core::ErrorCode::SyllabusGenerationError);
    }
}

APTP::Core::Result<Syllabus> SyllabusGenerator::generateFromDocumentFile(
    const std::filesystem::path& filePath,
    const ProgressCallback& progressCallback) {
    
    // Process the document first
    APTP::Document::DocumentProcessor::ProgressCallback docProgressCallback = nullptr;
    
    if (progressCallback) {
        docProgressCallback = [&progressCallback](const APTP::Document::ProcessingProgress& docProgress) {
            // Convert document processing progress to syllabus generation progress
            // Scale to 0-50% to represent the document processing phase
            GenerationProgress genProgress;
            genProgress.percentComplete = docProgress.percentComplete * 0.5;
            genProgress.currentStage = "Document processing: " + docProgress.currentStage;
            genProgress.message = docProgress.message;
            genProgress.warnings = docProgress.warnings;
            genProgress.errors = docProgress.errors;
            
            progressCallback(genProgress);
        };
    }
    
    // Create document processor based on file type
    auto docProcessor = APTP::Document::DocumentProcessor::createProcessor(filePath);
    auto docResult = docProcessor->processDocument(filePath, docProgressCallback);
    
    if (docResult.isError()) {
        return APTP::Core::Error<Syllabus>(APTP::Core::ErrorCode::SyllabusGenerationError);
    }
    
    // Adjust progress callback for syllabus generation phase (50-100%)
    ProgressCallback syllabusProgressCallback = nullptr;
    
    if (progressCallback) {
        syllabusProgressCallback = [&progressCallback](const GenerationProgress& syllProgress) {
            GenerationProgress adjustedProgress = syllProgress;
            // Scale from 0-100% to 50-100%
            adjustedProgress.percentComplete = 50.0 + (syllProgress.percentComplete * 0.5);
            progressCallback(adjustedProgress);
        };
    }
    
    // Generate syllabus from processed document
    return generateFromDocument(docResult.value(), syllabusProgressCallback);
}

// Additional method implementations would follow similar patterns

APTP::Core::Result<void> SyllabusGenerator::saveToFile(
    const Syllabus& syllabus, 
    const std::filesystem::path& filePath) {
    
    try {
        nlohmann::json jsonSyllabus;
        
        // Convert syllabus to JSON
        jsonSyllabus["id"] = syllabus.id;
        jsonSyllabus["title"] = syllabus.title;
        jsonSyllabus["description"] = syllabus.description;
        jsonSyllabus["version"] = syllabus.version;
        jsonSyllabus["creationDate"] = syllabus.creationDate;
        jsonSyllabus["lastModifiedDate"] = syllabus.lastModifiedDate;
        jsonSyllabus["author"] = syllabus.author;
        
        // Convert modules
        nlohmann::json modulesJson = nlohmann::json::array();
        for (const auto& module : syllabus.modules) {
            nlohmann::json moduleJson;
            moduleJson["id"] = module.id;
            moduleJson["title"] = module.title;
            moduleJson["description"] = module.description;
            
            // Convert lessons
            nlohmann::json lessonsJson = nlohmann::json::array();
            for (const auto& lesson : module.lessons) {
                nlohmann::json lessonJson;
                lessonJson["id"] = lesson.id;
                lessonJson["title"] = lesson.title;
                lessonJson["description"] = lesson.description;
                lessonJson["durationHours"] = lesson.durationHours;
                
                // Convert objectives
                nlohmann::json objectivesJson = nlohmann::json::array();
                for (const auto& objective : lesson.objectives) {
                    nlohmann::json objectiveJson;
                    objectiveJson["id"] = objective.id;
                    objectiveJson["description"] = objective.description;
                    objectiveJson["targetLevel"] = static_cast<int>(objective.targetLevel);
                    objectiveJson["keywords"] = objective.keywords;
                    objectiveJson["prerequisites"] = objective.prerequisites;
                    objectiveJson["metadata"] = objective.metadata;
                    
                    objectivesJson.push_back(objectiveJson);
                }
                lessonJson["objectives"] = objectivesJson;
                
                // Convert assessment criteria
                nlohmann::json criteriaJson = nlohmann::json::array();
                for (const auto& criteria : lesson.assessmentCriteria) {
                    nlohmann::json criterionJson;
                    criterionJson["id"] = criteria.id;
                    criterionJson["description"] = criteria.description;
                    criterionJson["minimumLevel"] = static_cast<int>(criteria.minimumLevel);
                    criterionJson["isMandatory"] = criteria.isMandatory;
                    criterionJson["assessmentMethods"] = criteria.assessmentMethods;
                    
                    criteriaJson.push_back(criterionJson);
                }
                lessonJson["assessmentCriteria"] = criteriaJson;
                
                lessonJson["resources"] = lesson.resources;
                lessonJson["metadata"] = lesson.metadata;
                
                lessonsJson.push_back(lessonJson);
            }
            moduleJson["lessons"] = lessonsJson;
            
            // Convert regulatory requirements
            nlohmann::json requirementsJson = nlohmann::json::array();
            for (const auto& req : module.regulatoryRequirements) {
                nlohmann::json reqJson;
                reqJson["id"] = req.id;
                reqJson["body"] = static_cast<int>(req.body);
                reqJson["customBody"] = req.customBody;
                reqJson["regulationId"] = req.regulationId;
                reqJson["sectionId"] = req.sectionId;
                reqJson["description"] = req.description;
                reqJson["applicableContexts"] = req.applicableContexts;
                
                requirementsJson.push_back(reqJson);
            }
            moduleJson["regulatoryRequirements"] = requirementsJson;
            
            moduleJson["metadata"] = module.metadata;
            
            modulesJson.push_back(moduleJson);
        }
        jsonSyllabus["modules"] = modulesJson;
        
        // Convert global regulatory requirements
        nlohmann::json globalReqsJson = nlohmann::json::array();
        for (const auto& req : syllabus.globalRequirements) {
            nlohmann::json reqJson;
            reqJson["id"] = req.id;
            reqJson["body"] = static_cast<int>(req.body);
            reqJson["customBody"] = req.customBody;
            reqJson["regulationId"] = req.regulationId;
            reqJson["sectionId"] = req.sectionId;
            reqJson["description"] = req.description;
            reqJson["applicableContexts"] = req.applicableContexts;
            
            globalReqsJson.push_back(reqJson);
        }
        jsonSyllabus["globalRequirements"] = globalReqsJson;
        
        jsonSyllabus["metadata"] = syllabus.metadata;
        
        // Write to file
        std::ofstream file(filePath);
        file << jsonSyllabus.dump(4); // Pretty print with 4-space indentation
        file.close();
        
        return APTP::Core::Success();
    } catch (const std::exception& e) {
        APTP::Core::Logger::getInstance().error("Failed to save syllabus to file: {}", e.what());
        return APTP::Core::Error<void>(APTP::Core::ErrorCode::SyllabusGenerationError);
    }
}

// Implementation for SyllabusTemplateManager would follow a similar pattern
// with methods to load, save, and manipulate syllabus templates

} // namespace APTP::Syllabus

// src/backend/syllabus/SyllabusGenerator.h
#pragma once

#include <memory>
#include <string>
#include <vector>
#include <unordered_map>
#include <optional>
#include <functional>

#include "../core/Result.h"
#include "../core/Logger.h"
#include "../core/ConfigurationManager.h"
#include "../document/DocumentProcessor.h"

namespace PilotTraining {
namespace Syllabus {

/**
 * @brief Type of learning objective
 */
enum class ObjectiveType {
    KNOWLEDGE,   // Knowledge-based objective
    SKILL,       // Skill-based objective
    ATTITUDE     // Attitude-based objective
};

/**
 * @brief Type of syllabus element
 */
enum class ElementType {
    MODULE,      // Top-level container (e.g., "Basic Flight Maneuvers")
    LESSON,      // Mid-level container (e.g., "Introduction to Takeoffs")
    EXERCISE,    // Specific activity (e.g., "Normal Takeoff Procedure")
    ASSESSMENT   // Evaluation activity
};

/**
 * @brief Type of training environment
 */
enum class TrainingEnvironment {
    CLASSROOM,   // Classroom instruction
    SIMULATOR,   // Simulator training
    AIRCRAFT,    // Aircraft training
    CBT,         // Computer-based training
    BRIEFING,    // Pre/post-flight briefing
    OTHER        // Other environment
};

/**
 * @brief Learning objective definition
 */
struct LearningObjective {
    std::string id;
    std::string description;
    ObjectiveType type;
    std::string taxonomyLevel; // e.g., "Apply", "Analyze", "Evaluate"
    std::vector<std::string> relatedRegulations;
    std::vector<std::string> prerequisiteObjectives;
    int difficulty; // 1-5 scale
    std::string assessmentMethod;
};

/**
 * @brief Competency area definition
 */
struct CompetencyArea {
    std::string id;
    std::string name;
    std::string description;
    std::vector<std::string> indicators; // Performance indicators
    std::vector<std::string> objectives; // Related learning objectives
    std::vector<std::string> regulations; // Related regulations
};

/**
 * @brief Regulatory requirement definition
 */
struct RegulatoryRequirement {
    std::string id;
    std::string authority; // e.g., "FAA", "EASA"
    std::string reference; // e.g., "14 CFR  61.107"
    std::string description;
    std::string textContent;
    bool mandatory;
    std::vector<std::string> relatedObjectives;
};

/**
 * @brief Syllabus module (top-level container)
 */
struct SyllabusModule {
    std::string id;
    std::string title;
    std::string description;
    int sequenceNumber;
    std::vector<std::string> prerequisites;
    std::vector<std::string> objectives;
    std::vector<std::string> lessons;
    int estimatedDuration; // In minutes
};

/**
 * @brief Syllabus lesson (mid-level container)
 */
struct SyllabusLesson {
    std::string id;
    std::string title;
    std::string description;
    int sequenceNumber;
    std::string moduleId;
    std::vector<std::string> objectives;
    std::vector<std::string> exercises;
    TrainingEnvironment environment;
    int estimatedDuration; // In minutes
};

/**
 * @brief Syllabus exercise (specific activity)
 */
struct SyllabusExercise {
    std::string id;
    std::string title;
    std::string description;
    int sequenceNumber;
    std::string lessonId;
    std::vector<std::string> objectives;
    std::string procedure;
    std::vector<std::string> resources;
    TrainingEnvironment environment;
    int estimatedDuration; // In minutes
    std::string assessmentCriteria;
};

/**
 * @brief Complete syllabus structure
 */
struct Syllabus {
    std::string id;
    std::string title;
    std::string description;
    std::string version;
    std::string author;
    std::string organization;
    std::string createdDate;
    std::string lastModifiedDate;
    std::string regulatoryFramework;
    
    std::vector<LearningObjective> objectives;
    std::vector<CompetencyArea> competencies;
    std::vector<RegulatoryRequirement> regulations;
    std::vector<SyllabusModule> modules;
    std::unordered_map<std::string, SyllabusLesson> lessons;
    std::unordered_map<std::string, SyllabusExercise> exercises;
    
    std::unordered_map<std::string, std::string> metadata;
};

/**
 * @brief Configuration for the syllabus generator
 */
struct SyllabusGeneratorConfig {
    std::string defaultRegulator;
    std::vector<std::string> regulatoryDocuments;
    std::string templateDirectory;
    bool enableAIExtraction;
    bool enableRegulationMapping;
    std::string outputDirectory;
};

/**
 * @brief Generator for training syllabi
 * 
 * This class processes training materials and regulatory documents to extract
 * structured syllabus elements, maps regulatory requirements to training elements,
 * and generates complete training syllabi.
 */
class SyllabusGenerator {
public:
    /**
     * @brief Construct a new Syllabus Generator
     * 
     * @param configManager Configuration manager
     * @param documentProcessor Document processor for parsing input materials
     */
    SyllabusGenerator(
        std::shared_ptr<Core::ConfigurationManager> configManager,
        std::shared_ptr<Document::DocumentProcessingPipeline> documentProcessor
    );
    
    /**
     * @brief Destroy the Syllabus Generator
     */
    ~SyllabusGenerator();
    
    /**
     * @brief Initialize the generator with configuration
     * 
     * @param config Generator configuration
     * @return Core::Result<void> Success or error
     */
    Core::Result<void> initialize(const SyllabusGeneratorConfig& config);
    
    /**
     * @brief Process a training document to extract syllabus elements
     * 
     * @param documentPath Path to the document
     * @return Core::Result<std::string> Document ID if successful
     */
    Core::Result<std::string> processDocument(const std::string& documentPath);
    
    /**
     * @brief Process a regulatory document to extract requirements
     * 
     * @param documentPath Path to the document
     * @param regulator Regulatory authority (e.g., "FAA", "EASA")
     * @return Core::Result<std::string> Document ID if successful
     */
    Core::Result<std::string> processRegulatoryDocument(
        const std::string& documentPath,
        const std::string& regulator
    );
    
    /**
     * @brief Extract learning objectives from processed documents
     * 
     * @return Core::Result<std::vector<LearningObjective>> Extracted objectives
     */
    Core::Result<std::vector<LearningObjective>> extractLearningObjectives();
    
    /**
     * @brief Extract competency areas from processed documents
     * 
     * @return Core::Result<std::vector<CompetencyArea>> Extracted competencies
     */
    Core::Result<std::vector<CompetencyArea>> extractCompetencyAreas();
    
    /**
     * @brief Extract regulatory requirements from processed documents
     * 
     * @return Core::Result<std::vector<RegulatoryRequirement>> Extracted requirements
     */
    Core::Result<std::vector<RegulatoryRequirement>> extractRegulatoryRequirements();
    
    /**
     * @brief Map regulatory requirements to learning objectives
     * 
     * @param regulations Regulatory requirements
     * @param objectives Learning objectives
     * @return Core::Result<void> Success or error
     */
    Core::Result<void> mapRegulationsToObjectives(
        const std::vector<RegulatoryRequirement>& regulations,
        std::vector<LearningObjective>& objectives
    );
    
    /**
     * @brief Create a syllabus structure from extracted elements
     * 
     * @param title Syllabus title
     * @param description Syllabus description
     * @param regulatoryFramework Regulatory framework
     * @return Core::Result<Syllabus> Generated syllabus
     */
    Core::Result<Syllabus> createSyllabus(
        const std::string& title,
        const std::string& description,
        const std::string& regulatoryFramework
    );
    
    /**
     * @brief Apply a syllabus template to generate a complete syllabus
     * 
     * @param templatePath Path to the template file
     * @param objectives Learning objectives
     * @param competencies Competency areas
     * @param regulations Regulatory requirements
     * @return Core::Result<Syllabus> Generated syllabus
     */
    Core::Result<Syllabus> applyTemplate(
        const std::string& templatePath,
        const std::vector<LearningObjective>& objectives,
        const std::vector<CompetencyArea>& competencies,
        const std::vector<RegulatoryRequirement>& regulations
    );
    
    /**
     * @brief Customize a syllabus by adding, removing, or modifying elements
     * 
     * @param syllabus Syllabus to customize
     * @param customizations Customization operations
     * @return Core::Result<Syllabus> Customized syllabus
     */
    Core::Result<Syllabus> customizeSyllabus(
        const Syllabus& syllabus,
        const std::unordered_map<std::string, std::string>& customizations
    );
    
    /**
     * @brief Export a syllabus to a file
     * 
     * @param syllabus Syllabus to export
     * @param format Export format (e.g., "json", "xml", "html", "pdf")
     * @param outputPath Output file path
     * @return Core::Result<void> Success or error
     */
    Core::Result<void> exportSyllabus(
        const Syllabus& syllabus,
        const std::string& format,
        const std::string& outputPath
    );
    
    /**
     * @brief Validate a syllabus for completeness and regulatory compliance
     * 
     * @param syllabus Syllabus to validate
     * @return Core::Result<std::unordered_map<std::string, std::string>> Validation results
     */
    Core::Result<std::unordered_map<std::string, std::string>> validateSyllabus(
        const Syllabus& syllabus
    );
    
    /**
     * @brief Add a custom learning objective
     * 
     * @param objective Learning objective to add
     * @return Core::Result<std::string> Objective ID if successful
     */
    Core::Result<std::string> addLearningObjective(const LearningObjective& objective);
    
    /**
     * @brief Add a custom competency area
     * 
     * @param competency Competency area to add
     * @return Core::Result<std::string> Competency ID if successful
     */
    Core::Result<std::string> addCompetencyArea(const CompetencyArea& competency);
    
    /**
     * @brief Add a custom regulatory requirement
     * 
     * @param requirement Regulatory requirement to add
     * @return Core::Result<std::string> Requirement ID if successful
     */
    Core::Result<std::string> addRegulatoryRequirement(const RegulatoryRequirement& requirement);

private:
    std::shared_ptr<Core::ConfigurationManager> _configManager;
    std::shared_ptr<Document::DocumentProcessingPipeline> _documentProcessor;
    SyllabusGeneratorConfig _config;
    
    std::vector<Document::ProcessingResult> _processedDocuments;
    
    // Extract structured content from document processing results
    std::vector<LearningObjective> extractObjectivesFromDocument(const Document::ProcessingResult& result);
    std::vector<CompetencyArea> extractCompetenciesFromDocument(const Document::ProcessingResult& result);
    std::vector<RegulatoryRequirement> extractRegulationsFromDocument(const Document::ProcessingResult& result);
    
    // Helper methods for syllabus generation
    void organizeModules(Syllabus& syllabus);
    void organizeLessons(Syllabus& syllabus);
    void organizeExercises(Syllabus& syllabus);
    
    // AI-assisted content extraction
    Core::Result<std::vector<LearningObjective>> extractObjectivesWithAI(const std::string& documentContent);
    Core::Result<std::vector<CompetencyArea>> extractCompetenciesWithAI(const std::string& documentContent);
    Core::Result<std::vector<RegulatoryRequirement>> extractRegulationsWithAI(const std::string& documentContent);
    
    // Template handling
    Core::Result<Syllabus> loadTemplate(const std::string& templatePath);
    void applyObjectivesToTemplate(Syllabus& syllabus, const std::vector<LearningObjective>& objectives);
    
    // Validation and compliance checking
    bool validateObjectiveCoverage(const Syllabus& syllabus, std::unordered_map<std::string, std::string>& results);
    bool validateRegulatoryCoverage(const Syllabus& syllabus, std::unordered_map<std::string, std::string>& results);
    bool validateStructuralIntegrity(const Syllabus& syllabus, std::unordered_map<std::string, std::string>& results);
};

} // namespace Syllabus
} // namespace PilotTraining

// src/backend/syllabus/SyllabusGenerator.cpp
#include "SyllabusGenerator.h"
#include <fstream>
#include <sstream>
#include <filesystem>
#include <chrono>
#include <algorithm>
#include <cctype>
#include <regex>
#include <nlohmann/json.hpp>
#include <tinyxml2.h>

using json = nlohmann::json;
using namespace tinyxml2;

namespace PilotTraining {
namespace Syllabus {

SyllabusGenerator::SyllabusGenerator(
    std::shared_ptr<Core::ConfigurationManager> configManager,
    std::shared_ptr<Document::DocumentProcessingPipeline> documentProcessor)
    : _configManager(std::move(configManager)),
      _documentProcessor(std::move(documentProcessor)) {
    
    Core::Logger::info("SyllabusGenerator created");
}

SyllabusGenerator::~SyllabusGenerator() {
    Core::Logger::info("SyllabusGenerator destroyed");
}

Core::Result<void> SyllabusGenerator::initialize(const SyllabusGeneratorConfig& config) {
    try {
        _config = config;
        
        // Create output directory if it doesn't exist
        std::filesystem::create_directories(_config.outputDirectory);
        
        // Ensure template directory exists
        if (!_config.templateDirectory.empty() && 
            !std::filesystem::exists(_config.templateDirectory)) {
            return Core::Result<void>::failure(
                Core::ErrorCode::DirectoryNotFound,
                "Template directory not found: " + _config.templateDirectory
            );
        }
        
        Core::Logger::info("SyllabusGenerator initialized with regulator: {}", _config.defaultRegulator);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to initialize SyllabusGenerator: {}", e.what());
        return Core::Result<void>::failure(
            Core::ErrorCode::InitializationFailed,
            "Failed to initialize SyllabusGenerator: " + std::string(e.what())
        );
    }
}

Core::Result<std::string> SyllabusGenerator::processDocument(const std::string& documentPath) {
    try {
        if (!std::filesystem::exists(documentPath)) {
            return Core::Result<std::string>::failure(
                Core::ErrorCode::FileNotFound,
                "Document file not found: " + documentPath
            );
        }
        
        // Create document metadata
        Document::DocumentMetadata metadata;
        metadata.id = "doc-" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
        metadata.filename = std::filesystem::path(documentPath).filename().string();
        metadata.contentType = "application/octet-stream"; // Default, will be determined by processor
        metadata.organizationId = "default-org";
        metadata.uploadedBy = "system";
        metadata.createdAt = std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
        metadata.updatedAt = metadata.createdAt;
        metadata.type = Document::DocumentType::UNKNOWN; // Will be determined by processor
        metadata.fileSize = std::filesystem::file_size(documentPath);
        
        // Process the document
        auto result = _documentProcessor->processDocument(documentPath, metadata);
        if (!result.isSuccess()) {
            return Core::Result<std::string>::failure(
                result.getError().code,
                "Failed to process document: " + result.getError().message
            );
        }
        
        // Store the processing result
        _processedDocuments.push_back(result.getValue());
        
        Core::Logger::info("Processed document: {}", metadata.filename);
        return Core::Result<std::string>::success(metadata.id);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to process document: {}", e.what());
        return Core::Result<std::string>::failure(
            Core::ErrorCode::DocumentProcessingFailed,
            "Failed to process document: " + std::string(e.what())
        );
    }
}

Core::Result<std::string> SyllabusGenerator::processRegulatoryDocument(
    const std::string& documentPath,
    const std::string& regulator) {
    
    try {
        if (!std::filesystem::exists(documentPath)) {
            return Core::Result<std::string>::failure(
                Core::ErrorCode::FileNotFound,
                "Regulatory document file not found: " + documentPath
            );
        }
        
        // Create document metadata
        Document::DocumentMetadata metadata;
        metadata.id = "reg-" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
        metadata.filename = std::filesystem::path(documentPath).filename().string();
        metadata.contentType = "application/octet-stream"; // Default, will be determined by processor
        metadata.organizationId = "default-org";
        metadata.uploadedBy = "system";
        metadata.createdAt = std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
        metadata.updatedAt = metadata.createdAt;
        metadata.type = Document::DocumentType::UNKNOWN; // Will be determined by processor
        metadata.fileSize = std::filesystem::file_size(documentPath);
        
        // Add regulatory authority to metadata
        metadata.additionalMetadata["regulator"] = regulator;
        metadata.additionalMetadata["documentType"] = "regulatory";
        
        // Process the document
        auto result = _documentProcessor->processDocument(documentPath, metadata);
        if (!result.isSuccess()) {
            return Core::Result<std::string>::failure(
                result.getError().code,
                "Failed to process regulatory document: " + result.getError().message
            );
        }
        
        // Store the processing result
        _processedDocuments.push_back(result.getValue());
        
        Core::Logger::info("Processed regulatory document: {}", metadata.filename);
        return Core::Result<std::string>::success(metadata.id);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to process regulatory document: {}", e.what());
        return Core::Result<std::string>::failure(
            Core::ErrorCode::DocumentProcessingFailed,
            "Failed to process regulatory document: " + std::string(e.what())
        );
    }
}

Core::Result<std::vector<LearningObjective>> SyllabusGenerator::extractLearningObjectives() {
    try {
        std::vector<LearningObjective> allObjectives;
        
        // Process each document
        for (const auto& document : _processedDocuments) {
            auto objectives = extractObjectivesFromDocument(document);
            allObjectives.insert(allObjectives.end(), objectives.begin(), objectives.end());
        }
        
        // De-duplicate objectives
        std::unordered_map<std::string, LearningObjective> uniqueObjectives;
        for (const auto& objective : allObjectives) {
            // Use description as a key for deduplication
            std::string key = objective.description;
            
            // Convert to lowercase for case-insensitive comparison
            std::transform(key.begin(), key.end(), key.begin(), 
                [](unsigned char c) { return std::tolower(c); });
            
            // Keep the objective with the most complete data
            if (uniqueObjectives.find(key) == uniqueObjectives.end()) {
                uniqueObjectives[key] = objective;
            } else {
                // If new objective has more data, update
                auto& existing = uniqueObjectives[key];
                if (existing.relatedRegulations.empty() && !objective.relatedRegulations.empty()) {
                    existing.relatedRegulations = objective.relatedRegulations;
                }
                if (existing.prerequisiteObjectives.empty() && !objective.prerequisiteObjectives.empty()) {
                    existing.prerequisiteObjectives = objective.prerequisiteObjectives;
                }
                if (existing.assessmentMethod.empty() && !objective.assessmentMethod.empty()) {
                    existing.assessmentMethod = objective.assessmentMethod;
                }
            }
        }
        
        // Convert map back to vector
        std::vector<LearningObjective> result;
        result.reserve(uniqueObjectives.size());
        for (const auto& [_, objective] : uniqueObjectives) {
            result.push_back(objective);
        }
        
        Core::Logger::info("Extracted {} unique learning objectives", result.size());
        return Core::Result<std::vector<LearningObjective>>::success(result);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to extract learning objectives: {}", e.what());
        return Core::Result<std::vector<LearningObjective>>::failure(
            Core::ErrorCode::ExtractionFailed,
            "Failed to extract learning objectives: " + std::string(e.what())
        );
    }
}

Core::Result<std::vector<CompetencyArea>> SyllabusGenerator::extractCompetencyAreas() {
    try {
        std::vector<CompetencyArea> allCompetencies;
        
        // Process each document
        for (const auto& document : _processedDocuments) {
            auto competencies = extractCompetenciesFromDocument(document);
            allCompetencies.insert(allCompetencies.end(), competencies.begin(), competencies.end());
        }
        
        // De-duplicate competencies
        std::unordered_map<std::string, CompetencyArea> uniqueCompetencies;
        for (const auto& competency : allCompetencies) {
            // Use name as a key for deduplication
            std::string key = competency.name;
            
            // Convert to lowercase for case-insensitive comparison
            std::transform(key.begin(), key.end(), key.begin(), 
                [](unsigned char c) { return std::tolower(c); });
            
            // Keep the competency with the most complete data
            if (uniqueCompetencies.find(key) == uniqueCompetencies.end()) {
                uniqueCompetencies[key] = competency;
            } else {
                // If new competency has more data, update
                auto& existing = uniqueCompetencies[key];
                if (existing.description.empty() && !competency.description.empty()) {
                    existing.description = competency.description;
                }
                if (existing.indicators.empty() && !competency.indicators.empty()) {
                    existing.indicators = competency.indicators;
                }
                if (existing.objectives.empty() && !competency.objectives.empty()) {
                    existing.objectives = competency.objectives;
                }
                if (existing.regulations.empty() && !competency.regulations.empty()) {
                    existing.regulations = competency.regulations;
                }
            }
        }
        
        // Convert map back to vector
        std::vector<CompetencyArea> result;
        result.reserve(uniqueCompetencies.size());
        for (const auto& [_, competency] : uniqueCompetencies) {
            result.push_back(competency);
        }
        
        Core::Logger::info("Extracted {} unique competency areas", result.size());
        return Core::Result<std::vector<CompetencyArea>>::success(result);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to extract competency areas: {}", e.what());
        return Core::Result<std::vector<CompetencyArea>>::failure(
            Core::ErrorCode::ExtractionFailed,
            "Failed to extract competency areas: " + std::string(e.what())
        );
    }
}

Core::Result<std::vector<RegulatoryRequirement>> SyllabusGenerator::extractRegulatoryRequirements() {
    try {
        std::vector<RegulatoryRequirement> allRegulations;
        
        // Process each document
        for (const auto& document : _processedDocuments) {
            // Only process documents marked as regulatory
            if (document.content.metadata.find("documentType") != document.content.metadata.end() &&
                document.content.metadata.at("documentType") == "regulatory") {
                
                auto regulations = extractRegulationsFromDocument(document);
                allRegulations.insert(allRegulations.end(), regulations.begin(), regulations.end());
            }
        }
        
        // De-duplicate regulations
        std::unordered_map<std::string, RegulatoryRequirement> uniqueRegulations;
        for (const auto& regulation : allRegulations) {
            // Use reference as a key for deduplication
            std::string key = regulation.authority + "-" + regulation.reference;
            
            // Keep the regulation with the most complete data
            if (uniqueRegulations.find(key) == uniqueRegulations.end()) {
                uniqueRegulations[key] = regulation;
            } else {
                // If new regulation has more data, update
                auto& existing = uniqueRegulations[key];
                if (existing.description.empty() && !regulation.description.empty()) {
                    existing.description = regulation.description;
                }
                if (existing.textContent.empty() && !regulation.textContent.empty()) {
                    existing.textContent = regulation.textContent;
                }
                if (existing.relatedObjectives.empty() && !regulation.relatedObjectives.empty()) {
                    existing.relatedObjectives = regulation.relatedObjectives;
                }
            }
        }
        
        // Convert map back to vector
        std::vector<RegulatoryRequirement> result;
        result.reserve(uniqueRegulations.size());
        for (const auto& [_, regulation] : uniqueRegulations) {
            result.push_back(regulation);
        }
        
        Core::Logger::info("Extracted {} unique regulatory requirements", result.size());
        return Core::Result<std::vector<RegulatoryRequirement>>::success(result);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to extract regulatory requirements: {}", e.what());
        return Core::Result<std::vector<RegulatoryRequirement>>::failure(
            Core::ErrorCode::ExtractionFailed,
            "Failed to extract regulatory requirements: " + std::string(e.what())
        );
    }
}

Core::Result<void> SyllabusGenerator::mapRegulationsToObjectives(
    const std::vector<RegulatoryRequirement>& regulations,
    std::vector<LearningObjective>& objectives) {
    
    try {
        // Use AI to help with mapping if enabled
        if (_config.enableRegulationMapping) {
            // For each regulation
            for (const auto& regulation : regulations) {
                // Find relevant objectives based on content similarity
                for (auto& objective : objectives) {
                    bool isRelevant = false;
                    
                    // Simple keyword matching (would be replaced with more sophisticated NLP in real implementation)
                    std::string regText = regulation.textContent + " " + regulation.description;
                    std::string objText = objective.description;
                    
                    // Convert to lowercase for comparison
                    std::transform(regText.begin(), regText.end(), regText.begin(), 
                        [](unsigned char c) { return std::tolower(c); });
                    std::transform(objText.begin(), objText.end(), objText.begin(), 
                        [](unsigned char c) { return std::tolower(c); });
                    
                    // Extract key terms (simplified for demo)
                    std::vector<std::string> keyTerms = {
                        "takeoff", "landing", "maneuver", "navigation", "communication",
                        "emergency", "procedure", "operate", "control", "flight",
                        "safety", "instrument", "visual", "weather", "preflight"
                    };
                    
                    // Check if both texts contain the same key terms
                    for (const auto& term : keyTerms) {
                        if (regText.find(term) != std::string::npos && 
                            objText.find(term) != std::string::npos) {
                            isRelevant = true;
                            break;
                        }
                    }
                    
                    // If relevant, add reference
                    if (isRelevant) {
                        // Check if regulation is already linked
                        auto it = std::find(objective.relatedRegulations.begin(), 
                                          objective.relatedRegulations.end(), 
                                          regulation.id);
                        
                        if (it == objective.relatedRegulations.end()) {
                            objective.relatedRegulations.push_back(regulation.id);
                        }
                    }
                }
            }
        } else {
            // Manual mapping would be done here in a real implementation
            Core::Logger::info("Regulation mapping disabled, skipping");
        }
        
        Core::Logger::info("Mapped regulations to objectives");
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to map regulations to objectives: {}", e.what());
        return Core::Result<void>::failure(
            Core::ErrorCode::MappingFailed,
            "Failed to map regulations to objectives: " + std::string(e.what())
        );
    }
}

Core::Result<Syllabus> SyllabusGenerator::createSyllabus(
    const std::string& title,
    const std::string& description,
    const std::string& regulatoryFramework) {
    
    try {
        // Create a new syllabus
        Syllabus syllabus;
        syllabus.id = "syllabus-" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
        syllabus.title = title;
        syllabus.description = description;
        syllabus.version = "1.0";
        syllabus.author = "System";
        syllabus.organization = "Default Organization";
        
        // Set dates
        auto now = std::chrono::system_clock::now();
        auto now_time_t = std::chrono::system_clock::to_time_t(now);
        std::stringstream ss;
        ss << std::put_time(std::localtime(&now_time_t), "%Y-%m-%d %H:%M:%S");
        syllabus.createdDate = ss.str();
        syllabus.lastModifiedDate = ss.str();
        
        syllabus.regulatoryFramework = regulatoryFramework;
        
        // Extract elements from processed documents
        auto objectivesResult = extractLearningObjectives();
        if (!objectivesResult.isSuccess()) {
            return Core::Result<Syllabus>::failure(
                objectivesResult.getError().code,
                objectivesResult.getError().message
            );
        }
        syllabus.objectives = objectivesResult.getValue();
        
        auto competenciesResult = extractCompetencyAreas();
        if (!competenciesResult.isSuccess()) {
            return Core::Result<Syllabus>::failure(
                competenciesResult.getError().code,
                competenciesResult.getError().message
            );
        }
        syllabus.competencies = competenciesResult.getValue();
        
        auto regulationsResult = extractRegulatoryRequirements();
        if (!regulationsResult.isSuccess()) {
            return Core::Result<Syllabus>::failure(
                regulationsResult.getError().code,
                regulationsResult.getError().message
            );
        }
        syllabus.regulations = regulationsResult.getValue();
        
        // Map regulations to objectives
        auto mapResult = mapRegulationsToObjectives(syllabus.regulations, syllabus.objectives);
        if (!mapResult.isSuccess()) {
            return Core::Result<Syllabus>::failure(
                mapResult.getError().code,
                mapResult.getError().message
            );
        }
        
        // Create initial structure
        // This would be more sophisticated in a real implementation
        organizeModules(syllabus);
        organizeLessons(syllabus);
        organizeExercises(syllabus);
        
        Core::Logger::info("Created syllabus: {}", syllabus.title);
        return Core::Result<Syllabus>::success(syllabus);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to create syllabus: {}", e.what());
        return Core::Result<Syllabus>::failure(
            Core::ErrorCode::CreationFailed,
            "Failed to create syllabus: " + std::string(e.what())
        );
    }
}

Core::Result<Syllabus> SyllabusGenerator::applyTemplate(
    const std::string& templatePath,
    const std::vector<LearningObjective>& objectives,
    const std::vector<CompetencyArea>& competencies,
    const std::vector<RegulatoryRequirement>& regulations) {
    
    try {
        // Load template
        auto templateResult = loadTemplate(templatePath);
        if (!templateResult.isSuccess()) {
            return templateResult;
        }
        
        // Get template syllabus
        Syllabus syllabus = templateResult.getValue();
        
        // Add objectives, competencies, and regulations
        syllabus.objectives = objectives;
        syllabus.competencies = competencies;
        syllabus.regulations = regulations;
        
        // Apply objectives to template structure
        applyObjectivesToTemplate(syllabus, objectives);
        
        // Update metadata
        auto now = std::chrono::system_clock::now();
        auto now_time_t = std::chrono::system_clock::to_time_t(now);
        std::stringstream ss;
        ss << std::put_time(std::localtime(&now_time_t), "%Y-%m-%d %H:%M:%S");
        syllabus.lastModifiedDate = ss.str();
        syllabus.version = "1.0";
        
        Core::Logger::info("Applied template to create syllabus: {}", syllabus.title);
        return Core::Result<Syllabus>::success(syllabus);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to apply template: {}", e.what());
        return Core::Result<Syllabus>::failure(
            Core::ErrorCode::TemplateFailed,
            "Failed to apply template: " + std::string(e.what())
        );
    }
}

Core::Result<Syllabus> SyllabusGenerator::customizeSyllabus(
    const Syllabus& syllabus,
    const std::unordered_map<std::string, std::string>& customizations) {
    
    try {
        // Create a copy to work with
        Syllabus customizedSyllabus = syllabus;
        
        // Apply customizations
        for (const auto& [key, value] : customizations) {
            std::string action, target;
            
            // Parse customization key (format: "action:target")
            size_t colonPos = key.find(':');
            if (colonPos != std::string::npos) {
                action = key.substr(0, colonPos);
                target = key.substr(colonPos + 1);
            } else {
                action = key;
            }
            
            // Apply action
            if (action == "title") {
                customizedSyllabus.title = value;
            } else if (action == "description") {
                customizedSyllabus.description = value;
            } else if (action == "version") {
                customizedSyllabus.version = value;
            } else if (action == "author") {
                customizedSyllabus.author = value;
            } else if (action == "organization") {
                customizedSyllabus.organization = value;
            } else if (action == "remove_module" && !target.empty()) {
                // Remove module
                customizedSyllabus.modules.erase(
                    std::remove_if(
                        customizedSyllabus.modules.begin(),
                        customizedSyllabus.modules.end(),
                        [&target](const SyllabusModule& module) { return module.id == target; }
                    ),
                    customizedSyllabus.modules.end()
                );
            } else if (action == "remove_lesson" && !target.empty()) {
                // Remove lesson
                customizedSyllabus.lessons.erase(target);
            } else if (action == "remove_exercise" && !target.empty()) {
                // Remove exercise
                customizedSyllabus.exercises.erase(target);
            } else if (action == "add_module" && !value.empty()) {
                // Parse module data from JSON
                try {
                    json moduleData = json::parse(value);
                    SyllabusModule module;
                    module.id = moduleData.value("id", "module-" + std::to_string(customizedSyllabus.modules.size() + 1));
                    module.title = moduleData.value("title", "New Module");
                    module.description = moduleData.value("description", "");
                    module.sequenceNumber = moduleData.value("sequenceNumber", static_cast<int>(customizedSyllabus.modules.size() + 1));
                    
                    if (moduleData.contains("prerequisites") && moduleData["prerequisites"].is_array()) {
                        for (const auto& prereq : moduleData["prerequisites"]) {
                            module.prerequisites.push_back(prereq);
                        }
                    }
                    
                    if (moduleData.contains("objectives") && moduleData["objectives"].is_array()) {
                        for (const auto& obj : moduleData["objectives"]) {
                            module.objectives.push_back(obj);
                        }
                    }
                    
                    if (moduleData.contains("lessons") && moduleData["lessons"].is_array()) {
                        for (const auto& lesson : moduleData["lessons"]) {
                            module.lessons.push_back(lesson);
                        }
                    }
                    
                    module.estimatedDuration = moduleData.value("estimatedDuration", 0);
                    
                    customizedSyllabus.modules.push_back(module);
                } catch (const json::exception& e) {
                    Core::Logger::error("Failed to parse module JSON: {}", e.what());
                }
            } else if (action == "add_lesson" && !value.empty() && !target.empty()) {
                // Parse lesson data from JSON and add to specified module
                try {
                    json lessonData = json::parse(value);
                    SyllabusLesson lesson;
                    lesson.id = lessonData.value("id", "lesson-" + std::to_string(customizedSyllabus.lessons.size() + 1));
                    lesson.title = lessonData.value("title", "New Lesson");
                    lesson.description = lessonData.value("description", "");
                    lesson.sequenceNumber = lessonData.value("sequenceNumber", 1);
                    lesson.moduleId = target;
                    
                    if (lessonData.contains("objectives") && lessonData["objectives"].is_array()) {
                        for (const auto& obj : lessonData["objectives"]) {
                            lesson.objectives.push_back(obj);
                        }
                    }
                    
                    if (lessonData.contains("exercises") && lessonData["exercises"].is_array()) {
                        for (const auto& exercise : lessonData["exercises"]) {
                            lesson.exercises.push_back(exercise);
                        }
                    }
                    
                    std::string envStr = lessonData.value("environment", "CLASSROOM");
                    if (envStr == "CLASSROOM") lesson.environment = TrainingEnvironment::CLASSROOM;
                    else if (envStr == "SIMULATOR") lesson.environment = TrainingEnvironment::SIMULATOR;
                    else if (envStr == "AIRCRAFT") lesson.environment = TrainingEnvironment::AIRCRAFT;
                    else if (envStr == "CBT") lesson.environment = TrainingEnvironment::CBT;
                    else if (envStr == "BRIEFING") lesson.environment = TrainingEnvironment::BRIEFING;
                    else lesson.environment = TrainingEnvironment::OTHER;
                    
                    lesson.estimatedDuration = lessonData.value("estimatedDuration", 0);
                    
                    // Add lesson to syllabus
                    customizedSyllabus.lessons[lesson.id] = lesson;
                    
                    // Add lesson to module
                    for (auto& module : customizedSyllabus.modules) {
                        if (module.id == target) {
                            module.lessons.push_back(lesson.id);
                            break;
                        }
                    }
                } catch (const json::exception& e) {
                    Core::Logger::error("Failed to parse lesson JSON: {}", e.what());
                }
            } else if (action == "add_exercise" && !value.empty() && !target.empty()) {
                // Parse exercise data from JSON and add to specified lesson
                try {
                    json exerciseData = json::parse(value);
                    SyllabusExercise exercise;
                    exercise.id = exerciseData.value("id", "exercise-" + std::to_string(customizedSyllabus.exercises.size() + 1));
                    exercise.title = exerciseData.value("title", "New Exercise");
                    exercise.description = exerciseData.value("description", "");
                    exercise.sequenceNumber = exerciseData.value("sequenceNumber", 1);
                    exercise.lessonId = target;
                    
                    if (exerciseData.contains("objectives") && exerciseData["objectives"].is_array()) {
                        for (const auto& obj : exerciseData["objectives"]) {
                            exercise.objectives.push_back(obj);
                        }
                    }
                    
                    exercise.procedure = exerciseData.value("procedure", "");
                    
                    if (exerciseData.contains("resources") && exerciseData["resources"].is_array()) {
                        for (const auto& resource : exerciseData["resources"]) {
                            exercise.resources.push_back(resource);
                        }
                    }
                    
                    std::string envStr = exerciseData.value("environment", "CLASSROOM");
                    if (envStr == "CLASSROOM") exercise.environment = TrainingEnvironment::CLASSROOM;
                    else if (envStr == "SIMULATOR") exercise.environment = TrainingEnvironment::SIMULATOR;
                    else if (envStr == "AIRCRAFT") exercise.environment = TrainingEnvironment::AIRCRAFT;
                    else if (envStr == "CBT") exercise.environment = TrainingEnvironment::CBT;
                    else if (envStr == "BRIEFING") exercise.environment = TrainingEnvironment::BRIEFING;
                    else exercise.environment = TrainingEnvironment::OTHER;
                    
                    exercise.estimatedDuration = exerciseData.value("estimatedDuration", 0);
                    exercise.assessmentCriteria = exerciseData.value("assessmentCriteria", "");
                    
                    // Add exercise to syllabus
                    customizedSyllabus.exercises[exercise.id] = exercise;
                    
                    // Add exercise to lesson
                    auto lessonIt = customizedSyllabus.lessons.find(target);
                    if (lessonIt != customizedSyllabus.lessons.end()) {
                        lessonIt->second.exercises.push_back(exercise.id);
                    }
                } catch (const json::exception& e) {
                    Core::Logger::error("Failed to parse exercise JSON: {}", e.what());
                }
            }
        }
        
        // Update modification date
        auto now = std::chrono::system_clock::now();
        auto now_time_t = std::chrono::system_clock::to_time_t(now);
        std::stringstream ss;
        ss << std::put_time(std::localtime(&now_time_t), "%Y-%m-%d %H:%M:%S");
        customizedSyllabus.lastModifiedDate = ss.str();
        
        Core::Logger::info("Customized syllabus: {}", customizedSyllabus.title);
        return Core::Result<Syllabus>::success(customizedSyllabus);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to customize syllabus: {}", e.what());
        return Core::Result<Syllabus>::failure(
            Core::ErrorCode::CustomizationFailed,
            "Failed to customize syllabus: " + std::string(e.what())
        );
    }
}

Core::Result<void> SyllabusGenerator::exportSyllabus(
    const Syllabus& syllabus,
    const std::string& format,
    const std::string& outputPath) {
    
    try {
        std::string path = outputPath;
        
        // If output path is a directory, create a filename
        if (std::filesystem::is_directory(outputPath)) {
            std::string filename = syllabus.title;
            
            // Replace spaces and special characters
            std::regex nonAlphanumeric("[^a-zA-Z0-9]");
            filename = std::regex_replace(filename, nonAlphanumeric, "_");
            
            path = (std::filesystem::path(outputPath) / (filename + "." + format)).string();
        }
        
        // Export based on format
        if (format == "json") {
            // Convert syllabus to JSON
            json syllabusJson;
            
            // Basic metadata
            syllabusJson["id"] = syllabus.id;
            syllabusJson["title"] = syllabus.title;
            syllabusJson["description"] = syllabus.description;
            syllabusJson["version"] = syllabus.version;
            syllabusJson["author"] = syllabus.author;
            syllabusJson["organization"] = syllabus.organization;
            syllabusJson["createdDate"] = syllabus.createdDate;
            syllabusJson["lastModifiedDate"] = syllabus.lastModifiedDate;
            syllabusJson["regulatoryFramework"] = syllabus.regulatoryFramework;
            
            // Learning objectives
            syllabusJson["objectives"] = json::array();
            for (const auto& objective : syllabus.objectives) {
                json obj;
                obj["id"] = objective.id;
                obj["description"] = objective.description;
                obj["type"] = static_cast<int>(objective.type);
                obj["taxonomyLevel"] = objective.taxonomyLevel;
                obj["relatedRegulations"] = objective.relatedRegulations;
                obj["prerequisiteObjectives"] = objective.prerequisiteObjectives;
                obj["difficulty"] = objective.difficulty;
                obj["assessmentMethod"] = objective.assessmentMethod;
                
                syllabusJson["objectives"].push_back(obj);
            }
            
            // Competency areas
            syllabusJson["competencies"] = json::array();
            for (const auto& competency : syllabus.competencies) {
                json comp;
                comp["id"] = competency.id;
                comp["name"] = competency.name;
                comp["description"] = competency.description;
                comp["indicators"] = competency.indicators;
                comp["objectives"] = competency.objectives;
                comp["regulations"] = competency.regulations;
                
                syllabusJson["competencies"].push_back(comp);
            }
            
            // Regulatory requirements
            syllabusJson["regulations"] = json::array();
            for (const auto& regulation : syllabus.regulations) {
                json reg;
                reg["id"] = regulation.id;
                reg["authority"] = regulation.authority;
                reg["reference"] = regulation.reference;
                reg["description"] = regulation.description;
                reg["textContent"] = regulation.textContent;
                reg["mandatory"] = regulation.mandatory;
                reg["relatedObjectives"] = regulation.relatedObjectives;
                
                syllabusJson["regulations"].push_back(reg);
            }
            
            // Modules
            syllabusJson["modules"] = json::array();
            for (const auto& module : syllabus.modules) {
                json mod;
                mod["id"] = module.id;
                mod["title"] = module.title;
                mod["description"] = module.description;
                mod["sequenceNumber"] = module.sequenceNumber;
                mod["prerequisites"] = module.prerequisites;
                mod["objectives"] = module.objectives;
                mod["lessons"] = module.lessons;
                mod["estimatedDuration"] = module.estimatedDuration;
                
                syllabusJson["modules"].push_back(mod);
            }
            
            // Lessons
            syllabusJson["lessons"] = json::object();
            for (const auto& [id, lesson] : syllabus.lessons) {
                json les;
                les["id"] = lesson.id;
                les["title"] = lesson.title;
                les["description"] = lesson.description;
                les["sequenceNumber"] = lesson.sequenceNumber;
                les["moduleId"] = lesson.moduleId;
                les["objectives"] = lesson.objectives;
                les["exercises"] = lesson.exercises;
                les["environment"] = static_cast<int>(lesson.environment);
                les["estimatedDuration"] = lesson.estimatedDuration;
                
                syllabusJson["lessons"][id] = les;
            }
            
            // Exercises
            syllabusJson["exercises"] = json::object();
            for (const auto& [id, exercise] : syllabus.exercises) {
                json ex;
                ex["id"] = exercise.id;
                ex["title"] = exercise.title;
                ex["description"] = exercise.description;
                ex["sequenceNumber"] = exercise.sequenceNumber;
                ex["lessonId"] = exercise.lessonId;
                ex["objectives"] = exercise.objectives;
                ex["procedure"] = exercise.procedure;
                ex["resources"] = exercise.resources;
                ex["environment"] = static_cast<int>(exercise.environment);
                ex["estimatedDuration"] = exercise.estimatedDuration;
                ex["assessmentCriteria"] = exercise.assessmentCriteria;
                
                syllabusJson["exercises"][id] = ex;
            }
            
            // Additional metadata
            syllabusJson["metadata"] = syllabus.metadata;
            
            // Write to file
            std::ofstream outFile(path);
            if (!outFile.is_open()) {
                return Core::Result<void>::failure(
                    Core::ErrorCode::FileWriteFailed,
                    "Failed to open output file: " + path
                );
            }
            
            outFile << std::setw(4) << syllabusJson << std::endl;
            outFile.close();
        } else if (format == "xml") {
            // Create XML document
            XMLDocument doc;
            
            // Root element
            XMLElement* rootElement = doc.NewElement("Syllabus");
            rootElement->SetAttribute("id", syllabus.id.c_str());
            rootElement->SetAttribute("version", syllabus.version.c_str());
            doc.InsertEndChild(rootElement);
            
            // Metadata
            XMLElement* metaElement = doc.NewElement("Metadata");
            rootElement->InsertEndChild(metaElement);
            
            XMLElement* titleElement = doc.NewElement("Title");
            titleElement->SetText(syllabus.title.c_str());
            metaElement->InsertEndChild(titleElement);
            
            XMLElement* descElement = doc.NewElement("Description");
            descElement->SetText(syllabus.description.c_str());
            metaElement->InsertEndChild(descElement);
            
            XMLElement* authorElement = doc.NewElement("Author");
            authorElement->SetText(syllabus.author.c_str());
            metaElement->InsertEndChild(authorElement);
            
            XMLElement* orgElement = doc.NewElement("Organization");
            orgElement->SetText(syllabus.organization.c_str());
            metaElement->InsertEndChild(orgElement);
            
            XMLElement* createdElement = doc.NewElement("CreatedDate");
            createdElement->SetText(syllabus.createdDate.c_str());
            metaElement->InsertEndChild(createdElement);
            
            XMLElement* modifiedElement = doc.NewElement("LastModifiedDate");
            modifiedElement->SetText(syllabus.lastModifiedDate.c_str());
            metaElement->InsertEndChild(modifiedElement);
            
            XMLElement* frameworkElement = doc.NewElement("RegulatoryFramework");
            frameworkElement->SetText(syllabus.regulatoryFramework.c_str());
            metaElement->InsertEndChild(frameworkElement);
            
            // Objectives
            XMLElement* objectivesElement = doc.NewElement("LearningObjectives");
            rootElement->InsertEndChild(objectivesElement);
            
            for (const auto& objective : syllabus.objectives) {
                XMLElement* objElement = doc.NewElement("Objective");
                objElement->SetAttribute("id", objective.id.c_str());
                objElement->SetAttribute("type", static_cast<int>(objective.type));
                
                XMLElement* objDescElement = doc.NewElement("Description");
                objDescElement->SetText(objective.description.c_str());
                objElement->InsertEndChild(objDescElement);
                
                XMLElement* objTaxElement = doc.NewElement("TaxonomyLevel");
                objTaxElement->SetText(objective.taxonomyLevel.c_str());
                objElement->InsertEndChild(objTaxElement);
                
                XMLElement* objDiffElement = doc.NewElement("Difficulty");
                objDiffElement->SetText(objective.difficulty);
                objElement->InsertEndChild(objDiffElement);
                
                XMLElement* objAssessElement = doc.NewElement("AssessmentMethod");
                objAssessElement->SetText(objective.assessmentMethod.c_str());
                objElement->InsertEndChild(objAssessElement);
                
                if (!objective.relatedRegulations.empty()) {
                    XMLElement* objRegsElement = doc.NewElement("RelatedRegulations");
                    objElement->InsertEndChild(objRegsElement);
                    
                    for (const auto& reg : objective.relatedRegulations) {
                        XMLElement* regElement = doc.NewElement("Regulation");
                        regElement->SetAttribute("id", reg.c_str());
                        objRegsElement->InsertEndChild(regElement);
                    }
                }
                
                if (!objective.prerequisiteObjectives.empty()) {
                    XMLElement* objPrereqsElement = doc.NewElement("Prerequisites");
                    objElement->InsertEndChild(objPrereqsElement);
                    
                    for (const auto& prereq : objective.prerequisiteObjectives) {
                        XMLElement* prereqElement = doc.NewElement("Prerequisite");
                        prereqElement->SetAttribute("id", prereq.c_str());
                        objPrereqsElement->InsertEndChild(prereqElement);
                    }
                }
                
                objectivesElement->InsertEndChild(objElement);
            }
            
            // Modules
            XMLElement* modulesElement = doc.NewElement("Modules");
            rootElement->InsertEndChild(modulesElement);
            
            for (const auto& module : syllabus.modules) {
                XMLElement* modElement = doc.NewElement("Module");
                modElement->SetAttribute("id", module.id.c_str());
                modElement->SetAttribute("sequenceNumber", module.sequenceNumber);
                
                XMLElement* modTitleElement = doc.NewElement("Title");
                modTitleElement->SetText(module.title.c_str());
                modElement->InsertEndChild(modTitleElement);
                
                XMLElement* modDescElement = doc.NewElement("Description");
                modDescElement->SetText(module.description.c_str());
                modElement->InsertEndChild(modDescElement);
                
                XMLElement* modDurElement = doc.NewElement("EstimatedDuration");
                modDurElement->SetText(module.estimatedDuration);
                modElement->InsertEndChild(modDurElement);
                
                if (!module.objectives.empty()) {
                    XMLElement* modObjsElement = doc.NewElement("Objectives");
                    modElement->InsertEndChild(modObjsElement);
                    
                    for (const auto& obj : module.objectives) {
                        XMLElement* objElement = doc.NewElement("Objective");
                        objElement->SetAttribute("id", obj.c_str());
                        modObjsElement->InsertEndChild(objElement);
                    }
                }
                
                if (!module.lessons.empty()) {
                    XMLElement* modLessonsElement = doc.NewElement("Lessons");
                    modElement->InsertEndChild(modLessonsElement);
                    
                    for (const auto& lesson : module.lessons) {
                        XMLElement* lessonElement = doc.NewElement("Lesson");
                        lessonElement->SetAttribute("id", lesson.c_str());
                        modLessonsElement->InsertEndChild(lessonElement);
                    }
                }
                
                modulesElement->InsertEndChild(modElement);
            }
            
            // Lessons
            XMLElement* lessonsElement = doc.NewElement("Lessons");
            rootElement->InsertEndChild(lessonsElement);
            
            for (const auto& [id, lesson] : syllabus.lessons) {
                XMLElement* lesElement = doc.NewElement("Lesson");
                lesElement->SetAttribute("id", lesson.id.c_str());
                lesElement->SetAttribute("sequenceNumber", lesson.sequenceNumber);
                lesElement->SetAttribute("moduleId", lesson.moduleId.c_str());
                
                XMLElement* lesTitleElement = doc.NewElement("Title");
                lesTitleElement->SetText(lesson.title.c_str());
                lesElement->InsertEndChild(lesTitleElement);
                
                XMLElement* lesDescElement = doc.NewElement("Description");
                lesDescElement->SetText(lesson.description.c_str());
                lesElement->InsertEndChild(lesDescElement);
                
                XMLElement* lesEnvElement = doc.NewElement("Environment");
                lesEnvElement->SetText(static_cast<int>(lesson.environment));
                lesElement->InsertEndChild(lesEnvElement);
                
                XMLElement* lesDurElement = doc.NewElement("EstimatedDuration");
                lesDurElement->SetText(lesson.estimatedDuration);
                lesElement->InsertEndChild(lesDurElement);
                
                if (!lesson.objectives.empty()) {
                    XMLElement* lesObjsElement = doc.NewElement("Objectives");
                    lesElement->InsertEndChild(lesObjsElement);
                    
                    for (const auto& obj : lesson.objectives) {
                        XMLElement* objElement = doc.NewElement("Objective");
                        objElement->SetAttribute("id", obj.c_str());
                        lesObjsElement->InsertEndChild(objElement);
                    }
                }
                
                if (!lesson.exercises.empty()) {
                    XMLElement* lesExsElement = doc.NewElement("Exercises");
                    lesElement->InsertEndChild(lesExsElement);
                    
                    for (const auto& exercise : lesson.exercises) {
                        XMLElement* exElement = doc.NewElement("Exercise");
                        exElement->SetAttribute("id", exercise.c_str());
                        lesExsElement->InsertEndChild(exElement);
                    }
                }
                
                lessonsElement->InsertEndChild(lesElement);
            }
            
            // Exercises
            XMLElement* exercisesElement = doc.NewElement("Exercises");
            rootElement->InsertEndChild(exercisesElement);
            
            for (const auto& [id, exercise] : syllabus.exercises) {
                XMLElement* exElement = doc.NewElement("Exercise");
                exElement->SetAttribute("id", exercise.id.c_str());
                exElement->SetAttribute("sequenceNumber", exercise.sequenceNumber);
                exElement->SetAttribute("lessonId", exercise.lessonId.c_str());
                
                XMLElement* exTitleElement = doc.NewElement("Title");
                exTitleElement->SetText(exercise.title.c_str());
                exElement->InsertEndChild(exTitleElement);
                
                XMLElement* exDescElement = doc.NewElement("Description");
                exDescElement->SetText(exercise.description.c_str());
                exElement->InsertEndChild(exDescElement);
                
                XMLElement* exEnvElement = doc.NewElement("Environment");
                exEnvElement->SetText(static_cast<int>(exercise.environment));
                exElement->InsertEndChild(exEnvElement);
                
                XMLElement* exDurElement = doc.NewElement("EstimatedDuration");
                exDurElement->SetText(exercise.estimatedDuration);
                exElement->InsertEndChild(exDurElement);
                
                XMLElement* exProcElement = doc.NewElement("Procedure");
                exProcElement->SetText(exercise.procedure.c_str());
                exElement->InsertEndChild(exProcElement);
                
                XMLElement* exAssessElement = doc.NewElement("AssessmentCriteria");
                exAssessElement->SetText(exercise.assessmentCriteria.c_str());
                exElement->InsertEndChild(exAssessElement);
                
                if (!exercise.objectives.empty()) {
                    XMLElement* exObjsElement = doc.NewElement("Objectives");
                    exElement->InsertEndChild(exObjsElement);
                    
                    for (const auto& obj : exercise.objectives) {
                        XMLElement* objElement = doc.NewElement("Objective");
                        objElement->SetAttribute("id", obj.c_str());
                        exObjsElement->InsertEndChild(objElement);
                    }
                }
                
                if (!exercise.resources.empty()) {
                    XMLElement* exResElement = doc.NewElement("Resources");
                    exElement->InsertEndChild(exResElement);
                    
                    for (const auto& resource : exercise.resources) {
                        XMLElement* resElement = doc.NewElement("Resource");
                        resElement->SetText(resource.c_str());
                        exResElement->InsertEndChild(resElement);
                    }
                }
                
                exercisesElement->InsertEndChild(exElement);
            }
            
            // Save XML document
            XMLError result = doc.SaveFile(path.c_str());
            if (result != XML_SUCCESS) {
                return Core::Result<void>::failure(
                    Core::ErrorCode::FileWriteFailed,
                    "Failed to write XML file: " + path
                );
            }
        } else if (format == "html") {
            // Simple HTML export
            std::ofstream outFile(path);
            if (!outFile.is_open()) {
                return Core::Result<void>::failure(
                    Core::ErrorCode::FileWriteFailed,
                    "Failed to open output file: " + path
                );
            }
            
            // Write HTML header
            outFile << "<!DOCTYPE html>\n"
                    << "<html>\n"
                    << "<head>\n"
                    << "  <title>" << syllabus.title << "</title>\n"
                    << "  <style>\n"
                    << "    body { font-family: Arial, sans-serif; margin: 20px; }\n"
                    << "    h1, h2, h3, h4 { color: #333; }\n"
                    << "    .module { margin-bottom: 20px; border: 1px solid #ddd; padding: 10px; }\n"
                    << "    .lesson { margin: 10px 0; margin-left: 20px; border: 1px solid #eee; padding: 10px; }\n"
                    << "    .exercise { margin: 10px 0; margin-left: 40px; border: 1px solid #f0f0f0; padding: 10px; }\n"
                    << "    .metadata { color: #666; font-size: 0.9em; }\n"
                    << "  </style>\n"
                    << "</head>\n"
                    << "<body>\n"
                    << "  <h1>" << syllabus.title << "</h1>\n"
                    << "  <div class=\"metadata\">\n"
                    << "    <p><strong>Version:</strong> " << syllabus.version << "</p>\n"
                    << "    <p><strong>Author:</strong> " << syllabus.author << "</p>\n"
                    << "    <p><strong>Organization:</strong> " << syllabus.organization << "</p>\n"
                    << "    <p><strong>Created:</strong> " << syllabus.createdDate << "</p>\n"
                    << "    <p><strong>Last Modified:</strong> " << syllabus.lastModifiedDate << "</p>\n"
                    << "    <p><strong>Regulatory Framework:</strong> " << syllabus.regulatoryFramework << "</p>\n"
                    << "  </div>\n"
                    << "  <h2>Description</h2>\n"
                    << "  <p>" << syllabus.description << "</p>\n";
            
            // Modules
            outFile << "  <h2>Modules</h2>\n";
            
            // Sort modules by sequence number
            std::vector<SyllabusModule> sortedModules = syllabus.modules;
            std::sort(sortedModules.begin(), sortedModules.end(),
                [](const SyllabusModule& a, const SyllabusModule& b) {
                    return a.sequenceNumber < b.sequenceNumber;
                });
            
            for (const auto& module : sortedModules) {
                outFile << "  <div class=\"module\">\n"
                        << "    <h3>" << module.sequenceNumber << ". " << module.title << "</h3>\n"
                        << "    <p>" << module.description << "</p>\n"
                        << "    <p><strong>Duration:</strong> " << module.estimatedDuration << " minutes</p>\n";
                
                // Objectives
                if (!module.objectives.empty()) {
                    outFile << "    <h4>Learning Objectives</h4>\n"
                            << "    <ul>\n";
                    
                    for (const auto& objId : module.objectives) {
                        // Find objective by ID
                        auto it = std::find_if(syllabus.objectives.begin(), syllabus.objectives.end(),
                            [&objId](const LearningObjective& obj) { return obj.id == objId; });
                        
                        if (it != syllabus.objectives.end()) {
                            outFile << "      <li>" << it->description << "</li>\n";
                        } else {
                            outFile << "      <li>Objective ID: " << objId << "</li>\n";
                        }
                    }
                    
                    outFile << "    </ul>\n";
                }
                
                // Lessons
                if (!module.lessons.empty()) {
                    outFile << "    <h4>Lessons</h4>\n";
                    
                    // Find and sort lessons by sequence number
                    std::vector<std::reference_wrapper<const SyllabusLesson>> moduleLessons;
                    for (const auto& lessonId : module.lessons) {
                        auto it = syllabus.lessons.find(lessonId);
                        if (it != syllabus.lessons.end()) {
                            moduleLessons.push_back(std::cref(it->second));
                        }
                    }
                    
                    std::sort(moduleLessons.begin(), moduleLessons.end(),
                        [](const std::reference_wrapper<const SyllabusLesson>& a, 
                           const std::reference_wrapper<const SyllabusLesson>& b) {
                            return a.get().sequenceNumber < b.get().sequenceNumber;
                        });
                    
                    for (const auto& lessonRef : moduleLessons) {
                        const auto& lesson = lessonRef.get();
                        
                        // Environment string
                        std::string envStr;
                        switch (lesson.environment) {
                            case TrainingEnvironment::CLASSROOM: envStr = "Classroom"; break;
                            case TrainingEnvironment::SIMULATOR: envStr = "Simulator"; break;
                            case TrainingEnvironment::AIRCRAFT: envStr = "Aircraft"; break;
                            case TrainingEnvironment::CBT: envStr = "Computer-Based Training"; break;
                            case TrainingEnvironment::BRIEFING: envStr = "Briefing"; break;
                            case TrainingEnvironment::OTHER: envStr = "Other"; break;
                            default: envStr = "Unknown";
                        }
                        
                        outFile << "    <div class=\"lesson\">\n"
                                << "      <h4>" << module.sequenceNumber << "." << lesson.sequenceNumber 
                                << ". " << lesson.title << "</h4>\n"
                                << "      <p>" << lesson.description << "</p>\n"
                                << "      <p><strong>Environment:</strong> " << envStr << "</p>\n"
                                << "      <p><strong>Duration:</strong> " << lesson.estimatedDuration << " minutes</p>\n";
                        
                        // Exercises
                        if (!lesson.exercises.empty()) {
                            outFile << "      <h5>Exercises</h5>\n";
                            
                            // Find and sort exercises by sequence number
                            std::vector<std::reference_wrapper<const SyllabusExercise>> lessonExercises;
                            for (const auto& exerciseId : lesson.exercises) {
                                auto it = syllabus.exercises.find(exerciseId);
                                if (it != syllabus.exercises.end()) {
                                    lessonExercises.push_back(std::cref(it->second));
                                }
                            }
                            
                            std::sort(lessonExercises.begin(), lessonExercises.end(),
                                [](const std::reference_wrapper<const SyllabusExercise>& a, 
                                  const std::reference_wrapper<const SyllabusExercise>& b) {
                                    return a.get().sequenceNumber < b.get().sequenceNumber;
                                });
                            
                            for (const auto& exerciseRef : lessonExercises) {
                                const auto& exercise = exerciseRef.get();
                                
                                // Environment string
                                std::string exEnvStr;
                                switch (exercise.environment) {
                                    case TrainingEnvironment::CLASSROOM: exEnvStr = "Classroom"; break;
                                    case TrainingEnvironment::SIMULATOR: exEnvStr = "Simulator"; break;
                                    case TrainingEnvironment::AIRCRAFT: exEnvStr = "Aircraft"; break;
                                    case TrainingEnvironment::CBT: exEnvStr = "Computer-Based Training"; break;
                                    case TrainingEnvironment::BRIEFING: exEnvStr = "Briefing"; break;
                                    case TrainingEnvironment::OTHER: exEnvStr = "Other"; break;
                                    default: exEnvStr = "Unknown";
                                }
                                
                                outFile << "      <div class=\"exercise\">\n"
                                        << "        <h5>" << module.sequenceNumber << "." << lesson.sequenceNumber 
                                        << "." << exercise.sequenceNumber << ". " << exercise.title << "</h5>\n"
                                        << "        <p>" << exercise.description << "</p>\n"
                                        << "        <p><strong>Environment:</strong> " << exEnvStr << "</p>\n"
                                        << "        <p><strong>Duration:</strong> " << exercise.estimatedDuration << " minutes</p>\n";
                                
                                if (!exercise.procedure.empty()) {
                                    outFile << "        <h6>Procedure</h6>\n"
                                            << "        <p>" << exercise.procedure << "</p>\n";
                                }
                                
                                if (!exercise.assessmentCriteria.empty()) {
                                    outFile << "        <h6>Assessment Criteria</h6>\n"
                                            << "        <p>" << exercise.assessmentCriteria << "</p>\n";
                                }
                                
                                outFile << "      </div>\n";
                            }
                        }
                        
                        outFile << "    </div>\n";
                    }
                }
                
                outFile << "  </div>\n";
            }
            
            // HTML footer
            outFile << "</body>\n"
                    << "</html>\n";
            
            outFile.close();
        } else {
            return Core::Result<void>::failure(
                Core::ErrorCode::UnsupportedFormat,
                "Unsupported export format: " + format
            );
        }
        
        Core::Logger::info("Exported syllabus to {}", path);
        return Core::Result<void>::success();
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to export syllabus: {}", e.what());
        return Core::Result<void>::failure(
            Core::ErrorCode::ExportFailed,
            "Failed to export syllabus: " + std::string(e.what())
        );
    }
}

Core::Result<std::unordered_map<std::string, std::string>> SyllabusGenerator::validateSyllabus(
    const Syllabus& syllabus) {
    
    try {
        std::unordered_map<std::string, std::string> results;
        
        // Validate structural integrity
        if (!validateStructuralIntegrity(syllabus, results)) {
            return Core::Result<std::unordered_map<std::string, std::string>>::success(results);
        }
        
        // Validate objective coverage
        if (!validateObjectiveCoverage(syllabus, results)) {
            return Core::Result<std::unordered_map<std::string, std::string>>::success(results);
        }
        
        // Validate regulatory coverage
        if (!validateRegulatoryCoverage(syllabus, results)) {
            return Core::Result<std::unordered_map<std::string, std::string>>::success(results);
        }
        
        // If we get here, no issues were found
        if (results.empty()) {
            results["overall"] = "Syllabus validation passed with no issues.";
        }
        
        Core::Logger::info("Validated syllabus: {}", syllabus.title);
        return Core::Result<std::unordered_map<std::string, std::string>>::success(results);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to validate syllabus: {}", e.what());
        return Core::Result<std::unordered_map<std::string, std::string>>::failure(
            Core::ErrorCode::ValidationFailed,
            "Failed to validate syllabus: " + std::string(e.what())
        );
    }
}

Core::Result<std::string> SyllabusGenerator::addLearningObjective(const LearningObjective& objective) {
    try {
        // Generate an ID if not provided
        std::string id = objective.id;
        if (id.empty()) {
            id = "obj-" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
        }
        
        Core::Logger::info("Added learning objective: {}", id);
        return Core::Result<std::string>::success(id);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to add learning objective: {}", e.what());
        return Core::Result<std::string>::failure(
            Core::ErrorCode::CreationFailed,
            "Failed to add learning objective: " + std::string(e.what())
        );
    }
}

Core::Result<std::string> SyllabusGenerator::addCompetencyArea(const CompetencyArea& competency) {
    try {
        // Generate an ID if not provided
        std::string id = competency.id;
        if (id.empty()) {
            id = "comp-" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
        }
        
        Core::Logger::info("Added competency area: {}", id);
        return Core::Result<std::string>::success(id);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to add competency area: {}", e.what());
        return Core::Result<std::string>::failure(
            Core::ErrorCode::CreationFailed,
            "Failed to add competency area: " + std::string(e.what())
        );
    }
}

Core::Result<std::string> SyllabusGenerator::addRegulatoryRequirement(const RegulatoryRequirement& requirement) {
    try {
        // Generate an ID if not provided
        std::string id = requirement.id;
        if (id.empty()) {
            id = "reg-" + std::to_string(std::chrono::system_clock::now().time_since_epoch().count());
        }
        
        Core::Logger::info("Added regulatory requirement: {}", id);
        return Core::Result<std::string>::success(id);
    } catch (const std::exception& e) {
        Core::Logger::error("Failed to add regulatory requirement: {}", e.what());
        return Core::Result<std::string>::failure(
            Core::ErrorCode::CreationFailed,
            "Failed to add regulatory requirement: " + std::string(e.what())
        );
    }
}

// Private methods

std::vector<LearningObjective> SyllabusGenerator::extractObjectivesFromDocument(const Document::ProcessingResult& result) {
    std::vector<LearningObjective> objectives;
    
    // Extract from structured content
    for (const auto& objective : result.trainingElements.learningObjectives) {
        LearningObjective newObj;
        newObj.id = objective.id;
        newObj.description = objective.description;
        
        // Determine objective type (simplified)
        if (objective.description.find("knowledge") != std::string::npos ||
            objective.description.find("understand") != std::string::npos ||
            objective.description.find("identify") != std::string::npos) {
            newObj.type = ObjectiveType::KNOWLEDGE;
        } else if (objective.description.find("attitude") != std::string::npos ||
                  objective.description.find("value") != std::string::npos ||
                  objective.description.find("appreciate") != std::string::npos) {
            newObj.type = ObjectiveType::ATTITUDE;
        } else {
            newObj.type = ObjectiveType::SKILL;
        }
        
        // Determine taxonomy level (simplified)
        if (objective.description.find("analyze") != std::string::npos ||
            objective.description.find("evaluate") != std::string::npos) {
            newObj.taxonomyLevel = "Analyze";
        } else if (objective.description.find("apply") != std::string::npos ||
                  objective.description.find("demonstrate") != std::string::npos ||
                  objective.description.find("perform") != std::string::npos) {
            newObj.taxonomyLevel = "Apply";
        } else if (objective.description.find("create") != std::string::npos ||
                  objective.description.find("design") != std::string::npos ||
                  objective.description.find("develop") != std::string::npos) {
            newObj.taxonomyLevel = "Create";
        } else {
            newObj.taxonomyLevel = "Understand";
        }
        
        // Add related regulations
        for (const auto& reg : objective.relatedRegulations) {
            newObj.relatedRegulations.push_back(reg);
        }
        
        // Add prerequisites
        for (const auto& prereq : objective.prerequisites) {
            newObj.prerequisiteObjectives.push_back(prereq);
        }
        
        // Assign difficulty (simplified)
        newObj.difficulty = objective.importance > 0.8 ? 5 : 
                          objective.importance > 0.6 ? 4 :
                          objective.importance > 0.4 ? 3 :
                          objective.importance > 0.2 ? 2 : 1;
        
        // Determine assessment method (simplified)
        if (newObj.type == ObjectiveType::KNOWLEDGE) {
            newObj.assessmentMethod = "Written test";
        } else if (newObj.type == ObjectiveType::SKILL) {
            newObj.assessmentMethod = "Performance demonstration";
        } else {
            newObj.assessmentMethod = "Observation";
        }
        
        objectives.push_back(newObj);
    }
    
    // If AI extraction is enabled, use it for additional objectives
    if (_config.enableAIExtraction) {
        try {
            auto aiObjectives = extractObjectivesWithAI(result.content.rawText);
            if (aiObjectives.isSuccess()) {
                objectives.insert(objectives.end(), 
                                 aiObjectives.getValue().begin(), 
                                 aiObjectives.getValue().end());
            }
        } catch (const std::exception& e) {
            Core::Logger::error("AI extraction error: {}", e.what());
        }
    }
    
    return objectives;
}

std::vector<CompetencyArea> SyllabusGenerator::extractCompetenciesFromDocument(const Document::ProcessingResult& result) {
    std::vector<CompetencyArea> competencies;
    
    // Extract from document structure sections
    for (const auto& section : result.structure.sections) {
        // Look for competency sections
        if (section.title.find("Competenc") != std::string::npos ||
            section.title.find("Proficienc") != std::string::npos ||
            section.title.find("Skill") != std::string::npos) {
            
            CompetencyArea competency;
            competency.id = "comp-" + std::to_string(competencies.size() + 1);
            competency.name = section.title;
            competency.description = section.content;
            
            // Extract indicators from subsections
            for (const auto& subsection : section.subsections) {
                if (subsection.title.find("Indicator") != std::string::npos ||
                    subsection.title.find("Criteria") != std::string::npos ||
                    subsection.title.find("Standard") != std::string::npos) {
                    
                    // Parse content as indicators (simplified)
                    std::istringstream iss(subsection.content);
                    std::string line;
                    while (std::getline(iss, line)) {
                        // Remove leading/trailing whitespace
                        line.erase(0, line.find_first_not_of(" \t\r\n"));
                        line.erase(line.find_last_not_of(" \t\r\n") + 1);
                        
                        if (!line.empty()) {
                            competency.indicators.push_back(line);
                        }
                    }
                }
            }
            
            competencies.push_back(competency);
        }
    }
    
    // If AI extraction is enabled, use it for additional competencies
    if (_config.enableAIExtraction) {
        try {
            auto aiCompetencies = extractCompetenciesWithAI(result.content.rawText);
            if (aiCompetencies.isSuccess()) {
                competencies.insert(competencies.end(), 
                                   aiCompetencies.getValue().begin(), 
                                   aiCompetencies.getValue().end());
            }
        } catch (const std::exception& e) {
            Core::Logger::error("AI extraction error: {}", e.what());
        }
    }
    
    return competencies;
}

std::vector<RegulatoryRequirement> SyllabusGenerator::extractRegulationsFromDocument(const Document::ProcessingResult& result) {
    std::vector<RegulatoryRequirement> regulations;
    
    // Extract from document structure sections
    for (const auto& section : result.structure.sections) {
        // Look for regulatory sections
        if (section.title.find("Regulation") != std::string::npos ||
            section.title.find("Requirement") != std::string::npos ||
            section.title.find("Compliance") != std::string::npos) {
            
            RegulatoryRequirement regulation;
            regulation.id = "reg-" + std::to_string(regulations.size() + 1);
            
            // Determine authority from metadata
            regulation.authority = result.content.metadata.find("regulator") != result.content.metadata.end() ?
                                  result.content.metadata.at("regulator") : _config.defaultRegulator;
            
            // Extract reference from title (simplified)
            std::regex refRegex(R"((\w+\s*\d+(\.\d+)*)|(Part\s*\d+))");
            std::smatch match;
            if (std::regex_search(section.title, match, refRegex)) {
                regulation.reference = match[0];
            } else {
                regulation.reference = section.title;
            }
            
            regulation.description = section.title;
            regulation.textContent = section.content;
            regulation.mandatory = true; // Assume all extracted regulations are mandatory
            
            regulations.push_back(regulation);
        }
    }
    
    // Extract from regulatory references in document
    for (const auto& [reference, citations] : result.structure.regulatoryReferences) {
        RegulatoryRequirement regulation;
        regulation.id = "reg-" + std::to_string(regulations.size() + 1);
        regulation.authority = result.content.metadata.find("regulator") != result.content.metadata.end() ?
                              result.content.metadata.at("regulator") : _config.defaultRegulator;
        regulation.reference = reference;
        regulation.description = reference;
        
        // Combine citations as text content
        std::ostringstream citationText;
        for (const auto& citation : citations) {
            citationText << citation << "\n\n";
        }
        regulation.textContent = citationText.str();
        regulation.mandatory = true; // Assume all extracted regulations are mandatory
        
        regulations.push_back(regulation);
    }
    
    // If AI extraction is enabled, use it for additional regulations
    if (_config.enableAIExtraction) {
        try {
            auto aiRegulations = extractRegulationsWithAI(result.content.rawText);
            if (aiRegulations.isSuccess()) {
                regulations.insert(regulations.end(), 
                                  aiRegulations.getValue().begin(), 
                                  aiRegulations.getValue().end());
            }
        } catch (const std::exception& e) {
            Core::Logger::error("AI extraction error: {}", e.what());
        }
    }
    
    return regulations;
}

void SyllabusGenerator::organizeModules(Syllabus& syllabus) {
    // Group objectives by category/topic
    std::unordered_map<std::string, std::vector<std::string>> objectiveGroups;
    
    // Simple grouping by keywords (would be more sophisticated in real implementation)
    std::vector<std::pair<std::string, std::vector<std::string>>> moduleKeywords = {
        {"Basic Aircraft Knowledge", {"aircraft", "system", "component", "instrument"}},
        {"Flight Fundamentals", {"basic", "fundamental", "principle", "aerodynamic"}},
        {"Takeoff and Landing", {"takeoff", "landing", "approach"}},
        {"Navigation", {"navigation", "route", "chart", "plan"}},
        {"Emergency Procedures", {"emergency", "abnormal", "failure", "malfunction"}},
        {"Advanced Maneuvers", {"advanced", "maneuver", "stall", "spin"}}
    };
    
    // Group objectives by module
    for (const auto& objective : syllabus.objectives) {
        std::string bestMatch;
        int bestMatchCount = 0;
        
        // Convert description to lowercase for comparison
        std::string lowerDesc = objective.description;
        std::transform(lowerDesc.begin(), lowerDesc.end(), lowerDesc.begin(), 
            [](unsigned char c) { return std::tolower(c); });
        
        // Find best match
        for (const auto& [module, keywords] : moduleKeywords) {
            int matchCount = 0;
            for (const auto& keyword : keywords) {
                if (lowerDesc.find(keyword) != std::string::npos) {
                    matchCount++;
                }
            }
            
            if (matchCount > bestMatchCount) {
                bestMatchCount = matchCount;
                bestMatch = module;
            }
        }
        
        // If no match found, put in "Other"
        if (bestMatch.empty()) {
            bestMatch = "Other";
        }
        
        objectiveGroups[bestMatch].push_back(objective.id);
    }
    
    // Create modules from groups
    int sequenceNumber = 1;
    for (const auto& [moduleName, objectiveIds] : objectiveGroups) {
        SyllabusModule module;
        module.id = "module-" + std::to_string(sequenceNumber);
        module.title = moduleName;
        module.description = "Module covering " + moduleName + " topics";
        module.sequenceNumber = sequenceNumber++;
        module.objectives = objectiveIds;
        module.estimatedDuration = objectiveIds.size() * 30; // Estimate 30 minutes per objective
        
        syllabus.modules.push_back(module);
    }
}

void SyllabusGenerator::organizeLessons(Syllabus& syllabus) {
    // Create lessons for each module
    for (auto& module : syllabus.modules) {
        // Group objectives for lessons (simplified)
        std::vector<std::vector<std::string>> lessonGroups;
        
        // Naive grouping - just split objectives into groups of 3
        const int objectivesPerLesson = 3;
        for (size_t i = 0; i < module.objectives.size(); i += objectivesPerLesson) {
            std::vector<std::string> group;
            for (size_t j = i; j < i + objectivesPerLesson && j < module.objectives.size(); j++) {
                group.push_back(module.objectives[j]);
            }
            lessonGroups.push_back(group);
        }
        
        // Create lessons from groups
        int sequenceNumber = 1;
        for (const auto& objectiveIds : lessonGroups) {
            SyllabusLesson lesson;
            lesson.id = module.id + "-lesson-" + std::to_string(sequenceNumber);
            
            // Generate lesson title
            if (objectiveIds.empty()) {
                lesson.title = module.title + " Lesson " + std::to_string(sequenceNumber);
            } else {
                // Find objective text for first objective
                auto it = std::find_if(syllabus.objectives.begin(), syllabus.objectives.end(),
                    [&objectiveIds](const LearningObjective& obj) { return obj.id == objectiveIds[0]; });
                
                if (it != syllabus.objectives.end()) {
                    // Take first few words as lesson title
                    std::istringstream iss(it->description);
                    std::vector<std::string> words;
                    std::string word;
                    int wordCount = 0;
                    while (iss >> word && wordCount++ < 5) {
                        words.push_back(word);
                    }
                    
                    lesson.title = "";
                    for (const auto& w : words) {
                        if (!lesson.title.empty()) {
                            lesson.title += " ";
                        }
                        lesson.title += w;
                    }
                    
                    if (!lesson.title.empty()) {
                        lesson.title += "...";
                    } else {
                        lesson.title = module.title + " Lesson " + std::to_string(sequenceNumber);
                    }
                } else {
                    lesson.title = module.title + " Lesson " + std::to_string(sequenceNumber);
                }
            }
            
            lesson.description = "Lesson covering " + lesson.title + " topics";
            lesson.sequenceNumber = sequenceNumber++;
            lesson.moduleId = module.id;
            lesson.objectives = objectiveIds;
            lesson.estimatedDuration = objectiveIds.size() * 30; // Estimate 30 minutes per objective
            
            // Determine environment based on objectives
            // Default to classroom, but use simulator or aircraft if keywords suggest it
            lesson.environment = TrainingEnvironment::CLASSROOM;
            
            for (const auto& objId : objectiveIds) {
                auto it = std::find_if(syllabus.objectives.begin(), syllabus.objectives.end(),
                    [&objId](const LearningObjective& obj) { return obj.id == objId; });
                
                if (it != syllabus.objectives.end()) {
                    std::string lowerDesc = it->description;
                    std::transform(lowerDesc.begin(), lowerDesc.end(), lowerDesc.begin(), 
                        [](unsigned char c) { return std::tolower(c); });
                    
                    if (lowerDesc.find("simulator") != std::string::npos || 
                        lowerDesc.find("fly") != std::string::npos ||
                        lowerDesc.find("perform") != std::string::npos ||
                        lowerDesc.find("demonstrate") != std::string::npos) {
                        lesson.environment = TrainingEnvironment::SIMULATOR;
                        break;
                    }
                    
                    if (lowerDesc.find("aircraft") != std::string::npos && 
                        (lowerDesc.find("actual") != std::string::npos || 
                         lowerDesc.find("real") != std::string::npos)) {
                        lesson.environment = TrainingEnvironment::AIRCRAFT;
                        break;
                    }
                }
            }
            
            // Add lesson to module
            module.lessons.push_back(lesson.id);
            
            // Add lesson to syllabus
            syllabus.lessons[lesson.id] = lesson;
        }
    }
}

void SyllabusGenerator::organizeExercises(Syllabus& syllabus) {
    // Create exercises for each lesson
    for (auto& [lessonId, lesson] : syllabus.lessons) {
        // Create one exercise per objective
        int sequenceNumber = 1;
        for (const auto& objId : lesson.objectives) {
            SyllabusExercise exercise;
            exercise.id = lessonId + "-exercise-" + std::to_string(sequenceNumber);
            
            // Find objective
            auto it = std::find_if(syllabus.objectives.begin(), syllabus.objectives.end(),
                [&objId](const LearningObjective& obj) { return obj.id == objId; });
            
            if (it != syllabus.objectives.end()) {
                exercise.title = it->description;
                
                // Determine exercise type based on objective
                std::string lowerDesc = it->description;
                std::transform(lowerDesc.begin(), lowerDesc.end(), lowerDesc.begin(), 
                    [](unsigned char c) { return std::tolower(c); });
                
                if (lowerDesc.find("describe") != std::string::npos || 
                    lowerDesc.find("explain") != std::string::npos ||
                    lowerDesc.find("identify") != std::string::npos) {
                    exercise.description = "Discussion exercise on " + it->description;
                    exercise.procedure = "1. Instructor introduction\n2. Group discussion\n3. Q&A session\n4. Summary";
                } else if (lowerDesc.find("demonstrate") != std::string::npos || 
                          lowerDesc.find("perform") != std::string::npos ||
                          lowerDesc.find("execute") != std::string::npos) {
                    exercise.description = "Practical exercise on " + it->description;
                    exercise.procedure = "1. Instructor demonstration\n2. Student practice\n3. Feedback\n4. Evaluation";
                } else {
                    exercise.description = "Exercise on " + it->description;
                    exercise.procedure = "1. Introduction\n2. Practice\n3. Assessment";
                }
            } else {
                exercise.title = "Exercise " + std::to_string(sequenceNumber);
                exercise.description = "Exercise related to lesson " + lesson.title;
                exercise.procedure = "1. Introduction\n2. Main activity\n3. Conclusion";
            }
            
            exercise.sequenceNumber = sequenceNumber++;
            exercise.lessonId = lessonId;
            exercise.objectives = {objId};
            exercise.environment = lesson.environment;
            exercise.estimatedDuration = 30; // Default 30 minutes per exercise
            
            // Assessment criteria based on objective
            if (it != syllabus.objectives.end()) {
                exercise.assessmentCriteria = "The student should be able to " + it->description + 
                                            " according to the standards.";
            } else {
                exercise.assessmentCriteria = "The student should be able to complete the exercise satisfactorily.";
            }
            
            // Add exercise to lesson
            lesson.exercises.push_back(exercise.id);
            
            // Add exercise to syllabus
            syllabus.exercises[exercise.id] = exercise;
        }
    }
}

Core::Result<std::vector<LearningObjective>> SyllabusGenerator::extractObjectivesWithAI(const std::string& documentContent) {
    // This would be implemented with actual AI integration in a real system
    // For this example, we'll return a simplified result
    
    std::vector<LearningObjective> objectives;
    
    // Simulate AI extraction with a few sample objectives
    LearningObjective obj1;
    obj1.id = "ai-obj-1";
    obj1.description = "Demonstrate proper use of flight controls during normal takeoff";
    obj1.type = ObjectiveType::SKILL;
    obj1.taxonomyLevel = "Apply";
    obj1.difficulty = 3;
    obj1.assessmentMethod = "Performance demonstration";
    
    LearningObjective obj2;
    obj2.id = "ai-obj-2";
    obj2.description = "Explain the aerodynamic principles affecting the aircraft during stall recovery";
    obj2.type = ObjectiveType::KNOWLEDGE;
    obj2.taxonomyLevel = "Understand";
    obj2.difficulty = 4;
    obj2.assessmentMethod = "Written test";
    
    LearningObjective obj3;
    obj3.id = "ai-obj-3";
    obj3.description = "Analyze the impact of weather conditions on flight planning decisions";
    obj3.type = ObjectiveType::SKILL;
    obj3.taxonomyLevel = "Analyze";
    obj3.difficulty = 4;
    obj3.assessmentMethod = "Case study";
    
    objectives.push_back(obj1);
    objectives.push_back(obj2);
    objectives.push_back(obj3);
    
    Core::Logger::debug("AI extraction simulated {} objectives", objectives.size());
    return Core::Result<std::vector<LearningObjective>>::success(objectives);
}

Core::Result<std::vector<CompetencyArea>> SyllabusGenerator::extractCompetenciesWithAI(const std::string& documentContent) {
    // This would be implemented with actual AI integration in a real system
    // For this example, we'll return a simplified result
    
    std::vector<CompetencyArea> competencies;
    
    // Simulate AI extraction with a few sample competencies
    CompetencyArea comp1;
    comp1.id = "ai-comp-1";
    comp1.name = "Aircraft Control";
    comp1.description = "Ability to maintain precise control of the aircraft throughout all phases of flight";
    comp1.indicators = {
        "Maintains altitude within 100 feet",
        "Maintains heading within 10 degrees",
        "Maintains airspeed within 10 knots"
    };
    
    CompetencyArea comp2;
    comp2.id = "ai-comp-2";
    comp2.name = "Decision Making";
    comp2.description = "Ability to make sound decisions based on available information and changing conditions";
    comp2.indicators = {
        "Identifies potential issues before they become critical",
        "Evaluates multiple options before selecting course of action",
        "Adapts plan when conditions change"
    };
    
    competencies.push_back(comp1);
    competencies.push_back(comp2);
    
    Core::Logger::debug("AI extraction simulated {} competencies", competencies.size());
    return Core::Result<std::vector<CompetencyArea>>::success(competencies);
}

Core::Result<std::vector<RegulatoryRequirement>> SyllabusGenerator::extractRegulationsWithAI(const std::string& documentContent) {
    // This would be implemented with actual AI integration in a real system
    // For this example, we'll return a simplified result
    
    std::vector<RegulatoryRequirement> regulations;
    
    // Simulate AI extraction with a few sample regulations
    RegulatoryRequirement reg1;
    reg1.id = "ai-reg-1";
    reg1.authority = "FAA";
    reg1.reference = "14 CFR  61.109";
    reg1.description = "Aeronautical experience for private pilot certificate";
    reg1.textContent = "A person who applies for a private pilot certificate must present logbook entries showing...";
    reg1.mandatory = true;
    
    RegulatoryRequirement reg2;
    reg2.id = "ai-reg-2";
    reg2.authority = "EASA";
    reg2.reference = "FCL.210";
    reg2.description = "Training course for private pilot license";
    reg2.textContent = "Applicants for a PPL shall complete a training course at an ATO...";
    reg2.mandatory = true;
    
    regulations.push_back(reg1);
    regulations.push_back(reg2);
    
    Core::Logger::debug("AI extraction simulated {} regulations", regulations.size());
    return Core::Result<std::vector<RegulatoryRequirement>>::success(regulations);
}

Core::Result<Syllabus> SyllabusGenerator::loadTemplate(const std::string& templatePath) {
    try {
        // Check if template file exists
        if (!std::filesystem::exists(templatePath)) {
            return Core::Result<Syllabus>::failure(
                Core::ErrorCode::FileNotFound,
                "Template file not found: " + templatePath
            );
        }
        
        // Determine template format
        std::string extension = std::filesystem::path(templatePath).extension().string();
        
        if (extension == ".json") {
            // Load JSON template
            std::ifstream file(templatePath);
            if (!file.is_open()) {
                return Core::Result<Syllabus>::failure(
                    Core::ErrorCode::FileOpenFailed,
                    "Failed to open template file: " + templatePath
                );
            }
            
            json templateJson;
            file >> templateJson;
            file.close();
            
            // Parse JSON into syllabus
            Syllabus syllabus;
            
            // Basic metadata
            syllabus.id = templateJson.value("id", "syllabus-template");
            syllabus.title = templateJson.value("title", "Syllabus Template");
            syllabus.description = templateJson.value("description", "");
            syllabus.version = templateJson.value("version", "1.0");
            syllabus.author = templateJson.value("author", "System");
            syllabus.organization = templateJson.value("organization", "Default Organization");
            
            // Set dates
            auto now = std::chrono::system_clock::now();
            auto now_time_t = std::chrono::system_clock::to_time_t(now);
            std::stringstream ss;
            ss << std::put_time(std::localtime(&now_time_t), "%Y-%m-%d %H:%M:%S");
            syllabus.createdDate = templateJson.value("createdDate", ss.str());
            syllabus.lastModifiedDate = ss.str();
            
            syllabus.regulatoryFramework = templateJson.value("regulatoryFramework", "");
            
            // Modules
            if (templateJson.contains("modules") && templateJson["modules"].is_array()) {
                for (const auto& modJson : templateJson["modules"]) {
                    SyllabusModule module;
                    module.id = modJson.value("id", "");
                    module.title = modJson.value("title", "");
                    module.description = modJson.value("description
cmake_minimum_required(VERSION 3.20)
project(syllabus-generator-service VERSION 1.0.0 LANGUAGES CXX)

# Set C++20 standard
set(CMAKE_CXX_STANDARD 20)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

# Set output directories
set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)
set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin)

# Find required packages
find_package(gRPC REQUIRED)
find_package(Protobuf REQUIRED)
find_package(OpenSSL REQUIRED)
find_package(nlohmann_json 3.10.0 REQUIRED)
find_package(spdlog REQUIRED)
find_package(prometheus-cpp REQUIRED)
find_package(cpprestsdk REQUIRED)
find_package(Boost REQUIRED COMPONENTS system filesystem)
find_package(TBB REQUIRED)
find_package(ICU REQUIRED COMPONENTS uc i18n)

# Include directories
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}/include
    ${CMAKE_CURRENT_BINARY_DIR}/generated
)

# Generate protobuf and gRPC code
set(PROTO_FILES
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/syllabus_generator.proto
    ${CMAKE_CURRENT_SOURCE_DIR}/proto/core_service.proto
)

protobuf_generate_cpp(PROTO_SRCS PROTO_HDRS ${PROTO_FILES})
grpc_generate_cpp(GRPC_SRCS GRPC_HDRS ${CMAKE_CURRENT_BINARY_DIR}/generated ${PROTO_FILES})

# Source files
file(GLOB_RECURSE SOURCES 
    ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp
)

# Add executable
add_executable(${PROJECT_NAME} ${SOURCES} ${PROTO_SRCS} ${PROTO_HDRS} ${GRPC_SRCS} ${GRPC_HDRS})

# Link libraries
target_link_libraries(${PROJECT_NAME}
    PRIVATE
    gRPC::grpc++
    gRPC::grpc++_reflection
    protobuf::libprotobuf
    OpenSSL::SSL
    OpenSSL::Crypto
    nlohmann_json::nlohmann_json
    spdlog::spdlog
    prometheus-cpp::core
    prometheus-cpp::push
    cpprestsdk::cpprest
    Boost::system
    Boost::filesystem
    TBB::tbb
    ICU::uc
    ICU::i18n
    pthread
)

# Copy configuration files to build directory
configure_file(
    ${CMAKE_CURRENT_SOURCE_DIR}/config/config.json
    ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}/config/config.json
    COPYONLY
)

# Add tests
enable_testing()
add_subdirectory(tests)

# Installation
install(TARGETS ${PROJECT_NAME}
    RUNTIME DESTINATION bin
    LIBRARY DESTINATION lib
    ARCHIVE DESTINATION lib
)

install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/config/
    DESTINATION etc/${PROJECT_NAME}
    FILES_MATCHING PATTERN "*.json"
)

# Documentation
find_package(Doxygen)
if(DOXYGEN_FOUND)
    set(DOXYGEN_IN ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in)
    set(DOXYGEN_OUT ${CMAKE_CURRENT_BINARY_DIR}/Doxyfile)
    
    configure_file(${DOXYGEN_IN} ${DOXYGEN_OUT} @ONLY)
    
    add_custom_target(docs
        COMMAND ${DOXYGEN_EXECUTABLE} ${DOXYGEN_OUT}
        WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}
        COMMENT "Generating API documentation with Doxygen"
        VERBATIM
    )
endif()
syntax = "proto3";

package syllabusgen;

// Service definition for syllabus generator
service SyllabusGeneratorService {
  // Generate a syllabus from documents
  rpc GenerateSyllabus (GenerateSyllabusRequest) returns (SyllabusResponse);
  
  // Extract training content from documents
  rpc ExtractTrainingContent (ExtractContentRequest) returns (ContentResponse);
  
  // Generate syllabus structure
  rpc GenerateSyllabusStructure (StructureRequest) returns (StructureResponse);
  
  // Validate syllabus against regulatory requirements
  rpc ValidateSyllabusCompliance (ValidationRequest) returns (ValidationResponse);
  
  // Manage syllabus templates
  rpc CreateTemplate (TemplateRequest) returns (TemplateResponse);
  rpc GetTemplate (GetTemplateRequest) returns (TemplateResponse);
  rpc UpdateTemplate (TemplateRequest) returns (TemplateResponse);
  rpc DeleteTemplate (DeleteTemplateRequest) returns (DeleteTemplateResponse);
  rpc ListTemplates (ListTemplatesRequest) returns (ListTemplatesResponse);
  
  // Analyze compliance impact of modifications
  rpc AnalyzeComplianceImpact (ImpactAnalysisRequest) returns (ImpactAnalysisResponse);
}

// Request to generate a syllabus
message GenerateSyllabusRequest {
  string course_id = 1;
  string title = 2;
  string description = 3;
  string author_id = 4;
  repeated string document_ids = 5;
  string template_id = 6;
  string regulation_id = 7;
  map<string, string> metadata = 8;
}

// Response containing generated syllabus
message SyllabusResponse {
  bool success = 1;
  string syllabus_id = 2;
  string error_message = 3;
  string syllabus_json = 4;
  repeated string warnings = 5;
}

// Request to extract training content
message ExtractContentRequest {
  repeated string document_ids = 1;
  repeated string content_types = 2;  // "objectives", "procedures", "references", etc.
}

// Response with extracted content
message ContentResponse {
  bool success = 1;
  repeated ContentItem items = 2;
  string error_message = 3;
  map<string, double> confidence_scores = 4;
}

// Content item extracted from documents
message ContentItem {
  string content_id = 1;
  string content_type = 2;  // "objective", "procedure", "reference", etc.
  string text = 3;
  string source_document_id = 4;
  int32 page_number = 5;
  double confidence_score = 6;
  repeated string keywords = 7;
  string parent_id = 8;  // For hierarchical content
  int32 sequence_number = 9;
  map<string, string> metadata = 10;
}

// Request to generate syllabus structure
message StructureRequest {
  repeated ContentItem content_items = 1;
  string template_id = 2;
  string regulation_id = 3;
}

// Response with syllabus structure
message StructureResponse {
  bool success = 1;
  repeated StructureSection sections = 2;
  string error_message = 3;
}

// Syllabus structure section
message StructureSection {
  string section_id = 1;
  string title = 2;
  string description = 3;
  int32 order = 4;
  repeated StructureExercise exercises = 5;
  map<string, string> metadata = 6;
}

// Syllabus structure exercise
message StructureExercise {
  string exercise_id = 1;
  string title = 2;
  string description = 3;
  int32 order = 4;
  int32 duration_minutes = 5;
  string exercise_type = 6;  // "ground", "simulator", "flight", etc.
  repeated string objectives = 7;
  repeated string references = 8;
  repeated string equipment = 9;
  repeated GradingCriteria grading_criteria = 10;
  repeated string prerequisite_exercises = 11;
  map<string, string> metadata = 12;
}

// Grading criteria
message GradingCriteria {
  string criteria_id = 1;
  string name = 2;
  string description = 3;
  repeated GradeDefinition grade_definitions = 4;
  bool is_required = 5;
  map<string, string> regulation_references = 6;
}

// Grade definition
message GradeDefinition {
  int32 grade = 1;  // 1-4 scale
  string description = 2;
  bool is_passing = 3;
}

// Request to validate syllabus compliance
message ValidationRequest {
  string syllabus_json = 1;
  string regulation_id = 2;
}

// Response with validation results
message ValidationResponse {
  bool is_compliant = 1;
  repeated ComplianceIssue issues = 2;
  double compliance_percentage = 3;
  repeated RegulatoryRequirement covered_requirements = 4;
  repeated RegulatoryRequirement missing_requirements = 5;
}

// Compliance issue
message ComplianceIssue {
  string issue_id = 1;
  string requirement_id = 2;
  string requirement_name = 3;
  string element_id = 4;
  string element_type = 5;  // "section", "exercise", "criteria", etc.
  string severity = 6;  // "critical", "warning", "info"
  string description = 7;
  string suggested_fix = 8;
}

// Regulatory requirement
message RegulatoryRequirement {
  string requirement_id = 1;
  string name = 2;
  string regulation_id = 3;
  string reference = 4;
  string description = 5;
}

// Request to create/update template
message TemplateRequest {
  string template_id = 1;  // Optional for creation
  string name = 2;
  string description = 3;
  string author_id = 4;
  SyllabusTemplate template = 5;
}

// Response with template
message TemplateResponse {
  bool success = 1;
  string template_id = 2;
  string error_message = 3;
  SyllabusTemplate template = 4;
}

// Request to get template
message GetTemplateRequest {
  string template_id = 1;
}

// Request to delete template
message DeleteTemplateRequest {
  string template_id = 1;
}

// Response to delete template
message DeleteTemplateResponse {
  bool success = 1;
  string error_message = 2;
}

// Request to list templates
message ListTemplatesRequest {
  string author_id = 1;  // Optional
  int32 page = 2;
  int32 page_size = 3;
}

// Response with template list
message ListTemplatesResponse {
  bool success = 1;
  repeated TemplateSummary templates = 2;
  int32 total_count = 3;
  string error_message = 4;
}

// Template summary
message TemplateSummary {
  string template_id = 1;
  string name = 2;
  string description = 3;
  string author_id = 4;
  int64 created_at = 5;  // Milliseconds since epoch
  int64 updated_at = 6;  // Milliseconds since epoch
}

// Syllabus template
message SyllabusTemplate {
  string template_id = 1;
  string name = 2;
  string description = 3;
  string author_id = 4;
  repeated TemplateSectionSchema sections = 5;
  map<string, string> metadata = 6;
  int64 created_at = 7;  // Milliseconds since epoch
  int64 updated_at = 8;  // Milliseconds since epoch
}

// Template section schema
message TemplateSectionSchema {
  string section_id = 1;
  string title = 2;
  string description = 3;
  bool required = 4;
  int32 min_exercises = 5;
  int32 max_exercises = 6;
  repeated TemplateExerciseSchema exercise_schemas = 7;
}

// Template exercise schema
message TemplateExerciseSchema {
  string exercise_id = 1;
  string title = 2;
  string description = 3;
  bool required = 4;
  repeated string allowed_exercise_types = 5;
  int32 min_duration_minutes = 6;
  int32 max_duration_minutes = 7;
  int32 min_objectives = 8;
  int32 max_objectives = 9;
  repeated TemplateCriteriaSchema criteria_schemas = 10;
}

// Template criteria schema
message TemplateCriteriaSchema {
  string criteria_id = 1;
  string name = 2;
  string description = 3;
  bool required = 4;
  bool requires_regulation_reference = 5;
}

// Request for impact analysis
message ImpactAnalysisRequest {
  string original_syllabus_json = 1;
  string modified_syllabus_json = 2;
  string regulation_id = 3;
}

// Response with impact analysis
message ImpactAnalysisResponse {
  bool success = 1;
  bool impacts_compliance = 2;
  double compliance_change_percentage = 3;
  repeated ComplianceIssue new_issues = 4;
  repeated ComplianceIssue resolved_issues = 5;
  repeated string affected_requirements = 6;
  string summary = 7;
  string error_message = 8;
}
#include <drogon/drogon.h>
#include <json/json.h>
#include <memory>
#include <string>
#include <vector>
#include <unordered_map>
#include "syllabus_repository.h"
#include "regulatory_compliance.h"
#include "version_manager.h"

namespace atp {
namespace syllabus {

class SyllabusTemplateSystem : public drogon::HttpController<SyllabusTemplateSystem> {
public:
    METHOD_LIST_BEGIN
    ADD_METHOD_TO(SyllabusTemplateSystem::getTemplates, "/api/syllabus/templates", drogon::Get);
    ADD_METHOD_TO(SyllabusTemplateSystem::getTemplate, "/api/syllabus/templates/{id}", drogon::Get);
    ADD_METHOD_TO(SyllabusTemplateSystem::createTemplate, "/api/syllabus/templates", drogon::Post);
    ADD_METHOD_TO(SyllabusTemplateSystem::updateTemplate, "/api/syllabus/templates/{id}", drogon::Put);
    ADD_METHOD_TO(SyllabusTemplateSystem::analyzeImpact, "/api/syllabus/templates/{id}/impact", drogon::Post);
    ADD_METHOD_TO(SyllabusTemplateSystem::applyTemplate, "/api/syllabus/apply-template", drogon::Post);
    ADD_METHOD_TO(SyllabusTemplateSystem::compareVersions, "/api/syllabus/templates/{id}/versions/compare", drogon::Get);
    ADD_METHOD_TO(SyllabusTemplateSystem::trackEvolution, "/api/syllabus/templates/{id}/evolution", drogon::Get);
    METHOD_LIST_END

    SyllabusTemplateSystem();

    void getTemplates(const drogon::HttpRequestPtr& req, 
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void getTemplate(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& id);
    
    void createTemplate(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void updateTemplate(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id);
    
    void analyzeImpact(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                       const std::string& id);
    
    void applyTemplate(const drogon::HttpRequestPtr& req,
                       std::function<void(const drogon::HttpResponsePtr&)>&& callback);
    
    void compareVersions(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id);
    
    void trackEvolution(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id);

private:
    std::shared_ptr<SyllabusRepository> syllabusRepo_;
    std::shared_ptr<RegulatoryCompliance> regulatoryCompliance_;
    std::shared_ptr<VersionManager> versionManager_;
    
    // Template categories
    std::unordered_map<std::string, std::string> templateCategories_;
    
    // Helper methods
    Json::Value validateTemplateStructure(const Json::Value& template_);
    Json::Value mergeWithBase(const Json::Value& template_, const std::string& baseTemplateId);
    Json::Value applyCustomizations(const Json::Value& template_, const Json::Value& customizations);
    Json::Value getTemplateDependencies(const std::string& templateId);
};

SyllabusTemplateSystem::SyllabusTemplateSystem() {
    // Initialize components
    syllabusRepo_ = std::make_shared<SyllabusRepository>();
    regulatoryCompliance_ = std::make_shared<RegulatoryCompliance>();
    versionManager_ = std::make_shared<VersionManager>();
    
    // Initialize template categories
    templateCategories_["joc_mcc"] = "Joint Operations Course / Multi-Crew Cooperation";
    templateCategories_["initial_type"] = "Initial Type Rating";
    templateCategories_["recurrent"] = "Recurrent Training";
    templateCategories_["instructor"] = "Instructor Training";
    templateCategories_["line_training"] = "Line Training";
    templateCategories_["conversion"] = "Conversion Course";
}

void SyllabusTemplateSystem::getTemplates(const drogon::HttpRequestPtr& req, 
                    std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    // Extract query parameters
    auto params = req->getParameters();
    std::string category = params.find("category") != params.end() ? params["category"] : "";
    std::string regulationType = params.find("regulation") != params.end() ? params["regulation"] : "";
    
    // Get templates from repository
    auto templates = syllabusRepo_->getTemplates(category, regulationType);
    
    // Add category information
    for (auto& template_ : templates) {
        std::string templateCategory = template_["category"].asString();
        if (templateCategories_.find(templateCategory) != templateCategories_.end()) {
            template_["category_name"] = templateCategories_[templateCategory];
        }
    }
    
    // Prepare response
    Json::Value result;
    result["templates"] = templates;
    result["total"] = templates.size();
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    callback(resp);
}

void SyllabusTemplateSystem::getTemplate(const drogon::HttpRequestPtr& req,
                   std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                   const std::string& id) {
    // Get template from repository
    auto template_ = syllabusRepo_->getTemplate(id);
    
    if (template_.isNull()) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k404NotFound);
        resp->setBody("Template not found");
        callback(resp);
        return;
    }
    
    // Add version history
    template_["versions"] = versionManager_->getVersionHistory(id);
    
    // Add dependencies
    template_["dependencies"] = getTemplateDependencies(id);
    
    // Add regulatory compliance status
    template_["compliance"] = regulatoryCompliance_->checkCompliance(template_);
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(template_);
    callback(resp);
}

void SyllabusTemplateSystem::createTemplate(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    // Validate template structure
    auto validationResult = validateTemplateStructure(*json);
    if (!validationResult["valid"].asBool()) {
        auto resp = drogon::HttpResponse::newHttpJsonResponse(validationResult);
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    // Check if based on another template
    std::string baseTemplateId = (*json)["base_template_id"].asString();
    Json::Value finalTemplate = *json;
    
    if (!baseTemplateId.empty()) {
        // Merge with base template
        finalTemplate = mergeWithBase(finalTemplate, baseTemplateId);
    }
    
    // Add metadata
    finalTemplate["created_at"] = drogon::utils::getFormattedDate();
    finalTemplate["version"] = "1.0";
    
    // Save template
    std::string templateId = syllabusRepo_->createTemplate(finalTemplate);
    
    // Create initial version
    versionManager_->createVersion(templateId, "1.0", "Initial creation", finalTemplate);
    
    // Check regulatory compliance
    auto compliance = regulatoryCompliance_->checkCompliance(finalTemplate);
    
    // Prepare response
    Json::Value result;
    result["template_id"] = templateId;
    result["version"] = "1.0";
    result["compliance"] = compliance;
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    resp->setStatusCode(drogon::k201Created);
    callback(resp);
}

void SyllabusTemplateSystem::updateTemplate(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                      const std::string& id) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    // Get existing template
    auto existingTemplate = syllabusRepo_->getTemplate(id);
    if (existingTemplate.isNull()) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k404NotFound);
        resp->setBody("Template not found");
        callback(resp);
        return;
    }
    
    // Validate template structure
    auto validationResult = validateTemplateStructure(*json);
    if (!validationResult["valid"].asBool()) {
        auto resp = drogon::HttpResponse::newHttpJsonResponse(validationResult);
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    // Get current version
    std::string currentVersion = existingTemplate["version"].asString();
    
    // Increment version
    std::string newVersion;
    std::string changeMessage = (*json)["change_message"].asString();
    
    if (changeMessage.empty()) {
        changeMessage = "Updated template";
    }
    
    // Simple version incrementing (would be more sophisticated in production)
    int majorVersion = std::stoi(currentVersion.substr(0, currentVersion.find('.')));
    int minorVersion = std::stoi(currentVersion.substr(currentVersion.find('.')+1));
    
    if ((*json)["major_update"].asBool()) {
        majorVersion++;
        minorVersion = 0;
    } else {
        minorVersion++;
    }
    
    newVersion = std::to_string(majorVersion) + "." + std::to_string(minorVersion);
    
    // Update template
    Json::Value updatedTemplate = *json;
    updatedTemplate["version"] = newVersion;
    updatedTemplate["updated_at"] = drogon::utils::getFormattedDate();
    
    // Save template
    syllabusRepo_->updateTemplate(id, updatedTemplate);
    
    // Create new version
    versionManager_->createVersion(id, newVersion, changeMessage, updatedTemplate);
    
    // Check regulatory compliance
    auto compliance = regulatoryCompliance_->checkCompliance(updatedTemplate);
    
    // Prepare response
    Json::Value result;
    result["template_id"] = id;
    result["version"] = newVersion;
    result["previous_version"] = currentVersion;
    result["compliance"] = compliance;
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    callback(resp);
}

void SyllabusTemplateSystem::analyzeImpact(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                     const std::string& id) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    // Get existing template
    auto existingTemplate = syllabusRepo_->getTemplate(id);
    if (existingTemplate.isNull()) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k404NotFound);
        resp->setBody("Template not found");
        callback(resp);
        return;
    }
    
    // Analyze impact of proposed changes
    Json::Value changes = *json;
    
    // Apply changes to create a proposed template
    Json::Value proposedTemplate = existingTemplate;
    
    if (changes.isMember("modules")) {
        proposedTemplate["modules"] = changes["modules"];
    }
    
    if (changes.isMember("metadata")) {
        for (const auto& key : changes["metadata"].getMemberNames()) {
            proposedTemplate["metadata"][key] = changes["metadata"][key];
        }
    }
    
    // Compare compliance between existing and proposed template
    auto existingCompliance = regulatoryCompliance_->checkCompliance(existingTemplate);
    auto proposedCompliance = regulatoryCompliance_->checkCompliance(proposedTemplate);
    
    // Identify changes in compliance
    Json::Value complianceChanges;
    complianceChanges["before"] = existingCompliance;
    complianceChanges["after"] = proposedCompliance;
    
    // Calculate compliance impact statistics
    int totalReqsBefore = existingCompliance["requirements_total"].asInt();
    int metReqsBefore = existingCompliance["requirements_met"].asInt();
    
    int totalReqsAfter = proposedCompliance["requirements_total"].asInt();
    int metReqsAfter = proposedCompliance["requirements_met"].asInt();
    
    double compliancePercentBefore = (double)metReqsBefore / totalReqsBefore * 100.0;
    double compliancePercentAfter = (double)metReqsAfter / totalReqsAfter * 100.0;
    
    complianceChanges["compliance_before_percent"] = compliancePercentBefore;
    complianceChanges["compliance_after_percent"] = compliancePercentAfter;
    complianceChanges["compliance_change_percent"] = compliancePercentAfter - compliancePercentBefore;
    
    // Identify affected items
    Json::Value affectedItems;
    
    // Example: analyze which modules and lessons are affected by changes
    // This would be more sophisticated in a real implementation
    if (changes.isMember("modules")) {
        for (const auto& module : changes["modules"]) {
            std::string moduleId = module["id"].asString();
            
            // Find corresponding module in existing template
            bool moduleExists = false;
            for (const auto& existingModule : existingTemplate["modules"]) {
                if (existingModule["id"].asString() == moduleId) {
                    moduleExists = true;
                    
                    // Compare and identify changes
                    Json::Value moduleChanges;
                    moduleChanges["id"] = moduleId;
                    moduleChanges["title"] = module["title"].asString();
                    
                    // Identify lesson changes
                    if (module.isMember("lessons") && existingModule.isMember("lessons")) {
                        Json::Value lessonChanges;
                        
                        for (const auto& lesson : module["lessons"]) {
                            std::string lessonId = lesson["id"].asString();
                            
                            // Find corresponding lesson
                            bool lessonExists = false;
                            for (const auto& existingLesson : existingModule["lessons"]) {
                                if (existingLesson["id"].asString() == lessonId) {
                                    lessonExists = true;
                                    
                                    // Check if lesson changed
                                    if (lesson.toStyledString() != existingLesson.toStyledString()) {
                                        lessonChanges.append(lessonId);
                                    }
                                    
                                    break;
                                }
                            }
                            
                            // New lesson
                            if (!lessonExists) {
                                lessonChanges.append(lessonId + " (new)");
                            }
                        }
                        
                        // Check for removed lessons
                        for (const auto& existingLesson : existingModule["lessons"]) {
                            std::string lessonId = existingLesson["id"].asString();
                            
                            bool lessonExists = false;
                            for (const auto& lesson : module["lessons"]) {
                                if (lesson["id"].asString() == lessonId) {
                                    lessonExists = true;
                                    break;
                                }
                            }
                            
                            // Removed lesson
                            if (!lessonExists) {
                                lessonChanges.append(lessonId + " (removed)");
                            }
                        }
                        
                        if (lessonChanges.size() > 0) {
                            moduleChanges["lessons"] = lessonChanges;
                        }
                    }
                    
                    affectedItems.append(moduleChanges);
                    break;
                }
            }
            
            // New module
            if (!moduleExists) {
                Json::Value moduleChanges;
                moduleChanges["id"] = moduleId;
                moduleChanges["title"] = module["title"].asString();
                moduleChanges["status"] = "new";
                
                affectedItems.append(moduleChanges);
            }
        }
        
        // Check for removed modules
        for (const auto& existingModule : existingTemplate["modules"]) {
            std::string moduleId = existingModule["id"].asString();
            
            bool moduleExists = false;
            for (const auto& module : changes["modules"]) {
                if (module["id"].asString() == moduleId) {
                    moduleExists = true;
                    break;
                }
            }
            
            // Removed module
            if (!moduleExists) {
                Json::Value moduleChanges;
                moduleChanges["id"] = moduleId;
                moduleChanges["title"] = existingModule["title"].asString();
                moduleChanges["status"] = "removed";
                
                affectedItems.append(moduleChanges);
            }
        }
    }
    
    // Prepare response
    Json::Value result;
    result["template_id"] = id;
    result["current_version"] = existingTemplate["version"].asString();
    result["compliance_impact"] = complianceChanges;
    result["affected_items"] = affectedItems;
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    callback(resp);
}

void SyllabusTemplateSystem::applyTemplate(const drogon::HttpRequestPtr& req,
                     std::function<void(const drogon::HttpResponsePtr&)>&& callback) {
    auto json = req->getJsonObject();
    if (!json) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        callback(resp);
        return;
    }
    
    // Get template
    std::string templateId = (*json)["template_id"].asString();
    auto template_ = syllabusRepo_->getTemplate(templateId);
    
    if (template_.isNull()) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k404NotFound);
        resp->setBody("Template not found");
        callback(resp);
        return;
    }
    
    // Get customizations
    Json::Value customizations = (*json)["customizations"];
    
    // Apply customizations to template
    Json::Value customizedTemplate = applyCustomizations(template_, customizations);
    
    // Add metadata
    customizedTemplate["based_on_template"] = templateId;
    customizedTemplate["based_on_version"] = template_["version"].asString();
    customizedTemplate["created_at"] = drogon::utils::getFormattedDate();
    
    // Save as new syllabus or template based on request type
    std::string newId;
    if ((*json)["create_type"].asString() == "template") {
        // Save as new template
        customizedTemplate["name"] = (*json)["name"].asString();
        customizedTemplate["description"] = (*json)["description"].asString();
        customizedTemplate["version"] = "1.0";
        
        newId = syllabusRepo_->createTemplate(customizedTemplate);
        versionManager_->createVersion(newId, "1.0", "Created from template " + templateId, customizedTemplate);
    } else {
        // Save as syllabus
        customizedTemplate["name"] = (*json)["name"].asString();
        customizedTemplate["description"] = (*json)["description"].asString();
        
        newId = syllabusRepo_->createSyllabus(customizedTemplate);
    }
    
    // Check regulatory compliance
    auto compliance = regulatoryCompliance_->checkCompliance(customizedTemplate);
    
    // Prepare response
    Json::Value result;
    result["id"] = newId;
    result["based_on_template"] = templateId;
    result["based_on_version"] = template_["version"].asString();
    result["type"] = (*json)["create_type"].asString();
    result["compliance"] = compliance;
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    resp->setStatusCode(drogon::k201Created);
    callback(resp);
}

void SyllabusTemplateSystem::compareVersions(const drogon::HttpRequestPtr& req,
                        std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                        const std::string& id) {
    // Extract query parameters
    auto params = req->getParameters();
    std::string version1 = params.find("v1") != params.end() ? params["v1"] : "";
    std::string version2 = params.find("v2") != params.end() ? params["v2"] : "";
    
    if (version1.empty() || version2.empty()) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k400BadRequest);
        resp->setBody("Missing version parameters (v1, v2)");
        callback(resp);
        return;
    }
    
    // Get template versions
    auto templateV1 = versionManager_->getVersion(id, version1);
    auto templateV2 = versionManager_->getVersion(id, version2);
    
    if (templateV1.isNull() || templateV2.isNull()) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k404NotFound);
        resp->setBody("One or both template versions not found");
        callback(resp);
        return;
    }
    
    // Compare versions
    Json::Value differences;
    
    // Compare metadata
    Json::Value metadataDiff;
    for (const auto& key : templateV1["metadata"].getMemberNames()) {
        if (!templateV2["metadata"].isMember(key) || 
            templateV1["metadata"][key].toStyledString() != templateV2["metadata"][key].toStyledString()) {
            metadataDiff[key] = Json::Value(Json::objectValue);
            metadataDiff[key]["v1"] = templateV1["metadata"][key];
            metadataDiff[key]["v2"] = templateV2["metadata"].isMember(key) ? 
                                      templateV2["metadata"][key] : Json::Value(Json::nullValue);
        }
    }
    
    for (const auto& key : templateV2["metadata"].getMemberNames()) {
        if (!templateV1["metadata"].isMember(key)) {
            metadataDiff[key] = Json::Value(Json::objectValue);
            metadataDiff[key]["v1"] = Json::Value(Json::nullValue);
            metadataDiff[key]["v2"] = templateV2["metadata"][key];
        }
    }
    
    if (!metadataDiff.empty()) {
        differences["metadata"] = metadataDiff;
    }
    
    // Compare modules
    Json::Value modulesDiff;
    
    // Build module maps for easier comparison
    std::unordered_map<std::string, Json::Value> modulesV1;
    std::unordered_map<std::string, Json::Value> modulesV2;
    
    for (const auto& module : templateV1["modules"]) {
        modulesV1[module["id"].asString()] = module;
    }
    
    for (const auto& module : templateV2["modules"]) {
        modulesV2[module["id"].asString()] = module;
    }
    
    // Find changed and removed modules
    for (const auto& pair : modulesV1) {
        std::string moduleId = pair.first;
        Json::Value moduleV1 = pair.second;
        
        if (modulesV2.find(moduleId) != modulesV2.end()) {
            // Module exists in both versions, check for changes
            Json::Value moduleV2 = modulesV2[moduleId];
            
            if (moduleV1.toStyledString() != moduleV2.toStyledString()) {
                // Module changed
                Json::Value moduleDiff;
                moduleDiff["id"] = moduleId;
                moduleDiff["title_v1"] = moduleV1["title"];
                moduleDiff["title_v2"] = moduleV2["title"];
                
                // Check for lesson changes
                Json::Value lessonsDiff;
                
                // Build lesson maps
                std::unordered_map<std::string, Json::Value> lessonsV1;
                std::unordered_map<std::string, Json::Value> lessonsV2;
                
                for (const auto& lesson : moduleV1["lessons"]) {
                    lessonsV1[lesson["id"].asString()] = lesson;
                }
                
                for (const auto& lesson : moduleV2["lessons"]) {
                    lessonsV2[lesson["id"].asString()] = lesson;
                }
                
                // Compare lessons
                for (const auto& lessonPair : lessonsV1) {
                    std::string lessonId = lessonPair.first;
                    Json::Value lessonV1 = lessonPair.second;
                    
                    if (lessonsV2.find(lessonId) != lessonsV2.end()) {
                        // Lesson exists in both versions
                        Json::Value lessonV2 = lessonsV2[lessonId];
                        
                        if (lessonV1.toStyledString() != lessonV2.toStyledString()) {
                            // Lesson changed
                            Json::Value lessonDiff;
                            lessonDiff["id"] = lessonId;
                            lessonDiff["title_v1"] = lessonV1["title"];
                            lessonDiff["title_v2"] = lessonV2["title"];
                            lessonDiff["status"] = "changed";
                            
                            lessonsDiff[lessonId] = lessonDiff;
                        }
                    } else {
                        // Lesson removed in v2
                        Json::Value lessonDiff;
                        lessonDiff["id"] = lessonId;
                        lessonDiff["title"] = lessonV1["title"];
                        lessonDiff["status"] = "removed";
                        
                        lessonsDiff[lessonId] = lessonDiff;
                    }
                }
                
                // Find new lessons in v2
                for (const auto& lessonPair : lessonsV2) {
                    std::string lessonId = lessonPair.first;
                    
                    if (lessonsV1.find(lessonId) == lessonsV1.end()) {
                        // New lesson in v2
                        Json::Value lessonDiff;
                        lessonDiff["id"] = lessonId;
                        lessonDiff["title"] = lessonPair.second["title"];
                        lessonDiff["status"] = "added";
                        
                        lessonsDiff[lessonId] = lessonDiff;
                    }
                }
                
                if (!lessonsDiff.empty()) {
                    moduleDiff["lessons"] = lessonsDiff;
                }
                
                modulesDiff[moduleId] = moduleDiff;
            }
        } else {
            // Module removed in v2
            Json::Value moduleDiff;
            moduleDiff["id"] = moduleId;
            moduleDiff["title"] = moduleV1["title"];
            moduleDiff["status"] = "removed";
            
            modulesDiff[moduleId] = moduleDiff;
        }
    }
    
    // Find new modules in v2
    for (const auto& pair : modulesV2) {
        std::string moduleId = pair.first;
        
        if (modulesV1.find(moduleId) == modulesV1.end()) {
            // New module in v2
            Json::Value moduleDiff;
            moduleDiff["id"] = moduleId;
            moduleDiff["title"] = pair.second["title"];
            moduleDiff["status"] = "added";
            
            modulesDiff[moduleId] = moduleDiff;
        }
    }
    
    if (!modulesDiff.empty()) {
        differences["modules"] = modulesDiff;
    }
    
    // Compare compliance
    auto complianceV1 = regulatoryCompliance_->checkCompliance(templateV1);
    auto complianceV2 = regulatoryCompliance_->checkCompliance(templateV2);
    
    Json::Value complianceDiff;
    complianceDiff["v1"] = complianceV1;
    complianceDiff["v2"] = complianceV2;
    
    differences["compliance"] = complianceDiff;
    
    // Prepare response
    Json::Value result;
    result["template_id"] = id;
    result["version1"] = version1;
    result["version2"] = version2;
    result["differences"] = differences;
    result["has_differences"] = !differences.empty();
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    callback(resp);
}

void SyllabusTemplateSystem::trackEvolution(const drogon::HttpRequestPtr& req,
                      std::function<void(const drogon::HttpResponsePtr&)>&& callback,
                      const std::string& id) {
    // Get version history
    auto versionHistory = versionManager_->getVersionHistory(id);
    
    if (versionHistory.empty()) {
        auto resp = drogon::HttpResponse::newHttpResponse();
        resp->setStatusCode(drogon::k404NotFound);
        resp->setBody("Template not found or no version history available");
        callback(resp);
        return;
    }
    
    // Track evolution metrics
    Json::Value evolutionMetrics;
    
    // Size metrics
    Json::Value sizeMetrics;
    std::vector<int> moduleCountHistory;
    std::vector<int> lessonCountHistory;
    std::vector<std::string> versionLabels;
    
    // Compliance metrics
    Json::Value complianceMetrics;
    std::vector<double> complianceScoreHistory;
    
    // Effectiveness metrics (if available)
    Json::Value effectivenessMetrics;
    std::vector<double> effectivenessScoreHistory;
    
    // Calculate metrics for each version
    for (const auto& versionInfo : versionHistory) {
        std::string version = versionInfo["version"].asString();
        versionLabels.push_back(version);
        
        // Get version content
        auto versionContent = versionManager_->getVersion(id, version);
        
        // Size metrics
        int moduleCount = versionContent["modules"].size();
        moduleCountHistory.push_back(moduleCount);
        
        int lessonCount = 0;
        for (const auto& module : versionContent["modules"]) {
            lessonCount += module["lessons"].size();
        }
        lessonCountHistory.push_back(lessonCount);
        
        // Compliance metrics
        auto compliance = regulatoryCompliance_->checkCompliance(versionContent);
        double complianceScore = compliance["requirements_met"].asInt() * 100.0 / compliance["requirements_total"].asInt();
        complianceScoreHistory.push_back(complianceScore);
        
        // Effectiveness metrics (if available)
        // This would typically be calculated from training outcome data
        // For this example, we'll use a placeholder value
        effectivenessScoreHistory.push_back(0.0);
    }
    
    // Prepare metrics JSON
    for (size_t i = 0; i < versionLabels.size(); ++i) {
        Json::Value versionMetrics;
        versionMetrics["module_count"] = moduleCountHistory[i];
        versionMetrics["lesson_count"] = lessonCountHistory[i];
        versionMetrics["compliance_score"] = complianceScoreHistory[i];
        
        if (effectivenessScoreHistory[i] > 0) {
            versionMetrics["effectiveness_score"] = effectivenessScoreHistory[i];
        }
        
        sizeMetrics[versionLabels[i]] = versionMetrics;
    }
    
    evolutionMetrics["size"] = sizeMetrics;
    
    // Calculate trend analysis
    Json::Value trends;
    
    // Module count trend
    trends["module_count_trend"] = calculateTrend(moduleCountHistory);
    
    // Lesson count trend
    trends["lesson_count_trend"] = calculateTrend(lessonCountHistory);
    
    // Compliance score trend
    trends["compliance_score_trend"] = calculateTrend(complianceScoreHistory);
    
    evolutionMetrics["trends"] = trends;
    
    // Generate best practice recommendations
    Json::Value recommendations;
    
    // Check for potential issues based on metrics
    if (calculateTrend(moduleCountHistory) > 0.5) {
        recommendations.append("Template is growing rapidly in module count. Consider reviewing for potential redundancy.");
    }
    
    if (calculateTrend(complianceScoreHistory) < 0) {
        recommendations.append("Compliance score is trending downward. Review recent changes for regulatory alignment.");
    }
    
    // Add more recommendations (in a real implementation, these would be AI-generated)
    recommendations.append("Consider organizing modules into logical groups for improved navigation");
    recommendations.append("Ensure assessment criteria are clearly defined for each lesson");
    
    evolutionMetrics["recommendations"] = recommendations;
    
    // Prepare response
    Json::Value result;
    result["template_id"] = id;
    result["version_count"] = versionHistory.size();
    result["latest_version"] = versionLabels.back();
    result["first_version"] = versionLabels.front();
    result["evolution_metrics"] = evolutionMetrics;
    
    auto resp = drogon::HttpResponse::newHttpJsonResponse(result);
    callback(resp);
}

// Helper methods
Json::Value SyllabusTemplateSystem::validateTemplateStructure(const Json::Value& template_) {
    Json::Value result;
    result["valid"] = true;
    Json::Value errors;
    
    // Check for required fields
    if (!template_.isMember("name") || template_["name"].asString().empty()) {
        errors.append("Template name is required");
        result["valid"] = false;
    }
    
    if (!template_.isMember("category") || template_["category"].asString().empty()) {
        errors.append("Template category is required");
        result["valid"] = false;
    }
    
    if (!template_.isMember("modules") || !template_["modules"].isArray()) {
        errors.append("Modules array is required");
        result["valid"] = false;
    } else {
        // Validate modules
        for (int i = 0; i < template_["modules"].size(); ++i) {
            const auto& module = template_["modules"][i];
            
            if (!module.isMember("id") || module["id"].asString().empty()) {
                errors.append("Module at index " + std::to_string(i) + " is missing ID");
                result["valid"] = false;
            }
            
            if (!module.isMember("title") || module["title"].asString().empty()) {
                errors.append("Module at index " + std::to_string(i) + " is missing title");
                result["valid"] = false;
            }
            
            if (module.isMember("lessons") && module["lessons"].isArray()) {
                // Validate lessons
                for (int j = 0; j < module["lessons"].size(); ++j) {
                    const auto& lesson = module["lessons"][j];
                    
                    if (!lesson.isMember("id") || lesson["id"].asString().empty()) {
                        errors.append("Lesson at index " + std::to_string(j) + " in module " + 
                                     module["id"].asString() + " is missing ID");
                        result["valid"] = false;
                    }
                    
                    if (!lesson.isMember("title") || lesson["title"].asString().empty()) {
                        errors.append("Lesson at index " + std::to_string(j) + " in module " + 
                                     module["id"].asString() + " is missing title");
                        result["valid"] = false;
                    }
                }
            }
        }
    }
    
    if (!result["valid"].asBool()) {
        result["errors"] = errors;
    }
    
    return result;
}

Json::Value SyllabusTemplateSystem::mergeWithBase(const Json::Value& template_, const std::string& baseTemplateId) {
    // Get base template
    auto baseTemplate = syllabusRepo_->getTemplate(baseTemplateId);
    
    if (baseTemplate.isNull()) {
        // Return original template if base not found
        return template_;
    }
    
    // Create merged template
    Json::Value mergedTemplate = baseTemplate;
    
    // Override metadata
    if (template_.isMember("metadata")) {
        for (const auto& key : template_["metadata"].getMemberNames()) {
            mergedTemplate["metadata"][key] = template_["metadata"][key];
        }
    }
    
    // Override modules if provided
    if (template_.isMember("modules")) {
        mergedTemplate["modules"] = template_["modules"];
    }
    
    // Add derivation information
    mergedTemplate["derived_from"] = baseTemplateId;
    mergedTemplate["derived_from_version"] = baseTemplate["version"];
    
    // Override name and description
    if (template_.isMember("name")) {
        mergedTemplate["name"] = template_["name"];
    }
    
    if (template_.isMember("description")) {
        mergedTemplate["description"] = template_["description"];
    }
    
    return mergedTemplate;
}

Json::Value SyllabusTemplateSystem::applyCustomizations(const Json::Value& template_, const Json::Value& customizations) {
    // Create customized template
    Json::Value customizedTemplate = template_;
    
    // Apply metadata customizations
    if (customizations.isMember("metadata")) {
        for (const auto& key : customizations["metadata"].getMemberNames()) {
            customizedTemplate["metadata"][key] = customizations["metadata"][key];
        }
    }
    
    // Apply module customizations
    if (customizations.isMember("modules")) {
        // Convert template modules to map for easier access
        std::unordered_map<std::string, Json::Value> moduleMap;
        Json::Value newModules(Json::arrayValue);
        
        for (const auto& module : template_["modules"]) {
            moduleMap[module["id"].asString()] = module;
        }
        
        // Process module customizations
        for (const auto& moduleCustomization : customizations["modules"]) {
            std::string moduleId = moduleCustomization["id"].asString();
            
            if (moduleMap.find(moduleId) != moduleMap.end()) {
                // Module exists, apply customizations
                Json::Value customizedModule = moduleMap[moduleId];
                
                // Override module properties
                for (const auto& key : moduleCustomization.getMemberNames()) {
                    if (key != "id" && key != "lessons") {
                        customizedModule[key] = moduleCustomization[key];
                    }
                }
                
                // Apply lesson customizations
                if (moduleCustomization.isMember("lessons")) {
                    // Convert lessons to map
                    std::unordered_map<std::string, Json::Value> lessonMap;
                    Json::Value newLessons(Json::arrayValue);
                    
                    for (const auto& lesson : customizedModule["lessons"]) {
                        lessonMap[lesson["id"].asString()] = lesson;
                    }
                    
                    // Process lesson customizations
                    for (const auto& lessonCustomization : moduleCustomization["lessons"]) {
                        std::string lessonId = lessonCustomization["id"].asString();
                        
                        if (lessonMap.find(lessonId) != lessonMap.end()) {
                            // Lesson exists, apply customizations
                            Json::Value customizedLesson = lessonMap[lessonId];
                            
                            // Override lesson properties
                            for (const auto& key : lessonCustomization.getMemberNames()) {
                                if (key != "id") {
                                    customizedLesson[key] = lessonCustomization[key];
                                }
                            }
                            
                            newLessons.append(customizedLesson);
                            lessonMap.erase(lessonId);
                        } else {
                            // New lesson
                            newLessons.append(lessonCustomization);
                        }
                    }
                    
                    // Add remaining lessons
                    for (const auto& pair : lessonMap) {
                        newLessons.append(pair.second);
                    }
                    
                    customizedModule["lessons"] = newLessons;
                }
                
                newModules.append(customizedModule);
                moduleMap.erase(moduleId);
            } else {
                // New module
                newModules.append(moduleCustomization);
            }
        }
        
        // Add remaining modules
        for (const auto& pair : moduleMap) {
            newModules.append(pair.second);
        }
        
        customizedTemplate["modules"] = newModules;
    }
    
    return customizedTemplate;
}

Json::Value SyllabusTemplateSystem::getTemplateDependencies(const std::string& templateId) {
    // Get all templates that depend on this one
    auto dependencies = syllabusRepo_->getTemplateDependencies(templateId);
    
    Json::Value result;
    result["derived_templates"] = dependencies["derived_templates"];
    result["derived_syllabi"] = dependencies["derived_syllabi"];
    
    return result;
}

double SyllabusTemplateSystem::calculateTrend(const std::vector<int>& values) {
    if (values.size() < 2) {
        return 0.0;
    }
    
    double sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;
    
    for (size_t i = 0; i < values.size(); ++i) {
        double x = i;
        double y = values[i];
        
        sumX += x;
        sumY += y;
        sumXY += x * y;
        sumX2 += x * x;
    }
    
    double n = values.size();
    double slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
    
    // Normalize slope to -1 to 1 range
    double maxSlope = *std::max_element(values.begin(), values.end()) - *std::min_element(values.begin(), values.end());
    if (maxSlope > 0) {
        return slope / maxSlope;
    }
    
    return 0.0;
}

double SyllabusTemplateSystem::calculateTrend(const std::vector<double>& values) {
    if (values.size() < 2) {
        return 0.0;
    }
    
    double sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;
    
    for (size_t i = 0; i < values.size(); ++i) {
        double x = i;
        double y = values[i];
        
        sumX += x;
        sumY += y;
        sumXY += x * y;
        sumX2 += x * x;
    }
    
    double n = values.size();
    double slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
    
    // Normalize slope to -1 to 1 range
    double maxVal = *std::max_element(values.begin(), values.end());
    double minVal = *std::min_element(values.begin(), values.end());
    double maxSlope = maxVal - minVal;
    
    if (maxSlope > 0) {
        return slope / maxSlope;
    }
    
    return 0.0;
}

} // namespace syllabus
} // namespace atp

// Main application setup
int main() {
    // Configure Drogon app
    drogon::app().setLogPath("./")
                 .setLogLevel(trantor::Logger::kInfo)
                 .addListener("0.0.0.0", 8081)
                 .setThreadNum(16)
                 .run();
    
    return 0;
}

# Advanced Pilot Training Platform - System Architecture Overview

## 1. Architecture Summary

The Advanced Pilot Training Platform implements a microservice-based architecture with:

- High-performance C++ backends for data-intensive processing
- React frontends for user interfaces
- Shared PostgreSQL database with schema separation per service
- Centralized authentication and authorization via Core Platform Service
- Service-to-service communication via gRPC
- External API access via REST through API Gateway
- Monitoring stack with Prometheus and Grafana
- Containerized deployment with Docker and orchestration with docker-compose

## 2. Service Components

### Core Platform Service (`core-platform-service`)
- **Purpose**: Provides authentication, authorization, service discovery, and centralized logging
- **Key Features**:
  - JWT-based authentication with X.509 certificate support
  - Role-based access control with hierarchical permissions
  - Configuration management with environment overrides
  - gRPC communication between services
  - Distributed logging with ELK stack integration
  - Metrics collection for Prometheus

### Data Acquisition Service (`data-acquisition-service`)
- **Purpose**: Collects, processes, and distributes data from training devices
- **Key Features**:
  - Hardware device connectors (eye tracking, physiological monitors)
  - Simulator integration via ARINC 610D standard
  - Real-time data processing with <5ms latency
  - Multi-modal data fusion with Kalman filtering
  - Edge computing capability with offline sync

### Electronic Training Records Service (`etr-service`)
- **Purpose**: Manages training records, certifications, and regulatory compliance
- **Key Features**:
  - CRUD operations for training records with immutable audit logs
  - Digital signature system with X.509 certificate integration
  - Regulatory compliance mapper for FAA/EASA requirements
  - Syllabus version control with change tracking
  - REST API with OpenAPI specification

### AI & Analytics Engine (`ai-analytics-service`)
- **Purpose**: Provides machine learning models for performance assessment and prediction
- **Key Features**:
  - TensorFlow C++ integration for model inference
  - Cognitive state assessment models
  - Performance prediction models
  - Real-time analytics dashboard data services
  - Benchmarking system with statistical analysis

### Document Management Service (`document-service`)
- **Purpose**: Manages training materials, regulations, and procedure documents
- **Key Features**:
  - Document storage with content-addressable hashing
  - Parsers for PDF, DOCX, XLSX, HTML
  - Version control with delta compression
  - Full-text search with OCR integration
  - Document categorization with ML classification

### AI Syllabus Generator (`syllabus-generator-service`)
- **Purpose**: Generates and customizes training syllabi based on regulations and trainee needs
- **Key Features**:
  - NLP-based content extraction from training documents
  - Syllabus structure generation with logical sequencing
  - Regulatory requirement mapper
  - Template system with customization points
  - Compliance impact analyzer for modifications

### Assessment System (`assessment-service`)
- **Purpose**: Evaluates and tracks trainee performance and competency
- **Key Features**:
  - 1-4 scale grading with criteria-based assessment
  - Session status tracking with real-time updates
  - Compliance benchmarking against regulatory requirements
  - User feedback collection with analysis
  - Performance trend visualization

### API Gateway
- **Purpose**: Provides a unified REST API interface for external clients
- **Key Features**:
  - Authentication and authorization
  - Request routing to appropriate microservices
  - Response transformation
  - Rate limiting and throttling
  - API documentation with Swagger

### Frontend Applications
- **Purpose**: Provides user interfaces for different user roles
- **Key Features**:
  - Responsive web application with React 18+
  - Instructor tools with debriefing interfaces
  - Administrative dashboards with analytics visualizations
  - Trainee portals with personalized content
  - Syllabus builder with drag-and-drop interface

## 3. Inter-Service Communication

### Communication Patterns

1. **Synchronous Request-Response**: Used for direct service-to-service API calls via gRPC
2. **Asynchronous Messaging**: Used for events and background processing
3. **Database Sharing**: Each service has its own schema in a shared PostgreSQL database

### Authentication Flow

1. Client authenticates with Core Platform Service
2. Core Platform Service issues JWT token
3. Client includes token in requests to API Gateway
4. API Gateway validates token with Core Platform Service
5. API Gateway forwards authenticated requests to appropriate services
6. Services validate token with Core Platform Service

### Data Flow Examples

#### Training Session Recording
1. Data Acquisition Service collects real-time data from simulators and devices
2. Data is processed, filtered, and fused in real-time
3. Session data is stored in time-series database
4. ETR Service creates training record linked to session data
5. AI Analytics Service processes session data for performance metrics
6. Assessment Service generates preliminary grading based on metrics
7. Instructor reviews and finalizes assessment
8. Compliance checks are triggered against regulatory requirements

#### Syllabus Generation
1. Document Service extracts content from regulatory documents
2. AI Syllabus Generator creates draft syllabus based on regulations
3. Draft syllabus is reviewed and modified by training designers
4. Syllabus is approved and digitally signed
5. ETR Service links syllabus to training programs
6. Assessment Service configures grading criteria based on syllabus

## 4. Data Model

### Core Data Entities

1. **Users**: Trainees, instructors, administrators
2. **Training Records**: Session data, assessments, grades
3. **Syllabi**: Training programs, courses, exercises
4. **Compliance Requirements**: Regulatory mappings, certification requirements
5. **Documents**: Training materials, regulations, procedures
6. **Assessment Criteria**: Grading scales, competency definitions
7. **Session Data**: Raw and processed data from training sessions

### Database Organization

- PostgreSQL with TimescaleDB extension for time-series data
- Service-specific schemas:
  - `core`: Users, roles, permissions
  - `etr`: Training records, signatures, compliance
  - `acquisition`: Device data, session recordings
  - `analytics`: Performance metrics, predictions
  - `document`: Document metadata, categories
  - `syllabus`: Training programs, courses, exercises
  - `assessment`: Grading criteria, assessments

## 5. Security Architecture

### Authentication & Authorization

- X.509 certificate-based authentication for high-security operations
- JWT tokens with short expiry for session management
- Role-based access control with hierarchical permissions
- Fine-grained resource access control

### Data Protection

- AES-256 encryption for sensitive data at rest
- TLS 1.3 for all communications
- Digital signatures for training records and approvals
- Immutable audit logs for all changes

### API Security

- Rate limiting and throttling
- Input validation for all endpoints
- CSRF protection
- OWASP Top 10 mitigation

## 6. Deployment Architecture

### Container Structure

Each service is containerized with:
- Service executable
- Configuration
- Service-specific dependencies

### Infrastructure Components

- PostgreSQL database
- Prometheus monitoring
- Grafana dashboards
- API Gateway
- Load balancer

### Scaling Considerations

- Stateless services for horizontal scaling
- Database connection pooling
- Caching for frequently accessed data
- Background processing for compute-intensive tasks

## 7. Monitoring & Observability

### Metrics Collection

- Service-level metrics (requests, latency, errors)
- Business metrics (users, sessions, compliance)
- System metrics (CPU, memory, disk, network)

### Logging Strategy

- Structured logging with correlation IDs
- Centralized log aggregation
- Log level configuration per service
- Audit logging for security events

### Alerting Configuration

- Service health alerts
- Performance degradation alerts
- Security event alerts
- Business metric anomaly alerts
import { EventEmitter } from 'events';
import { v4 as uuidv4 } from 'uuid';
import { RetryStrategy, WorkflowTask, TaskStatus, WorkflowDefinition, 
         WorkflowInstance, TaskDefinition, WorkflowEvent, 
         ConditionalExpression, TaskResult } from '../models/workflow.types';
import { NotificationService } from '../services/notification.service';
import { ExternalApiService } from '../services/external-api.service';
import { Logger } from '../utils/logger';

/**
 * Workflow Engine for configurable document processing pipelines
 * Provides event-driven task execution with conditional paths and retry mechanisms
 */
export class WorkflowEngine {
  private workflowDefinitions: Map<string, WorkflowDefinition>;
  private workflowInstances: Map<string, WorkflowInstance>;
  private eventEmitter: EventEmitter;
  private notificationService: NotificationService;
  private externalApiService: ExternalApiService;
  private logger: Logger;

  constructor(
    notificationService: NotificationService,
    externalApiService: ExternalApiService,
    logger: Logger
  ) {
    this.workflowDefinitions = new Map();
    this.workflowInstances = new Map();
    this.eventEmitter = new EventEmitter();
    this.notificationService = notificationService;
    this.externalApiService = externalApiService;
    this.logger = logger;
    
    // Set up event listeners
    this.setupEventListeners();
  }

  /**
   * Register a new workflow definition
   */
  registerWorkflow(definition: WorkflowDefinition): string {
    const workflowId = definition.id || uuidv4();
    
    // Validate workflow definition
    this.validateWorkflowDefinition(definition);
    
    // Store with validated ID
    const validatedDefinition = { 
      ...definition, 
      id: workflowId 
    };
    
    this.workflowDefinitions.set(workflowId, validatedDefinition);
    this.logger.info(`Workflow definition registered: ${workflowId}`);
    
    return workflowId;
  }

  /**
   * Start a workflow instance based on a registered definition
   */
  async startWorkflow(
    definitionId: string, 
    initialData: Record<string, any> = {}
  ): Promise<string> {
    const definition = this.workflowDefinitions.get(definitionId);
    
    if (!definition) {
      throw new Error(`Workflow definition not found: ${definitionId}`);
    }
    
    const instanceId = uuidv4();
    
    // Create workflow instance
    const instance: WorkflowInstance = {
      id: instanceId,
      definitionId,
      status: 'running',
      currentTasks: [],
      completedTasks: [],
      failedTasks: [],
      data: { ...initialData },
      startTime: new Date(),
      endTime: null,
      auditLog: [{
        timestamp: new Date(),
        event: 'workflow_started',
        details: { definitionId }
      }]
    };
    
    this.workflowInstances.set(instanceId, instance);
    
    // Find starting tasks (those with no dependencies)
    const startingTasks = definition.tasks.filter(task => 
      !task.dependsOn || task.dependsOn.length === 0
    );
    
    // Queue starting tasks for execution
    for (const taskDef of startingTasks) {
      await this.queueTask(instanceId, taskDef.id);
    }
    
    this.logger.info(`Workflow instance started: ${instanceId} (definition: ${definitionId})`);
    
    return instanceId;
  }

  /**
   * Pause a running workflow instance
   */
  pauseWorkflowInstance(instanceId: string): void {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    if (instance.status !== 'running') {
      throw new Error(`Cannot pause workflow in status: ${instance.status}`);
    }
    
    // Update status
    instance.status = 'paused';
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'workflow_paused',
      details: {}
    });
    
    this.logger.info(`Workflow instance paused: ${instanceId}`);
  }

  /**
   * Resume a paused workflow instance
   */
  async resumeWorkflowInstance(instanceId: string): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    if (instance.status !== 'paused') {
      throw new Error(`Cannot resume workflow in status: ${instance.status}`);
    }
    
    // Update status
    instance.status = 'running';
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'workflow_resumed',
      details: {}
    });
    
    // Re-queue current tasks
    for (const task of instance.currentTasks) {
      if (task.status === 'paused') {
        task.status = 'queued';
        await this.executeTask(instanceId, task.id);
      }
    }
    
    this.logger.info(`Workflow instance resumed: ${instanceId}`);
  }

  /**
   * Cancel a workflow instance
   */
  cancelWorkflowInstance(instanceId: string): void {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    if (instance.status === 'completed' || instance.status === 'failed' || instance.status === 'cancelled') {
      throw new Error(`Cannot cancel workflow in status: ${instance.status}`);
    }
    
    // Update status
    instance.status = 'cancelled';
    instance.endTime = new Date();
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'workflow_cancelled',
      details: {}
    });
    
    // Cancel all current tasks
    for (const task of instance.currentTasks) {
      if (task.status !== 'completed' && task.status !== 'failed') {
        task.status = 'cancelled';
        this.emitTaskEvent(instanceId, task.id, 'task_cancelled');
      }
    }
    
    this.logger.info(`Workflow instance cancelled: ${instanceId}`);
  }

  /**
   * Get workflow instance status and data
   */
  getWorkflowInstance(instanceId: string): WorkflowInstance | undefined {
    return this.workflowInstances.get(instanceId);
  }

  /**
   * Queue a task for execution
   */
  private async queueTask(instanceId: string, taskId: string): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    const definition = this.workflowDefinitions.get(instance.definitionId);
    
    if (!definition) {
      throw new Error(`Workflow definition not found: ${instance.definitionId}`);
    }
    
    const taskDef = definition.tasks.find(t => t.id === taskId);
    
    if (!taskDef) {
      throw new Error(`Task definition not found: ${taskId}`);
    }
    
    // Check if the task is already in the current tasks list
    const existingTask = instance.currentTasks.find(t => t.id === taskId);
    
    if (existingTask) {
      // Task is already queued or running
      return;
    }
    
    // If task has conditions, evaluate them
    if (taskDef.conditions && !this.evaluateConditions(taskDef.conditions, instance.data)) {
      // Conditions not met, skip this task
      this.logger.info(`Task conditions not met, skipping: ${taskId} in workflow ${instanceId}`);
      
      // Find and queue next tasks
      await this.queueNextTasks(instanceId, taskId);
      return;
    }
    
    // Create task instance
    const task: WorkflowTask = {
      id: taskId,
      status: 'queued',
      attempts: 0,
      startTime: null,
      endTime: null,
      error: null,
      result: null
    };
    
    // Add to current tasks
    instance.currentTasks.push(task);
    
    // Log task queued
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'task_queued',
      details: { taskId }
    });
    
    // Execute task if workflow is running
    if (instance.status === 'running') {
      await this.executeTask(instanceId, taskId);
    }
  }

  /**
   * Execute a queued task
   */
  private async executeTask(instanceId: string, taskId: string): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    if (instance.status !== 'running') {
      // Workflow is not running, don't execute task
      return;
    }
    
    const taskIndex = instance.currentTasks.findIndex(t => t.id === taskId);
    
    if (taskIndex === -1) {
      throw new Error(`Task not found in current tasks: ${taskId}`);
    }
    
    const task = instance.currentTasks[taskIndex];
    
    if (task.status !== 'queued') {
      // Task is not queued, don't execute
      return;
    }
    
    const definition = this.workflowDefinitions.get(instance.definitionId);
    
    if (!definition) {
      throw new Error(`Workflow definition not found: ${instance.definitionId}`);
    }
    
    const taskDef = definition.tasks.find(t => t.id === taskId);
    
    if (!taskDef) {
      throw new Error(`Task definition not found: ${taskId}`);
    }
    
    // Update task status
    task.status = 'running';
    task.startTime = new Date();
    task.attempts++;
    
    // Log task started
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'task_started',
      details: { taskId, attempt: task.attempts }
    });
    
    this.emitTaskEvent(instanceId, taskId, 'task_started');
    
    try {
      // Execute task
      let result: any;
      
      switch (taskDef.type) {
        case 'document_processing':
          result = await this.executeDocumentProcessingTask(taskDef, instance.data);
          break;
        case 'notification':
          result = await this.executeNotificationTask(taskDef, instance.data);
          break;
        case 'external_api':
          result = await this.executeExternalApiTask(taskDef, instance.data);
          break;
        case 'data_transformation':
          result = await this.executeDataTransformationTask(taskDef, instance.data);
          break;
        default:
          throw new Error(`Unsupported task type: ${taskDef.type}`);
      }
      
      // Update task status
      task.status = 'completed';
      task.endTime = new Date();
      task.result = result;
      
      // Update workflow data
      if (taskDef.outputDataMapping) {
        this.applyOutputDataMapping(taskDef.outputDataMapping, result, instance.data);
      }
      
      // Log task completed
      instance.auditLog.push({
        timestamp: new Date(),
        event: 'task_completed',
        details: { taskId }
      });
      
      this.emitTaskEvent(instanceId, taskId, 'task_completed');
      
      // Move task to completed tasks
      instance.currentTasks.splice(taskIndex, 1);
      instance.completedTasks.push(task);
      
      // Queue next tasks
      await this.queueNextTasks(instanceId, taskId);
      
      // Check if workflow is completed
      this.checkWorkflowCompletion(instanceId);
    } catch (error) {
      // Handle task failure
      await this.handleTaskFailure(instanceId, taskIndex, task, taskDef, error);
    }
  }

  /**
   * Handle task execution failure with retry mechanism
   */
  private async handleTaskFailure(
    instanceId: string,
    taskIndex: number,
    task: WorkflowTask,
    taskDef: TaskDefinition,
    error: any
  ): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      return;
    }
    
    // Update task with error
    task.error = {
      message: error.message || 'Unknown error',
      stack: error.stack,
      timestamp: new Date()
    };
    
    // Log task error
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'task_error',
      details: { 
        taskId: task.id, 
        attempt: task.attempts, 
        error: task.error.message 
      }
    });
    
    this.emitTaskEvent(instanceId, task.id, 'task_error');
    
    // Check if retry is possible
    const retryStrategy = taskDef.retryStrategy || { maxAttempts: 1, delay: 0 };
    
    if (task.attempts < retryStrategy.maxAttempts) {
      // Set status to retry
      task.status = 'retry';
      
      // Log retry scheduled
      instance.auditLog.push({
        timestamp: new Date(),
        event: 'task_retry_scheduled',
        details: { 
          taskId: task.id, 
          attempt: task.attempts, 
          nextAttempt: task.attempts + 1, 
          delay: retryStrategy.delay 
        }
      });
      
      // Schedule retry
      setTimeout(async () => {
        if (instance.status === 'running') {
          task.status = 'queued';
          await this.executeTask(instanceId, task.id);
        }
      }, retryStrategy.delay);
    } else {
      // Max retries reached, mark as failed
      task.status = 'failed';
      task.endTime = new Date();
      
      // Log task failed
      instance.auditLog.push({
        timestamp: new Date(),
        event: 'task_failed',
        details: { 
          taskId: task.id, 
          attempts: task.attempts 
        }
      });
      
      this.emitTaskEvent(instanceId, task.id, 'task_failed');
      
      // Move to failed tasks
      instance.currentTasks.splice(taskIndex, 1);
      instance.failedTasks.push(task);
      
      // Handle error based on task configuration
      if (taskDef.errorHandling === 'continue') {
        // Continue workflow despite failure
        await this.queueNextTasks(instanceId, task.id);
        this.checkWorkflowCompletion(instanceId);
      } else {
        // Fail the workflow
        instance.status = 'failed';
        instance.endTime = new Date();
        
        // Log workflow failed
        instance.auditLog.push({
          timestamp: new Date(),
          event: 'workflow_failed',
          details: { 
            reason: `Task failed: ${task.id}`,
            error: task.error?.message 
          }
        });
      }
    }
  }

  /**
   * Queue next tasks that depend on the completed task
   */
  private async queueNextTasks(instanceId: string, completedTaskId: string): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      return;
    }
    
    const definition = this.workflowDefinitions.get(instance.definitionId);
    
    if (!definition) {
      return;
    }
    
    // Find tasks that depend on the completed task
    const nextTasks = definition.tasks.filter(task => 
      task.dependsOn && task.dependsOn.includes(completedTaskId)
    );
    
    for (const nextTask of nextTasks) {
      // Check if all dependencies are completed
      const allDependenciesMet = nextTask.dependsOn?.every(depTaskId => {
        // Check if dependency is in completed tasks
        return instance.completedTasks.some(t => t.id === depTaskId);
      }) ?? true;
      
      if (allDependenciesMet) {
        // Queue the task
        await this.queueTask(instanceId, nextTask.id);
      }
    }
  }

  /**
   * Check if workflow is completed (no more tasks to execute)
   */
  private checkWorkflowCompletion(instanceId: string): void {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      return;
    }
    
    if (instance.status !== 'running') {
      // Workflow is not running, nothing to check
      return;
    }
    
    if (instance.currentTasks.length === 0) {
      // No more tasks, workflow is completed
      instance.status = 'completed';
      instance.endTime = new Date();
      
      // Log workflow completed
      instance.auditLog.push({
        timestamp: new Date(),
        event: 'workflow_completed',
        details: {
          totalTasks: instance.completedTasks.length + instance.failedTasks.length,
          failedTasks: instance.failedTasks.length
        }
      });
      
      this.emitWorkflowEvent(instanceId, 'workflow_completed');
    }
  }

  /**
   * Set up event listeners for the workflow engine
   */
  private setupEventListeners(): void {
    // Example event listeners
    this.eventEmitter.on('workflow_started', (event: WorkflowEvent) => {
      this.logger.info(`Workflow started: ${event.instanceId}`);
    });
    
    this.eventEmitter.on('workflow_completed', (event: WorkflowEvent) => {
      this.logger.info(`Workflow completed: ${event.instanceId}`);
    });
    
    this.eventEmitter.on('workflow_failed', (event: WorkflowEvent) => {
      this.logger.warn(`Workflow failed: ${event.instanceId}`, event.data);
    });
  }

  /**
   * Emit a task-related event
   */
  private emitTaskEvent(instanceId: string, taskId: string, eventType: string): void {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      return;
    }
    
    const task = [...instance.currentTasks, ...instance.completedTasks, ...instance.failedTasks]
      .find(t => t.id === taskId);
    
    if (!task) {
      return;
    }
    
    const event: WorkflowEvent = {
      eventType,
      instanceId,
      definitionId: instance.definitionId,
      taskId,
      timestamp: new Date(),
      data: {
        taskStatus: task.status,
        taskResult: task.result,
        taskError: task.error
      }
    };
    
    this.eventEmitter.emit(eventType, event);
  }

  /**
   * Emit a workflow-related event
   */
  private emitWorkflowEvent(instanceId: string, eventType: string): void {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      return;
    }
    
    const event: WorkflowEvent = {
      eventType,
      instanceId,
      definitionId: instance.definitionId,
      timestamp: new Date(),
      data: {
        status: instance.status,
        completedTasks: instance.completedTasks.length,
        failedTasks: instance.failedTasks.length
      }
    };
    
    this.eventEmitter.emit(eventType, event);
  }

  /**
   * Evaluate conditional expressions
   */
  private evaluateConditions(conditions: ConditionalExpression[], data: Record<string, any>): boolean {
    // Simple condition evaluator
    return conditions.every(condition => {
      const leftValue = this.resolveDataPath(condition.left, data);
      const rightValue = typeof condition.right === 'string' && condition.right.startsWith(') 
        ? this.resolveDataPath(condition.right, data) 
        : condition.right;
      
      switch (condition.operator) {
        case 'eq':
          return leftValue === rightValue;
        case 'neq':
          return leftValue !== rightValue;
        case 'gt':
          return leftValue > rightValue;
        case 'gte':
          return leftValue >= rightValue;
        case 'lt':
          return leftValue < rightValue;
        case 'lte':
          return leftValue <= rightValue;
        case 'contains':
          return String(leftValue).includes(String(rightValue));
        case 'startsWith':
          return String(leftValue).startsWith(String(rightValue));
        case 'endsWith':
          return String(leftValue).endsWith(String(rightValue));
        case 'exists':
          return leftValue !== undefined && leftValue !== null;
        default:
          return false;
      }
    });
  }

  /**
   * Apply output data mapping to workflow data
   */
  private applyOutputDataMapping(
    mapping: Record<string, string>, 
    taskResult: any, 
    data: Record<string, any>
  ): void {
    for (const [targetPath, sourcePath] of Object.entries(mapping)) {
      const value = this.resolveDataPath(sourcePath, taskResult);
      this.setDataAtPath(targetPath, value, data);
    }
  }

  /**
   * Execute specific task types
   */
  private async executeDocumentProcessingTask(
    taskDef: TaskDefinition, 
    data: Record<string, any>
  ): Promise<TaskResult> {
    // Implementation for document processing task
    // This would integrate with document processing services
    return { processed: true, status: 'success' };
  }

  private async executeNotificationTask(
    taskDef: TaskDefinition, 
    data: Record<string, any>
  ): Promise<TaskResult> {
    const templateId = taskDef.config?.templateId;
    const recipients = taskDef.config?.recipients;
    const resolvedRecipients = Array.isArray(recipients) 
      ? recipients.map(r => typeof r === 'string' && r.startsWith(') 
          ? this.resolveDataPath(r, data) 
          : r)
      : [];
    
    // Send notification using the notification service
    await this.notificationService.sendNotification({
      templateId,
      recipients: resolvedRecipients,
      data: this.prepareNotificationData(taskDef.config?.dataMapping, data)
    });
    
    return { sent: true, recipients: resolvedRecipients.length };
  }

  private async executeExternalApiTask(
    taskDef: TaskDefinition, 
    data: Record<string, any>
  ): Promise<TaskResult> {
    const endpoint = taskDef.config?.endpoint;
    const method = taskDef.config?.method || 'GET';
    const headers = taskDef.config?.headers || {};
    const resolvedHeaders: Record<string, string> = {};
    
    // Resolve header values from data
    for (const [key, value] of Object.entries(headers)) {
      resolvedHeaders[key] = typeof value === 'string' && value.startsWith(') 
        ? this.resolveDataPath(value, data) 
        : value;
    }
    
    // Prepare request body if applicable
    let body = undefined;
    if (taskDef.config?.body) {
      if (typeof taskDef.config.body === 'string' && taskDef.config.body.startsWith(')) {
        body = this.resolveDataPath(taskDef.config.body, data);
      } else if (taskDef.config.bodyMapping) {
        body = this.prepareApiRequestBody(taskDef.config.bodyMapping, data);
      } else {
        body = taskDef.config.body;
      }
    }
    
    // Call external API
    const response = await this.externalApiService.callExternalApi({
      endpoint,
      method,
      headers: resolvedHeaders,
      body
    });
    
    return response;
  }

  private async executeDataTransformationTask(
    taskDef: TaskDefinition, 
    data: Record<string, any>
  ): Promise<TaskResult> {
    // Implementation for data transformation task
    // This would apply transformations to workflow data
    const transformations = taskDef.config?.transformations || [];
    const result: Record<string, any> = {};
    
    for (const transformation of transformations) {
      switch (transformation.type) {
        case 'map':
          result[transformation.target] = this.mapTransformation(transformation, data);
          break;
        case 'filter':
          result[transformation.target] = this.filterTransformation(transformation, data);
          break;
        case 'reduce':
          result[transformation.target] = this.reduceTransformation(transformation, data);
          break;
        case 'format':
          result[transformation.target] = this.formatTransformation(transformation, data);
          break;
        default:
          throw new Error(`Unsupported transformation type: ${transformation.type}`);
      }
    }
    
    return result;
  }

  /**
   * Helper methods for data transformation
   */
  private mapTransformation(transformation: any, data: Record<string, any>): any {
    const source = this.resolveDataPath(transformation.source, data);
    
    if (!Array.isArray(source)) {
      throw new Error('Map transformation requires array source');
    }
    
    return source.map(item => {
      const result: Record<string, any> = {};
      
      for (const [key, path] of Object.entries(transformation.mapping)) {
        result[key] = this.resolveDataPath(path as string, item);
      }
      
      return result;
    });
  }

  private filterTransformation(transformation: any, data: Record<string, any>): any {
    const source = this.resolveDataPath(transformation.source, data);
    
    if (!Array.isArray(source)) {
      throw new Error('Filter transformation requires array source');
    }
    
    return source.filter(item => 
      this.evaluateConditions(transformation.conditions, item)
    );
  }

  private reduceTransformation(transformation: any, data: Record<string, any>): any {
    const source = this.resolveDataPath(transformation.source, data);
    
    if (!Array.isArray(source)) {
      throw new Error('Reduce transformation requires array source');
    }
    
    const initialValue = transformation.initialValue !== undefined 
      ? transformation.initialValue 
      : {};
    
    return source.reduce((acc, item) => {
      switch (transformation.operation) {
        case 'sum':
          return acc + (typeof item === 'number' ? item : 0);
        case 'concat':
          return Array.isArray(acc) ? [...acc, item] : [acc, item];
        case 'merge':
          return { ...acc, ...item };
        default:
          return acc;
      }
    }, initialValue);
  }

  private formatTransformation(transformation: any, data: Record<string, any>): any {
    const source = this.resolveDataPath(transformation.source, data);
    
    switch (transformation.format) {
      case 'string':
        return String(source);
      case 'number':
        return Number(source);
      case 'boolean':
        return Boolean(source);
      case 'date':
        return new Date(source);
      case 'json':
        return typeof source === 'string' ? JSON.parse(source) : source;
      case 'template':
        return this.applyTemplate(transformation.template, data);
      default:
        return source;
    }
  }

  /**
   * Helper methods for data access and manipulation
   */
  private resolveDataPath(path: string, data: any): any {
    if (!path.startsWith(')) {
      return path;
    }
    
    const parts = path.substring(1).split('.');
    let value = data;
    
    for (const part of parts) {
      if (value === undefined || value === null) {
        return undefined;
      }
      
      value = value[part];
    }
    
    return value;
  }

  private setDataAtPath(path: string, value: any, data: Record<string, any>): void {
    const parts = path.split('.');
    let current = data;
    
    for (let i = 0; i < parts.length - 1; i++) {
      const part = parts[i];
      
      if (!(part in current)) {
        current[part] = {};
      }
      
      current = current[part];
    }
    
    current[parts[parts.length - 1]] = value;
  }

  private prepareNotificationData(
    mapping: Record<string, string> | undefined, 
    data: Record<string, any>
  ): Record<string, any> {
    if (!mapping) {
      return data;
    }
    
    const result: Record<string, any> = {};
    
    for (const [key, path] of Object.entries(mapping)) {
      result[key] = this.resolveDataPath(path, data);
    }
    
    return result;
  }

  private prepareApiRequestBody(
    mapping: Record<string, string> | undefined, 
    data: Record<string, any>
  ): Record<string, any> {
    if (!mapping) {
      return data;
    }
    
    const result: Record<string, any> = {};
    
    for (const [key, path] of Object.entries(mapping)) {
      result[key] = this.resolveDataPath(path, data);
    }
    
    return result;
  }

  private applyTemplate(template: string, data: Record<string, any>): string {
    return template.replace(/\${([^}]+)}/g, (match, path) => {
      const value = this.resolveDataPath(`${path}`, data);
      return value !== undefined ? String(value) : match;
    });
  }

  /**
   * Validate a workflow definition
   */
  private validateWorkflowDefinition(definition: WorkflowDefinition): void {
    // Check for required fields
    if (!definition.name) {
      throw new Error('Workflow definition must have a name');
    }
    
    if (!definition.tasks || !Array.isArray(definition.tasks) || definition.tasks.length === 0) {
      throw new Error('Workflow definition must have at least one task');
    }
    
    // Check that all tasks have unique IDs
    const taskIds = new Set<string>();
    
    for (const task of definition.tasks) {
      if (!task.id) {
        throw new Error('All tasks must have an ID');
      }
      
      if (taskIds.has(task.id)) {
        throw new Error(`Duplicate task ID found: ${task.id}`);
      }
      
      taskIds.add(task.id);
    }
    
    // Check that all task dependencies exist
    for (const task of definition.tasks) {
      if (task.dependsOn) {
        for (const depTaskId of task.dependsOn) {
          if (!taskIds.has(depTaskId)) {
            throw new Error(`Task ${task.id} depends on non-existent task: ${depTaskId}`);
          }
        }
      }
    }
    
    // Check for cycles in the task dependencies
    this.checkForCycles(definition.tasks);
  }

  /**
   * Check for cycles in task dependencies
   */
  private checkForCycles(tasks: TaskDefinition[]): void {
    const visited = new Set<string>();
    const recursionStack = new Set<string>();
    
    for (const task of tasks) {
      if (!visited.has(task.id)) {
        if (this.isCyclicUtil(task.id, tasks, visited, recursionStack)) {
          throw new Error('Cycle detected in task dependencies');
        }
      }
    }
  }

  private isCyclicUtil(
    taskId: string,
    tasks: TaskDefinition[],
    visited: Set<string>,
    recursionStack: Set<string>
  ): boolean {
    visited.add(taskId);
    recursionStack.add(taskId);
    
    const task = tasks.find(t => t.id === taskId);
    
    if (task && task.dependsOn) {
      for (const depTaskId of task.dependsOn) {
        if (!visited.has(depTaskId)) {
          if (this.isCyclicUtil(depTaskId, tasks, visited, recursionStack)) {
            return true;
          }
        } else if (recursionStack.has(depTaskId)) {
          return true;
        }
      }
    }
    
    recursionStack.delete(taskId);
    return false;
  }
}
import { EventEmitter } from 'events';
import { v4 as uuidv4 } from 'uuid';
import { RetryStrategy, WorkflowTask, TaskStatus, WorkflowDefinition, 
         WorkflowInstance, TaskDefinition, WorkflowEvent, 
         ConditionalExpression, TaskResult } from '../models/workflow.types';
import { NotificationService } from '../services/notification.service';
import { ExternalApiService } from '../services/external-api.service';
import { Logger } from '../utils/logger';

/**
 * Workflow Engine for configurable document processing pipelines
 * Provides event-driven task execution with conditional paths and retry mechanisms
 */
export class WorkflowEngine {
  private workflowDefinitions: Map<string, WorkflowDefinition>;
  private workflowInstances: Map<string, WorkflowInstance>;
  private eventEmitter: EventEmitter;
  private notificationService: NotificationService;
  private externalApiService: ExternalApiService;
  private logger: Logger;

  constructor(
    notificationService: NotificationService,
    externalApiService: ExternalApiService,
    logger: Logger
  ) {
    this.workflowDefinitions = new Map();
    this.workflowInstances = new Map();
    this.eventEmitter = new EventEmitter();
    this.notificationService = notificationService;
    this.externalApiService = externalApiService;
    this.logger = logger;
    
    // Set up event listeners
    this.setupEventListeners();
  }

  /**
   * Register a new workflow definition
   */
  registerWorkflow(definition: WorkflowDefinition): string {
    const workflowId = definition.id || uuidv4();
    
    // Validate workflow definition
    this.validateWorkflowDefinition(definition);
    
    // Store with validated ID
    const validatedDefinition = { 
      ...definition, 
      id: workflowId 
    };
    
    this.workflowDefinitions.set(workflowId, validatedDefinition);
    this.logger.info(`Workflow definition registered: ${workflowId}`);
    
    return workflowId;
  }

  /**
   * Start a workflow instance based on a registered definition
   */
  async startWorkflow(
    definitionId: string, 
    initialData: Record<string, any> = {}
  ): Promise<string> {
    const definition = this.workflowDefinitions.get(definitionId);
    
    if (!definition) {
      throw new Error(`Workflow definition not found: ${definitionId}`);
    }
    
    const instanceId = uuidv4();
    
    // Create workflow instance
    const instance: WorkflowInstance = {
      id: instanceId,
      definitionId,
      status: 'running',
      currentTasks: [],
      completedTasks: [],
      failedTasks: [],
      data: { ...initialData },
      startTime: new Date(),
      endTime: null,
      auditLog: [{
        timestamp: new Date(),
        event: 'workflow_started',
        details: { definitionId }
      }]
    };
    
    this.workflowInstances.set(instanceId, instance);
    
    // Find starting tasks (those with no dependencies)
    const startingTasks = definition.tasks.filter(task => 
      !task.dependsOn || task.dependsOn.length === 0
    );
    
    // Queue starting tasks for execution
    for (const taskDef of startingTasks) {
      await this.queueTask(instanceId, taskDef.id);
    }
    
    this.logger.info(`Workflow instance started: ${instanceId} (definition: ${definitionId})`);
    
    return instanceId;
  }

  /**
   * Pause a running workflow instance
   */
  pauseWorkflowInstance(instanceId: string): void {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    if (instance.status !== 'running') {
      throw new Error(`Cannot pause workflow in status: ${instance.status}`);
    }
    
    // Update status
    instance.status = 'paused';
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'workflow_paused',
      details: {}
    });
    
    this.logger.info(`Workflow instance paused: ${instanceId}`);
  }

  /**
   * Resume a paused workflow instance
   */
  async resumeWorkflowInstance(instanceId: string): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    if (instance.status !== 'paused') {
      throw new Error(`Cannot resume workflow in status: ${instance.status}`);
    }
    
    // Update status
    instance.status = 'running';
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'workflow_resumed',
      details: {}
    });
    
    // Re-queue current tasks
    for (const task of instance.currentTasks) {
      if (task.status === 'paused') {
        task.status = 'queued';
        await this.executeTask(instanceId, task.id);
      }
    }
    
    this.logger.info(`Workflow instance resumed: ${instanceId}`);
  }

  /**
   * Cancel a workflow instance
   */
  cancelWorkflowInstance(instanceId: string): void {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    if (instance.status === 'completed' || instance.status === 'failed' || instance.status === 'cancelled') {
      throw new Error(`Cannot cancel workflow in status: ${instance.status}`);
    }
    
    // Update status
    instance.status = 'cancelled';
    instance.endTime = new Date();
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'workflow_cancelled',
      details: {}
    });
    
    // Cancel all current tasks
    for (const task of instance.currentTasks) {
      if (task.status !== 'completed' && task.status !== 'failed') {
        task.status = 'cancelled';
        this.emitTaskEvent(instanceId, task.id, 'task_cancelled');
      }
    }
    
    this.logger.info(`Workflow instance cancelled: ${instanceId}`);
  }

  /**
   * Get workflow instance status and data
   */
  getWorkflowInstance(instanceId: string): WorkflowInstance | undefined {
    return this.workflowInstances.get(instanceId);
  }

  /**
   * Queue a task for execution
   */
  private async queueTask(instanceId: string, taskId: string): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    const definition = this.workflowDefinitions.get(instance.definitionId);
    
    if (!definition) {
      throw new Error(`Workflow definition not found: ${instance.definitionId}`);
    }
    
    const taskDef = definition.tasks.find(t => t.id === taskId);
    
    if (!taskDef) {
      throw new Error(`Task definition not found: ${taskId}`);
    }
    
    // Check if the task is already in the current tasks list
    const existingTask = instance.currentTasks.find(t => t.id === taskId);
    
    if (existingTask) {
      // Task is already queued or running
      return;
    }
    
    // If task has conditions, evaluate them
    if (taskDef.conditions && !this.evaluateConditions(taskDef.conditions, instance.data)) {
      // Conditions not met, skip this task
      this.logger.info(`Task conditions not met, skipping: ${taskId} in workflow ${instanceId}`);
      
      // Find and queue next tasks
      await this.queueNextTasks(instanceId, taskId);
      return;
    }
    
    // Create task instance
    const task: WorkflowTask = {
      id: taskId,
      status: 'queued',
      attempts: 0,
      startTime: null,
      endTime: null,
      error: null,
      result: null
    };
    
    // Add to current tasks
    instance.currentTasks.push(task);
    
    // Log task queued
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'task_queued',
      details: { taskId }
    });
    
    // Execute task if workflow is running
    if (instance.status === 'running') {
      await this.executeTask(instanceId, taskId);
    }
  }

  /**
   * Execute a queued task
   */
  private async executeTask(instanceId: string, taskId: string): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      throw new Error(`Workflow instance not found: ${instanceId}`);
    }
    
    if (instance.status !== 'running') {
      // Workflow is not running, don't execute task
      return;
    }
    
    const taskIndex = instance.currentTasks.findIndex(t => t.id === taskId);
    
    if (taskIndex === -1) {
      throw new Error(`Task not found in current tasks: ${taskId}`);
    }
    
    const task = instance.currentTasks[taskIndex];
    
    if (task.status !== 'queued') {
      // Task is not queued, don't execute
      return;
    }
    
    const definition = this.workflowDefinitions.get(instance.definitionId);
    
    if (!definition) {
      throw new Error(`Workflow definition not found: ${instance.definitionId}`);
    }
    
    const taskDef = definition.tasks.find(t => t.id === taskId);
    
    if (!taskDef) {
      throw new Error(`Task definition not found: ${taskId}`);
    }
    
    // Update task status
    task.status = 'running';
    task.startTime = new Date();
    task.attempts++;
    
    // Log task started
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'task_started',
      details: { taskId, attempt: task.attempts }
    });
    
    this.emitTaskEvent(instanceId, taskId, 'task_started');
    
    try {
      // Execute task
      let result: any;
      
      switch (taskDef.type) {
        case 'document_processing':
          result = await this.executeDocumentProcessingTask(taskDef, instance.data);
          break;
        case 'notification':
          result = await this.executeNotificationTask(taskDef, instance.data);
          break;
        case 'external_api':
          result = await this.executeExternalApiTask(taskDef, instance.data);
          break;
        case 'data_transformation':
          result = await this.executeDataTransformationTask(taskDef, instance.data);
          break;
        default:
          throw new Error(`Unsupported task type: ${taskDef.type}`);
      }
      
      // Update task status
      task.status = 'completed';
      task.endTime = new Date();
      task.result = result;
      
      // Update workflow data
      if (taskDef.outputDataMapping) {
        this.applyOutputDataMapping(taskDef.outputDataMapping, result, instance.data);
      }
      
      // Log task completed
      instance.auditLog.push({
        timestamp: new Date(),
        event: 'task_completed',
        details: { taskId }
      });
      
      this.emitTaskEvent(instanceId, taskId, 'task_completed');
      
      // Move task to completed tasks
      instance.currentTasks.splice(taskIndex, 1);
      instance.completedTasks.push(task);
      
      // Queue next tasks
      await this.queueNextTasks(instanceId, taskId);
      
      // Check if workflow is completed
      this.checkWorkflowCompletion(instanceId);
    } catch (error) {
      // Handle task failure
      await this.handleTaskFailure(instanceId, taskIndex, task, taskDef, error);
    }
  }

  /**
   * Handle task execution failure with retry mechanism
   */
  private async handleTaskFailure(
    instanceId: string,
    taskIndex: number,
    task: WorkflowTask,
    taskDef: TaskDefinition,
    error: any
  ): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      return;
    }
    
    // Update task with error
    task.error = {
      message: error.message || 'Unknown error',
      stack: error.stack,
      timestamp: new Date()
    };
    
    // Log task error
    instance.auditLog.push({
      timestamp: new Date(),
      event: 'task_error',
      details: { 
        taskId: task.id, 
        attempt: task.attempts, 
        error: task.error.message 
      }
    });
    
    this.emitTaskEvent(instanceId, task.id, 'task_error');
    
    // Check if retry is possible
    const retryStrategy = taskDef.retryStrategy || { maxAttempts: 1, delay: 0 };
    
    if (task.attempts < retryStrategy.maxAttempts) {
      // Set status to retry
      task.status = 'retry';
      
      // Log retry scheduled
      instance.auditLog.push({
        timestamp: new Date(),
        event: 'task_retry_scheduled',
        details: { 
          taskId: task.id, 
          attempt: task.attempts, 
          nextAttempt: task.attempts + 1, 
          delay: retryStrategy.delay 
        }
      });
      
      // Schedule retry
      setTimeout(async () => {
        if (instance.status === 'running') {
          task.status = 'queued';
          await this.executeTask(instanceId, task.id);
        }
      }, retryStrategy.delay);
    } else {
      // Max retries reached, mark as failed
      task.status = 'failed';
      task.endTime = new Date();
      
      // Log task failed
      instance.auditLog.push({
        timestamp: new Date(),
        event: 'task_failed',
        details: { 
          taskId: task.id, 
          attempts: task.attempts 
        }
      });
      
      this.emitTaskEvent(instanceId, task.id, 'task_failed');
      
      // Move to failed tasks
      instance.currentTasks.splice(taskIndex, 1);
      instance.failedTasks.push(task);
      
      // Handle error based on task configuration
      if (taskDef.errorHandling === 'continue') {
        // Continue workflow despite failure
        await this.queueNextTasks(instanceId, task.id);
        this.checkWorkflowCompletion(instanceId);
      } else {
        // Fail the workflow
        instance.status = 'failed';
        instance.endTime = new Date();
        
        // Log workflow failed
        instance.auditLog.push({
          timestamp: new Date(),
          event: 'workflow_failed',
          details: { 
            reason: `Task failed: ${task.id}`,
            error: task.error?.message 
          }
        });
      }
    }
  }

  /**
   * Queue next tasks that depend on the completed task
   */
  private async queueNextTasks(instanceId: string, completedTaskId: string): Promise<void> {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      return;
    }
    
    const definition = this.workflowDefinitions.get(instance.definitionId);
    
    if (!definition) {
      return;
    }
    
    // Find tasks that depend on the completed task
    const nextTasks = definition.tasks.filter(task => 
      task.dependsOn && task.dependsOn.includes(completedTaskId)
    );
    
    for (const nextTask of nextTasks) {
      // Check if all dependencies are completed
      const allDependenciesMet = nextTask.dependsOn?.every(depTaskId => {
        // Check if dependency is in completed tasks
        return instance.completedTasks.some(t => t.id === depTaskId);
      }) ?? true;
      
      if (allDependenciesMet) {
        // Queue the task
        await this.queueTask(instanceId, nextTask.id);
      }
    }
  }

  /**
   * Check if workflow is completed (no more tasks to execute)
   */
  private checkWorkflowCompletion(instanceId: string): void {
    const instance = this.workflowInstances.get(instanceId);
    
    if (!instance) {
      return;
    }
    
    if (instance.status !== 'running') {
      // Workflow is not running, nothing to check
      return;
    }
    
    if (instance.currentTasks.length === 0) {
      // No more tasks, workflow is completed
      instance.status = 'completed';
      instance.endTime = new Date();
      
      // Log workflow completed
      instance.auditLog.push({
        timestamp: new Date(),
        event: 'workflow_completed',
        details: {
          totalTasks: instance.complet
